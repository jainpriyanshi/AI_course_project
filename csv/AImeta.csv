Id,Text,Topic,processed_Text
1,"<p>Besides being ""one of the 7 meta questions every site should ask"", it's just plain important. An ""AI Stackexchange"" site has been tried before, at least once, and possibly a few times.   And in the past, it's been killed for lack of activity.  :-(</p>

<p>So... how so we promote this site well enough to attract a critical mass of participants? And how do we get people participating?  </p>
",AImeta,besides one 7 meta questions every site ask plain important ai stackexchange site tried least possibly times past killed lack activity promote site well enough attract critical mass participants get people participating
1,"<p>I've clicked on <em>chat</em> link, but the list is empty. Also I've tried to create one, but I couldn't, as it's saying:</p>

<blockquote>
  <p>This room might already exist.</p>
</blockquote>

<p>But it's not there yet.</p>
",AImeta,clicked chat link list empty also tried create one could saying room might already exist yet
1,"<p>I think this will be a crucial thing to figure out.  On the one hand, I think it's important to be as inclusive as possible, and avoid being overly pedantic and stay away from the extreme degree of elitism that infects many stackexchange sites.  BUT.. on the other hand, we want the site to be of interest to everyone from hobbyists to serious academic researchers.   </p>

<p>The one thing I think we need to be leery of, is having the site become overly oriented towards trans-humanism, Singularity, etc.  I think those things are on-topic, but I suspect it would be easy to drift into a place where we're more fringe-science / sci-fi than serious AI research.   Exactly how to strike that balance, I'm afraid I don't really know.  </p>
",AImeta,think crucial thing figure one hand think important inclusive possible avoid overly pedantic stay away extreme degree elitism infects many stackexchange sites hand want site interest everyone hobbyists serious academic researchers one thing think need leery site become overly oriented towards trans humanism singularity etc think things topic suspect would easy drift place fringe science sci fi serious ai research exactly strike balance afraid really know
1,"<p>Are all questions asked on stats and data science SE also on topic here? Or is there some rule such as (on-topic in stats or data science SE implies off-topic here)?</p>

<p>Data science and the stats SE already have a huge overlap (>~80%), I am worried to have a third SE that also significantly overlaps with them.</p>

<hr>

<p>As a side note, many other SE have an AI tags, e.g.:</p>

<ul>
<li><a href=""https://philosophy.stackexchange.com/questions/tagged/artificial-intelligence"">https://philosophy.stackexchange.com/questions/tagged/artificial-intelligence</a></li>
<li><a href=""https://worldbuilding.stackexchange.com/questions/tagged/artificial-intelligence"">https://worldbuilding.stackexchange.com/questions/tagged/artificial-intelligence</a> (for the most sci-fi questions)</li>
<li><a href=""https://cstheory.stackexchange.com/questions/tagged/ai.artificial-intel"">https://cstheory.stackexchange.com/questions/tagged/ai.artificial-intel</a></li>
<li><a href=""https://cs.stackexchange.com/questions/tagged/artificial-intelligence"">https://cs.stackexchange.com/questions/tagged/artificial-intelligence</a></li>
<li><a href=""https://cogsci.stackexchange.com/questions/tagged/artificial-intelligence"">https://cogsci.stackexchange.com/questions/tagged/artificial-intelligence</a></li>
<li><a href=""https://hsm.stackexchange.com/questions/tagged/artificial-intelligence"">https://hsm.stackexchange.com/questions/tagged/artificial-intelligence</a></li>
<li><a href=""https://stackoverflow.com/questions/tagged/artificial-intelligence"">https://stackoverflow.com/questions/tagged/artificial-intelligence</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/tagged/ai"">https://gamedev.stackexchange.com/questions/tagged/ai</a></li>
</ul>
",AImeta,questions asked stats data science se also topic rule topic stats data science se implies topic data science stats se already huge overlap 80 worried third se also significantly overlaps side note many se ai tags eg sci fi questions
1,"<p>I've seen several questions that use the <a href=""https://ai.stackexchange.com/questions/tagged/artificial-intelligence"" class=""post-tag"" title=""show questions tagged &#39;artificial-intelligence&#39;"" rel=""tag"">artificial-intelligence</a> tag, sometimes as the only tag on the question. That is not useful for categorizing questions, so please don't add this to your question. </p>

<p>For this reason, the site name is usually blacklisted as tag name. </p>

<ul>
<li>So the <a href=""https://ai.stackexchange.com/questions/tagged/bug"" class=""post-tag"" title=""show questions tagged &#39;bug&#39;"" rel=""tag"">bug</a> is: Why isn't <a href=""https://ai.stackexchange.com/questions/tagged/artificial-intelligence"" class=""post-tag"" title=""show questions tagged &#39;artificial-intelligence&#39;"" rel=""tag"">artificial-intelligence</a> blacklisted?</li>
<li>The <a href=""https://ai.stackexchange.com/questions/tagged/feature-request"" class=""post-tag"" title=""show questions tagged &#39;feature-request&#39;"" rel=""tag"">feature-request</a> is: Please blacklist <a href=""https://ai.stackexchange.com/questions/tagged/artificial-intelligence"" class=""post-tag"" title=""show questions tagged &#39;artificial-intelligence&#39;"" rel=""tag"">artificial-intelligence</a>.</li>
</ul>
",AImeta,seen several questions use tag sometimes tag question useful categorizing questions please add question reason site name usually blacklisted tag name blacklisted please blacklist
1,"<p>I think the answer is ""yes"".  To the user asking a question, closing it feels like a very hostile action and makes the site seem unfriendly and not welcoming.  My feeling is that marginal questions should <em>not</em> be closed explicitly, but should simply remain open but voted to an appropriate score (including negative, even very negative).  </p>

<p>The questions I'd close are the ones that are just gratuitously bad, in terms of being <strong>completely</strong> off-topic (eg, ""how do I rebuild a Holley carburetor?""), or that having attacking / discriminatory language, obvious trolling (slashdot level stuff... GNAA references, etc.), and the like.  </p>

<p>IOW, I'd rely on up/down votes for almost all moderation and save the ""close hammer"" for extreme situations. </p>

<p>Thoughts? </p>
",AImeta,think answer yes user asking question closing feels like hostile action makes site seem unfriendly welcoming feeling marginal questions closed explicitly simply remain open voted appropriate score including negative even negative questions would close ones gratuitously bad terms completely topic eg rebuild holley carburetor attacking discriminatory language obvious trolling slashdot level stuff gnaa references etc like iow would rely votes almost moderation save close hammer extreme situations thoughts
1,"<p>No, data science and the implementation of artificial intelligence are off-topic. <a href=""https://area51.meta.stackexchange.com/a/24016/136466"">A community manager explicitly said so in the Area 51 discussions for this site.</a> There have been at least two AI sites on SE before, and they've all failed. We need to bring something new to the table, especially in the private beta stage. Once that's over, we can consider whether we can bring a new viewpoint to such questions.</p>
",AImeta,data science implementation artificial intelligence topic least two ai sites se failed need bring something new table especially private beta stage consider whether bring new viewpoint questions
1,"<p>Definitely not. In some minutes we can see lots of questions asking for specific technical solutions about neural networks and genetic algorithms. I agree with Ben that we need to make this site different and start migrating all these questions to other sites, where there <em>is already</em> an answer to most of them.</p>

<p>Why would we want to ask them again?
(apart from rush for reputation)</p>
",AImeta,definitely minutes see lots questions asking specific technical solutions neural networks genetic algorithms agree ben need make site different start migrating questions sites already answer would want ask againapart rush reputation
1,"<p>As you might know sites remain in private beta for three weeks:  </p>

<p><a href=""https://hardwarerecs.meta.stackexchange.com/a/75/237"">We've extended the private betas to last about three weeks total.</a>  </p>

<p><a href=""https://meta.stackexchange.com/a/266555/226369"">Usually new communities are concerned that we didn't give them enough time.</a>  </p>

<p>And I think in this three weeks, the core users should try their best to enrich the site's content.<br>
I think we should ask questions that are easily google-enabled and a usual concern for most of artificial intelligence researchers that are even asked before in other forums (local forums maybe). This way, after the end of private beta if someone googles that question and sees that are site has better answered the question, they'll rely on our site and it is more probable to become a member of the site and ask their future questions in the site.<br>
Any way are questions should not be opinion-based, subjective, etc.<br>
In fact I'm not an expert or research-level student. I'm a remote sensing student with some experience in photogrammetry and programming with OpenGL API on C++. 
So I cannot add good questions myself but I'm really curious about everything related to accelerating the code and real-time programming.<br>
Anyway since I'm an Iranian, I wanted to know if it's OK to translate good and popular questions in Iranian artificial intelligence forum which have the features of a good question that have introduced before or discussed about?  </p>

<p><a href=""http://blog.stackoverflow.com/2010/07/area-51-asking-the-first-questions/"">Your New Site: Asking the First Questions</a><br>
<a href=""http://blog.stackoverflow.com/2010/09/good-subjective-bad-subjective/"">Good Subjective, Bad Subjective</a><br>
<a href=""http://blog.stackoverflow.com/2011/01/real-questions-have-answers/"">Real Questions Have Answers</a><br>
<a href=""http://blog.stackoverflow.com/2011/02/are-some-questions-too-simple/"">Are Some Questions Too Simple?</a>  </p>

<p>in order to enrich the content?<br>
I think this way any Iranian who tries to google that question in English and then enters this site will see that the quality of answers is better here (because in these 3 weeks experts should try their best to add comprehensive answers) will be a fan of <a href=""http://ai.stackexchange.com"">ai.stackexchange.com</a>.</p>
",AImeta,might know sites remain private beta three weeks think three weeks core users try best enrich site content think ask questions easily google enabled usual concern artificial intelligence researchers even asked forums local forums maybe way end private beta someone googles question sees site better answered question rely site probable become member site ask future questions site way questions opinion based subjective etc fact expert research level student remote sensing student experience photogrammetry programming opengl api c add good questions really curious everything related accelerating code real time programming anyway since iranian wanted know ok translate good popular questions iranian artificial intelligence forum features good question introduced discussed order enrich content think way iranian tries google question english enters site see quality answers better 3 weeks experts try best add comprehensive answers fan
1,"<p>I created a new <a href=""http://chat.stackexchange.com/rooms/43371/artificial-intelligence"">chat room for this site</a>.</p>

<p>Seems like the one from the previous AI site prevented creating a chat room.</p>
",AImeta,created new seems like one previous ai site prevented creating chat room
1,"<p>I'm seeing a lot of answers from people along the lines of ""AI is just bits and bytes and ultimately cannot be smarter than its creator because its creator would have to use their brain to make something smarter than themselves, which isn't possible.""</p>

<p>It's kind of baffling to me to see these answers, especially in regards to the singularity, on a forum dedicated to AI. There is already image recognition that can recognize objects more accurately than humans, IBM's Watson can diagnose lung cancer at a rate much more accurately than human physicians, and Google's Alpha Go beat the Go world champion, even while experts were predicting that AI wouldn't succeed at doing this for another 10 years.</p>

<p>At the same time, I am completely certain that any of the individual programmers of Alpha Go would not have succeeded in defeating the Go champion of the world. I'm also fairly certain that the Watson programmers would not do better than Watson or a human physician at identifying lung cancer. These are already cases of the AI being more intelligent than its programmer, albeit in domain-specific cases.</p>

<p>Therefore, it seems wholly lazy and uncreative for people to provide such answers that AI cannot be more intelligent than a single creator and therefore human-level AI and beyond is not possible. I think it does not contribute to the discussion.</p>
",AImeta,seeing lot answers people along lines ai bits bytes ultimately smarter creator creator would use brain make something smarter possible kind baffling see answers especially regards singularity forum dedicated ai already image recognition recognize objects accurately humans ibm watson diagnose lung cancer rate much accurately human physicians google alpha go beat go world champion even experts predicting ai would succeed another 10 years time completely certain individual programmers alpha go would succeeded defeating go champion world also fairly certain watson programmers would better watson human physician identifying lung cancer already cases ai intelligent programmer albeit domain specific cases therefore seems wholly lazy uncreative people provide answers ai intelligent single creator therefore human level ai beyond possible think contribute discussion
1,"<p>I'm going to say ""yes"".  That doesn't mean we need to <em>solicit</em> those kinds of questions, but if / when they show up, I think we should just handle them ""organically"" if you will.  That is, up/down vote them, answer them, comment on them, etc., exactly as we would anything else.  I don't see any point in us taking on the effort of cross-checking with other sites and migrating questions, etc.   IF the SE infrastructure makes it super easy to do some in some cases, then sure, fine, I guess.  But I oppose having ai.se mods waste their energy and time dealing with pedantic quibbling over which site is ""most"" appropriate for a question.</p>
",AImeta,going say yes mean need solicit kinds questions show think handle organically vote answer comment etc exactly would anything else see point us taking effort cross checking sites migrating questions etc se infrastructure makes super easy cases sure fine guess oppose aise mods waste energy time dealing pedantic quibbling site appropriate question
1,"<p>If an answer is wrong, it should be downvoted, plain and simple. Clearly we want to discourage wrong information, and downvotes are designed to point out incorrect, irrelevant, or otherwise poor content. You seem to have really good examples that show such answers are wrong, so please feel free to mention them in a comment when downvoting!</p>
",AImeta,answer wrong downvoted plain simple clearly want discourage wrong information downvotes designed point incorrect irrelevant otherwise poor content seem really good examples show answers wrong please feel free mention comment downvoting
1,"<p>Experience with many beta sites from the start and through initial pro-tem moderation suggests that yes, for questions that could be on topic, let's give the benefit of the doubt in the early stages to help growth.</p>

<p>For posts that are definitely off topic, close them down as fast as possible, though - and a good way to do this in the Public Beta stage before we hit critical mass is to have frequent use of the chat room and point the CM's or mods at such questions.</p>

<p>Once we have a good number of folks with close privileges, it gets easier and I'd agree that normal voting should carry it from there.</p>

<p>The corollary to this is that we must use our votes. Upvote good posts, and downvote the bad ones - this helps make sure the good ones are seen and their owners rewarded, but also gets us that critical mass of users with the necessary privileges as fast as possible.</p>
",AImeta,experience many beta sites start initial pro tem moderation suggests yes questions could topic let give benefit doubt early stages help growth posts definitely topic close fast possible though good way public beta stage hit critical mass frequent use chat room point cm mods questions good number folks close privileges gets easier would agree normal voting carry corollary must use votes upvote good posts downvote bad ones helps make sure good ones seen owners rewarded also gets us critical mass users necessary privileges fast possible
1,"<p>I was clicking around and wanted to post a question. Started doing research to be able to ask an interesting one that I have in mind, and, well:</p>
<blockquote>
<p>Avoid “easy” questions</p>
<p>It’s tempting to start with easy, superficial questions: surveys, polls, and rudimentary questions like “what are some good books on this topic” or “what are the best blogs on this topic”. Those are not good questions for the private beta – they don’t reflect the actual content that we want this site to contain, and are not representative of it.</p>
</blockquote>
<hr />
<p>I think that there will be a rush to farm reputation on the first hours. Something similar was seen recently on <a href=""https://meta.stackoverflow.com/questions/328703/addressing-documentation-repgateapocalypse"">stackoverflow-docs</a>.</p>
<p>I do not complain about the reputation itself, I was rather hoping that the site deals with topics more related with intelligence, deeper than the technical way to train an ANN or how to program a mobile robot in a specific platform. For that, we already have <a href=""https://stats.stackexchange.com/"">crossvalidated</a>, <a href=""https://datascience.stackexchange.com/"">data science</a>, <a href=""https://electronics.stackexchange.com/"">electronics</a>, <a href=""https://robotics.stackexchange.com/"">robotics</a>, and stackoverflow itself. However, the first bunch of questions <em>will</em> define a path (am I right here?).</p>
<p>I understand that many of us got involved in the stackexchange network because we <em>solve</em> things in a sort of engineering way, but I think the site for AI has much more interesting questions (for instance <em>philosophy of AI</em>). The thing is, those questions cost more time and effort to ask and answer, so I could expect a slower pace than in stackoverflow or english sites.</p>
<p><strong>Which kind of topics are we aiming for?</strong></p>
<hr />
<p>See also this <a href=""https://ai.meta.stackexchange.com/questions/4/are-all-questions-asked-on-stats-and-data-science-se-also-on-topic-here?cb=1"">Related question</a></p>
",AImeta,clicking around wanted post question started research able ask interesting one mind well avoid easy questions tempting start easy superficial questions surveys polls rudimentary questions like good books topic best blogs topic good questions private beta nt reflect actual content want site contain representative think rush farm reputation first hours something similar seen recently complain reputation rather hoping site deals topics related intelligence deeper technical way train ann program mobile robot specific platform already stackoverflow however first bunch questions define path right understand many us got involved stackexchange network solve things sort engineering way think site ai much interesting questions instance philosophy ai thing questions cost time effort ask answer could expect slower pace stackoverflow english sites kind topics aiming see also
1,"<p>As Franck neatly put: First step would be to clearly define the scope of the site.</p>

<p>Next, there are very active Data Science, AI and ML communities on Reddit and other community sites like facebook groups, etc; and they would be an excellent way to get new users.</p>

<p>And as AI is a very hot topic right now, we would be getting traffic and users as long as we keep the scope well pruned and the posts well curated.</p>
",AImeta,franck neatly put first step would clearly define scope site next active data science ai ml communities reddit community sites like facebook groups etc would excellent way get new users ai hot topic right would getting traffic users long keep scope well pruned posts well curated
1,"<p>To answer the title question, easy-to-Google questions are <strong>not OK</strong> for the private beta. Flooding the site with trivial questions and simple answers is a great way to demolish any chance of attracting big-name experts. Artificial intelligence site proposals have already failed a couple times - once explicitly <a href=""https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/"">because of terribad pedestrian questions</a>.</p>

<p>If we want to survive and grow, we have to keep quality high. We can do that by downvoting low-effort questions and closing non-constructive questions (e.g. requests for off-site resources). And of course, we'll need to dig into the literature to see what kinds of good questions we can explore.</p>
",AImeta,answer title question easy google questions ok private beta flooding site trivial questions simple answers great way demolish chance attracting big name experts artificial intelligence site proposals already failed couple times explicitly want survive grow keep quality high downvoting low effort questions closing non constructive questions eg requests site resources course need dig literature see kinds good questions explore
1,"<p>The latter is the canonical way to refer to the field, and its unclear when, if ever, [deep-network] would be preferable. Its a small change, but it'd help avoid very odd sounding questions like <a href=""https://ai.stackexchange.com/q/96/109"">""What is Deep Network?""</a></p>
",AImeta,latter canonical way refer field unclear ever deep network would preferable small change would help avoid odd sounding questions like
1,"<p><strong>Yes</strong></p>

<p>I am sorry to be the one who posts Yes, but as we are in the beta, I want to be straight forward.</p>

<p>In addition to that, AI is also on-topic in the CS site. <a href=""https://area51.meta.stackexchange.com/q/22939/142759"">I was the one who raised this in the definition phase</a>.</p>

<p>So, a lot of topic which this site aims to cover are already covered in the existing sites.</p>
",AImeta,yes sorry one posts yes beta want straight forward addition ai also topic cs site lot topic site aims cover already covered existing sites
1,"<p>Most Stack Exchange sites (including this one) are English-only, and it's not expected that users will be able to use other languages. Therefore, if there are resources that are not available in English, it would be very good to make them accessible to English speakers somewhere, and this site would be a fine place for doing so. </p>

<p>Make sure, of course, that the question is good (i.e. well-researched, not trivially Google-able in English) and constructive (i.e. on-topic). To avoid accusations of cross-language plagiarism, try to paraphrase rather than translating word-for-word. In the same vein, link back to the original site when you draw heavily from it. That's all part of being a good Internet citizen. If you can improve the answer by drawing from additional sources, that's great too!</p>

<p>Relevant SE blog post: <a href=""https://blog.stackoverflow.com/2011/02/are-some-questions-too-simple/"">Are some questions too simple?</a></p>
",AImeta,stack exchange sites including one english expected users able use languages therefore resources available english would good make accessible english speakers somewhere site would fine place make sure course question good ie well researched trivially google able english constructive ie topic avoid accusations cross language plagiarism try paraphrase rather translating word word vein link back original site draw heavily part good internet citizen improve answer drawing additional sources great relevant se blog post
1,"<p>Stack Exchange sites have a mechanism called ""intrinsic tag blacklisting"" that's intended to do exactly this - prevent the tag that simply describes the topic from being used.</p>

<p>However, the way the system works means that it doesn't always work. The system takes the URL slug <em>before</em> <code>.stackexchange.com</code>, and blacklists that as an intrinsic tag. For this site, that means that the <a href=""https://ai.stackexchange.com/questions/tagged/ai"" class=""post-tag"" title=""show questions tagged &#39;ai&#39;"" rel=""tag"">ai</a> tag is blacklisted, but <a href=""https://ai.stackexchange.com/questions/tagged/artificial-intelligence"" class=""post-tag"" title=""show questions tagged &#39;artificial-intelligence&#39;"" rel=""tag"">artificial-intelligence</a> is not. That's the explanation of the bug.</p>
",AImeta,stack exchange sites mechanism called intrinsic tag blacklisting intended exactly prevent tag simply describes topic used however way system works means always work system takes url slug blacklists intrinsic tag site means tag blacklisted explanation bug
1,"<p>During the private beta we have the opportunity to send Emails via stack exchange:<br>
<a href=""https://i.stack.imgur.com/2c4CE.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2c4CE.jpg"" alt=""enter image description here""></a><br>
And because stackexchange is already well-known on the net, it is more probable that our invitation will be read and clicked on. And I don't think there would be any academic mail server which rejects mail sent by the domain stackexchange.com.
As you know <a href=""http://www.scimagojr.com/journalrank.php?category=1702"" rel=""nofollow noreferrer"">there are a lot of artificial intelligence related journals</a>, I want to see if it is useful or allowed to use the emails of some of those young researchers who have published papers in this journals recently and introduce them this new site?<br>
Because my friends or the people that I have met directly will always notice the emails sent by me personally but a stranger may consider it a spam.</p>
",AImeta,private beta opportunity send emails via stack exchange stackexchange already well known net probable invitation read clicked think would academic mail server rejects mail sent domain stackexchangecomas know want see useful allowed use emails young researchers published papers journals recently introduce new site friends people met directly always notice emails sent personally stranger may consider spam
1,"<p>I would say yes. I don't know many people who use the term ""deep network"" like that. You may hear ""deep neural network"", but that's still basically synonymous with ""deep learning"" as far as I can tell.</p>
",AImeta,would say yes know many people use term deep network like may hear deep neural network still basically synonymous deep learning far tell
1,"<p>Certainly, asking real AI researchers to join would be great!</p>

<p>Paper authors include their e-mail addresses in their publications exactly for the purpose of being contacted about their work. I'm sure it would bring most students great happiness to know that their work has been noticed.</p>

<p>Students who aren't terribly busy will probably be willing to read all the e-mails they receive in their academic/professional e-mail inboxes, no matter whether the messages from from an <code>@stackexchange.com</code> address or a personal address. Indeed, composing a personal (non-automated) message mentioning how you enjoyed a paper would be appreciated, even if the person doesn't have the time or inclination to check out our site.</p>
",AImeta,certainly asking real ai researchers join would great paper authors include e mail addresses publications exactly purpose contacted work sure would bring students great happiness know work noticed students terribly busy probably willing read e mails receive academic professional e mail inboxes matter whether messages address personal address indeed composing personal non automated message mentioning enjoyed paper would appreciated even person time inclination check site
1,"<p>SemWeb is a broad topic, obviously, but there are definitely elements of AI involved.  Generally speaking, should we welcome SemWeb questions? </p>
",AImeta,semweb broad topic obviously definitely elements ai involved generally speaking welcome semweb questions
1,"<p>Yes, that sounds like an excellent idea to me.  </p>
",AImeta,yes sounds like excellent idea
1,"<p>I asked a question that was meant to discuss artificial intelligence in general. I tagged it <a href=""https://ai.stackexchange.com/questions/tagged/artificial-intelligence"" class=""post-tag"" title=""show questions tagged &#39;artificial-intelligence&#39;"" rel=""tag"">artificial-intelligence</a>, and someone fairly pointed out that that's redundant. I changed it to <a href=""https://ai.stackexchange.com/questions/tagged/agi"" class=""post-tag"" title=""show questions tagged &#39;agi&#39;"" rel=""tag"">agi</a>, because the question referred specifically to how <a href=""https://ai.stackexchange.com/questions/tagged/optimization"" class=""post-tag"" title=""show questions tagged &#39;optimization&#39;"" rel=""tag"">optimization</a> applies to artificial intelligence, but I'm not sure that was right.</p>

<p>Should the <a href=""https://ai.stackexchange.com/questions/tagged/agi"" class=""post-tag"" title=""show questions tagged &#39;agi&#39;"" rel=""tag"">agi</a> tag refer only to questions that reference Artificial General Intelligence specifically, or can it be used for questions that could be related to AGI in more indirect ways? </p>
",AImeta,asked question meant discuss artificial intelligence general tagged someone fairly pointed redundant changed question referred specifically applies artificial intelligence sure right tag refer questions reference artificial general intelligence specifically used questions could related agi indirect ways
1,"<p>It appears that a community manager has now blacklisted <a href=""https://ai.stackexchange.com/questions/tagged/artificial-intelligence"" class=""post-tag"" title=""show questions tagged &#39;artificial-intelligence&#39;"" rel=""tag"">artificial-intelligence</a>. Questions that only had that tag are now <a href=""https://ai.stackexchange.com/questions/tagged/untagged"" class=""post-tag"" title=""show questions tagged &#39;untagged&#39;"" rel=""tag"">untagged</a>. (The version without the hyphen, <a href=""https://ai.stackexchange.com/questions/tagged/artificialintelligence"" class=""post-tag"" title=""show questions tagged &#39;artificialintelligence&#39;"" rel=""tag"">artificialintelligence</a>, is blocked too.)</p>
",AImeta,appears community manager blacklisted questions tag version without hyphen blocked
1,"<p><a href=""https://ai.stackexchange.com/questions/tagged/artificial-intelligence"" class=""post-tag"" title=""show questions tagged &#39;artificial-intelligence&#39;"" rel=""tag"">artificial-intelligence</a> is what SE calls an <strong>intrinsic</strong> tag, as is <a href=""https://ai.stackexchange.com/questions/tagged/ai"" class=""post-tag"" title=""show questions tagged &#39;ai&#39;"" rel=""tag"">ai</a>.</p>

<p>Intrinsic tags are effectively pointless tags on a site, ie this site is about artificial intelligence, so does not need a tag on artificial intelligence. Likewise, <a href=""https://ai.stackexchange.com/questions/tagged/programming"" class=""post-tag"" title=""show questions tagged &#39;programming&#39;"" rel=""tag"">programming</a> is not needed on Programming.SE</p>

<p><a href=""https://ai.stackexchange.com/questions/tagged/optimization"" class=""post-tag"" title=""show questions tagged &#39;optimization&#39;"" rel=""tag"">optimization</a> is much more relevant, as it is a specific class of questions within the site scope.</p>
",AImeta,se calls intrinsic tag intrinsic tags effectively pointless tags site ie site artificial intelligence need tag artificial intelligence likewise needed programmingse much relevant specific class questions within site scope
1,"<p>Apparently, we cannot flag a question as belonging to other network during beta:</p>

<p><a href=""https://i.stack.imgur.com/Rh6fs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Rh6fs.png"" alt=""enter image description here""></a></p>

<hr>

<p><a href=""https://i.stack.imgur.com/jgiqb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jgiqb.png"" alt=""enter image description here""></a></p>

<p><strong>What is the recommended way to go in these situations?</strong></p>
",AImeta,apparently flag question belonging network beta recommended way go situations
1,"<p>For those unfamiliar, the <a href=""https://en.wikipedia.org/wiki/Semantic_Web"" rel=""nofollow"">Semantic Web</a> is basically an extension to HTML that calls out the content of certain elements as certain kinds of information. For example, the sentence ""John Smith was born in Chicago"" would have the name and birthplace marked up appropriately, with a reference to a schema on the enclosing element.</p>

<p>It doesn't seem like the Semantic Web is itself an AI thing, but if questions about artificial intelligence happen to touch on it, I see no reason to reject them.</p>
",AImeta,unfamiliar basically extension html calls content certain elements certain kinds information example sentence john smith born chicago would name birthplace marked appropriately reference schema enclosing element seem like semantic web ai thing questions artificial intelligence happen touch see reason reject
1,"<p>If a question is off-topic here, just close it with the generic off-topic reason. Our scope isn't set in stone yet, so we want to keep things on our site in case they need to be reopened. If a <strong>question owner</strong> - not just any user passing by - really wants their question migrated, they can raise a custom mod flag and a CM will take care of it. (Though if the question didn't get any answers, it's easier to just delete it here and ask it somewhere else.)</p>

<p>Once the site graduates, we'll get migration paths to other SE sites and we'll become eligible as a migration target from other sites.</p>
",AImeta,question topic close generic topic reason scope set stone yet want keep things site case need reopened question owner user passing really wants question migrated raise custom mod flag cm take care though question get answers easier delete ask somewhere else site graduates get migration paths se sites become eligible migration target sites
1,"<p>From what I've seen so far, most of the questions on the site currently seem to be either about AI in general or about common techniques and algorithms. </p>

<p>What about more specialized topics? Can people ask questions about e.g. the basic principles of computer vision or speech recognition? Both of these are areas of research which use AI techniques to a great degree.</p>
",AImeta,seen far questions site currently seem either ai general common techniques algorithms specialized topics people ask questions eg basic principles computer vision speech recognition areas research use ai techniques great degree
1,"<p>Certainly, assuming the questions are reasonably scoped. ""What are the principles of computer vision?"" would be way too broad and closed as such. More specific questions like ""Can a computer know the difference between someone's face and a printed-out held-up photograph of that face?"" would be interesting.</p>

<p>Do be careful that we don't get bogged down in the implementation, which is the subject of existing sites like Data Science. Programming is also off-topic, in my understanding. We're focused on the academic/somewhat-theoretical aspects of artificial intelligence.</p>
",AImeta,certainly assuming questions reasonably scoped principles computer vision would way broad closed specific questions like computer know difference someone face printed held photograph face would interesting careful get bogged implementation subject existing sites like data science programming also topic understanding focused academic somewhat theoretical aspects artificial intelligence
1,"<p>I was going to answer a question about reinforcement learning and wanted to show some formulas using the same notation I use on CrossValidated, for instance:</p>

<p>$r_{t+1}+\gamma \max_a Q(s_{t+1},a)$</p>

<p>But it is currently not supported, at least the way I tried it. Can we have support for LaTeX formatting here?</p>

<p>Examples:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/157"">What artificial intelligence strategies are useful for summarization?</a></li>
</ul>
",AImeta,going answer question reinforcement learning wanted show formulas using notation use crossvalidated instance r_t1gamma max_a qs_t1a currently supported least way tried support latex formatting examples
1,"<p>While it might be nice to have for some questions, most questions you would need LaTeX for should be off-topic here. This site is not meant for machine learning questions, as Cross Validated and Data Science Stack Exchange sufficiently cover those subjects. </p>

<p>See: <a href=""https://ai.meta.stackexchange.com/questions/4/are-all-questions-asked-on-stats-and-data-science-se-also-on-topic-here?cb=1"">Are all questions asked on stats and data science SE also on topic here?</a></p>

<blockquote>
  <p><strong>Note:</strong> I posted this answer when I didn't know very much about AI, and I have misunderstood or missed some of the parts of AI that should be on-topic here, I am now of the opinion that we should have LaTeX here. I'll leave this answer here because of the votes (and vote balance) on it, but I don't agree myself anymore with it. So please count an extra downvote from me.</p>
</blockquote>
",AImeta,might nice questions questions would need latex topic site meant machine learning questions cross validated data science stack exchange sufficiently cover subjects see note posted answer know much ai misunderstood missed parts ai topic opinion latex leave answer votes vote balance agree anymore please count extra downvote
1,"<p>If <code>deep-learning</code> is preferred, then <code>deep-network</code> should be set up as a <a href=""https://meta.stackexchange.com/a/70718/135236"">tag synonym</a> for it, that way if anyone tries to use it, it gets mapped to the preferred name.  We need someone with 1250 reputation to do that.</p>
",AImeta,preferred set way anyone tries use gets mapped preferred name need someone 1250 reputation
1,"<p>We have a <a href=""//chat.stackexchange.com/rooms/43371/artificial-intelligence"">chatroom</a>. At the moment it doesn't really have a name. Other sites' chatroom names include:</p>

<ul>
<li>Super User's ""Root Access""</li>
<li>PPCG's ""The Nineteenth Byte""</li>
<li>Blender's ""The Renderfarm""</li>
<li>Pets' ""The Litterbox""</li>
<li>Travel's ""You Are Here""</li>
<li>Aviation's ""The Hangar""</li>
</ul>

<p>So, what should we call ours?</p>

<p>While we're at it, what should we name our resident feed bots (Main and Meta)?</p>
",AImeta,moment really name sites chatroom names include super user root access ppcg nineteenth byte blender renderfarm pets litterbox travel aviation hangar call name resident feed bots main meta
1,"<h1>Turing Testing Room</h1>

<p>A play on the term ""Turing test"" (an examination of how well a machine mimics natural conversation with a human): tests taken by human students are usually administered in a testing room.</p>

<p>Questions on the main site are currently posted to the ticker, so we don't see the username, but if that's changed, it could be called <strong><a href=""https://en.wikipedia.org/wiki/Multivac"" rel=""nofollow"">Multivac</a></strong> after the computer from some of Asimov's stories. We could call the meta bot <strong><a href=""https://en.wikipedia.org/wiki/Watson_(computer)"" rel=""nofollow"">Watson</a></strong>.</p>
",AImeta,turing testing room play term turing test examination well machine mimics natural conversation human tests taken human students usually administered testing room questions main site currently posted ticker see username changed could called computer asimov stories could call meta bot
1,"<p>A core goal of the private beta is to generate high-quality content that will attract experts. We are also given the opportunity to invite experts by email to the private beta. My question is simple: exactly what kind of experts are we trying to attract?</p>

<p>According to <a href=""https://ai.meta.stackexchange.com/questions/4/are-all-questions-asked-on-stats-and-data-science-se-also-on-topic-here?cb=1""> this question </a>, data science and the <em>implementation</em> of artificial intelligence are off-topic. The problem is that we don't want to become a duplicate of Stats or Data Science SE. The question links to <a href=""https://area51.meta.stackexchange.com/questions/24014/will-machine-learning-be-considered-as-on-topic/24016#24016"">this answer</a> on Area 51 which says that this site is for questions in the ""academic humanities arena"". This seems to suggest that we want experts in academic humanities.</p>

<p>However, most experts in the field of artificial intelligence <em>are experts of implementation</em>. They are applied mathematicians and computer scientists who are trying to make artificial intelligence a reality. The recent advances in artificial intelligence, like <a href=""https://deepmind.com/alpha-go"" rel=""nofollow noreferrer""> Alpha Go</a>, have been the result of breakthroughs in implementation.</p>

<p>If this site is about humanities-style questions about Artificial Intelligence, then what appeal does it have to the type of people who created Alpha Go, who are primarily computer scientists and mathematicians? I'm not convinced they have special expertise about the ramifications of Artifical Intelligence on human society, politics, law, etc.</p>

<p>Perhaps we need to redefine what this site is about. I think a place to look for inspiration is Math SE and MathOverflow. One is about mathematics at any level, while the other is a site for research level mathematicians. Maybe Artificial Intelligence SE should be to Data Science SE and Stats SE what MathOverflow is to Math SE. That is, it should be a site about tackling research level AI problems with the tools of data science and statistics. </p>

<p>This means that we'll have to seriously elevate the quality of our questions and answers to attract real AI experts. But at least we'll have  experts to attract.</p>
",AImeta,core goal private beta generate high quality content attract experts also given opportunity invite experts email private beta question simple exactly kind experts trying attract according data science implementation artificial intelligence topic problem want become duplicate stats data science se question links area 51 says site questions academic humanities arena seems suggest want experts academic humanities however experts field artificial intelligence experts implementation applied mathematicians computer scientists trying make artificial intelligence reality recent advances artificial intelligence like result breakthroughs implementation site humanities style questions artificial intelligence appeal type people created alpha go primarily computer scientists mathematicians convinced special expertise ramifications artifical intelligence human society politics law etc perhaps need redefine site think place look inspiration math se mathoverflow one mathematics level site research level mathematicians maybe artificial intelligence se data science se stats se mathoverflow math se site tackling research level ai problems tools data science statistics means seriously elevate quality questions answers attract real ai experts least experts attract
1,"<h1>Automata</h1>

<p>Study of abstract machines as well as the computational problems that can be solved using them.</p>
",AImeta,automata study abstract machines well computational problems solved using
1,"<h1>The Thought</h1>

<blockquote>
  <p>Artificial intelligence is based on the assumption that the process of human <strong>thought</strong> can be mechanized.</p>
</blockquote>
",AImeta,thought artificial intelligence based assumption process human thought mechanized
1,"<h2><strong>The Singularity</strong></h2>

<p>I probably don't need to explain that :-)</p>

<p>And for the bots, how about Daneel and Giskard?</p>
",AImeta,singularity probably need explain bots daneel giskard
1,"<h1>Searle's Room</h1>

<p>Bots: Meta &amp; Cognition</p>
",AImeta,searle room bots meta cognition
1,"<p>First up, when I posted <a href=""https://ai.meta.stackexchange.com/a/7/75"">my answer to the question you reference</a>, I was just passing along the information given to us by Robert Cartaino. I'm not wedded to that opinion.</p>

<p>I think all the scientists working on AI would be helpful here even though we're not working on implementation. This is what the original Area 51 Discussion post said (excerpted):</p>

<blockquote>
  <p>Data Science is an <em>applied</em> site for all the programmers/statisticians/mathematicians who are trying to make this stuff <em>work</em>.</p>
</blockquote>

<p>There's some leeway there. Specifically, technical questions seem to be OK, as long as they're not super in depth about the math or programming. There are also ""why"" questions (as opposed to ""how"") that are very interesting and educational. I like <a href=""https://ai.stackexchange.com/q/92/75"">this question</a> a lot. Scientists are welcome.</p>

<p>We don't <em>have</em> to limit ourselves to the philosophy and practical effects of AI, though they're in scope. Philosophers are welcome too.</p>
",AImeta,first posted passing along information given us robert cartaino wedded opinion think scientists working ai would helpful even though working implementation original area 51 discussion post said excerpted data science applied site programmers statisticians mathematicians trying make stuff work leeway specifically technical questions seem ok long super depth math programming also questions opposed interesting educational like lot scientists welcome limit philosophy practical effects ai though scope philosophers welcome
1,"<p>First there is a need to distinguish modeling from implementation. They are not exactly the same, although strongly related. This was a very difficult lesson to learn among mathematicians and early programmers, notably in the 70s (mathematical proofs can demand a lot of non-trivial programming work to make them ""computable"", as in runnable on a computer).</p>

<p>As for Machine Learning (by far the most active AI category), modeling belongs to Data Science SE---perhaps the one thing that most people agree on. Implementation should be out of there, as the issues and focus differ (but again, they are related).</p>

<p>Now, should implementation issues be in AI SE, or StackOverflow? The recurring example is TensorFlow, who's home page states that questions should go to StackOverflow. And we should respect that...</p>

<p>But we should keep in mind that the TensorFlow team will choose SO, because it is the largest community, and because the team has something else to do rather than experimenting with hardly visible communities. Well, size matters. We may think that if AI SE becomes big enough on the implementation side, the TensorFlow team (and other major frameworks) may move actually.</p>

<p>In fact, I think now that implementation questions would benefit from a dedicated site (my view has evolved since the Area 51 definition phase). I have replied and tried to reply to several SO questions related to ML tools, and I think some are out of place compared to other questions. For example, <a href=""https://stackoverflow.com/questions/38321024/why-this-simple-tensorflow-code-is-not-successful-convnetjs-using-tensorflow/38368469#comment64172189_38368469"">some</a> TensorFlow questions are not really programming questions, and not really framework questions. I mean, there is background knowledge on graph construction and execution, as well as background knowledge about statistics and probabilities that are really necessary to make meaningful contributions.</p>

<p>This is not to say that <em>all</em> questions are out of place on SO. <a href=""https://stackoverflow.com/questions/38297581/tensorflow-gpu-utilization-is-almost-always-at-0#comment64124967_38297581"">Some</a> are <em>really</em> framework issues or (Python) programming issues, and they are good there.</p>

<p>Based on this opinion, I think the site should be interested in implementation experts, whether they work on ML or Expert Systems (or both?).</p>

<p>See also some threads on Area 51 like <a href=""https://area51.meta.stackexchange.com/questions/23789/the-example-questions-will-not-attract-experts"">this one</a> and <a href=""https://area51.meta.stackexchange.com/a/23528/69948"">this one</a>.</p>
",AImeta,first need distinguish modeling implementation exactly although strongly related difficult lesson learn among mathematicians early programmers notably 70s mathematical proofs demand lot non trivial programming work make computable runnable computer machine learning far active ai category modeling belongs data science se perhaps one thing people agree implementation issues focus differ related implementation issues ai se stackoverflow recurring example tensorflow home page states questions go stackoverflow respect keep mind tensorflow team choose largest community team something else rather experimenting hardly visible communities well size matters may think ai se becomes big enough implementation side tensorflow team major frameworks may move actually fact think implementation questions would benefit dedicated site view evolved since area 51 definition phase replied tried reply several questions related ml tools think place compared questions example tensorflow questions really programming questions really framework questions mean background knowledge graph construction execution well background knowledge statistics probabilities really necessary make meaningful contributions say questions place really framework issues python programming issues good based opinion think site interested implementation experts whether work ml expert systems see also threads area 51 like
1,"<blockquote>
  <p>I'm seeing a lot of answers from people along the lines of ""AI is just bits and bytes and ultimately cannot be smarter than its creator because its creator would have to use their brain to make something smarter than themselves, which isn't possible.""</p>
</blockquote>

<p>I think this argument is a bit unclear and needs some refinement. It is true that AI can indeed be smarter than the creator at certain tasks (AlphaGo being better at Go than the programmers of AlphaGo, for instance). What I think this argument is really saying is:</p>

<blockquote>
  <p>""AI is just bits and bytes programmed by its creator. The creator would be able to <em>know</em> how the AI works, otherwise he would be unable to create it in the first place. Therefore, the creator can be said to be <em>superior</em> to that of its creation, since the creator can understand its creation.""</p>
</blockquote>

<p>That seems like a more logical premise. Sure, AlphaGo is better at Go than the programmers of AlphaGo, but AlphaGo's programmers actually knows how AlphaGo operates. This type of argument was made in the paper <a href=""http://kryten.mm.rpi.edu/lovelace.pdf"" rel=""nofollow"">Creativity, the Turing Test, and the (better) Lovelace Test</a>, which specifically argues that  AIs cannot be creative since programmers are able to figure out what their creations (AIs) are doing. Another paper <a href=""http://arxiv.org/pdf/1410.6142v3.pdf"" rel=""nofollow"">""The Lovelace 2.0 Test of Artificial Creativity and Intelligence""</a> saw this argument as so self-evidently true that it tried to create a weaker version of the Lovelace Test to identify and measure AI creativity.</p>

<p>The programmers, basically, know how their program works. That doesn't mean the program is less intelligent than the programmers. Just that the programmers can understand why their programs behave the way they do, given enough time and patience.</p>

<p>Either way, I would not support discouraging answers such as these, if only because this view does have support within the AI scholarly community. If you have experts who hold this view, then we should let this view be given exposure.</p>
",AImeta,seeing lot answers people along lines ai bits bytes ultimately smarter creator creator would use brain make something smarter possible think argument bit unclear needs refinement true ai indeed smarter creator certain tasks alphago better go programmers alphago instance think argument really saying ai bits bytes programmed creator creator would able know ai works otherwise would unable create first place therefore creator said superior creation since creator understand creation seems like logical premise sure alphago better go programmers alphago alphago programmers actually knows alphago operates type argument made paper specifically argues ais creative since programmers able figure creations ais another paper saw argument self evidently true tried create weaker version lovelace test identify measure ai creativity programmers basically know program works mean program less intelligent programmers programmers understand programs behave way given enough time patience either way would support discouraging answers view support within ai scholarly community experts hold view let view given exposure
1,"<h1><strong>The nth layer</strong></h1>
<p>This would be about deep learning which is about multiple layers of neurons. So, as DL has been very hot in the domain currently, I think this name would be appropriate.</p>
",AImeta,nth layer would deep learning multiple layers neurons dl hot domain currently think name would appropriate
1,"<h1>Replicants</h1>

<p>As in Blade Runner. And HAL and Computer for the bots.</p>
",AImeta,replicants blade runner hal computer bots
1,"<p><strong>Electric sheep</strong></p>

<p>I think everyone knows this, just in case: <a href=""https://en.wikipedia.org/wiki/Do_Androids_Dream_of_Electric_Sheep%3F"" rel=""nofollow"">wiki link</a></p>
",AImeta,electric sheep think everyone knows case
1,"<h1>The Chinese Room</h1>
<p>A reference to the <a href=""https://en.wikipedia.org/wiki/Chinese_room"" rel=""nofollow noreferrer"">Chinese Room Argument</a>.</p>
<p>We would need to make it clear that we're separate from <a href=""https://chinese.stackexchange.com"">Chinese.SE</a> though...!</p>
<p>One of the bots could be named Searle, who invented the thought experiment.<br />
Then we really have a Searle getting inputs and producing outputs, just as in the thought experiment.</p>
",AImeta,chinese room reference would need make clear separate though one bots could named searle invented thought experiment really searle getting inputs producing outputs thought experiment
1,"<h2>Back Propagation</h2>
<p>A reference to backpropagation neural networks. We could use this name because in our chatroom, ideas will be propagated back and forth.</p>
",AImeta,back propagation reference backpropagation neural networks could use name chatroom ideas propagated back forth
1,"<p>Is it AI or A.I., or both abbreviations are fine? Basically, with the dots or without?</p>
",AImeta,ai ai abbreviations fine basically dots without
1,"<p>There are two tags: <a href=""https://ai.stackexchange.com/questions/tagged/quantum-computers"" class=""post-tag"" title=""show questions tagged &#39;quantum-computers&#39;"" rel=""tag"">quantum-computers</a> and <a href=""https://ai.stackexchange.com/questions/tagged/quantum-computing"" class=""post-tag"" title=""show questions tagged &#39;quantum-computing&#39;"" rel=""tag"">quantum-computing</a>. Some question were moved from computing to computers.</p>

<p>Which tag should be the main one?</p>

<p>I think 'quantum computers' sounds more like hardware questions, and 'quantum computing' is a verb which is about using quantum computers for computation.</p>

<p>Which tag should be used then for asking AI questions? Or make another the synonym of it?</p>
",AImeta,two tags question moved computing computers tag main one think quantum computers sounds like hardware questions quantum computing verb using quantum computers computation tag used asking ai questions make another synonym
1,"<p>AI is a bloated term---we are facing this since day 1 of the definition stage. There are already quite a few questions going beyond the original (blurry) boundary of the proposal, notably on implementation issues.</p>

<p>But the worst problem seems to be the lack of objectivity in answers, and sometimes in questions too.</p>

<p>I will single out this <a href=""https://ai.stackexchange.com/questions/111/how-would-self-driving-cars-make-ethical-decisions-about-who-to-kill"">question</a> at time of reading, but there are already several like this one.</p>

<p>We must avoid too many threads that lack objectivity. I intend to vote down answers that are too subjective (but, well, I cannot down vote infinitely, as you know), and comment as necessary. Scalability issue, even in this private beta.</p>

<p>What would be the best way to proceed?</p>
",AImeta,ai bloated term facing since day 1 definition stage already quite questions going beyond original blurry boundary proposal notably implementation issues worst problem seems lack objectivity answers sometimes questions single time reading already several like one must avoid many threads lack objectivity intend vote answers subjective well vote infinitely know comment necessary scalability issue even private beta would best way proceed
1,"<p>In British English it has to be ""AI"". 
In American English it can be both ""AI"" and ""A.I."".</p>

<p>Sources:</p>

<ul>
<li><a href=""http://www.oxforddictionaries.com/us/words/punctuation-in-abbreviations-american"" rel=""nofollow"">http://www.oxforddictionaries.com/us/words/punctuation-in-abbreviations-american</a></li>
<li>Oxford A–Z of Grammar and Punctuation by John Seely.</li>
<li><a href=""https://en.wikipedia.org/wiki/Full_stop#Abbreviations_and_personal_titles_of_address"" rel=""nofollow"">https://en.wikipedia.org/wiki/Full_stop#Abbreviations_and_personal_titles_of_address</a></li>
</ul>
",AImeta,british english ai american english ai ai sources oxford z grammar punctuation john seely
1,"<p>AGI stands for Artificial General Intelligence, which is an AI that's powerful enough to be applied in general. A human would be an AGI, so to say - the human is generally applicable. So when your question is about such an AI - one that is not made for one specific task, but instead for things in general - where you'd need an AI that can think and learn as it goes - to deal with moving goalposts - that's the sort of question you'd use <a href=""https://ai.stackexchange.com/questions/tagged/agi"" class=""post-tag"" title=""show questions tagged &#39;agi&#39;"" rel=""tag"">agi</a> for.</p>
",AImeta,agi stands artificial general intelligence ai powerful enough applied general human would agi say human generally applicable question ai one made one specific task instead things general would need ai think learn goes deal moving goalposts sort question would use
1,"<p>I'd (personally) go for <strong>computing</strong> because it is about doing things with computers rather than the computers themselves, as you state in the question yourself.</p>
",AImeta,would personally go computing things computers rather computers state question
1,"<p>Today, I was looking at the oldest questions asked in other sites. Take <strong>Geographic Information Systems</strong> as an example:<br>
<a href=""http://stackexchange.com/sites#technology-oldest"">The site's age is 6y1m</a> and and as it is seen in <a href=""http://area51.stackexchange.com/proposals/1425"">the area51 page of the site</a>:  </p>

<ul>
<li><a href=""http://area51.stackexchange.com/posts/1425/revisions"">The definition phase has started on June 1th 2010.</a></li>
<li><a href=""http://area51.stackexchange.com/proposals/1425?page=54&amp;phase=commitment&amp;committers=mostrecent#tab-top"">The Commitment phase has started on June 14th 2010.</a></li>
<li><a href=""http://area51.stackexchange.com/proposals/1425?page=1&amp;phase=commitment&amp;committers=mostrecent#tab-top"">The private beta phase has started on July 22th 2010.</a>  </li>
</ul>

<p>And because that time the private betas last for only one week, probably the public beta started on July 29th 2010.<br>
If you take a look to the oldest questions, you'll see that some of them have been asked even before July 22th 2010. <a href=""https://gis.stackexchange.com/q/15541/19874"">like this one which has been asked on August 9th 2009 and has been migrated from stackoverflow.com to GIS.SE.</a><br>
Also if you cast a glance to <a href=""https://gis.stackexchange.com/questions?page=1431&amp;sort=newest"">questions asked before July 29th 2011</a>, you'll see that some of them has been migrated from another sites like superuser.com, etc.<br>
I wanna see if you're going to migrate some questions from other sites to here in private beta?<br>
Or it should be done after getting assured that private beta has ended successfully?<br>
And how will the migration take place?</p>
",AImeta,today looking oldest questions asked sites take geographic information systems example seen time private betas last one week probably public beta started july 29th 2010 take look oldest questions see asked even july 22th 2010 also cast glance see migrated another sites like superusercom etc wanna see going migrate questions sites private beta done getting assured private beta ended successfully migration take place
1,"<p>The question you link is a perfectly valid question in the philosophy of artificial intelligence. Philosophy is the other large part of AI, together with technology, so they should be on-topic here.</p>

<p>However, one should be careful when answering these questions, that one does not base the answer on own opinions. One should reference what philosophers have said in the past, like one of the answers on the question you link mentions the Trolley problem.</p>
",AImeta,question link perfectly valid question philosophy artificial intelligence philosophy large part ai together technology topic however one careful answering questions one base answer opinions one reference philosophers said past like one answers question link mentions trolley problem
1,"<p>Migration to and from this site, in private beta, is most likely not going to be done. You'd have to invite people to the community in order for them to see the question - and when it comes to migrating from this site, it's easier to just close and re-ask (provided there are no answers yet).</p>

<p>After private beta... well, I suppose you could post a comment on such an Stack Overflow question that their question might be better off at ai.stackexchange. But those would have to be some good questions, and they'd have to be served here better than at Stack Overflow.</p>

<p>As for the example question, I think such a migration wouldn't be helping all that much - it's already answered, and as you can see, after migration, not much else happened to the question. It seems it was moved because both the asker and the answerer have an established presence on the other site, and because it fits better there. </p>

<p>Migration is not something to do quickly.</p>
",AImeta,migration site private beta likely going done would invite people community order see question comes migrating site easier close ask provided answers yet private beta well suppose could post comment stack overflow question question might better aistackexchange would good questions would served better stack overflow example question think migration would helping much already answered see migration much else happened question seems moved asker answerer established presence site fits better migration something quickly
1,"<p><sup>Note: This post is (nearly) identical to <a href=""https://languagelearning.meta.stackexchange.com/questions/6/vote-early-vote-often"">this one on Language Learning.SE</a>.</sup></p>
<p>I would like to echo a post that <a href=""https://tex.meta.stackexchange.com/questions/12/vote-early-and-often"">Scott Morrison made on Meta.Tex.SE</a>:</p>
<blockquote>
<p>I'm a moderator from MathOverflow, and this &quot;question&quot; is actually unsolicited advice, based on our experience from the initial launch of MathOverflow.</p>
<blockquote>
<p>We should encourage everyone to vote positively as often as possible!</p>
</blockquote>
<p>Every Stack Exchange site will eventually end up with a different &quot;base level&quot; of voting --- that is, the expected number of upvotes for a question of a given level of excellence. (This effect occurs because people see a good question, but already with a certain number of votes, and think &quot;oh, I would have upvoted this, but it already has enough&quot;.)</p>
<p>It's easy for us to affect this &quot;base level&quot; by encouraging high levels of upvoting now. We're setting the standards, and this really will have an effect.</p>
<p>(On MathOverflow, we were very active about this early on, specifically encouraging all the initial round of users to vote early and often. You can compare statistics, and see that the average vote total for a MathOverflow question is much higher than on any of the other SE 1.0 sites.)</p>
<p>In case it's not obvious: the rationale for wanting this base level to be high is that it provides better positive feedback to good contributors.&quot;</p>
</blockquote>
<p>Especially in the beginning, let us vote early, and vote often. More voting always helps. Downvotes, too, are good – we want to weed out the wheat from the chaff here, and get rid of poor questions and answers.</p>
",AImeta,note post nearly identical would like echo post moderator mathoverflow actually unsolicited advice based experience initial launch mathoverflow encourage everyone vote positively often possible every stack exchange site eventually end different easy us affect encouraging high levels upvoting setting standards really effect mathoverflow active early specifically encouraging initial round users vote early often compare statistics see average vote total mathoverflow question much higher se 10 sites case obvious rationale wanting base level high provides better positive feedback good contributors especially beginning let us vote early vote often voting always helps downvotes good want weed wheat chaff get rid poor questions answers
1,"<p>No, that wouldn't happen. A site only becomes eligible as a migration target from other sites' close dialogs after it loses the ""beta"" label entirely. Also, questions older than 60 days <a href=""https://meta.stackexchange.com/a/156255/295684"">cannot be migrated</a>, even by moderators! The migration you mentioned took place before that rule was instated.</p>

<p>Besides, a question being on-topic at the target site is not a sufficient reason to migrate it. It would have to be explicitly off-topic on the source too. (There's an exception for question owners who want their unanswered question moved: they can flag their post with a custom reason requesting migration.)</p>
",AImeta,would happen site becomes eligible migration target sites close dialogs loses beta label entirely also questions older 60 days even moderators migration mentioned took place rule instated besides question topic target site sufficient reason migrate would explicitly topic source exception question owners want unanswered question moved flag post custom reason requesting migration
1,"<p>Once we figure out what we're about exactly, we need to haul in some real experts.</p>

<p>This is a good idea right here: <a href=""https://ai.meta.stackexchange.com/q/22/75"">Can we send messages to young researchers who have recently published papers in artificial intelligence related journals during the private beta?</a> Scholarly papers generally include their authors' e-mail addresses. Papers that don't have e-mails will at least have author names, and some Googling could turn up contact information.</p>
",AImeta,figure exactly need haul real experts good idea right scholarly papers generally include authors e mail addresses papers e mails least author names googling could turn contact information
1,"<p>To be honest, I've never seen it written ""A.I."", but both look fine to me. If somebody wants to use the dots, more power to them. As Marqin showed, it's kind of dependent on whether a person is using British or American English. Suggested edits that only change stylistic things like this should be rejected; let the post author choose as long as it's consistent within a post. </p>

<p>If there is ever a similar question about tag names, the official policy is that the American style should be used. (SE is an American company.)</p>

<p>Source: <a href=""https://meta.stackexchange.com/a/23873/295684"">Meta Stack Exchange</a></p>
",AImeta,honest never seen written ai look fine somebody wants use dots power marqin showed kind dependent whether person using british american english suggested edits change stylistic things like rejected let post author choose long consistent within post ever similar question tag names official policy american style used se american company source
1,"<p>During this private beta, you actually can downvote infinitely - the minimum rep for that privilege in this stage is 1. I think we're still subject to the <a href=""https://blog.stackoverflow.com/2010/03/important-reputation-rule-changes/"">""upvote one thing for every two things you downvote""</a> rule, though, but that shouldn't be limiting, especially considering you have to have cast 300 votes before it takes effect.</p>

<p>It looks like you've already figured out what to do with nonconstructive answers and questions: downvote. For answers, you'll take a little hit of 1 point, but if it means saving the site from drivel, that's a fine price to pay. Questions that can <em>only</em> be answered subjectively can be closed as primarily opinion-based.</p>
",AImeta,private beta actually downvote infinitely minimum rep privilege stage 1 think still subject rule though limiting especially considering cast 300 votes takes effect looks like already figured nonconstructive answers questions downvote answers take little hit 1 point means saving site drivel fine price pay questions answered subjectively closed primarily opinion based
1,"<p>The title, all in all. Do we need to start writing usage guidance and descriptions for the tags yet? This is needed in the future, but in the beta I'm not sure of. Ideas?</p>
",AImeta,title need start writing usage guidance descriptions tags yet needed future beta sure ideas
1,"<p>I'm going to make something of a counterpoint here.</p>

<p>If everybody upvotes all the good content, good stuff will look the same as great stuff. Everybody should put some effort into looking at each post and judging the quality thereof. The community needs at least a few people with higher standards so higher vote counts call out our best content. You're right, though, in that we currently don't have very much voting activity at all.</p>

<p>If an answer or question is good but could be better, a comment would be a great way to provide positive feedback and advise slight adjustment if necessary. That way, we can improve our content even more.</p>

<p>Content that is misleading or actively bad should of course be downvoted. Don't be afraid to downvote. Once the problem is fixed with an edit, you can remove or reverse your downvote.</p>
",AImeta,going make something counterpoint everybody upvotes good content good stuff look great stuff everybody put effort looking post judging quality thereof community needs least people higher standards higher vote counts call best content right though currently much voting activity answer question good could better comment would great way provide positive feedback advise slight adjustment necessary way improve content even content misleading actively bad course downvoted afraid downvote problem fixed edit remove reverse downvote
1,"<p>Yes! Explaining what the various tags are <em>for</em> is critical for a new site. Besides that, it also looks good when one goes to tag a question and sees that work has been put into the tag system.</p>

<p>Anybody can suggest tag wiki/excerpt edits. At the moment, we don't have any users able to approve them (it takes 750 rep to review tag edits during private beta), but that shouldn't stop anybody from getting a head start on filling in our tags. Besides, community managers will hopefully be around to work the queues that we can't yet handle.</p>
",AImeta,yes explaining various tags critical new site besides also looks good one goes tag question sees work put tag system anybody suggest tag wiki excerpt edits moment users able approve takes 750 rep review tag edits private beta stop anybody getting head start filling tags besides community managers hopefully around work queues yet handle
1,"<p>I consolidated the tags to <a href=""https://ai.stackexchange.com/questions/tagged/quantum-computing"" class=""post-tag"" title=""show questions tagged &#39;quantum-computing&#39;"" rel=""tag"">quantum-computing</a> because this is not an <em>applied</em> hardware and programming site. </p>

<p>A tag synonym isn't really appropriate here. Synonyms were intended to link two completely separate words meaning essentially the same thing (think 'car' vs 'auto'). For simple variations on the <em>same</em> word, there's no need to bulk up the tag listings with every word inflection. Text completion will help guide the user to the correct usage:</p>

<p><kbd>q</kbd><kbd>u</kbd><kbd>a</kbd><kbd>n</kbd> &rarr; <kbd>quantum-computing</kbd></p>
",AImeta,consolidated tags applied hardware programming site tag synonym really appropriate synonyms intended link two completely separate words meaning essentially thing think car vs auto simple variations word need bulk tag listings every word inflection text completion help guide user correct usage q u n quantum computing
1,"<p>Few examples:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/209/8"">https://ai.stackexchange.com/q/209/8</a></li>
<li><a href=""https://ai.stackexchange.com/q/68/8"">What genetic algorithm designs are there that includes models of epigenetics?</a></li>
<li><a href=""https://ai.stackexchange.com/q/181/8"">https://ai.stackexchange.com/q/181/8</a></li>
<li><a href=""https://ai.stackexchange.com/q/1611/8"">What are good APIs out there for (untrained) intent detection?</a></li>
</ul>
",AImeta,examples
1,"<p>I would suggest that ""programming"" and ""implementation problems"" be explicitly listed as outside the scope of <strong><em>this</em></strong> site. If you see them, I would <em>thoughtfully</em> direct the authors to bring these questions to sites which were explicitly created to handle these ""technical"" issues.</p>

<h3>But why can't we have these questions here, too?</h3>

<p>Many sites have <em>some</em> overlap in their subject spaces, but we do not want to optimize for sites that explicitly do so. In the formative stages of this proposal, many opponents argued that the development of AI is clearly already covered among sites like Stack Overflow, Statistics, Data Science, and similar <em>applied</em> sites. </p>

<p><strong>But&hellip;</strong> the <strong><em>claim</em></strong> that we've identified a collection of academic, sociological, and <em>conceptual</em> questions that fall between the cracks of these site is what gave this proposal a chance to launch.  See <a href=""https://area51.meta.stackexchange.com/a/17846/5"">Apparently this is a duplicate</a>. </p>

<p>We still have to see how that claim stands up in actual practice.</p>

<p>I wrote a bit more about this during the proposal process &mdash; <a href=""https://area51.meta.stackexchange.com/a/24016/5"">Will machine learning be considered as on-topic?</a> &mdash;  and the folks looking on seemed widely accepting of that premise as justification for trying out this site. </p>

<blockquote>
  <h3>Will [machine learning] be considered as on-topic?</h3>
  
  <p>No, machine learning as far as implementation goes is not on topic for this site. We've had two previous failures in launching a site about AI (which already included machine learning) &mdash; and the resolution following those failures was to create a more-comprehensive site which included the development of AI, machine learning, statistical tools, big data, NLP, data mining, etc, etc.</p>
  
  <p>That site is <a href=""http://datascience.stackexchange.com""><strong>Data Science</strong></a> [among others].</p>
  
  <p>Data Science is an <em>applied</em> site for all the programmers/statisticians/mathematicians who are trying to make this stuff <em>work.</em></p>
  
  <h3>So why are we trying an AI site&hellip; again?</h3>
  
  <p>Notice that this proposal is in the 'Science' category; <em>not</em> 'Technology'. Despite the creation of a Data Science site to cover this topic, the community made a sufficiently compelling case that there is a swath of <strong>questions in the academic humanities arena</strong> that are <em>not</em> covered by our current sites. </p>
  
  <p>It was convincing enough to give this site another try, but if this site were to simply start reiterating the implementation/tools questions that are already covered elsewhere, this site will not likely make it out of private beta. </p>
</blockquote>
",AImeta,would suggest programming implementation problems explicitly listed outside scope site see would thoughtfully direct authors bring questions sites explicitly created handle technical issues questions many sites overlap subject spaces want optimize sites explicitly formative stages proposal many opponents argued development ai clearly already covered among sites like stack overflow statistics data science similar applied sites claim identified collection academic sociological conceptual questions fall cracks site gave proposal chance launch see still see claim stands actual practice wrote bit proposal process folks looking seemed widely accepting premise justification trying site machine learning considered topic machine learning far implementation goes topic site two previous failures launching site ai already included machine learning resolution following failures create comprehensive site included development ai machine learning statistical tools big data nlp data mining etc etc site among others data science applied site programmers statisticians mathematicians trying make stuff work trying ai site notice proposal iscience category notechnology despite creation data science site cover topic community made sufficiently compelling case swath questions academic humanities arena covered current sites convincing enough give site another try site simply start reiterating implementation tools questions already covered elsewhere site likely make private beta
1,"<p>For FSM's sake, not this again.  Please, no... stop with the ""let's attract experts"" verbiage.  I mean, don't get me wrong.. of course we <em>want</em> experts, but we don't want <em>only</em> experts and we don't want to anoint ""experts"" with some special degree of relevance.  This is a HUGE part of what made it so hard to have a successful ai.se before... we chased away the good, in pursuit of the perfect. </p>
",AImeta,fsm sake please stop let attract experts verbiage mean get wrong course want experts want experts want anoint experts special degree relevance huge part made hard successful aise chased away good pursuit perfect
1,"<p><a href=""http://mathematica.stackexchange.com"">Mathematica</a> has a question that is very useful for beginners:  </p>

<p><a href=""https://mathematica.stackexchange.com/questions/18393/what-are-the-most-common-pitfalls-awaiting-new-users"">What are the most common pitfalls awaiting new users?</a>  </p>

<p>For me as a beginner who wants to use artificial intelligence applications in remote sensing and is familiar with MATLAB, C++ and a little JAVA.<br>
There is always a question which open source or non open source libraries and APIs are there to implement an algorithm (for example which library can be used for implementing simulated annealing in C++, What libraries are there to implement wavelet transformation in C++) in a specific programming language and I have seen such questions in research gate a lot.  </p>

<p>For example someone has asked <strong>Which library is recommended for AI programming with Python?</strong>  </p>

<p>Such question is not allowed here because of being primarily opinion-based but I think we can have a reference instead considering all those conditions for a reference question:  </p>

<ul>
<li>One topic per answer .</li>
<li>Focus on non-advanced uses (it's intended to be useful for beginners and as a question closing reference).</li>
<li>Include a self explanatory title in h2 style.</li>
<li>Explain the symptoms, the mechanism behind the scenes and all possible causes and solutions you can think of. Be sure to include a beginner's level explanation (and a more advance one too, if you're in the mood) .</li>
<li>Include a link to your answer by editing the <strong>Index</strong> below (for quick reference).</li>
</ul>

<p>For example in an answer someone introduces all open source or non open source libraries that can be used to implement Bee colony algorithm in C++, lisp, prolog, etc together with advantages and disadvantages of each API.  </p>

<p>In another someone introduces APIs to implement SVM classifier in MathLab, C++, etc with its advantages and disadvantage.  </p>

<p>Do you think it can be a good fit for this site?</p>
",AImeta,question useful beginners beginner wants use artificial intelligence applications remote sensing familiar matlab c little java always question open source non open source libraries apis implement algorithm example library used implementing simulated annealing c libraries implement wavelet transformation c specific programming language seen questions research gate lot example someone asked library recommended ai programming python question allowed primarily opinion based think reference instead considering conditions reference question one topic per answer focus non advanced uses intended useful beginners question closing reference include self explanatory title h2 style explain symptoms mechanism behind scenes possible causes solutions think sure include beginner level explanation advance one mood include link answer editing index quick reference example answer someone introduces open source non open source libraries used implement bee colony algorithm c lisp prolog etc together advantages disadvantages api another someone introduces apis implement svm classifier mathlab c etc advantages disadvantage think good fit site
1,"<p><a href=""https://ai.meta.stackexchange.com/a/72/8"">@RobertCartaino suggested in this post</a> that:</p>
<blockquote>
<p>&quot;programming&quot; and &quot;implementation problems&quot; be explicitly listed as outside the scope of this site</p>
</blockquote>
<p>in order to direct the authors to sites which were explicitly created to handle these &quot;technical&quot; issues.</p>
<p>This site failed already two times, because people didn't ask the right questions and most of them were already covered by somewhere else (e.g. Stack Overflow, Statistics, Data Science, and similar applied sites).</p>
<p>Basically:</p>
<blockquote>
<p>Data Science is an applied site for all the programmers/statisticians/mathematicians who are trying to make this stuff work.</p>
<p>a more-comprehensive site which included the development of AI, machine learning, statistical tools, big data, NLP, data mining, etc,</p>
</blockquote>
<p>so:</p>
<blockquote>
<p>No, machine learning as far as implementation goes is not on topic for this site.</p>
</blockquote>
<p>and:</p>
<blockquote>
<p>if this site were to simply start reiterating the implementation/tools questions that are already covered elsewhere, this site will not likely make it out of private beta.</p>
</blockquote>
<hr />
<p>On the <a href=""https://area51.meta.stackexchange.com/questions/24014/will-machine-learning-be-considered-as-on-topic/24016#comment38287_24016"">other hand</a>:</p>
<blockquote>
<p>Everything in the proposal is considered when evaluating whether the site would likely be viable. If the proposal looks good across the board, that is the &quot;compelling case&quot;</p>
</blockquote>
",AImeta,explicitly listed outside scope site order direct authors sites explicitly created handle issues site failed already two times people ask right questions already covered somewhere else eg stack overflow statistics data science similar applied sites basically data science applied site programmers statisticians mathematicians trying make stuff work comprehensive site included development ai machine learning statistical tools big data nlp data mining etc machine learning far implementation goes topic site site simply start reiterating implementation tools questions already covered elsewhere site likely make private beta everything proposal considered evaluating whether site would likely viable proposal looks good across board
1,"<p>Conceptually speaking, I think it can be useful when a community decides that a <strong>rare</strong> ""big list"" question would be so incredibly useful, the community agrees collectively that it is worth the careful curation and on-going upkeep needed to keep it up to date [I'm hoping to build a feature to that effect in the future]. The downside of allowing these questions <strong><em>broadly</em></strong> is that these open-ended polls and all-in-one resource collections are <em>so</em> easy to ask, folks inevitably keep shoveling out boundless ""me too"" iterations in every conceivable topic space. The whole thing becomes annoying when folks become tired these questions and most of the threads fall into disrepair like <a href=""https://en.wikipedia.org/wiki/Abandonware"" rel=""nofollow noreferrer"">abandonware</a>.</p>

<p><strong>However&hellip;</strong></p>

<p>the examples you cited I believe are <strong>clearly off topic</strong> for this site. You seem to be advocating for some type of programming reference collection, API list, or some other type of programming resource for this community. That is not what this site is about. </p>

<p>This is supposed to be a site dealing in largely academic, sociological, and conceptual issues. To explain why, please see this post:</p>

<p><a href=""https://ai.meta.stackexchange.com/a/72/95""><strong>Is asking about AI algorithm recommendation on-topic?</strong></a></p>
",AImeta,conceptually speaking think useful community decides rare big list question would incredibly useful community agrees collectively worth careful curation going upkeep needed keep date hoping build feature effect future downside allowing questions broadly open ended polls one resource collections easy ask folks inevitably keep shoveling boundless iterations every conceivable topic space whole thing becomes annoying folks become tired questions threads fall disrepair like however examples cited believe clearly topic site seem advocating type programming reference collection api list type programming resource community site supposed site dealing largely academic sociological conceptual issues explain please see post
1,"<p>How should we write tag wikis for broad or general tags? Such as <code>algorithm</code>, or <code>history</code>?</p>
",AImeta,write tag wikis broad general tags
1,"<p>Technically I guess you could, but I think it would be fair to add some warnings such as the site might closed, and questions on Stack Exchange are sometimes deleted or closed for moderation reason. </p>
",AImeta,technically guess could think would fair add warnings site might closed questions stack exchange sometimes deleted closed moderation reason
1,"<p>How should we as a site treat answers which are simply copy-pasted from another source, (whether with or without attribution)? Particularly those which show little understanding of the topic on the part of the poster.</p>

<p>I won't name anyone, but I've seen an answer where the user apparently simply copy-pasted the first paragraph of the first relevant google result, which didn't even really answer the original question. Afterwards, they admitted to know nothing about the topic themselves. </p>

<p>To me, this seems wrong. What is the general stance on this sort of answers?</p>

<p>(To the person in question, if they recognize themselves: Sorry about this, but I think this sort of thing needs to be discussed.)</p>
",AImeta,site treat answers simply copy pasted another source whether without attribution particularly show little understanding topic part poster name anyone seen answer user apparently simply copy pasted first paragraph first relevant google result even really answer original question afterwards admitted know nothing topic seems wrong general stance sort answers person question recognize sorry think sort thing needs discussed
1,"<p>At one point I thought I got it, but then I lost again.</p>
<p>Few highlights:</p>
<ul>
<li><p><a href=""https://ai.meta.stackexchange.com/a/46"">https://ai.meta.stackexchange.com/a/46</a></p>
<blockquote>
<p>modeling belongs to Data Science SE</p>
<p>I think the site should be interested in implementation experts.</p>
</blockquote>
</li>
<li><p><a href=""https://ai.meta.stackexchange.com/a/7"">https://ai.meta.stackexchange.com/a/7</a></p>
<blockquote>
<p>No, data science and the implementation of artificial intelligence are off-topic.</p>
</blockquote>
</li>
<li><p><a href=""https://ai.meta.stackexchange.com/a/72"">https://ai.meta.stackexchange.com/a/72</a></p>
<blockquote>
<p>suggest that &quot;programming&quot; and &quot;implementation problems&quot; be explicitly listed as outside the scope of this site</p>
</blockquote>
</li>
</ul>
<p>Obvious points are:</p>
<ul>
<li>data science questions belong to <a href=""https://datascience.stackexchange.com/"">Data Science site</a>,</li>
<li>programming questions belong <a href=""http://stackoverflow.com"">Stack Overflow</a>.</li>
</ul>
<p>What about AI implementation and modelling? Above quotes are a bit contradictory.</p>
<p>So what's on-topic exactly, <a href=""https://ai.stackexchange.com/q/1297/8"">AI modelling or implementation</a>, or none of it?</p>
<p>If none of it, what should be?</p>
",AImeta,one point thought got lost highlights modeling belongs data science se think site interested implementation experts data science implementation artificial intelligence topic suggest explicitly listed outside scope site obvious points data science questions belong programming questions belong ai implementation modelling quotes bit contradictory topic exactly none none
1,"<p>Post consists almost entirely of content copied from elsewhere should NOT be considered a useful 'answer' in the context of this site. </p>

<p>Copying answers from external sources without permission is not allowed (and quoting or linking back to that site does <strong><em>not</em></strong> make that okay). Even posting an answer copied almost entirely from <em>reusable</em> content should be frowned upon, or even flagged to be removed. </p>

<p>This site was created to add something unique (and better) to the Internet. If we're simply copying stuff that's already out there, why bother? We're just adding another barrier between the folks searching for this stuff and the original source of the content.</p>

<p>Answers should create something original and useful for this community specifically. That is why we bring together individual communities of experts to host these topics. </p>

<p>And vetting is a <strong><em>big</em></strong> part of this site. Your <em>best</em> content should be rising to the top. <strong>Please stop up-voting these posts!</strong></p>
",AImeta,post consists almost entirely content copied elsewhere considered useful answer context site copying answers external sources without permission allowed quoting linking back site make okay even posting answer copied almost entirely reusable content frowned upon even flagged removed site created add something unique better internet simply copying stuff already bother adding another barrier folks searching stuff original source content answers create something original useful community specifically bring together individual communities experts host topics vetting big part site best content rising top please stop voting posts
1,"<p>Yes, absolutely. Tag excerpts are not meant to simply define what the <em>word</em> of a tag means. They are meant to describe when and how those tags should be used on this site specifically. </p>

<p>Since this site is not generically about either <em>algorithms</em> OR <em>history</em>, it becomes especially important to describe how those subjects fit in the context of <em>this</em> site. </p>

<p>I see some potentially misleading tags like [python], [engine], and [storage]. Adding a bit of context about where they should be used can help avoid the occasional off-topic question that may not fit this site at all. </p>
",AImeta,yes absolutely tag excerpts meant simply define word tag means meant describe tags used site specifically since site generically either algorithms history becomes especially important describe subjects fit context site see potentially misleading tags like python engine storage adding bit context used help avoid occasional topic question may fit site
1,"<p>It was <a href=""https://ai.meta.stackexchange.com/a/72/8"">suggested</a> that:</p>

<blockquote>
  <p>""implementation problems"" be explicitly listed as outside the scope of this site</p>
</blockquote>

<p>Can we clarify what this could mean? Some example would be useful.</p>

<hr>

<p><a href=""https://ai.meta.stackexchange.com/questions/1078/what-should-be-on-topic-modelling-or-implementation-or-anything-else#comment1065_1078"">@InquisitiveLurker</a> suggested that this could mean asking about inner workings of basic algorithms, but then how we define 'inner working'.</p>

<p>This also may help: <a href=""https://ai.stackexchange.com/q/1297/8"">How to distinguish AI modeling from implementation?</a></p>

<hr>

<p>Any ideas?</p>
",AImeta,implementation problems explicitly listed outside scope site clarify could mean example would useful suggested could mean asking inner workings basic algorithms define inner working also may help ideas
1,"<p>Programming, algorithm, modeling, math, philosophy, and history questions should the off-topic, as they are already on-topic in <a href=""https://ai.meta.stackexchange.com/q/4/4"">other SE</a>, such as Stats and Data Science.</p>

<p>Data science and the Stats SE already have a huge overlap (>~80%), and I am worried to have a third SE that also significantly overlaps with them. Personally, it would further demotivate me to write any answer, as it gets tiring to copy-paste content, and updating duplicated answers is a pain.</p>
",AImeta,programming algorithm modeling math philosophy history questions topic already topic stats data science data science stats se already huge overlap 80 worried third se also significantly overlaps personally would demotivate write answer gets tiring copy paste content updating duplicated answers pain
1,"<p>As long as it does answer the question, clearly indicates it is a quote, doesn't infringe licenses, and gives proper attribution, it is fine. </p>

<p>(Why reinventing the wheel?)</p>
",AImeta,long answer question clearly indicates quote infringe licenses gives proper attribution fine reinventing wheel
1,"<p>I think we should discourage the use of LaTeX, but should allow it. Our goal is to attract experts in AI, and the language of AI (today) is math. Like that post in the OP (which I wrote, btw), I think math makes a lot of concepts easier to understand. </p>

<p>I think this SE should focus on the <em>design</em> aspects of AI and AI research instead of the programming and libraries (those questions should go to Data Science) or the statistics (those should go to Cross Validated), but some mathematics is often a core component of AI theory.</p>
",AImeta,think discourage use latex allow goal attract experts ai language ai today math like post op wrote btw think math makes lot concepts easier understand think se focus design aspects ai ai research instead programming libraries questions go data science statistics go cross validated mathematics often core component ai theory
1,"<p>In these early days, how can we attract attention to the best questions? The current front page does not accurately reflect this. Keeping in mind that our goal is to invite experts, I think it would be great if we could manually curate a list of questions that we can tout as ideal questions for this SE. </p>

<p>(We could create a community wiki here with the answers as we discuss how to proceed)</p>
",AImeta,early days attract attention best questions current front page accurately reflect keeping mind goal invite experts think would great could manually curate list questions tout ideal questions se could create community wiki answers discuss proceed
1,"<h3>The early stopping</h3>

<blockquote>
  <p>Form of regularization used to avoid overfitting when training.</p>
</blockquote>

<p>See: <a href=""https://ai.stackexchange.com/q/16/8"">What is early stopping?</a></p>
",AImeta,early stopping form regularization used avoid overfitting training see
1,"<p>To give examples of questions I think are good, and that we should promote, in order with the best questions at the top:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/questions/92/how-is-it-possible-that-deep-neural-networks-are-so-easily-fooled"">How is it possible that deep neural networks are so easily fooled?</a> I would not have put ""easily"" in the title, but it is an excellent question that the AI experts I know spend a lot of time thinking about.</li>
<li><a href=""https://ai.stackexchange.com/questions/1294/how-does-hintons-capsules-theory-work"">How does Hinton&#39;s &quot;capsules theory&quot; work?</a></li>
<li><a href=""https://ai.stackexchange.com/questions/77/is-lisp-still-being-used-to-tackle-ai-problems"">Is Lisp still being used to tackle AI problems?</a></li>
<li><a href=""https://ai.stackexchange.com/questions/227/what-is-the-difference-between-mlp-and-rbf"">What is the difference between MLP and RBF?</a> : This can go to Crossvalidated but I'd argue it's out of place there and more at home here. Though it is a comparison of two specific algorithms, it reflects wider design issues in AI algorithms.</li>
</ul>

<p>Others may disagree on this list, but I'd like to put up here the questions I think are more on-topic here than I think in other SEs. Some overlap is inevitable.</p>
",AImeta,give examples questions think good promote order best questions top would put easily title excellent question ai experts know spend lot time thinking go crossvalidated would argue place home though comparison two specific algorithms reflects wider design issues ai algorithms others may disagree list would like put questions think topic think ses overlap inevitable
1,"<h1>The Dropout</h1>

<blockquote>
  <p>A technique of reducing overfitting in neural networks. The term ""dropout"" refers to dropping out units in a neural network.</p>
</blockquote>
",AImeta,dropout technique reducing overfitting neural networks term dropout refers dropping units neural network
1,"<p>These are some ways to highlight and promote nice content on the site:</p>

<ol>
<li>Organizing a quarterly post, where people are encouraged to post their favourite qns/ans and the top three would be awarded bounties by the mods or whoever is interested in contributing.</li>
<li>Cross-posting the nice ones to other sites like reddit, etc. This would help in marketing the site, as well as good karma by sharing good content.</li>
</ol>
",AImeta,ways highlight promote nice content site organizing quarterly post people encouraged post favourite qns ans top three would awarded bounties mods whoever interested contributing cross posting nice ones sites like reddit etc would help marketing site well good karma sharing good content
1,"<p>There is a constant war between spammers and website operators, to prevent websites from spam. CAPTCHA's are the tools to protect sites, and are the front line of this arms race.</p>

<p>This is an area of AI research that is directly relevant to the public.  </p>

<p>The question is if we should allow postings about how to defeat CAPTCHA's. They are probably in scope, but we don't want to help spammers.</p>

<p><a href=""https://xkcd.com/810/"" rel=""nofollow"">Obligatory XKCD link</a>.</p>

<p>We may get some inspiration from Security.SE. They have some experience in dealing with ethical issues. Over there, they have an explicit close reason for questions about hacking other systems: </p>

<blockquote>
  <p>Questions asking us to break the security of a specific system for you are off-topic unless they demonstrate an understanding of the concepts involved and clearly identify a specific problem. </p>
</blockquote>

<p>Maybe we need a similar close reason or off-topic flag?</p>
",AImeta,constant war spammers website operators prevent websites spam captcha tools protect sites front line arms race area ai research directly relevant public question allow postings defeat captcha probably scope want help spammers may get inspiration securityse experience dealing ethical issues explicit close reason questions hacking systems questions asking us break security specific system topic unless demonstrate understanding concepts involved clearly identify specific problem maybe need similar close reason topic flag
1,"<p>This is my question about a very common problem faced while training several data science and AI algorithms, and most importantly while backpropogating errors in neural networks, which is <strong>getting trapped in a local minima while descending gradient.</strong></p>

<p>So, according to the discussion under the qn, it is <a href=""https://ai.stackexchange.com/q/1362/101"">claimed to be off-topic</a></p>

<p>However, in the defence of my post, I think it is perfectly on-topic in this site, as it asks about a legit problem faced while training neural nets and several other AI algorithms.</p>

<p>So, I am looking forward to what the community thinks regarding this.</p>
",AImeta,question common problem faced training several data science ai algorithms importantly backpropogating errors neural networks getting trapped local minima descending gradient according discussion qn however defence post think perfectly topic site asks legit problem faced training neural nets several ai algorithms looking forward community thinks regarding
1,"<p>Escaping local optima is an extremely ubiquitous problem (in case it's unclear - there are vastly more applications than backprop), leading to many open questions (a great deal of metaheuristics research, indisputably part of AI, is concerned with this). </p>

<p>So, it is much more open-ended (and therefore subject to heuristic/AI solutions) than the more pedestrian questions (with procedural anwers) about e.g. backprop that appear to be within the AI SE remit.</p>

<p>Hence, I'd say it is definitely on topic ;-)</p>
",AImeta,escaping local optima extremely ubiquitous problem case unclear vastly applications backprop leading many open questions great deal metaheuristics research indisputably part ai concerned much open ended therefore subject heuristic ai solutions pedestrian questions procedural anwers eg backprop appear within ai se remit hence would say definitely topic
1,"<p><sub><sub>(Without seeing any actual examples&hellip;)</sub></sub></p>

<p>These can likely be closed as off topic <em>already.</em> A question sufficiently detailed enough to ask how to defeat a system based in AI will likely no longer be about the <strong><em>subject</em></strong> of AI itself. It would be like asking how to defeat the smart aliens in Galactic Uberblast 2020, or how to remove the T47/a access panel of your robot butler if he wont let you. </p>

<p>There's a point where a question is only <em>coincidentally</em> related to the subject of AI itself &mdash; close it as off topic.</p>

<p>There will always be sticky edge cases where someone might be asking how an AI-based security system <strong>works,</strong> but it becomes somewhat problematic to preempt any such questions by presuming the <em>intent</em> of an author before you see such questions in actual practice. It's probably too early to conjure up a broad policy statement when there is really no tangible problem to defeat. </p>
",AImeta,without seeing actual examples likely closed topic already question sufficiently detailed enough ask defeat system based ai likely longer subject ai would like asking defeat smart aliens galactic uberblast 2020 remove t47 access panel robot butler wo nt let point question coincidentally related subject ai close topic always sticky edge cases someone might asking ai based security system works becomes somewhat problematic preempt questions presuming intent author see questions actual practice probably early conjure broad policy statement really tangible problem defeat
1,"<p>Asking about how Captcha works or what is mechanism of AI recognising the text from the image, isn't illegal.</p>
<p>Neither whether has been cracked/hacked or not, which has been asked at Stack Overflow:</p>
<ul>
<li><a href=""https://stackoverflow.com/q/448963/55075"">Has reCaptcha been cracked / hacked / OCR'd / defeated / broken?</a></li>
</ul>
<p>Captcha is just a type of challenge-response test used in determine whether somebody is human or not and this technology is not owned by anybody. There are many research studies how to improve this technology to keep spammers away.</p>
<p>If the post doesn't indicate it's against the law and doesn't show any illegal activity, there is no reason to close it. If it's unethical, you can always down-vote it or ask for clarification. There are special agencies which deals with that problem, so you don't have to worry about it.</p>
<p>If it's not illegal, it's up to you how you'll use the knowledge from the posts. As it can be always used for research and educational purposes.</p>
<p>See also:</p>
<ul>
<li><p><a href=""https://meta.stackexchange.com/q/21706/191655"">Should unethical questions be answered?</a></p>
</li>
<li><p><a href=""https://meta.stackexchange.com/q/80495/191655"">Policy regarding questions related to unethical or “shady” practices</a></p>
<blockquote>
<p>we bury our heads in the sand, we're just pretending the problem doesn't exist and we can't help defend against it</p>
<p>If a process is clearly illegal, especially in the US, then it should not be discussed.</p>
</blockquote>
</li>
</ul>
",AImeta,asking captcha works mechanism ai recognising text image illegal neither whether cracked hacked asked stack overflow captcha type challenge response test used determine whether somebody human technology owned anybody many research studies improve technology keep spammers away post indicate law show illegal activity reason close unethical always vote ask clarification special agencies deals problem worry illegal use knowledge posts always used research educational purposes see also bury heads sand pretending problem exist help defend process clearly illegal especially us discussed
1,"<p>I think that Harsh's list is a good start if we want to get people who think of themselves as AI experts, instead of people who think of themselves as AGI experts. (The G is for 'general.') But in order to differentiate this site from Cross Validated or Data Science, we're trying to focus on the humanities / philosophy side. </p>

<p>I worry that this means that we're going to have a parade of AI 101 questions, like <a href=""https://ai.stackexchange.com/questions/179/how-do-multiple-intelligences-fit-in-ai"">How does multiple intelligences fit in AI?</a> or <a href=""https://ai.stackexchange.com/questions/1320/how-does-artificial-intelligence-work-in-games"">How does artificial intelligence Work in games?</a>, which isn't an implementation or algorithms question because it's so broad and basic, or simple discussions of complicated issues, like the on-hold <a href=""https://ai.stackexchange.com/questions/7/why-does-stephen-hawking-say-artificial-intelligence-will-kill-us-all"">Why does Stephen Hawking say ""Artificial Intelligence will kill us all""?</a>.</p>

<p>And this suggests that the AI experts are going to become rapidly bored and leave, since they can't ask the questions they're interested in and don't see any interesting questions to answer, and so they won't be around to contribute to the humanities side of the discussion. What good humanities questions have we had, so far? My short list is something like:</p>

<p><a href=""https://ai.stackexchange.com/questions/74/what-is-the-difference-between-strong-ai-and-weak-ai"">What is the different between strong-AI and weak-AI?</a> (though this is another 101 question)</p>

<p><a href=""https://ai.stackexchange.com/questions/15/is-the-turing-test-or-any-of-its-variants-a-reliable-test-of-artificial-intell"">Is the Turing Test, or any of its variants, a reliable test of artificial intelligence?</a></p>

<p><a href=""https://ai.stackexchange.com/questions/148/what-limits-if-any-does-the-halting-problem-put-on-artificial-intelligence"">What limits, if any, does the halting problem put on Artificial Intelligence?</a></p>

<p>But that's three good humanities questions out of the <a href=""https://ai.stackexchange.com/questions?sort=votes"">15 currently most upvoted questions</a>.</p>
",AImeta,think harsh list good start want get people think ai experts instead people think agi experts g general order differentiate site cross validated data science trying focus humanities philosophy side worry means going parade ai 101 questions like implementation algorithms question broad basic simple discussions complicated issues like hold suggests ai experts going become rapidly bored leave since ask questions interested see interesting questions answer around contribute humanities side discussion good humanities questions far short list something like though another 101 question three good humanities questions
1,"<p>The question is off-topic, as it's about how to the use of machine learning algorithms. (the other questions on neural nets, their architectures, backpropogation, are also off-topic).</p>

<p>Programming, algorithm, modeling, math, philosophy, and history questions should the off-topic, as they are already on-topic in <a href=""https://ai.meta.stackexchange.com/q/4/4"">other SE</a>, such as Stats and Data Science.</p>

<p>Data science and the Stats SE already have a huge overlap (>~80%), and I am worried to have a third SE that also significantly overlaps with them. Personally, it would further demotivate me to write any answer, as it gets tiring to copy-paste content, and updating duplicated answers is a pain.</p>
",AImeta,question topic use machine learning algorithms questions neural nets architectures backpropogation also topic programming algorithm modeling math philosophy history questions topic already topic stats data science data science stats se already huge overlap 80 worried third se also significantly overlaps personally would demotivate write answer gets tiring copy paste content updating duplicated answers pain
1,"<p>Personally, I consider gradient descent something akin to what something like differential equations is to physics - a useful piece of mathematics that has a large array of applications, but not really an AI topic by itself.</p>

<hr>

<p>When we talk about AI, there are different levels of detail and ""technicalness"" we can go into and I believe it's necessary to draw the line somewhere.</p>

<p>To illustrate what I mean, let me use the example of self-driving cars:</p>

<ul>
<li>There's the concept of the <strong>self-driving car</strong> itself</li>
<li>The car has some sort of <strong>computer-vision</strong> system</li>
<li>That system might involve a <strong>neural network</strong></li>
<li>That network needs to be <strong>trained</strong> somehow - there are different algorithms for that</li>
<li>One of the most common ones is <strong>backpropagation</strong></li>
<li>Backpropagation often uses <strong>gradient descent</strong></li>
<li>Gradient descent is an <strong>optimization algorithm</strong></li>
<li>and so on...</li>
</ul>

<p>We could look at an AI problem at any of those levels. But at some point, it becomes no longer really about AI but rather about mathematics or statistics. And those topics are already covered well by other sites.</p>

<p>Basically, what I believe is that this site should mainly concentrate on the top few lines of that list, and leave the rest to more appropriate venues.</p>
",AImeta,personally consider gradient descent something akin something like differential equations physics useful piece mathematics large array applications really ai topic talk ai different levels detail technicalness go believe necessary draw line somewhere illustrate mean let use example self driving cars concept self driving car car sort computer vision system system might involve neural network network needs trained somehow different algorithms one common ones backpropagation backpropagation often uses gradient descent gradient descent optimization algorithm could look ai problem levels point becomes longer really ai rather mathematics statistics topics already covered well sites basically believe site mainly concentrate top lines list leave rest appropriate venues
1,"<p>So, can someone help me understand what the scope of the site is?</p>

<p><a href=""https://ai.stackexchange.com/q/1358/101"">I ask a question about Monte Carlo search</a>, which is one of the core algorithms behind the Go playing <strong>AI bot</strong>, AlphaGo, and it is closed off as off-topic, citing this reason <code>This question does not appear to be about artificial intelligence</code>.</p>

<p>So, my question is: <strong>Why isn't it about AI?</strong> Isn't AlphaGo an AI bot? Why does asking about an AI algorithm of an AI bot make it off-topic?</p>

<p><strong>Can someone(maybe one of the close-voters) take the example of AlphaGo and explain what an on-topic question and an off-topic question(&lt;-- You can use mine if you want to.) would look like?</strong></p>

<p><a href=""https://ai.meta.stackexchange.com/q/1091/101"">I already asked a question about the scope of this site</a>, citing another example, where I'm yet to get a clear answer.</p>

<p>If all the questions get closed as on-topic in DS and CV, then why do we even have this site? (Sorry if I sound rude, but I really want this site to grow. So, the early we sought out our scope, the better.)</p>
",AImeta,someone help understand scope site one core algorithms behind go playing ai bot alphago closed topic citing reason question ai alphago ai bot asking ai algorithm ai bot make topic someonemaybe one close voters take example alphago explain topic question topic question use mine want would look like citing another example yet get clear answer questions get closed topic ds cv even site sorry sound rude really want site grow early sought scope better
1,"<p>I was one of the close voters.</p>

<p>First up, the close message you see is the generic off-topic message - we only get one reason under the ""off-topic"" branch of the close dialogs because we currently have no moderators to create and approve off-topic reasons. Therefore, anything deemed off-topic will get that one message. It's not that your question wasn't about AI, it wasn't about AI <em>as defined in the help center</em> (or, again, since we have no moderators yet, as defined on meta).</p>

<p>Your question, in my understanding, is about specific algorithms and how they work. We're not really into the math/statistics/implementation on this site, because those are already well covered by existing places.</p>

<p>I think that the question could be reopened if it was adjusted to ask something like ""Why is Alpha Go's approach more appropriate for games than existing technologies?"" Then the question wouldn't be about a specific algorithm, but answers could still dive in if they wanted.</p>

<p>As for whether we have a scope, we're still working on that, as evidenced by our abundance of meta posts about topicality! I think we do have at least some sketches of what should by on- and off-topic, though.</p>
",AImeta,one close voters first close message see generic topic message get one reason topic branch close dialogs currently moderators create approve topic reasons therefore anything deemed topic get one message question ai ai defined help center since moderators yet defined meta question understanding specific algorithms work really math statistics implementation site already well covered existing places think question could reopened adjusted ask something like alpha go approach appropriate games existing technologies question would specific algorithm answers could still dive wanted whether scope still working evidenced abundance meta posts topicality think least sketches topic though
1,"<p>The initial scope on <a href=""http://area51.stackexchange.com/proposals/93481/artificial-intelligence"">Area 51</a> proposal was:</p>

<blockquote>
  <p>Conceptual questions about life and challenges in a world where ""cognitive"" functions can be mimicked in purely digital environment.</p>
</blockquote>

<p>Of course this isn't a strict rule, because the final scope is defined by community based on the questions being asked, so if you have any great question related to AI, please ask. So after some time this site can find a distinct and unique scope in comparison to other existing <a href=""http://stackexchange.com/sites#science-questionsperday"">network sites</a>.</p>

<p>However please note that the questions about <a href=""https://stackoverflow.com/"">programming</a>, <a href=""https://ai.meta.stackexchange.com/q/71/8"">algorithms</a>, <a href=""https://stats.stackexchange.com/questions/tagged/machine-learning"">implementation</a> and <a href=""https://datascience.stackexchange.com/questions/tagged/machine-learning"">data modelling</a> are already on-topic on the other dedicated sites and are likely to be off-topic here in order to avoid <a href=""https://ai.meta.stackexchange.com/q/4/8"">huge overlap</a>.</p>

<hr>

<p>Basically the scope is still about <strong>artificial intelligence</strong>, but coming from the technical background, asking the right question could be challenging (because we've already a lot of sites dedicated to different aspects of AI). You can think about it like <a href=""https://softwareengineering.stackexchange.com/"">Programmers</a> SE site, but without asking actual programming questions.</p>
",AImeta,initial scope proposal conceptual questions life challenges world cognitive functions mimicked purely digital environment course strict rule final scope defined community based questions asked great question related ai please ask time site find distinct unique scope comparison existing however please note questions already topic dedicated sites likely topic order avoid basically scope still artificial intelligence coming technical background asking right question could challenging already lot sites dedicated different aspects ai think like se site without asking actual programming questions
1,"<p>It would be nice to add <a href=""https://stats.stackexchange.com/"">https://stats.stackexchange.com/</a> as a migration target:</p>

<p><a href=""https://i.stack.imgur.com/emrFr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/emrFr.png"" alt=""enter image description here""></a></p>
",AImeta,would nice add migration target
1,"<p>Yes, that would definitely be a good idea; we get a lot of questions that belong there.</p>

<p>The trick is that sites only get migration paths (in or out) after they graduate fully. The reasoning behind this is that beta sites are still figuring out their scopes, and it would be bad to send a question away forever with no way to reopen it at the source site.</p>

<p>Moderators can migrate things anywhere, but only if the question is less than 60 days old. If we get pro-tem mods in time, we could consider sending any good-but-definitely-off-topic questions away.</p>

<p>People might also want to migrate to <a href=""https://datascience.stackexchange.com/"">Data Science</a>, but it's still in public beta and is therefore not guaranteed to stick around. Migrations to beta sites are <a href=""https://meta.stackexchange.com/a/258601/295684"">discouraged</a>.</p>
",AImeta,yes would definitely good idea get lot questions belong trick sites get migration paths graduate fully reasoning behind beta sites still figuring scopes would bad send question away forever way reopen source site moderators migrate things anywhere question less 60 days old get pro tem mods time could consider sending good definitely topic questions away people might also want migrate still public beta therefore guaranteed stick around migrations beta sites
1,"<p>Implementation problems may refer to the ""how to do X with the Y tool/framework"" kind of questions. Such kind of questions are indirectly related to AI, via the X part, which could lead to ask the OP to change the question focus. So questions that solely pertain to Y should be off-topic.</p>

<p>One issue with this approach, is that, say, 10 years ago, Y would have been seen as AI from science fictions. At some point in time, ""we did it"", and Y just looks like another tool.</p>
",AImeta,implementation problems may refer x tool framework kind questions kind questions indirectly related ai via x part could lead ask op change question focus questions solely pertain topic one issue approach say 10 years ago would seen ai science fictions point time looks like another tool
1,"<p>I don't know, but that shouldn't have been closed.  It should be, in almost every case, sufficient to simply <em>ignore</em> any question which falls into a ""grey area"" regarding scope.  We should only close questions which are blatant spam, trolling, or so wildly off-topic that a 2 year old could see it (like a question about the best fuel injector cleaner to use for  1972 Ford Pinto, or something).</p>

<p>If questions are desired by the community, they'l bubble to the top. If they aren't, they'll die from lack of activity.  Explicitly closing a question is an aggressive and hostile act and should always be a measure of last resort.</p>
",AImeta,know closed almost every case sufficient simply ignore question falls grey area regarding scope close questions blatant spam trolling wildly topic 2 year old could see like question best fuel injector cleaner use 1972 ford pinto something questions desired community theyl bubble top die lack activity explicitly closing question aggressive hostile act always measure last resort
1,"<p>Personally I disagree with the entire premise that ""implementation should be off topic"".  I don't see any point in talking nothing but theory and never talking implementation.  My fear is that that will lead us into fringe-land with a lot of sketch posts asking philosophical questions that aren't really helpful to anybody. </p>
",AImeta,personally disagree entire premise implementation topic see point talking nothing theory never talking implementation fear lead us fringe land lot sketch posts asking philosophical questions really helpful anybody
1,"<h2>Add bounties.</h2>

<p>What else can you do? Adding bounties to questions puts them in a special category on the front page. If you want, you could even have two users who 'bounce' a bounty to each other on  few questions, to make sure that they stay there in the 'featured' tab.</p>
",AImeta,add bounties else adding bounties questions puts special category front page want could even two users bounce bounty questions make sure stay featured tab
1,"<p>Currently we've the following tags related to gaming:
<a href=""https://ai.stackexchange.com/questions/tagged/ai-games"" class=""post-tag"" title=""show questions tagged &#39;ai-games&#39;"" rel=""tag"">ai-games</a>, <a href=""https://ai.stackexchange.com/questions/tagged/gaming"" class=""post-tag"" title=""show questions tagged &#39;gaming&#39;"" rel=""tag"">gaming</a>, <a href=""https://ai.stackexchange.com/questions/tagged/go-game"" class=""post-tag"" title=""show questions tagged &#39;go-game&#39;"" rel=""tag"">go-game</a>, <a href=""https://ai.stackexchange.com/questions/tagged/game-theory"" class=""post-tag"" title=""show questions tagged &#39;game-theory&#39;"" rel=""tag"">game-theory</a>, <a href=""https://ai.stackexchange.com/questions/tagged/game-play"" class=""post-tag"" title=""show questions tagged &#39;game-play&#39;"" rel=""tag"">game-play</a>, <a href=""https://ai.stackexchange.com/questions/tagged/games"" class=""post-tag"" title=""show questions tagged &#39;games&#39;"" rel=""tag"">games</a>.</p>

<p>Can we decide on one or two to stick with related to gaming? Which one would be the most suitable?</p>
",AImeta,currently following tags related gaming decide one two stick related gaming one would suitable
1,"<p>Recently I asked a question and one of the <a href=""https://ai.stackexchange.com/a/1468/72"">most voted answer</a> is totally plagiarized from an answer to a similar question in <a href=""https://robotics.stackexchange.com/questions/2264/are-artificial-intelligence-and-robotics-different/2267#2267"">Robotics StackExchange</a></p>

<p>I think it is against the site policy as the answer is being copied here without any any attribute. </p>
",AImeta,recently asked question one totally plagiarized answer similar question think site policy answer copied without attribute
1,"<p>As you point out, it is a copy-paste without attribution, which is a <a href=""https://ai.stackexchange.com/help/licensing"">violation of the Stack Exchange rules</a>.</p>

<p>So it should be flagged, using a custom moderator flag to explain the situation.</p>

<p>I have raised that flag.</p>
",AImeta,point copy paste without attribution flagged using custom moderator flag explain situation raised flag
1,"<p>I would go with <a href=""https://ai.stackexchange.com/questions/tagged/gaming"" class=""post-tag"" title=""show questions tagged &#39;gaming&#39;"" rel=""tag"">gaming</a>. It's implied that questions on an AI site will be about AI, so there's no need to specify that in a tag. The gerund form makes it clear that gaming is something the AIs are doing.</p>

<p>We can add tags for specific games (like Go) if they become big topics.</p>
",AImeta,would go implied questions ai site ai need specify tag gerund form makes clear gaming something ais add tags specific games like go become big topics
1,"<p>I think we should have first the list of questions which are off-topic here, and on-topic there. If we've enough number of them, the migration target probably can be added later on. For now you can flag each question for moderation, so it can be migrated manually when accepted.</p>

<p>However as far as I've checked, there are only 73 questions tagged with <a href=""https://stats.stackexchange.com/questions/tagged/artificial-intelligence"">artificial-intelligence</a> on Stat.SE where 1/3 of them are still unanswered (24), so I believe some questions about artificial intelligence probably are better suited here. Unless they're specifically related to <a href=""https://stats.stackexchange.com/questions/tagged/machine-learning"">machine-learning</a> where, again, 40% of them are unanswered which make us think where they really belong.</p>

<p>On the other hand, using/programming/implementing AI, at the same time doesn't make me expert on statistics aka cross-validation/rotation estimation model, which to be honest, I don't know nothing about.</p>

<p>And it's not only me:</p>

<blockquote>
  <p>statistical learning is not the path to AI (Artificial Intelligence)</p>
</blockquote>

<p>Source: <a href=""https://www.quora.com/I-once-heard-statistical-learning-is-not-the-path-to-AI-Artificial-Intelligence-what-are-the-arguments-that-support-this-statement-claim"" rel=""nofollow noreferrer"">Quora</a>.</p>
",AImeta,think first list questions topic topic enough number migration target probably added later flag question moderation migrated manually accepted however far checked 73 questions tagged statse 13 still unanswered 24 believe questions artificial intelligence probably better suited unless specifically related 40 unanswered make us think really belong hand using programming implementing ai time make expert statistics aka cross validation rotation estimation model honest know nothing statistical learning path ai artificial intelligence source
1,"<p>Plagiarism is unethical, IMHO: if you're providing a link to a source, it's more than enough. But if you want to provide <em>a cite</em>, then it must be referenced and marked up in appropriate manner</p>
",AImeta,plagiarism unethical imho providing link source enough want provide cite must referenced marked appropriate manner
1,"<p>Some of these tags seem related but I think <a href=""https://ai.stackexchange.com/questions/tagged/game-theory"" class=""post-tag"" title=""show questions tagged &#39;game-theory&#39;"" rel=""tag"">game-theory</a> has a well-known definition (from <a href=""https://en.wikipedia.org/wiki/Game_theory"" rel=""nofollow noreferrer"">wikipedia</a>)</p>

<blockquote>
  <p>the study of mathematical models of conflict and cooperation between
  intelligent rational decision-makers</p>
</blockquote>

<p>and it's applied in other fields besides AI.</p>

<p>IMO there should also be different tags for <code>AI that's used in games</code> and <code>AI that plays games</code>, the first may correspond to <a href=""https://ai.stackexchange.com/questions/tagged/gaming"" class=""post-tag"" title=""show questions tagged &#39;gaming&#39;"" rel=""tag"">gaming</a> <a href=""https://ai.stackexchange.com/questions/tagged/games"" class=""post-tag"" title=""show questions tagged &#39;games&#39;"" rel=""tag"">games</a> or so and I would call the second <a href=""https://ai.stackexchange.com/questions/tagged/game-play"" class=""post-tag"" title=""show questions tagged &#39;game-play&#39;"" rel=""tag"">game-play</a>.</p>

<p>Moreover <a href=""https://en.wikipedia.org/wiki/Go_(game)"" rel=""nofollow noreferrer"">Go</a> refers to that specific board game, which had for long been considered as the only game that humans play better than machines until the AI <a href=""https://en.wikipedia.org/wiki/AlphaGo"" rel=""nofollow noreferrer"">AlphaGo</a> came into play. So <a href=""https://ai.stackexchange.com/questions/tagged/go-game"" class=""post-tag"" title=""show questions tagged &#39;go-game&#39;"" rel=""tag"">go-game</a> seems to be particularly for <a href=""https://en.wikipedia.org/wiki/Go_(game)"" rel=""nofollow noreferrer"">Go</a>.</p>

<p>So IMO at least <a href=""https://ai.stackexchange.com/questions/tagged/game-theory"" class=""post-tag"" title=""show questions tagged &#39;game-theory&#39;"" rel=""tag"">game-theory</a> <a href=""https://ai.stackexchange.com/questions/tagged/go-game"" class=""post-tag"" title=""show questions tagged &#39;go-game&#39;"" rel=""tag"">go-game</a> have clear definitions, and among the others there should be separate tags for <code>AI that's used in games</code> and <code>AI that plays games</code>.</p>
",AImeta,tags seem related think well known definition study mathematical models conflict cooperation intelligent rational decision makers applied fields besides ai imo also different tags first may correspond would call second moreover refers specific board game long considered game humans play better machines ai came play seems particularly imo least clear definitions among others separate tags
1,"<p>Are these tags (<a href=""https://ai.stackexchange.com/questions/tagged/definitions"" class=""post-tag"" title=""show questions tagged &#39;definitions&#39;"" rel=""tag"">definitions</a> vs <a href=""https://ai.stackexchange.com/questions/tagged/terminology"" class=""post-tag"" title=""show questions tagged &#39;terminology&#39;"" rel=""tag"">terminology</a>) should be the same, or one should be synonym over another? Or they have different purpose?</p>
",AImeta,tags vs one synonym another different purpose
1,"<p>Should the following question based on this <a href=""http://arstechnica.co.uk/security/2016/02/the-nsas-skynet-program-may-be-killing-thousands-of-innocent-people/"" rel=""nofollow"">article</a> be on-topic or not?</p>

<ul>
<li>Is it true that NSA's Skynet AI program killed thousands of innocent people?</li>
</ul>

<p>And why?</p>
",AImeta,following question based topic true nsa skynet ai program killed thousands innocent people
1,"<p>I believe questions asked at <a href=""https://stats.stackexchange.com/"">Stats.SE</a> about <a href=""https://stats.stackexchange.com/questions/tagged/artificial-intelligence"">artificial intelligence</a> should be on-topic here as well, because:</p>

<ul>
<li>since past 6 years there were only <a href=""https://stats.stackexchange.com/questions/tagged/artificial-intelligence"">~73 questions asked about AI</a>, 1/3 of them still <a href=""https://stats.stackexchange.com/questions/tagged/artificial-intelligence?sort=unanswered"">unanswered</a>,</li>
<li>40% of question about <a href=""https://stats.stackexchange.com/questions/tagged/machine-learning"">machine-learning</a> are also <a href=""https://stats.stackexchange.com/questions/tagged/machine-learning?sort=unanswered"">unanswered</a>, try scrolling.</li>
</ul>

<p>You may suggest they may lacking of AI experts there, so lets move there. However not all AI experts are using or are interested in statistics models with AI.</p>

<p>For example I'm no where near as statistician, I've no idea about cross-validation aka rotation estimation models, but I may use and implement practical AI algorithms.</p>

<p>Therefore I think our site has already its own distinct and unique scope in comparison to Stats.SE, because it is about pure Artificial Intelligence and beyond.</p>

<p>You can still asks about AI at Stats.SE, but it should be focused to <em>statistical learning</em>. To support that, <a href=""https://stats.meta.stackexchange.com/a/2095/12989"">check this post</a>:</p>

<blockquote>
  <p>Question on AI including a comparison with statistical learning would be pretty clearly on topic here.</p>
</blockquote>

<p>They were accepting even without that, but I think most likely because people didn't have the right place to ask. If they've asked, didn't have much attention (maybe AI experts aren't interested in statistical models).</p>

<p>If you've question about theoretical AI, you can consider asking at: <a href=""https://cstheory.stackexchange.com/questions/tagged/ai.artificial-intel"">CSTheory.SE</a> (not active either).</p>

<p>We can only hope that after <a href=""http://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/"">6 years</a> of previous failures, we're able to break some ice this time.</p>

<p>We've one-time final opportunity to not have AI spread across the whole network:</p>

<p>Stats.SE, CSTheory.SE, CogSci.SE, Philosophy.SE, Worldbuilding.SE, SO.SE, CS.SE, HSM.SE, Robotics.SE, GameDev.SE, gosh where else, with no real AI experts in one place.</p>

<p>So basically the goal of this site is as pointed by <a href=""https://area51.meta.stackexchange.com/questions/11658/faked-artificial-intelligence-like-in-game-development#comment18885_11709"">@lejlot</a>:</p>

<blockquote>
  <p>To bring people from this one particular field, which exists in
  between all above in one place. I see the reason behind it - as now
  questions regarding AI are scattered across these sites and get very
  little attention from actual experts, who also visit just a subset of
  these. Additionally - on each site these questions are tagged in a
  different way, so it is impossible to track them. Unification (new
  site) would make all of it much easier (and in fact - possible for the
  first time).</p>
</blockquote>

<p>If this going to fail this time, people still will have to have 10-20 different accounts to ask the right questions on the right sites (which is very inconvenient). This would be very sad. </p>

<hr>

<p>To summary, <a href=""https://www.quora.com/I-once-heard-statistical-learning-is-not-the-path-to-AI-Artificial-Intelligence-what-are-the-arguments-that-support-this-statement-claim"" rel=""nofollow noreferrer"">some say</a>:</p>

<blockquote>
  <p>statistical learning is not the path to AI (Artificial Intelligence)</p>
</blockquote>

<p>but it's open to debate.</p>
",AImeta,believe questions asked topic well since past 6 years 13 still 40 question also try scrolling may suggest may lacking ai experts lets move however ai experts using interested statistics models ai example near statistician idea cross validation aka rotation estimation models may use implement practical ai algorithms therefore think site already distinct unique scope comparison statsse pure artificial intelligence beyond still asks ai statsse focused statistical learning support question ai including comparison statistical learning would pretty clearly topic accepting even without think likely people right place ask asked much attention maybe ai experts interested statistical models question theoretical ai consider asking active either hope previous failures able break ice time one time final opportunity ai spread across whole network statsse cstheoryse cogscise philosophyse worldbuildingse sose csse hsmse roboticsse gamedevse gosh else real ai experts one place basically goal site pointed bring people one particular field exists one place see reason behind questions regarding ai scattered across sites get little attention actual experts also visit subset additionally site questions tagged different way impossible track unification new site would make much easier fact possible first time going fail time people still 10 20 different accounts ask right questions right sites inconvenient would sad summary statistical learning path ai artificial intelligence open debate
1,"<p>I don't think that question would be on-topic, as it has nothing to do with AI. It is more like a current affairs question.</p>

<p>A relevant question from the article would be maybe about the <code>limitations/shortcomings behind Skynet's AI program which have caused the disaster</code></p>
",AImeta,think question would topic nothing ai like current affairs question relevant question article would maybe
1,"<p>I think the tags are different. Let me explain with an example:</p>

<p><strong>definitions:</strong> What is a deep neural network?</p>

<p><strong>Terminology:</strong> Would this (&lt; Insert some tech. behind some AI product/bot >) be a deep neural network or a RNN?</p>
",AImeta,think tags different let explain example definitions deep neural network terminology would insert tech behind ai product bot deep neural network rnn
1,"<p>At the beginning we were worried that this site won't provide anything useful. Is that still the case?</p>

<p>As <a href=""http://chat.stackexchange.com/transcript/message/31517321#31517321"">@Ben</a> mentioned:</p>

<blockquote>
  <p>Right now, the default state is <strong>fail</strong> unless we can show SE that we bring something new to <em>the</em> network.</p>
</blockquote>

<p>Have we managed to bring something new to the <a href=""http://stackexchange.com/sites#science-questionsperday"">network</a> and this site has found its own distinct and unique scope? What do you think and why?</p>

<hr>

<p>Btw. I've already posted my opinion <a href=""https://ai.meta.stackexchange.com/a/1119/8"">here</a>.</p>
",AImeta,beginning worried site provide anything useful still case mentioned right default state fail unless show se bring something new network managed bring something new site found distinct unique scope think btw already posted opinion
1,"<p>We've this old thread at Area 51 (related to older site proposal which failed):</p>

<ul>
<li><a href=""https://area51.meta.stackexchange.com/q/11659/61861"">How is this proposal different from Cross Validated?</a></li>
</ul>

<p>In general accepted <a href=""https://area51.meta.stackexchange.com/a/11708/61861"">post</a> says:</p>

<blockquote>
  <p>First of all, artificial intelligence is a much broader term than machine learning. While at the same time Cross Validated is not about machine learning, but about statistics.</p>
</blockquote>

<p>Is it still valid point? Can we elaborate on this further more?</p>

<p>How this site is different from <em>Cross Validated</em>? Do we have now more arguments to it?</p>
",AImeta,old thread area 51 related older site proposal failed general accepted says first artificial intelligence much broader term machine learning time cross validated machine learning statistics still valid point elaborate site different cross validated arguments
1,"<p>Can I ask questions that were asked on the closed site as my own? What if I give attribution?</p>
",AImeta,ask questions asked closed site give attribution
1,"<p>I believe so, since all user contributions are licensed under cc by-sa 3.0 with attribution required (including the one from the previous dumps), so as long you give the attribution, that should be fine. In this case, it won't be stealing, but republishing.</p>

<p>See: <a href=""https://ai.stackexchange.com/help/licensing"">What is the license for the content I post?</a></p>

<blockquote>
  <p><a href=""http://blog.stackoverflow.com/2009/06/attribution-required/"">Proper attribution</a> is required if you republish any Stack Exchange content.</p>
</blockquote>
",AImeta,believe since user contributions licensed cc sa 30 attribution required including one previous dumps long give attribution fine case stealing republishing see required republish stack exchange content
1,"<p>A lot of questions are still focused on the technology part of Artificial Intelligence. However, a lot of those questions might fit better on stats.SE, or Data Science.SE. So what is left for this site?</p>

<p>The answer is that there is <em>more</em> than enough left for this site, we just have to explore it. In the past week, over 40 papers tagged Artificial Intelligence have been posted on <a href=""http://arxiv.org/list/cs.AI/recent"" rel=""nofollow"">arXiv</a>. I am sure there are a lot of papers there where we can ask good questions about, that are not on topic on stats.SE or Data.SE. So explore arXiv and ask good questions!</p>
",AImeta,lot questions still focused technology part artificial intelligence however lot questions might fit better statsse data sciencese left site answer enough left site explore past week 40 papers tagged artificial intelligence posted sure lot papers ask good questions topic statsse datase explore arxiv ask good questions
1,"<p>I'm of the opinion that we should allow ML and AI research-style questions here, of the sort that would also <em>could</em> be on-topic at Cross Validated but would be less likely to hit their intended audience there than they would here.</p>

<p>That is, I don't think there is a difference in topics so much as there is a difference between clusters of people who care about those topics, and the perspectives that they bring and the sort of questions and answers that they'll consider interestingly on-topic. </p>
",AImeta,opinion allow ml ai research style questions sort would also could topic cross validated would less likely hit intended audience would think difference topics much difference clusters people care topics perspectives bring sort questions answers consider interestingly topic
1,"<blockquote>
  <p>While at the same time Cross Validated is not about machine learning, but about statistics.</p>
</blockquote>

<p>This is not a valid point, as all machine learning questions are on-topic on CV.</p>

<p>It's unclear to me what extent non-statistical AI is on-topic on CV, so I asked there <a href=""https://stats.meta.stackexchange.com/questions/4257/what-is-our-stance-on-questions-about-non-statistical-artificial-intelligence"">https://stats.meta.stackexchange.com/questions/4257/what-is-our-stance-on-questions-about-non-statistical-artificial-intelligence</a> If no, it makes sense to have a (non-stat?) AI site. If yes, I think we should merge and rename CV.</p>
",AImeta,time cross validated machine learning statistics valid point machine learning questions topic cv unclear extent non statistical ai topic cv asked makes sense non stat ai site yes think merge rename cv
1,"<p>It's a tricky question.</p>
<p><sub><sup><em>This is NOT a site review, but a personal observation having followed this subject on the network for some time.</em></sup></sub></p>
<p>I think we've done a better job at scoping out something fundamentally more useful as a site. The formative question is whether we have a suitable audience to actually build out this space. But that has to happen here and now; they won't just <em>show up</em> later.</p>
<p>Stack Exchange is billed as a network of practitioners helping their peers solve everyday problems. Unfortunately, a large percentage of the questions being asked here sit squarely in the curiosity-seekers space. Questions mostly wallow conspicuously in played-out subjects which &quot;real&quot; AI researches have stopped asking a long ago — Is <em>this</em> AI? What does <em>concept</em> mean? When are we going to get there? When is AI going to do {x}?</p>
<p>I won't pass judgement on whether we've given up on actually building a peer-review site. I talked about some of this in <a href=""https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/"">no artificial intelligence in Area 51</a>.</p>
<p>There are certainly at least a few very knowledgeable people in this community — actual researchers working in this field — but there's a bifurcation of posts from folks with <em>active</em> experience and someone just showing up with whatever they find in a cursory Google search. <strong>The problem is that the community either doesn't know the difference, or doesn't care to vote up one over the other.</strong> It's hard to fault anyone for trying valiantly to get something going here, but watching something from Wikipedia being voted on with equal alacrity is somewhat… discouraging.</p>
<h3>Have we brought something new to the network?</h3>
<p>Probably. Questions here don't generally fit elsewhere.</p>
<h3>Have we created something useful?</h3>
<p>Hard to say; that's a big question for the final review.</p>
<h3>Does this a address a peer group prevalent in this space?</h3>
<p>That does not seem likely —  If you read <a href=""https://blog.stackoverflow.com/2010/07/area-51-asking-the-first-questions/""><strong>Asking the First Questions</strong></a>, I suspect that ship will have sailed by time we reach public beta.</p>
<h3>Have we improved the Internet in general?</h3>
<p>My suspicion is the lack of true peer review in this space will make most of what is posted here about <em>status quo</em> with what you can already find elsewhere. That is by no means certain; that is just my observation.</p>
",AImeta,tricky question site review personal observation followed subject network time think done better job scoping something fundamentally useful site formative question whether suitable audience actually build space happen show later stack exchange billed network practitioners helping peers solve everyday problems unfortunately large percentage questions asked sit squarely curiosity seekers space questions mostly wallow conspicuously played subjects ai researches stopped asking long ago ai concept mean going get ai going x pass judgement whether given actually building peer review site talked certainly least knowledgeable people community actual researchers working field bifurcation posts folks active experience someone showing whatever find cursory google search problem community either know difference care vote one hard fault anyone trying valiantly get something going watching something wikipedia voted equal alacrity somewhat discouraging brought something new network probably questions generally fit elsewhere created something useful hard say big question final review address peer group prevalent space seem likely read suspect ship sailed time reach public beta improved internet general suspicion lack true peer review space make posted status quo already find elsewhere means certain observation
1,"<p>I'd like to point out that every site has a greatest hits page. Ours is at</p>

<p><a href=""https://ai.stackexchange.com/questions/greatest-hits"">https://ai.stackexchange.com/questions/greatest-hits</a></p>

<p>Ours is currently empty, unfortunately, but I suspect that there will be questions there within a month or so. (An older site, Monero, still doesn't have any questions in this list. On the other hand, the Language Learning  site does, but that site is already three months old.)</p>
",AImeta,would like point every site greatest hits page currently empty unfortunately suspect questions within month older site monero still questions list hand language learning site site already three months old
1,"<p>Is there any significant difference between <a href=""https://ai.stackexchange.com/questions/tagged/training"" class=""post-tag"" title=""show questions tagged &#39;training&#39;"" rel=""tag"">training</a> and <a href=""https://ai.stackexchange.com/questions/tagged/pre-training"" class=""post-tag"" title=""show questions tagged &#39;pre-training&#39;"" rel=""tag"">pre-training</a>, or we an have one tag for it?</p>
",AImeta,significant difference one tag
1,"<p>I think there is a bit of a difference between <a href=""https://ai.stackexchange.com/questions/tagged/games"" class=""post-tag"" title=""show questions tagged &#39;games&#39;"" rel=""tag"">games</a> and <a href=""https://ai.stackexchange.com/questions/tagged/gaming"" class=""post-tag"" title=""show questions tagged &#39;gaming&#39;"" rel=""tag"">gaming</a>. I wouldn't call playing Go or chess gaming. I might call it, depending on the context, playing a game. </p>

<p>On the other hand, playing a game such as World of Warcraft or Plants vs. Zombies, I would call gaming. (not that I do it...)</p>
",AImeta,think bit difference would call playing go chess gaming might call depending context playing game hand playing game world warcraft plants vs zombies would call gaming
1,"<p>I wanted to ask which method for spamming detection would be more suitable for certain scenario, <em>Naïve Bayes</em> or <em>Artificial Neural Networks</em>, but then I've found 4 sites where <a href=""https://en.wikipedia.org/wiki/Naive_Bayes_classifier"" rel=""nofollow noreferrer"">Bayes classifiers</a> can be on-topic:</p>

<ul>
<li><a href=""https://stats.stackexchange.com/questions/tagged/naive-bayes"">Stats.SE</a> -> 316 questions (1/3 unanswered),</li>
<li><a href=""https://datascience.stackexchange.com/questions/tagged/naive-bayes-classifier"">DataScience.SE</a> -> 17 questions (4 unanswered)</li>
<li><a href=""https://math.stackexchange.com/questions/tagged/naive-bayes"">Math.SE</a> -> 35 questions (half unanswered),</li>
<li><a href=""https://cs.stackexchange.com/questions/tagged/bayesian-statistics"">CS.SE</a> -> 13 questions about bayesian statistics (no specific tag for classifiers),</li>
<li><a href=""https://cstheory.stackexchange.com/search?q=Bayes"">CSTheory.SE</a> -> 17 results on Bayes word, no tags for it at all.</li>
</ul>

<p>But then I've found that Wikipedia page for <a href=""https://en.wikipedia.org/wiki/Naive_Bayes_classifier"" rel=""nofollow noreferrer"">Naive Bayes classifier</a> says:</p>

<blockquote>
  <p><strong>In machine learning</strong>, naive Bayes classifiers are ...</p>
</blockquote>

<p>It doesn't say <em>in statistics</em> as oppose to <a href=""https://en.wikipedia.org/wiki/Sampling_(statistics)"" rel=""nofollow noreferrer"">'sampling'</a> (as example), where we can read:</p>

<blockquote>
  <p>In <strong>statistics</strong>, quality assurance, and survey methodology, sampling is </p>
</blockquote>

<p>It says specifically in <strong>machine learning</strong>, not statistics, which further more, the machine learning is a sub-field of Artificial Intelligence (as suggested in this <a href=""http://cs.colby.edu/courses/S15/cs251/LectureNotes/Lecture_15_MLandDMintro_03_09_2015.pdf"" rel=""nofollow noreferrer"">paper</a> or <a href=""https://area51.meta.stackexchange.com/q/9502/61861"">here</a>):</p>

<blockquote>
  <p><strong>Machine learning, a branch of artificial intelligence</strong>, is about the construction and study of systems that can learn from data.</p>
</blockquote>

<p>To make it more tricky, the <a href=""https://en.wikipedia.org/wiki/Machine_learning"" rel=""nofollow noreferrer"">machine learning</a> is also a subfield of computer science (as per wiki page). But on the other hand I'm not interested discussing math equations which I'm seeing a lot on <a href=""https://stats.stackexchange.com/q/151179/12989"">CS.SE</a>, because I'm looking for more practical oriented answers, not theories. Secondly they've not specific tags for these classifiers. I'm also not studying this topic (on academia level), but I'm doing this as a hobby, or more specifically, investigating practical problem solutions in my app stack.</p>

<p>Based on above logic, does it mean asking AI.SE is the most suitable place to ask practical questions about spamming detection using Bayes classifiers?</p>
",AImeta,wanted ask method spamming detection would suitable certain scenario naïve bayes artificial neural networks found 4 sites topic 316 questions 13 unanswered 17 questions 4 unanswered 35 questions half unanswered 13 questions bayesian statistics specific tag classifiers 17 results bayes word tags found wikipedia page says machine learning naive bayes classifiers say statistics oppose example read statistics quality assurance survey methodology sampling says specifically machine learning statistics machine learning sub field artificial intelligence suggested machine learning branch artificial intelligence construction study systems learn data make tricky also subfield computer science per wiki page hand interested discussing math equations seeing lot looking practical oriented answers theories secondly specific tags classifiers also studying topic academia level hobby specifically investigating practical problem solutions app stack based logic mean asking aise suitable place ask practical questions spamming detection using bayes classifiers
1,"<p>I think most questions about Naive Bayes classifier belong on stats.SE or data.SE. </p>

<p>It is part of data mining and data science, and it is probably on-topic on data.SE. Some examples of posts on data.SE that appear to be similiar to the question you want to ask:</p>

<ul>
<li><a href=""https://datascience.stackexchange.com/questions/1197/how-can-i-classify-text-considering-word-order-instead-of-just-using-a-bag-of-w"">How can I classify text considering word order, instead of just using a bag-of-words approach?</a></li>
<li><a href=""https://datascience.stackexchange.com/questions/6464/spam-detection-in-social-media/6466#6466"">Spam detection in social media</a>. This question uses another method, but Bayes is suggested in an answer.</li>
</ul>

<p>A question on stats.SE that is similiar: <a href=""https://stats.stackexchange.com/questions/50765/simple-text-classifier-classification-taking-forever/50792#50792"">Simple text classifier: classification taking forever?</a></p>

<p>The point is, a theoretical question about the Naive Bayes classifier will probably belong on stats.SE since it involves probability and statistics. An applied question would probably be better on data.SE. </p>

<p>Also, your wiki argument is not a really good one, since anyone can add or remove such sentence. Here is one from an other language that start with such sentence:</p>

<blockquote>
  <p>En teoría de la probabilidad y minería de datos, un clasificador Bayesiano [...] <br> (In the theory of probability and data mining, a Bayes classifier [...])</p>
</blockquote>
",AImeta,think questions naive bayes classifier belong statsse datase part data mining data science probably topic datase examples posts datase appear similiar question want ask question uses another method bayes suggested answer question statsse similiar point theoretical question naive bayes classifier probably belong statsse since involves probability statistics applied question would probably better datase also wiki argument really good one since anyone add remove sentence one language start sentence en teoría de la probabilidad minería de datos un clasificador bayesiano theory probability data mining bayes classifier
1,"<p>I think there should be two tags here:</p>

<p><strong><a href=""https://ai.stackexchange.com/questions/tagged/gaming"" class=""post-tag"" title=""show questions tagged &#39;gaming&#39;"" rel=""tag"">gaming</a> and <a href=""https://ai.stackexchange.com/questions/tagged/game-theory"" class=""post-tag"" title=""show questions tagged &#39;game-theory&#39;"" rel=""tag"">game-theory</a>.</strong></p>

<p><a href=""https://ai.stackexchange.com/questions/tagged/gaming"" class=""post-tag"" title=""show questions tagged &#39;gaming&#39;"" rel=""tag"">gaming</a> is for how AIs are used <em>in games</em>.</p>

<p><a href=""https://ai.stackexchange.com/questions/tagged/game-theory"" class=""post-tag"" title=""show questions tagged &#39;game-theory&#39;"" rel=""tag"">game-theory</a> should be used for AIs <em>playing games</em>.</p>
",AImeta,think two tags ais used games used ais playing games
1,"<p>Currently, I don't know what it's being used for<sup>1</sup>. What should it be used for? Should we burninate it?</p>

<hr>

<p><sub><sup>1</sup>Actually, it looks like its being used both for research claims and when people want to find something out.</sub></p>
",AImeta,currently know used 1 used burninate 1 actually looks like used research claims people want find something
1,"<p>Currently I think it is used when the question is about some specific research or study, or it expects some authoritative study references from the answers.</p>
<p><a href=""https://academia.stackexchange.com/questions/tagged/research"">Academia.SE</a> has similar tag and it's described as:</p>
<blockquote>
<p>Questions directly focused on performing academic research applicable to any discipline.</p>
<p>This tag is only for questions that are directly about research. Do not use it for questions tangentially related to research.</p>
<p>For example, if you are asking about how to best cite something, you are probably doing so because you are publishing your research. Such a question would only be <strong>related</strong> to research, but not about it, and should thus not be tagged <a href=""https://ai.stackexchange.com/questions/tagged/research"" class=""post-tag"" title=""show questions tagged &#39;research&#39;"" rel=""tag"">research</a>. If you are however asking, e.g., how to best organise your research, the question is actually <strong>about</strong> research and thus should be tagged <a href=""https://ai.stackexchange.com/questions/tagged/research"" class=""post-tag"" title=""show questions tagged &#39;research&#39;"" rel=""tag"">research</a>.</p>
</blockquote>
",AImeta,currently think used question specific research study expects authoritative study references answers similar tag described questions directly focused performing academic research applicable discipline tag questions directly research use questions tangentially related research example asking best cite something probably publishing research question would related research thus tagged however asking eg best organise research question actually research thus tagged
1,"<p>Is <a href=""https://ai.stackexchange.com/questions/tagged/decision-theory"" class=""post-tag"" title=""show questions tagged &#39;decision-theory&#39;"" rel=""tag"">decision-theory</a> tag basically the same as <a href=""https://ai.stackexchange.com/questions/tagged/decision-making"" class=""post-tag"" title=""show questions tagged &#39;decision-making&#39;"" rel=""tag"">decision-making</a>?</p>

<p>For example, can this question:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/1561/8"">Would Google&#39;s self-driving-car stop when it sees somebody with a T-shirt with a stop sign printed on it?</a></li>
</ul>

<p>had <a href=""https://ai.stackexchange.com/questions/tagged/decision-making"" class=""post-tag"" title=""show questions tagged &#39;decision-making&#39;"" rel=""tag"">decision-making</a> tag, however it has been suggested to have one unified <a href=""https://ai.stackexchange.com/questions/tagged/decision-theory"" class=""post-tag"" title=""show questions tagged &#39;decision-theory&#39;"" rel=""tag"">decision-theory</a>.</p>

<p>I'm asking, because decision theory is 'a study of the reasoning', so it's confusing for me whether simple AI decision can be included under this tag as well?</p>
",AImeta,tag basically example question tag however suggested one unified asking decision theory study reasoning confusing whether simple ai decision included tag well
1,"<p>By AI programming, I mean somebody asks how to solve programming issue which deals with AI logic specifically, e.g.</p>
<ul>
<li><a href=""https://ai.stackexchange.com/q/1570/8"">Why does my NN not classify these tic tac toe pattern correctly?</a></li>
</ul>
<p>The above example uses Keras, highly modular neural networks library written in Python.</p>
<hr />
<p>Are these off-topic and why they cannot be here?</p>
<p>If not, would be this ever considered? Especially the code which is very specific to AI coding?</p>
<hr />
<p>Related: <a href=""https://ai.meta.stackexchange.com/a/46/8"">What kind of experts are we trying to attract?</a></p>
<blockquote>
<p>In fact, I think now that implementation questions would benefit from a dedicated site (my view has evolved since the Area 51 definition phase). I have replied and tried to reply to several SO questions related to ML tools, and I think some are out of place compared to other questions. For example, some TensorFlow questions are not really programming questions, and not really framework questions. I mean, there is background knowledge on graph construction and execution, as well as background knowledge about statistics and probabilities that are really necessary to make meaningful contributions.</p>
<p>This is not to say that all questions are out of place on SO. Some are really framework issues or (Python) programming issues, and they are good there.</p>
<p>Based on this opinion, I think the site should be interested in implementation experts, whether they work on ML or Expert Systems (or both?).</p>
<p>-- @EricPlaton</p>
</blockquote>
<hr />
<p>So we're talking about coding highly modular neural networks libraries which require advanced background knowledge and AI expertise, and it was suggested.</p>
<p>The same as other specific modular frameworks, where coding questions are on-topic on their dedicated websites, they're allowed on: <a href=""https://drupal.stackexchange.com/"">Drupal.SE</a>, <a href=""https://wordpress.stackexchange.com/"">Wordpress.SE</a>, <a href=""https://tex.stackexchange.com/"">TeX.SE</a>, <a href=""https://salesforce.stackexchange.com/questions/tagged/apex"">Apex at Salesforce.SE</a>, etc. For a standard programmer without specific expertise, these are a bit of out-of-place on Stack Overflow.</p>
",AImeta,ai programming mean somebody asks solve programming issue deals ai logic specifically eg example uses keras highly modular neural networks library written python topic would ever considered especially code specific ai coding related fact think implementation questions would benefit dedicated site view evolved since area 51 definition phase replied tried reply several questions related ml tools think place compared questions example tensorflow questions really programming questions really framework questions mean background knowledge graph construction execution well background knowledge statistics probabilities really necessary make meaningful contributions say questions place really framework issues python programming issues good based opinion think site interested implementation experts whether work ml expert systems ericplaton talking coding highly modular neural networks libraries require advanced background knowledge ai expertise suggested specific modular frameworks coding questions topic dedicated websites allowed etc standard programmer without specific expertise bit place stack overflow
1,"<p>Upvote <em>only</em> good questions.</p>

<p>Down- and/or close-vote <em>all</em> bad questions.</p>
",AImeta,upvote good questions andor close vote bad questions
1,"<p>You can see that <a href=""http://area51.stackexchange.com/proposals/93481?phase=commitment"">here</a>. However, most of the questions here feel rather more on the technological side of artificial intelligence. Those questions are on-topic on Data Science. <em>That</em> site was created as a site for the technological aspect of machine learning and AI, and <em>that</em> is the site that is in the Technology category (see <a href=""http://area51.stackexchange.com/proposals/55053?phase=beta"">here</a>), in spite of having &quot;Science&quot; in its name.</p>
<p>This was already emphasized by Robert Cartaino on <a href=""https://area51.meta.stackexchange.com/questions/24014/will-machine-learning-be-considered-as-on-topic"">Area 51</a>:</p>
<blockquote>
<p>Data Science is an <em>applied</em> site for all the programmers/statisticians/mathematicians who are trying to make this stuff <em>work</em>. [...]</p>
<p>Notice that this proposal is in the 'Science' category; <em>not</em> 'Technology'.  [...]</p>
<p>It was convincing enough to give this site another try, but if this site were to simply start reiterating the implementation/tools questions that are already covered elsewhere, this site will not likely make it out of private beta.</p>
</blockquote>
<br>
<p>I already tried to give a hint where we could find science questions here:
<a href=""https://ai.meta.stackexchange.com/questions/1126/where-can-we-find-the-science-part-of-artificial-intelligence"">Where can we find the science part of Artificial Intelligence?</a> That is one thing we could do: ask more science questions. The other thing we can do, is closing questions. <em>Please do close</em> questions that are highly technological or asking for applications.</p>
<hr />
<p>I'd like to link some questions that are, in my opinion (but I could be wrong), scientifical :</p>
<ul>
<li><a href=""https://ai.stackexchange.com/questions/92/how-is-it-possible-that-deep-neural-networks-are-so-easily-fooled"">How is it possible that deep neural networks are so easily fooled?</a></li>
<li><a href=""https://ai.stackexchange.com/questions/74/what-is-the-difference-between-strong-ai-and-weak-ai"">What is the difference between strong-AI and weak-AI?</a></li>
<li><a href=""https://ai.stackexchange.com/questions/148/what-limits-if-any-does-the-halting-problem-put-on-artificial-intelligence"">What limits, if any, does the halting problem put on Artificial Intelligence?</a></li>
<li><a href=""https://ai.stackexchange.com/questions/1397/are-there-any-ai-that-have-passed-the-mist-test-so-far"">Are there any AI that have passed the MIST test so far?</a></li>
<li><a href=""https://ai.stackexchange.com/questions/1451/has-the-lovelace-test-2-0-been-successfully-used-in-an-academic-setting"">Has the Lovelace Test 2.0 been successfully used in an academic setting?</a></li>
<li><a href=""https://ai.stackexchange.com/questions/123/does-the-chinese-room-argument-hold-against-ai"">Does the Chinese Room argument hold against AI?</a></li>
<li><a href=""https://ai.stackexchange.com/questions/1479/do-scientists-know-what-is-happening-inside-artificial-neural-networks"">Do scientists know what is happening inside artificial neural networks?</a></li>
<li><a href=""https://ai.stackexchange.com/questions/1525/could-a-boltzmann-machine-store-more-patterns-than-a-hopfield-net"">Could a Boltzmann machine store more patterns than a Hopfield net?</a></li>
</ul>
<p>There are more questions around that are scientifical and high-quality (fortunately), I just picked a few from the first page of the highest voted list.</p>
",AImeta,see however questions feel rather technological side artificial intelligence questions topic data science site created site technological aspect machine learning ai site technology category see spite name already emphasized robert cartaino data science applied site programmers statisticians mathematicians trying make stuff work notice proposal iscience category notechnology convincing enough give site another try site simply start reiterating implementation tools questions already covered elsewhere site likely make private beta already tried give hint could find science questions one thing could ask science questions thing closing questions please close questions highly technological asking applications would like link questions opinion could wrong scientifical questions around scientifical high quality fortunately picked first page highest voted list
1,"<p>Also a friendly reminder that our <a href=""https://ai.stackexchange.com/tour"">tour page</a> (also <a href=""http://area51.stackexchange.com/proposals/93481/artificial-intelligence"">proposal</a>) states:</p>

<blockquote>
  <p>A question and answer site for people interested in <strong>conceptual questions about life and challenges in a world</strong> where ""cognitive"" functions can be mimicked in purely digital environment. It's built and run by you.</p>
</blockquote>

<p>So I don't see the reason why both kind of questions can be on-topic, conceptual and scientific or similar, otherwise we're limiting without any good reason.</p>

<p>Also please remember that it's run by us, so everybody can decide whether question should be on-topic by voting on it.</p>
",AImeta,also friendly reminder also states question answer site people interested conceptual questions life challenges world cognitive functions mimicked purely digital environment built run see reason kind questions topic conceptual scientific similar otherwise limiting without good reason also please remember run us everybody decide whether question topic voting
1,"<p>Clearly, <a href=""https://stats.stackexchange.com/"">Cross Validated</a> is about statistics - it's even in the URL, <code>stats.stackexchange.com</code>. They're a very math-heavy and calculation-oriented site. MathJax is enabled there, and every question I scanned from their front page involves code or mathematical formulae. <a href=""https://ai.stackexchange.com/questions/tagged/machine-learning"" class=""post-tag"" title=""show questions tagged &#39;machine-learning&#39;"" rel=""tag"">machine-learning</a> is their third most popular tag at the moment, and <a href=""https://stats.stackexchange.com/questions/tagged/machine-learning"">questions in it</a> are about the stats/math involved in machine learning.</p>

<p>Questions here are not expected to involve that level of detail. MathJax is not enabled here, and that <a href=""https://ai.meta.stackexchange.com/q/35/75"">might</a> be purposeful. Our questions should be about the <a href=""https://area51.meta.stackexchange.com/a/24016/136466"">science</a> - not so much the technology or math or implementation of - artificial intelligence. (For machine learning implementation, see <a href=""https://datascience.stackexchange.com/"">Data Science</a>.)</p>
",AImeta,clearly statistics even url math heavy calculation oriented site mathjax enabled every question scanned front page involves code mathematical formulae third popular tag moment stats math involved machine learning questions expected involve level detail mathjax enabled purposeful questions much technology math implementation artificial intelligence machine learning implementation see
1,"<p>I've seen this argument come up <a href=""https://ai.meta.stackexchange.com/a/1142/95"">here</a> and several times in other discussions about scope:</p>

<blockquote>
  <p>I don't see why both kinds of questions can't be on-topic</p>
</blockquote>

<p>It's because the OPPOSITION against creating this site argued (correctly) that we already created sites to handle this subject explicitly. The argument FOR creating this site claimed that we have a missing socio-scientific angle that needed filling. </p>

<p><strong>Private beta tests if that is a valid premise for creating a NEW site.</strong> </p>

<p>If the founding community does not live up to those expectations, it creates a strong argument for ""I told you so"" &mdash; that the initiative has failed. </p>

<p><strong>Stick to the mission.</strong> </p>

<p>Don't give credence to arguments for closure.</p>
",AImeta,seen argument come several times discussions scope see kinds questions topic opposition creating site argued correctly already created sites handle subject explicitly argument creating site claimed missing socio scientific angle needed filling private beta tests valid premise creating new site founding community live expectations creates strong argument told initiative failed stick mission give credence arguments closure
1,"<p>Ok, it's a new site and it's beta and everything... </p>

<p>But it's fun to think about these things too, isn't it?</p>

<p><strong>Do you have proposal on an image for a site's logo?</strong></p>

<p>(A little explanation would be nice too)</p>
",AImeta,ok new site beta everything fun think things proposal image site logo little explanation would nice
1,"<p>Sure I have an image myself:</p>

<p><a href=""https://i.stack.imgur.com/awUym.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/awUym.png"" alt=""enter image description here""></a></p>

<p>It is fairly easy and with high to recognition value. It has like everything to do with AI and is a discussion topic for <a href=""https://duckduckgo.com/?q=hal+9000+costume&amp;t=canonical&amp;iax=1&amp;ia=images"" rel=""nofollow noreferrer"">every party</a> :)</p>
",AImeta,sure image fairly easy high recognition value like everything ai discussion topic
1,"<p>I have learned a lot reading xkcd and talking about Hal9000 and Solaris over a beer. Granted: that does not make me any expert in AI, by far. But I see some value to it:</p>

<ul>
<li>I get to know concepts that I look up afterwards</li>
<li>I reflect and try to imagine new problems and solutions</li>
<li>I get another view on news or current (technical) problems I face</li>
<li>I get some things to procrastinate on</li>
</ul>

<p>What do you think about questions related to cinema, books and novels, science fiction, etc? What about jokes and funny AI-stuff? </p>

<p>I am not very sharp right now, but maybe something like:</p>

<p><strong>Was HAL9000 programmed to be an egoistic jerk or he just developed it by itself?</strong></p>

<p>Or:</p>

<p><strong>What is your favourite AI-joke?</strong></p>

<p>(<a href=""https://stackoverflow.com/questions/234075/what-is-your-best-programmer-joke/234476"">yeah, got it here :)</a>)</p>
",AImeta,learned lot reading xkcd talking hal9000 solaris beer granted make expert ai far see value get know concepts look afterwards reflect try imagine new problems solutions get another view news current technical problems face get things procrastinate think questions related cinema books novels science fiction etc jokes funny ai stuff sharp right maybe something like hal9000 programmed egoistic jerk developed favourite ai joke
1,"<p>The first question about HAL9000 I believe is on-topic either on <a href=""https://movies.stackexchange.com/"">Movies.SE</a>, <a href=""https://scifi.stackexchange.com/"">Sci-fi.SE</a> or <a href=""https://worldbuilding.stackexchange.com/questions/tagged/artificial-intelligence"">WorldBuilding.SE</a>, but not in here, where we require some real-world questions, not related to science fiction.</p>

<p>The second one regarding a joke, the quote from the closure reason from that link says it:</p>

<blockquote>
  <p>is not considered a good, on-topic question for this site</p>
</blockquote>

<p>this is because opinion-like questions or the one which are asking something from unlimited list of possibilities <a href=""https://meta.stackexchange.com/a/98366/191655"">'are not a good fit for this type of Q&amp;A site'</a>. As said by <a href=""https://meta.stackexchange.com/a/98366/191655"">@RCartaino</a>:</p>

<blockquote>
  <p>Stack Exchange is well-suited to asking very specific questions that represent real problems you encounter in your day-to-day work. A big part of that process is asking very long-tailed questions; the kind where folks with specific expertise in the subject can propose the best possible answer, which is then voted on so the best possible answers rise to the top.</p>
</blockquote>

<p>There was actually Humor site proposal, but it was <a href=""https://area51.meta.stackexchange.com/q/24036/61861"">closed</a>, because of above reasons.</p>
",AImeta,first question hal9000 believe topic either require real world questions related science fiction second one regarding joke quote closure reason link says considered good topic question site opinion like questions one asking something unlimited list possibilities said stack exchange well suited asking specific questions represent real problems encounter day day work big part process asking long tailed questions kind folks specific expertise subject propose best possible answer voted best possible answers rise top actually humor site proposal reasons
1,"<p>No, they're not. ""Getting to know you"" or fun, minimal-mind questions are not a good fit for Stack Exchange. Notice how the Stack Overflow question you linked is locked. If it hadn't been locked for historical significance, it would definitely have been deleted.</p>

<p>Especially during the private beta, we must focus on producing quality content. For fun, try <a href=""http://chat.stackexchange.com/rooms/43371/artificial-intelligence"">chat</a>!</p>
",AImeta,getting know fun minimal mind questions good fit stack exchange notice stack overflow question linked locked locked historical significance would definitely deleted especially private beta must focus producing quality content fun try
1,"<p>On what basis the:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/1560/8"">How does Google&#39;s self-driving car identify pedestrians?</a></li>
</ul>

<p>question has been closed?</p>

<p>The reason of closure was that it's off-topic and 'does not appear to be about artificial intelligence'.</p>

<p>However it asks about how specific AI mechanisms/algorithm works, which is basically how it recognizes objects such as people.</p>

<p>I believe it matches our <a href=""https://ai.stackexchange.com/tour"">scope</a> which says:</p>

<blockquote>
  <p>conceptual questions about life and challenges in a world where ""cognitive"" functions can be mimicked in purely digital environment</p>
</blockquote>
",AImeta,basis question closed reason closure topic wouldoes appear artificial intelligence however asks specific ai mechanisms algorithm works basically recognizes objects people believe matches says conceptual questions life challenges world cognitive functions mimicked purely digital environment
1,"<p>This question:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/16/8"">What is early stopping?</a></li>
</ul>

<p>has been closed as off-topic.</p>

<p>I don't see the reason why it should.</p>

<p>The 'early stopping', in machine learning (<strong>branch of AI</strong>) is used to avoid overfitting when training. Therefore I don't see this question as off-topic.</p>
",AImeta,question closed topic see reason early stopping machine learning branch ai used avoid overfitting training therefore see question topic
1,"<p>If you don't like a question, down-vote it.  That said, I disagree with the premise that there's a problem and ""ZOMG, s0meth1ng mus7 b3 d0ne, won'7 s0mebody th1nk of th3 ch1ldr3n1?!??!???""   </p>

<p>You can't dictate through top down command and control how a community should behave.  Just because the powers-that-be at StackExchange say ""no subjective questions"" doesn't mean that we need to reflect that and get all up in arms over any question that allows from an element of subjectivity.  The community will be what the community is, quit trying to social-engineer it. </p>

<blockquote>
  <p>There are already quite a few questions going beyond the original (blurry) boundary of the proposal, notably on implementation issues.</p>
</blockquote>

<p>Then the original boundary was wrong.</p>
",AImeta,like question vote said disagree premise problem zomg s0meth1ng mus7 b3 d0ne won7 s0mebody th1nk th3 ch1ldr3n1 dictate top command control community behave powers stackexchange say subjective questions mean need reflect get arms question allows element subjectivity community community quit trying social engineer already quite questions going beyond original blurry boundary proposal notably implementation issues original boundary wrong
1,"<p>I was one of the close voters, and let me explain here why I voted to close. </p>

<p>As I, and some other users, have said <em>multiple times</em> before, we should avoid questions that are only related to machine learning. Those questions are already on-topic on both Data Science and Cross Validated. </p>

<p>The point of creating this site was filling a gap that was not already covered by Data Science and Cross Validated. Early stopping is on-topic on both sites (<a href=""https://stats.stackexchange.com/search?q=early+stopping"">1</a>, <a href=""https://datascience.stackexchange.com/search?q=early+stopping"">2</a>). Remember that if this site looks to much like Data Science and/or Cross Validated it <em>will most likely <strong>not</strong> get out of private beta</em>.</p>
",AImeta,one close voters let explain voted close users said multiple times avoid questions related machine learning questions already topic data science cross validated point creating site filling gap already covered data science cross validated early stopping topic sites remember site looks much like data science andor cross validated likely get private beta
1,"<p>If I had voted to close it, I would have done so as ""too broad."" It's not entirely clear what an answer should contain: a response to ""how <strong>exactly</strong> does it identify people on the street?"" would have to go extremely deep. Notice how the answer, while very interesting, doesn't explain how the car figures out how to highlight what objects. As mentioned in a comment, it's unlikely that anyone without access to the source code will be able to give definitive details.</p>
",AImeta,voted close would done broad entirely clear answer contain response exactly identify people street would go extremely deep notice answer interesting explain car figures highlight objects mentioned comment unlikely anyone without access source code able give definitive details
1,"<p>Data science and the Stats SE already have a huge overlap (>~80%), and I am worried to have a third SE that also significantly overlaps with them, so that why I VTC. </p>

<p>I think the best solution would be along the lines of this proposal: <a href=""https://meta.stackexchange.com/q/199989/178179"">build and strengthen the Stack Exchange community with “crossover questions” between sites</a>.</p>
",AImeta,data science stats se already huge overlap 80 worried third se also significantly overlaps vtc think best solution would along lines proposal
1,"<p>After 10 days, the metrics on Area 51 seem to indicate that the site is doing well, except for the lack of users (""experts"") and visits.</p>

<ul>
<li>16.2 questions per day (10 questions per day is healthy, 5 questions need works)</li>
<li>85% answered (90% is healthy, 80% need works)</li>
<li>1.7 answers per questions (2.5 is healthy, 1 needs works)</li>
<li>108 visits/per day (1500 is healthy, 500 need works)</li>
<li>25 users with 200+ rep (250 users is healthy)</li>
</ul>

<p>Yet, it doesn't seem as though the site is actually healthy, as the question <a href=""https://ai.meta.stackexchange.com/questions/1122/have-we-brought-something-new-to-the-network"">Have we brought something new to the network?</a>, suggests. It seems that there is a high chance of closure, despite the stats supposedly being on our side.</p>

<p>However, interest in AI is <em>not</em> going away. It hasn't gone away the last time an AI StackExchange was proposed and shut down. We still need to deal with the humanities aspect of this field...and to help try to ""demystify"" the field of artificial intelligence. Until we get a good answer to this problem of dealing with artificial intelligence in a unified manner, all that's going to happen is a <em>fourth</em> AI proposal.</p>

<p>Now, technically, there are many sites that can handle AI questions. I mentioned about them in <a href=""https://area51.meta.stackexchange.com/a/23515/152111"">this Area51 post</a>, and how a programmer could build an AI simply by cobbling together answers from multiple StackExchange sites. I also stated that the <em>de facto</em> solution to the AI problem is a very problematic one:</p>

<blockquote>
  <p>The AI programmer is stuck traveling from one site to another (though Google is helping out), asking questions on each individual site, to try and figure out how to accomplish his single goal. This AI programmer is a migratory beast, out to stitch together random answers on Stack Exchange into a coherent 'whole' that he can then use. ... Is it sensible for AI programmers to be <em>dependent</em> on 6 to 8 different sites, at any given time? Is it sensible for these 6 to 8 sites to <em>pander</em> to these AI programmers instead of answering other questions? Or is it better to instead consolidate AI-specific questions from these 6 to 8 different sites, onto a single site that is easy to browse and look up? Some overlap between the communities may be inevitable, but it's better than the current status quo.</p>
</blockquote>

<p>This idea has been <a href=""https://area51.meta.stackexchange.com/a/25180/152111"">resurrected by by kenorb recently</a> very recently:</p>

<blockquote>
  <p>If it fails, the backup is to have 20 different accounts and ask the AI questions across the different sites such as Stats.SE, CSTheory.SE, CogSci.SE, Philosophy.SE, Worldbuilding.SE, SO.SE, CS.SE, HSM.SE, Robotics.SE, GameDev.SE, with no real AI experts focused in one place.</p>
</blockquote>

<p>I have built <a href=""http://stackai.herokuapp.com"" rel=""nofollow noreferrer"">""StackAI""</a>, a StackExchange aggregator of several AI-related StackExchange sites which I may plan on upgrading in the future to include other AI-related StackExchange sites (such as CogSci, Robotics, etc.). But I'm still dubious on whether this site would indeed be the best solution for our crisis. It's a good one-stop directory to help a migratory questioner know <em>where</em> they can ask their questions, but the process is still rather inefficient and we lack the consolidation that a standard AI site could provide for us...and, of course, I doubt that these other sites would even <em>appreciate</em> the influx of these migratory questioners.</p>

<p>Is there a better way to deal with the migratory AI questioner? Even if it is to just improve StackAI?</p>

<p>I get discouraged and cynical rather easily, so maybe I'm being overly pessimistic about this site. But I do care about helping out people, and will want to help them out, even if ""ai.stackexchange.com"" dies again.</p>
",AImeta,10 days metrics area 51 seem indicate site well except lack users experts visits 162 questions per day 10 questions per day healthy 5 questions need works 85 answered 90 healthy 80 need works 17 answers per questions 25 healthy 1 needs works 108 visits per day 1500 healthy 500 need works 25 users 200 rep 250 users healthy yet seem though site actually healthy question suggests seems high chance closure despite stats supposedly side however interest ai going away gone away last time ai stackexchange proposed shut still need deal humanities aspect field help try demystify field artificial intelligence get good answer problem dealing artificial intelligence unified manner going happen fourth ai proposal technically many sites handle ai questions mentioned programmer could build ai simply cobbling together answers multiple stackexchange sites also stated de facto solution ai problem problematic one ai programmer stuck traveling one site another though google helping asking questions individual site try figure accomplish single goal ai programmer migratory beast stitch together random answers stack exchange coherent whole use sensible ai programmers dependent 6 8 different sites given time sensible 6 8 sites pander ai programmers instead answering questions better instead consolidate ai specific questions 6 8 different sites onto single site easy browse look overlap communities may inevitable better current status quo idea recently fails backup 20 different accounts ask ai questions across different sites statsse cstheoryse cogscise philosophyse worldbuildingse sose csse hsmse roboticsse gamedevse real ai experts focused one place built stackexchange aggregator several ai related stackexchange sites may plan upgrading future include ai related stackexchange sites cogsci robotics etc still dubious whether site would indeed best solution crisis good one stop directory help migratory questioner know ask questions process still rather inefficient lack consolidation standard ai site could provide us course doubt sites would even appreciate influx migratory questioners better way deal migratory ai questioner even improve stackai get discouraged cynical rather easily maybe overly pessimistic site care helping people want help even aistackexchangecom dies
1,"<p>I think it's too early to worry about what to do if the site closes. We're different from previous AI sites in a couple important ways, and though we're not completely free of issues, we're making progress. For what it's worth, the target statistics on Area 51 are what you should expect from a site about to fully graduate (not one about to continue into public beta).</p>

<p>Without this site, the topic of artificial intelligence is indeed split across the network. Fortunately, each site's scope is fairly well-defined, so even if finding a good site is tricky, checking whether a question is OK for a given site is quite doable. <a href=""https://meta.stackexchange.com/"">Meta Stack Exchange</a> can help find a good home for questions - they even have <a href=""https://meta.stackexchange.com/questions/tagged/site-recommendation"">a tag for such inquiries</a>, and I think a question for routing people to the right AI site would be in order.</p>

<p>Again, don't get too worried. We'll cross that bridge if we come to it.</p>
",AImeta,think early worry site closes different previous ai sites couple important ways though completely free issues making progress worth target statistics area 51 expect site fully graduate one continue public beta without site topic artificial intelligence indeed split across network fortunately site scope fairly well defined even finding good site tricky checking whether question ok given site quite doable help find good home questions even think question routing people right ai site would order get worried cross bridge come
1,"<p><em>Have we brought something new to the network?</em></p>

<p>I think so. Yes, there's overlap with other sites, and yes it would be nice to have more deeper / research level questions and answers.  But I posit that getting to that level will happen IF the site is given enough time.  That and if we don't chase too many users away with too much bureaucracy and pedantry.</p>

<p>Remember the old ai.se was actually working well, just at a scale that was - at the time - deemed too small by the se powers-that-be.  If this site is allowed to live post-beta, I expect it to get steadily better. Keep in mind,  AI is difficult because it's such a broad topic.  And even now there's lingering resistance among some people to talking about ""artificial intelligence"" (as opposed to ""machine learning"", etc.) after the various AI Winters of the past.  </p>
",AImeta,brought something new network think yes overlap sites yes would nice deeper research level questions answers posit getting level happen site given enough time chase many users away much bureaucracy pedantry remember old aise actually working well scale time deemed small se powers site allowed live post beta expect get steadily better keep mind ai difficult broad topic even lingering resistance among people talking artificial intelligence opposed machine learning etc various ai winters past
1,"<p>Each time when I log in to the site, it shows there are some unread review items (4, sometimes 5), but most of the time there are always none (all zeros) when clicking.</p>

<blockquote>
  <p>4 total posts awaiting review</p>
</blockquote>

<p>I believe the cache is too aggressive or something, as I didn't see this much on other sites. I've checked in <em>incognito</em> mode (without cookies) and it's the same thing.</p>

<p><a href=""https://i.stack.imgur.com/mzd2Om.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mzd2Om.png"" alt=""SE review unread count""></a></p>

<p>Anybody else has the same issue?</p>
",AImeta,time log site shows unread review items 4 sometimes 5 time always none zeros clicking 4 total posts awaiting review believe cache aggressive something see much sites checked incognito mode without cookies thing anybody else issue
1,"<p>As mentioned in <a href=""https://meta.stackexchange.com/a/233536/295684"">the MSE question</a> linked in the comments, that indicator isn't calculated just for you. When you gain the ""access moderator tools"" privilege - 10K on graduated sites, 2K in public beta, 1K in private beta - you always see the total number of reviews pending <em>for anyone</em>. That is, even if the queues look empty to you (i.e. you reviewed each item already), that number is how many items are still awaiting consensus from the community.</p>

<p>Users with the edit privilege - 2K on graduated sites, 1K in public beta, 500 in private beta - but not the tools privilege will only see the number of items pending for them in the Suggested Edits queue.</p>
",AImeta,mentioned linked comments indicator calculated gain access moderator tools privilege 10k graduated sites 2k public beta 1k private beta always see total number reviews pending anyone even queues look empty ie reviewed item already number many items still awaiting consensus community users edit privilege 2k graduated sites 1k public beta 500 private beta tools privilege see number items pending suggested edits queue
1,"<p>I have provided an <a href=""https://ai.stackexchange.com/a/1522/169"">answer</a> where I fail to find a critical source. After looking for it again today, I still cannot find it. Worse still, I have read new articles, reviewed some at the time, and cannot find any other report that <em>explicitly</em> shares the critical source's point. I did find reports that <em>elude</em> to the argument.</p>

<p>I have added a <a href=""https://ai.stackexchange.com/a/1522/169"">warning</a> on that missing source. I believe it does not impact the answer value to the thread, but that missing source does impact credibility. As the accepted answer, I am thinking to delete the paragraph that mentions the source.</p>

<p>What should I do? Leave the warning, remove warning and paragraph?</p>
",AImeta,provided fail find critical source looking today still find worse still read new articles reviewed time find report explicitly shares critical source point find reports elude argument added missing source believe impact answer value thread missing source impact credibility accepted answer thinking delete paragraph mentions source leave warning remove warning paragraph
1,"<p>We are not requiring that every answer is fully supported by sources that you can currently link in the answer. So, if you are really certain that it is in fact true, you can leave it like it is. However, in this case, you aren't really certain anymore that it is true, or at least I wouldn't be. </p>

<p>If you find, such as now, that it might not be true, or that in fact the opposite might be true, you might want to clarify by just adding a paragraph claiming that the opposite is true (""On the other hand, (source 1) and (source 2) claim [...]""), instead of in addition to the warning. It might be a good thing to start the other paragraph with something like ""I've read this"", so that it it clear that the other paragraph is properly sourced while the original one is not. You might want to add a small conclusion (i.e. I'm not certain anymore, what it is).</p>

<p>You can also consider asking a question about it (this is not always appropriate) and linking to this question in your answer, at least when you receive a satisfactory answer. Also, please link to the answer in your question. </p>
",AImeta,requiring every answer fully supported sources currently link answer really certain fact true leave like however case really certain anymore true least would find might true fact opposite might true might want clarify adding paragraph claiming opposite true hand source 1 source 2 claim instead addition warning might good thing start paragraph something like read clear paragraph properly sourced original one might want add small conclusion ie certain anymore also consider asking question always appropriate linking question answer least receive satisfactory answer also please link answer question
1,"<p>If you can't verify the veracity of information, I think the safest thing to do - ethically speaking - is to annotate the information appropriately, as you've done. It's like Wikipedia's ""citation needed"" markers: they call out information that could be helpful, but is in need of further verification.</p>

<p>I agree with wythagoras's answer. In short, cite sources when possible, and make it clear that we might not have the right answer nailed down yet.</p>
",AImeta,verify veracity information think safest thing ethically speaking annotate information appropriately done like wikipedia citation needed markers call information could helpful need verification agree wythagoras answer short cite sources possible make clear might right answer nailed yet
1,"<p>Ideally Moderators are elected by the community, but until the community is large enough to hold a proper election, we will be appointing three provisional Moderators to fill those roles.</p>

<p>We need your help. Please nominate folks you would like to see become provisional moderators for this site. Your input will provide valuable insight to help us make our selections. You can read more about the process here: <strong><a href=""http://blog.stackoverflow.com/2010/07/moderator-pro-tempore/"">Moderators Pro Tempore</a>.</strong></p>

<h2>The Nomination Process:</h2>

<ul>
<li><strong>Nominate a user</strong> by posting an 'answer' below. Each nomination should be a separate answer. Use the template at the bottom of this post to complete your nomination.</li>
<li><strong>Self nominations are encouraged.</strong> This is a volunteer activity, so users should not feel obligated to accept these positions. A self-nomination is simply a way to say, ""I am very much interested in this, so let my record speak for itself.""</li>
<li><strong>Tell us about the candidates.</strong> Nominations can include links to other activities like Area 51 participation, participation in other sites, or any relevant thoughts/links that may help us make an informed decision.</li>
<li><strong>Nominee should indicate their acceptance</strong> by editing the answer to <strong>accept/decline</strong> the nomination. Nominees: please ensure your profile email is correct so we can contact you. Optionally, you are encouraged to write a bit about yourself following your acceptance.

<blockquote>
  <p>I accept/decline this nomination.</p>
  
  <p>Hi, I am name/location/fun fact (all optional). I live in &lt;location>, so I am generally active on this site from &lt;time> to &lt;time>. Some other things you may want to know about me are&hellip;</p>
</blockquote></li>
</ul>

<h2>Here is what we'll be looking for in a Moderator candidate:</h2>

<p>We are looking for members who are deeply engaged in the community's development; members who:</p>

<ul>
<li>Have been consistently active during the earliest weeks of this site's creation</li>
<li>Show an interest in their meta's community-building activities</li>
<li>Lead by example, showing patience and respect for their fellow community members in everything they write</li>
<li>Exhibit those intangible traits discussed in <a href=""http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/""><strong>A Theory of Moderation</strong></a></li>
</ul>

<hr>

<h2>Nomination Template</h2>

<p>To nominate a candidate, copy and paste the text below as an answer and complete your nomination writeup:</p>

<blockquote>
  <p>&lt;a href=""http://ai.stackexchange.com/users/<strong>UserID</strong>""><br>
  &lt;img src=""http://ai.stackexchange.com/users/flair/<strong>UserID</strong>.png"">&lt;/a><br>
  &lt;a href=""http://meta.ai.stackexchange.com/users/<strong>UserID</strong>""><br>
  &lt;img src=""http://meta.ai.stackexchange.com/users/flair/<strong>UserID</strong>.png"">&lt;/a><br><br>
  ###Notes:<br><br>
  This nominee would be a good choice because &hellip;</p>
</blockquote>

<p><img src=""https://i.stack.imgur.com/8Akvq.png"" alt=""""></p>
",AImeta,ideally moderators elected community community large enough hold proper election appointing three provisional moderators fill roles need help please nominate folks would like see become provisional moderators site input provide valuable insight help us make selections read process nomination process nominate user posting answer nomination separate answer use template bottom post complete nomination self nominations encouraged volunteer activity users feel obligated accept positions self nomination simply way say much interested let record speak tell us candidates nominations include links activities like area 51 participation participation sites relevant thoughts links may help us make informed decision nominee indicate acceptance editing answer accept decline nomination nominees please ensure profile email correct contact optionally encouraged write bit following acceptance accept decline nomination hi name location fun fact optional live looking moderator candidate looking members deeply engaged community development members consistently active earliest weeks site creation show interest meta community building activities lead example showing patience respect fellow community members everything write exhibit intangible traits discussed nomination template nominate candidate copy paste text answer complete nomination writeup hrefhttpaistackexchangecom users userid hrefhttpmetaaistackexchangecom users userid notes nominee would good choice
1,"<p><a href=""https://ai.stackexchange.com/users/42"">
<img src=""https://ai.stackexchange.com/users/flair/42.png""></a>
<a href=""https://ai.meta.stackexchange.com/users/42"">
<img src=""https://ai.meta.stackexchange.com/users/flair/42.png""></a>

<img src=""https://stackexchange.com/users/flair/1448821.png""></p>

<h3>Notes:</h3>

<p>Currently most voted and dedicated user with the relevant knowledge and skills about AI. In addition, he's working in this research area, so he knows what he's talking about. His skills may help to improve quality of this site.</p>

<p>EDIT by NietzscheanAI (formerly known as user217281728): <br>
Most kind, thanks. I'm happy to accept this nomination and want to work to make this a informative and useful site. I live in the UK, so tend to be active on the site between 07.00 and 23.00 GMT. My varied career has included games software company owner, generative music developer, software architect, pure mathematician and (for the last 13 years) AI researcher.</p>
",AImeta,notes currently voted dedicated user relevant knowledge skills ai addition working research area knows talking skills may help improve quality site edit nietzscheanai formerly known user217281728 kind thanks happy accept nomination want work make informative useful site live uk tend active site 0700 2300 gmt varied career included games software company owner generative music developer software architect pure mathematician last 13 years ai researcher
1,"<p><a href=""https://ai.stackexchange.com/users/75"">
<img src=""https://ai.stackexchange.com/users/flair/75.png""></a>
<a href=""https://ai.meta.stackexchange.com/users/75"">
<img src=""https://ai.meta.stackexchange.com/users/flair/75.png""></a>
<a href=""https://stackexchange.com/users/3364317/ben-n"">
<img src=""https://stackexchange.com/users/flair/3364317.png""></a></p>

<h3>Notes:</h3>

<p>This nominee would be a good choice because of his active involvement in the community's development during the private beta and his experience on Stack Exchange!</p>

<p>I'll step right up and offer my services to the community as a moderator pro tempore. I confess that I'm just an enthusiast when it comes to artificial intelligence, but I have been highly active here on meta, gaining the community's first silver badge: <a href=""https://ai.stackexchange.com/help/badges/68/convention"">Convention</a>. I thoroughly enjoy reviewing and I have been working the queues since the site's beginning. I've also spent a large (probably unhealthy, heh) amount of time reading Meta Stack Exchange and the SE blogs, so I'm familiar with the Stack Exchange model, the software, and the expectations for the various roles. I'm also active on <a href=""https://meta.superuser.com/users/380318/ben-n?tab=topactivity"">Meta Super User</a>, for what it's worth.</p>

<p>I live in Illinois (midwestern United States), so I'm usually awake from UTC 15:00 to 3:00. You can read about the things I've created in my profile. I have a blog <a href=""https://fleexlab.blogspot.com/2016/08/ai-stack-exchange-site.html"" rel=""nofollow noreferrer"">on which I mentioned the site a while back</a>.</p>

<p>I've been doing what I can to make sure this site survives, and that has required casting a few close votes. Hopefully I haven't come off as too much of a maniacal ruthless reviewer <code>:)</code>. When asked on meta, in comments, or in <a href=""http://chat.stackexchange.com/rooms/43371/artificial-intelligence"">chat</a> about why a question is closed, I always write up a helpful, respectful explanation. If I ever do something you think is less than ideal, please feel free to ask me about it! Like all humans (though perhaps not AIs!) I make the occasional mistake, and when I see that's happened, I make it right.</p>

<p>I have my own opinions and judgments, of course, but I would be happy to carry out as moderator pro tempore the consensus of the community, the mod team, and Stack Exchange. We're all in this together.</p>

<p>It's a pleasure building this community with everyone here. I look forward to continuing to the next stage of site growth with y'all!</p>
",AImeta,notes nominee would good choice active involvement community development private beta experience stack exchange step right offer services community moderator pro tempore confess enthusiast comes artificial intelligence highly active meta gaining community first silver badge thoroughly enjoy reviewing working queues since site beginning also spent large probably unhealthy heh amount time reading meta stack exchange se blogs familiar stack exchange model software expectations various roles also active worth live illinois midwestern united states usually awake utc 1500 300 read things created profile blog make sure site survives required casting close votes hopefully come much maniacal ruthless reviewer asked meta comments question closed always write helpful respectful explanation ever something think less ideal please feel free ask like humans though perhaps ais make occasional mistake see happened make right opinions judgments course would happy carry moderator pro tempore consensus community mod team stack exchange together pleasure building community everyone look forward continuing next stage site growth
1,"<p><a href=""https://ai.stackexchange.com/users/10"">
<img src=""https://ai.stackexchange.com/users/flair/10.png""></a>
<a href=""https://ai.meta.stackexchange.com/users/10"">
<img src=""https://ai.meta.stackexchange.com/users/flair/10.png""></a>
<a href=""https://stackexchange.com/users/555192"">
<img src=""https://stackexchange.com/users/flair/555192.png""></a></p>

<h3>Notes:</h3>

<p>The second most voted and active user, data scientist with the right skillset across different AI branches. His answers are reliable and interesting. His skills can be a great asset to improve quality of this site.</p>

<p>EDIT by Matthew Graves: Thanks for the nomination! I'm pleased to accept it. I'm interested in helping this site help people better understand AI and the issues surrounding it, both through direct effort and community building. I've been clearing out review queues here as soon as I got access to them, and that's typically the first thing I check after my comment inbox. </p>

<p>I'm currently in Austin, Texas, and so would typically be online from to about noon to 2am UTC. I've been doing machine-learning related work for, depending on how you count it, about 8 years now, mostly as a student but now also as a data scientist. My research effort has mostly been in numerical optimization, machine reliability, and time series analysis, rounded out by my personal interests in psychology, economics, and philosophy. I've been interested in intelligence for as long as I can remember, and that grew to encompass artificial intelligence as soon as I was introduced to it.</p>

<p>To a large degree I 'grew up on the internet'; forum-posting has been a major hobby for over half of my life at this point. I've consistently had a reputation for being polite, calm, and open-minded; qualities that I hope would serve me well as a moderator.</p>
",AImeta,notes second voted active user data scientist right skillset across different ai branches answers reliable interesting skills great asset improve quality site edit matthew graves thanks nomination pleased accept interested helping site help people better understand ai issues surrounding direct effort community building clearing review queues soon got access typically first thing check comment inbox currently austin texas would typically online noon 2 utc machine learning related work depending count 8 years mostly student also data scientist research effort mostly numerical optimization machine reliability time series analysis rounded personal interests psychology economics philosophy interested intelligence long remember grew encompass artificial intelligence soon introduced large degree grew internet forum posting major hobby half life point consistently reputation polite calm open minded qualities hope would serve well moderator
1,"<p>I'll volunteer myself.</p>

<p><a href=""https://ai.stackexchange.com/users/33/"">
<img src=""https://ai.stackexchange.com/users/flair/33.png""></a>
<a href=""https://ai.meta.stackexchange.com/users/33/"">
<img src=""https://ai.meta.stackexchange.com/users/flair/33.png""></a>
<a href=""https://stackexchange.com/users/48222/"">
<img src=""https://stackexchange.com/users/flair/48222.png""></a></p>

<h3>Notes:</h3>

<p>This nominee would be a good choice because - he is passionate about AI and its potential applications for improving the human condition.  This nominee is also a strong supporter of open exchange of scientific knowledge and technology, as expressed in the Open Source, Open Web, Open Data, Open Science and Open Hardware initiatives.   This nominee has been participating in multiple Stack Exchange communities for many years.   </p>

<p>You could consider this nominee to be the ""ruthless NON closer"" as he believes that closing questions is generally harmful to the community, as it is perceived as an aggressive and hostile act by whoever posted the question.  This nominee believes that ""bad"" questions can simply be down-voted and allowed to die from lack of activity in <em>almost</em> all cases.</p>

<p>This nominee believes we can strike a balance between being ""beginner friendly"" and still keeping things interesting enough to attract experts, but believes that it will take some time to establish our presence in the AI world and attract the high-level researchers and others of that ilk.  </p>

<hr>

<p>Since I volunteered myself, it should go without saying that I accept this nomination.</p>

<p>Hi, I am Phillip. I live in Chapel Hill, NC, so I am generally active on this site from around 10:00am through 1:00am Eastern time. Some other things you may want to know about me are: I am founder / president at <a href=""https://www.fogbeam.com"" rel=""nofollow noreferrer"">Fogbeam Labs</a>, an open source software company.  I was a volunteer firefighter for many years and was Assistant Fire Chief of my department for the last couple of years I was there.  </p>

<p>I am the founder/organizer of the Research Triangle Park ""Semantic Web / Artificial Intelligence / Machine Learning"" Meetup here in the Raleigh/Durham area.  I'm also active on <a href=""http://mindcrime.github.io"" rel=""nofollow noreferrer"">Github</a> and <a href=""https://news.ycombinator.com/user?id=mindcrime"" rel=""nofollow noreferrer"">Hacker News</a>.  </p>
",AImeta,volunteer notes nominee would good choice passionate ai potential applications improving human condition nominee also strong supporter open exchange scientific knowledge technology expressed open source open web open data open science open hardware initiatives nominee participating multiple stack exchange communities many years could consider nominee ruthless non closer believes closing questions generally harmful community perceived aggressive hostile act whoever posted question nominee believes bad questions simply voted allowed die lack activity almost cases nominee believes strike balance beginner friendly still keeping things interesting enough attract experts believes take time establish presence ai world attract high level researchers others ilk since volunteered go without saying accept nomination hi phillip live chapel hill nc generally active site around 1000am 100am eastern time things may want know founder president open source software company volunteer firefighter many years assistant fire chief department last couple years founder organizer research triangle park semantic web artificial intelligence machine learning meetup raleigh durham area also active
1,"<p><a href=""https://ai.stackexchange.com/users/5"">
<img src=""https://ai.stackexchange.com/users/flair/5.png""></a>
<a href=""https://ai.meta.stackexchange.com/users/5"">
<img src=""https://ai.meta.stackexchange.com/users/flair/5.png""></a></p>

<hr>

<h3>Notes:</h3>

<p>While I'm not the most knowledgeable about AI, and don't have the highest reputation level, I know a lot about moderating.</p>

<p>In the past three days, every single day, I've cleared all the review ques I have access to. I currently own two organizations, and I moderate, or lead, both of them. I have 2 pending proposals on Area51. I'm active on the Stack Exchange sites almost every single day. I have former experience from moderating as a former FPC from Scratch.</p>

<p>It would be an honor to be a moderator on this site.
Thank you for reading.</p>
",AImeta,notes knowledgeable ai highest reputation level know lot moderating past three days every single day cleared review ques access currently two organizations moderate lead 2 pending proposals area51 active stack exchange sites almost every single day former experience moderating former fpc scratch would honor moderator sitethank reading
1,"<p>Yes, absolutely.  Regardless of your position on the whole ""theory vs. implementation"" thing, math is an essential part of AI and having convenient access to LaTex would be a boon here. </p>
",AImeta,yes absolutely regardless position whole theory vs implementation thing math essential part ai convenient access latex would boon
1,"<p><a href=""https://ai.stackexchange.com/users/8"">
<img src=""https://ai.stackexchange.com/users/flair/8.png""></a>
<a href=""https://ai.meta.stackexchange.com/users/8"">
<img src=""https://ai.meta.stackexchange.com/users/flair/8.png""></a>
<a href=""https://stackexchange.com/users/22370"">
<img src=""https://stackexchange.com/users/flair/22370.png""></a></p>

<h3>Notes:</h3>

<p>This nominee would be a good choice because kenorb is a very active user, a person who knows a lot about AI, and, I feel, cares about helping this community grow. kenorb should be one of our moderators - even if his English isn't perfect, I still think he's perfect mod material. :)</p>

<hr>

<p>First of all, I would like to thank you for nomination and I am pleased to take the responsibility of being a pro tempore mod. I believe that this site has a unique opportunity to make a huge impact to global technology market driven by artificial intelligence and our everyday life in the very near future by sharing advanced knowledge accessible for all.</p>

<p>I have been using SE for over 7 years, I am experienced across a variety of fields and I am familiar with moderation tools and I understand their purpose.</p>

<p>I am an experienced software engineer specialising in a variety of information technology stacks with over 18 years experience consulting across a range of sectors and multination companies. One of the recent one is planning to <a href=""http://www.ft.com/cms/s/0/5ea4c668-1364-11e6-91da-096d89bd2173.html#axzz4HXDwufht"" rel=""nofollow noreferrer"">'to deploy drone army'</a> worldwide which can expand our scope of understanding of artificial intelligence (e.g. imagine flying drones in the restaurant and delivering your food to your table after pressing a single button). Check also my <a href=""https://stackoverflow.com/cv/kenorb"">user CV profile</a>.</p>

<p>My first AI program was a chat bot written over 18 years ago in Pascal with custom written assembler libraries in order to make my school mates believing that they are chatting on IRC with real people, while being on the computers without any internet connection, so other can play games on spare computers with the real network. This worked, for the first 15-30 minutes, later on they could find out that something was wrong or get bored. Second project was involved AI bots protecting IRC channels. I did some AI in games. Since then I am interested in practical applications of AI. This is my long term hobby and interest. Further projects required more sophisticated requirements. Currently I am working on integration AI with the financial algorithms and systems.</p>

<p>I am good team player, so I am able to cooperate with other mods, I'm also available on daily basis (GMT/DST time). I hope we can improve this site by keeping it away from chaos, spam and trolls, to provide high quality site. </p>
",AImeta,notes nominee would good choice kenorb active user person knows lot ai feel cares helping community grow kenorb one moderators even english perfect still think perfect mod material first would like thank nomination pleased take responsibility pro tempore mod believe site unique opportunity make huge impact global technology market driven artificial intelligence everyday life near future sharing advanced knowledge accessible using se 7 years experienced across variety fields familiar moderation tools understand purpose experienced software engineer specialising variety information technology stacks 18 years experience consulting across range sectors multination companies one recent one planning worldwide expand scope understanding artificial intelligence eg imagine flying drones restaurant delivering food table pressing single button check also first ai program chat bot written 18 years ago pascal custom written assembler libraries order make school mates believing chatting irc real people computers without internet connection play games spare computers real network worked first 15 30 minutes later could find something wrong get bored second project involved ai bots protecting irc channels ai games since interested practical applications ai long term hobby interest projects required sophisticated requirements currently working integration ai financial algorithms systems good team player able cooperate mods also available daily basis gmt dst time hope improve site keeping away chaos spam trolls provide high quality site
1,"<p><a href=""https://ai.stackexchange.com/users/145"">
<img src=""https://ai.stackexchange.com/users/flair/145.png""></a>
<a href=""https://ai.meta.stackexchange.com/users/145"">
<img src=""https://ai.meta.stackexchange.com/users/flair/145.png""></a>
<a href=""https://stackexchange.com/users/5129611"">
<img src=""https://stackexchange.com/users/flair/5129611.png?theme=dark"" width=""208"" height=""58"" alt=""profile for Mithrandir on Stack Exchange, a network of free, community-driven Q&amp;A sites"" title=""profile for Mithrandir on Stack Exchange, a network of free, community-driven Q&amp;A sites"">
</a></p>

<h3>Notes:</h3>

<p>I would like to offer my services as a pro-tem moderator on this site. I have watched been a relatively active member since I joined on Day 0. I have 135 edits (counting tag-only edits), I was the first one to earn the <a href=""https://ai.stackexchange.com/help/badges/12/strunk-white"">Strunk and White badge</a>, I am the top reviewer for both <a href=""https://ai.stackexchange.com/review/close/stats"">Close Votes</a> and <a href=""https://ai.stackexchange.com/review/reopen/stats"">Reopen Votes</a> on the main site, I was the first reviewer of <a href=""https://ai.stackexchange.com/review/late-answers/stats"">Late Answers</a>,  and I was the first reviewer on Meta. I have watched Meta, and pitched in when I could.<br>I was also one of 25 users to earn the <a href=""https://ai.stackexchange.com/help/badges/30/beta"">Beta badge</a>, which means that I was an active user in the Private Beta. I now also have the <a href=""https://ai.stackexchange.com/help/badges/68/convention"">Convention badge</a>, which means that I've been active here on Meta.<br><br> I may not know so much about AI, really, but I do know enough to be able to tell if something answers the question or not, I think. :)</p>

<p>Also, I am one of the only users who has ventured onto <a href=""http://chat.stackexchange.com/rooms/43371/the-singularity"">chat</a> :P</p>

<p>I am also active on this Meta, the Puzzling Meta, and the main Meta*.</p>

<p>I am fairly well-versed in the content in the Help Center and site policy, as well.</p>

<p><sub>* Okay, I mostly flag things as off-topic. But I have asked/answered some!</sub></p>

<p><strong>About Me</strong></p>

<p>I'm a 14 year-old kid. The only moderation experience I have is being an admin on 3 Wikias. (Not popular ones - little outdated backwater ones. :P) I live in the UTC+2/3 time zone, although I'm often on late.<br>
I don't go to school; I'm homeschooled.<br>
I am not a programmer.<br>
I have been using SE for a year and 11 months, roughly, so I have a pretty good idea about how the site works :P.</p>
",AImeta,notes would like offer services pro tem moderator site watched relatively active member since joined day 0 135 edits counting tag edits first one earn top reviewer main site first reviewer first reviewer meta watched meta pitched could also one 25 users earn means active user private beta also means active meta may know much ai really know enough able tell something answers question think also one users ventured onto p also active meta puzzling meta main meta fairly well versed content help center site policy well okay mostly flag things topic asked answered 14 year old kid moderation experience admin 3 wikias popular ones little outdated backwater ones p live utc23 time zone although often late go school homeschooled programmer using se year 11 months roughly pretty good idea site works p
1,"<p>This tag doesn't really seem to be much use. <a href=""https://ai.stackexchange.com/questions/tagged/brain"" class=""post-tag"" title=""show questions tagged &#39;brain&#39;"" rel=""tag"">brain</a> would seem a more appropriate  tag for a site like biology.SE.</p>
",AImeta,tag really seem much use would seem appropriate tag site like biologyse
1,"<p>I think a lot of topics about AI/ANN wants to achieve a brain simulation, so maybe we can rename it to: <a href=""https://ai.stackexchange.com/questions/tagged/brain-simulation"" class=""post-tag"" title=""show questions tagged &#39;brain-simulation&#39;"" rel=""tag"">brain-simulation</a>.</p>
",AImeta,think lot topics ai ann wants achieve brain simulation maybe rename
1,"<p>What would be the difference between brain-simulation and neuromorphic-computing tags?</p>
",AImeta,would difference brain simulation neuromorphic computing tags
1,"<p><a href=""https://ai.stackexchange.com/questions/tagged/deepqa"" class=""post-tag"" title=""show questions tagged &#39;deepqa&#39;"" rel=""tag"">deepqa</a> is just another name for <a href=""https://ai.stackexchange.com/questions/tagged/watson"" class=""post-tag"" title=""show questions tagged &#39;watson&#39;"" rel=""tag"">watson</a>.  Can we perhaps merge these tags, with <a href=""https://ai.stackexchange.com/questions/tagged/watson"" class=""post-tag"" title=""show questions tagged &#39;watson&#39;"" rel=""tag"">watson</a> being the real one?</p>
",AImeta,another name perhaps merge tags real one
1,"<p>Yes, it's pointless to have two tags referring to the same thing. Since <a href=""https://ai.stackexchange.com/questions/tagged/deepqa"" class=""post-tag"" title=""show questions tagged &#39;deepqa&#39;"" rel=""tag"">deepqa</a> had three questions and <a href=""https://ai.stackexchange.com/questions/tagged/watson"" class=""post-tag"" title=""show questions tagged &#39;watson&#39;"" rel=""tag"">watson</a> had four (and all but one DeepQA question had the Watson tag already), I manually merged the tags together by removing <a href=""https://ai.stackexchange.com/questions/tagged/deepqa"" class=""post-tag"" title=""show questions tagged &#39;deepqa&#39;"" rel=""tag"">deepqa</a>.</p>

<p>One could make the argument that DeepQA is the research project while Watson is the product, but all of the questions tagged <a href=""https://ai.stackexchange.com/questions/tagged/deepqa"" class=""post-tag"" title=""show questions tagged &#39;deepqa&#39;"" rel=""tag"">deepqa</a> were about Watson.</p>
",AImeta,yes pointless two tags referring thing since three questions four one deepqa question watson tag already manually merged tags together removing one could make argument deepqa research project watson product questions tagged watson
1,"<p><em>Watson</em> is the name of the computer, and <em>DeepQA</em> is the name of the technology  and software. They both correlated, but <em>Watson</em> sounds like more specific, but on the other hand there are no any known computers which are using <em>DeepQA</em> which aren't called <em>Watson</em>.</p>

<p>We do not know if there are any other computers which uses <em>DeepQA</em> technology, but not related to <em>Watson</em>. There could be some implementation of <em>DeepQA</em> not being called <em>Watson</em>. To simplify things, both terms can be synonyms where <a href=""https://ai.stackexchange.com/questions/tagged/watson"" class=""post-tag"" title=""show questions tagged &#39;watson&#39;"" rel=""tag"">watson</a> should be the main tag, since it is more popular (it has its own Wikipedia page, where <em>DeepQA</em> does not).</p>

<p>More detailed information about the differences check <a href=""https://ai.meta.stackexchange.com/a/1180/8"">@Avik post</a> and the following answer:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/1665/8"">Are there any DeepQA-based computers other than Watson?</a></li>
</ul>
",AImeta,watson name computer deepqa name technology software correlated watson sounds like specific hand known computers using deepqa called watson know computers uses deepqa technology related watson could implementation deepqa called watson simplify things terms synonyms main tag since popular wikipedia page deepqa detailed information differences check following answer
1,"<p>I would be careful to merge the two together. <a href=""https://ai.stackexchange.com/questions/tagged/deepqa"" class=""post-tag"" title=""show questions tagged &#39;deepqa&#39;"" rel=""tag"">deepqa</a> is very much just that - a deep learning approach to questions and answers. This covers NLP, hypothesis formation, candidate answer generation, and answer selection from the candidates. It is fully limited to that domain. </p>

<p>These pages show what I'm getting at: </p>

<p><a href=""https://www.research.ibm.com/deepqa/deepqa.shtml"" rel=""nofollow noreferrer"">https://www.research.ibm.com/deepqa/deepqa.shtml</a>
<a href=""http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2159"" rel=""nofollow noreferrer"">http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2159</a>
<a href=""http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2162"" rel=""nofollow noreferrer"">http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2162</a>
<a href=""http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2160"" rel=""nofollow noreferrer"">http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2160</a></p>

<p>On the other hand, <a href=""https://ai.stackexchange.com/questions/tagged/watson"" class=""post-tag"" title=""show questions tagged &#39;watson&#39;"" rel=""tag"">watson</a> is this titanic over-arching project that dips into culinary arts, healthcare, and more recently education and other topics I'm sure I'm missing. It is the foremost product of IBM's cognitive computing research and has numerous applications and uses, and elements that construct it. It goes well beyond just the QA portion (which is an integral part of Watson, but not the entirety or even nearly a synonym of Watson).</p>

<p>For this reason, I personally think they are certainly different topics, but being new to stack exchange I'm not sure how you would like to handle this.</p>
",AImeta,would careful merge two together much deep learning approach questions answers covers nlp hypothesis formation candidate answer generation answer selection candidates fully limited domain pages show getting hand titanic arching project dips culinary arts healthcare recently education topics sure missing foremost product ibm cognitive computing research numerous applications uses elements construct goes well beyond qa portion integral part watson entirety even nearly synonym watson reason personally think certainly different topics new stack exchange sure would like handle
1,"<p>Given the following question:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/1687/8"">How does Pinterest decipher what&#39;s on unmarked pictures and categorize them?</a></li>
</ul>

<p>which tags should be suitable for it in terms of the image recognition?</p>

<p><a href=""https://ai.stackexchange.com/questions/tagged/image-recognition"" class=""post-tag"" title=""show questions tagged &#39;image-recognition&#39;"" rel=""tag"">image-recognition</a>, <a href=""https://ai.stackexchange.com/questions/tagged/computer-vision"" class=""post-tag"" title=""show questions tagged &#39;computer-vision&#39;"" rel=""tag"">computer-vision</a> or <a href=""https://ai.stackexchange.com/questions/tagged/visual-search"" class=""post-tag"" title=""show questions tagged &#39;visual-search&#39;"" rel=""tag"">visual-search</a>?</p>

<p>Should we stick only to <a href=""https://ai.stackexchange.com/questions/tagged/image-recognition"" class=""post-tag"" title=""show questions tagged &#39;image-recognition&#39;"" rel=""tag"">image-recognition</a>, or the other can be useful in some cases as well?</p>

<p>If multiple, what's the difference?</p>
",AImeta,given following question tags suitable terms image recognition stick useful cases well multiple difference
1,"<p>Which of the following tags you can suggest to merge or remove?</p>

<ul>
<li><a href=""https://ai.stackexchange.com/questions/tagged/nlp"" class=""post-tag"" title=""show questions tagged &#39;nlp&#39;"" rel=""tag"">nlp</a></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/computational-linguistics"" class=""post-tag"" title=""show questions tagged &#39;computational-linguistics&#39;"" rel=""tag"">computational-linguistics</a></li>
<li><s><a href=""https://ai.stackexchange.com/questions/tagged/natural-language"" class=""post-tag"" title=""show questions tagged &#39;natural-language&#39;"" rel=""tag"">natural-language</a></s> (deleted)</li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/lexical-recognition"" class=""post-tag"" title=""show questions tagged &#39;lexical-recognition&#39;"" rel=""tag"">lexical-recognition</a></li>
<li><s><a href=""https://ai.stackexchange.com/questions/tagged/language-processing"" class=""post-tag"" title=""show questions tagged &#39;language-processing&#39;"" rel=""tag"">language-processing</a></s> (deleted)</li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/grammar-induction"" class=""post-tag"" title=""show questions tagged &#39;grammar-induction&#39;"" rel=""tag"">grammar-induction</a></li>
<li><s><a href=""https://ai.stackexchange.com/questions/tagged/pattern-languages"" class=""post-tag"" title=""show questions tagged &#39;pattern-languages&#39;"" rel=""tag"">pattern-languages</a></s> (deleted)</li>
</ul>

<p>And which one should be a synonym of another term? Basically, what should be the main tags for natural language processing? <a href=""https://ai.stackexchange.com/questions/tagged/nlp"" class=""post-tag"" title=""show questions tagged &#39;nlp&#39;"" rel=""tag"">nlp</a>?</p>
",AImeta,following tags suggest merge remove deleted deleted deleted one synonym another term basically main tags natural language processing
1,"<p>AI is broader than Machine Learning and Statistical Learning. Yes, the probabilistic / statistical stuff dominates the conversation these days, but AI includes rule based systems, expert systems, symbolic processing, logic programming and other things that would not be on-topic at Cross Validated (or Data Science).</p>

<p>We've also been saying that we have more of a focus on the philosophy of AI and the humanities related aspects, as opposed to strictly the technology.</p>
",AImeta,ai broader machine learning statistical learning yes probabilistic statistical stuff dominates conversation days ai includes rule based systems expert systems symbolic processing logic programming things would topic cross validated data science also saying focus philosophy ai humanities related aspects opposed strictly technology
1,"<p>Categorizing things in pictures as certain types of objects definitely sounds like <a href=""https://ai.stackexchange.com/questions/tagged/image-recognition"" class=""post-tag"" title=""show questions tagged &#39;image-recognition&#39;"" rel=""tag"">image-recognition</a> to me. After all, the computer is supposed to <em>recognize</em> what the thing is and then put them into categories.</p>

<p>Two of the three existing questions in <a href=""https://ai.stackexchange.com/questions/tagged/computer-vision"" class=""post-tag"" title=""show questions tagged &#39;computer-vision&#39;"" rel=""tag"">computer-vision</a> don't really seem to be related to computerized image comprehension at all. The last - the question you linked - would, in my opinion, be better served by <a href=""https://ai.stackexchange.com/questions/tagged/image-recognition"" class=""post-tag"" title=""show questions tagged &#39;image-recognition&#39;"" rel=""tag"">image-recognition</a>. <a href=""https://ai.stackexchange.com/questions/tagged/computer-vision"" class=""post-tag"" title=""show questions tagged &#39;computer-vision&#39;"" rel=""tag"">computer-vision</a> seems more appropriate for questions involving the AI moving around and continually <em>seeing</em> the world and the states of the things in it (like self-driving cars do), which involves more than just figuring out what objects are present.</p>

<p>Since <a href=""https://ai.stackexchange.com/questions/tagged/visual-search"" class=""post-tag"" title=""show questions tagged &#39;visual-search&#39;"" rel=""tag"">visual-search</a> doesn't exist yet, I think we should wait for a compelling distinction between it and <a href=""https://ai.stackexchange.com/questions/tagged/image-recognition"" class=""post-tag"" title=""show questions tagged &#39;image-recognition&#39;"" rel=""tag"">image-recognition</a> before creating it.</p>
",AImeta,categorizing things pictures certain types objects definitely sounds like computer supposed recognize thing put categories two three existing questions really seem related computerized image comprehension last question linked would opinion better served seems appropriate questions involving ai moving around continually seeing world states things like self driving cars involves figuring objects present since exist yet think wait compelling distinction creating
1,"<p><strong><a href=""https://ai.stackexchange.com/questions/tagged/natural-language"" class=""post-tag"" title=""show questions tagged &#39;natural-language&#39;"" rel=""tag"">natural-language</a> should stay. The others - synonymize.</strong></p>

<p><a href=""https://ai.stackexchange.com/questions/tagged/natural-language"" class=""post-tag"" title=""show questions tagged &#39;natural-language&#39;"" rel=""tag"">natural-language</a> is the most descriptive tag name, as a person who knows fairly close to nothing about AI. If you add the others as synonyms, then everyone will be able to find the right tag. :)</p>
",AImeta,stay others synonymize descriptive tag name person knows fairly close nothing ai add others synonyms everyone able find right tag
1,"<p><a href=""https://ai.stackexchange.com/questions/tagged/dnn"" class=""post-tag"" title=""show questions tagged &#39;dnn&#39;"" rel=""tag"">dnn</a> just stands for deep neural network, which we already have a tag for: <a href=""https://ai.stackexchange.com/questions/tagged/deep-network"" class=""post-tag"" title=""show questions tagged &#39;deep-network&#39;"" rel=""tag"">deep-network</a>. Can we just synonymize these?</p>
",AImeta,stands deep neural network already tag synonymize
1,"<p>Can we please merge the <a href=""https://ai.stackexchange.com/questions/tagged/robots"" class=""post-tag"" title=""show questions tagged &#39;robots&#39;"" rel=""tag"">robots</a> and <a href=""https://ai.stackexchange.com/questions/tagged/robotics"" class=""post-tag"" title=""show questions tagged &#39;robotics&#39;"" rel=""tag"">robotics</a> tags? We don't need both of them.</p>

<p>I think that <a href=""https://ai.stackexchange.com/questions/tagged/robotics"" class=""post-tag"" title=""show questions tagged &#39;robotics&#39;"" rel=""tag"">robotics</a> is the better tag, because it fits better with the theme of the site - we don't want people asking random robot questions here.</p>
",AImeta,please merge tags need think better tag fits better theme site want people asking random robot questions
1,"<p>The tag badge system seems to be inactive at the moment. No gear icon appears next to the privilege tracker for me on my main user profile (which would be used to switch it to tracking a tag badge), and everyone's meta profile only shows their reputation, not the tag badge tracker. Additionally, it looks like I <a href=""https://ai.meta.stackexchange.com/users/75/ben-n?tab=tags"">should</a> have a bronze <a href=""/questions/tagged/discussion"" class=""post-tag required-tag"" title=""show questions tagged &#39;discussion&#39;"" rel=""tag"">discussion</a> tag here on meta, but no such badge has been awarded.</p>

<p>Meta here (my profile):</p>

<p><a href=""https://i.stack.imgur.com/d9pDB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/d9pDB.png"" alt=""meta here""></a></p>

<p>Meta Super User (<a href=""https://meta.superuser.com/users/19943/mokubai?tab=topactivity"">Mokubai</a>'s profile):</p>

<p><a href=""https://i.stack.imgur.com/60Vst.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/60Vst.png"" alt=""meta SU""></a></p>

<p>This isn't urgent by any stretch of the imagination, and it could conceivably be by design during private betas (though I couldn't find an MSE on it), but I'll file a bug just in case.</p>
",AImeta,tag badge system seems inactive moment gear icon appears next privilege tracker main user profile would used switch tracking tag badge everyone meta profile shows reputation tag badge tracker additionally looks like bronze tag meta badge awarded meta profile meta super user profile urgent stretch imagination could conceivably design private betas though could find mse file bug case
1,"<p>This is <a href=""/questions/tagged/status-bydesign"" class=""post-tag moderator-tag"" title=""show questions tagged &#39;status-bydesign&#39;"" rel=""tag"">status-bydesign</a>, although it is not because of the private beta.</p>

<p>From <a href=""https://meta.stackexchange.com/questions/67397/list-of-all-badges-with-full-descriptions/188732#188732"">List of all badges with full descriptions</a>:</p>

<blockquote>
  <p>A tag must appear on a minimum of 100 questions to be considered for tag badges.</p>
</blockquote>

<p>Since we don't have tags with 100 questions or more, we don't yet see tag badges.</p>
",AImeta,although private beta tag must appear minimum 100 questions considered tag badges since tags 100 questions yet see tag badges
1,For requests to rename or reorganize existing tag(s).,AImeta,requests rename reorganize existing tags
1,For questions about the proper use of tags or the tagging system itself,AImeta,questions proper use tags tagging system
1,"<p>You can read more about tag synonyms here: <a href=""http://ai.stackexchange.com/help/privileges/suggest-tag-synonyms"">http://ai.stackexchange.com/help/privileges/suggest-tag-synonyms</a></p>
",AImeta,read tag synonyms
1,For questions about the proper use of tag synonyms or the tag-synonym system itself. ,AImeta,questions proper use tag synonyms tag synonym system
1,"<p>If you browse through the <a href=""/questions/tagged/scope"" class=""post-tag"" title=""show questions tagged &#39;scope&#39;"" rel=""tag"">scope</a> tag here on meta, you'll see that our scope might not be entirely obvious from the site title. When we open to the public, though, it's really important that we can quickly summarize our scope. Not everybody will have the patience to go through all our meta discussions before posting. Therefore, I think we should try to boil our consensuses down into a sentence or so, suitable for putting on the ""sign up"" banner.</p>

<p>For example, here's <a href=""https://superuser.com/"">Super User</a>'s, emphasis mine:</p>

<blockquote>
  <p>Super User is a question and answer site <strong>for computer enthusiasts and power users</strong>. Join them; it only takes a minute</p>
</blockquote>

<p><a href=""https://softwareengineering.stackexchange.com/"">Programmers</a>:</p>

<blockquote>
  <p>Programmers Stack Exchange is a question and answer site <strong>for professional programmers interested in conceptual questions about software development</strong>. Join them; it only takes a minute</p>
</blockquote>

<p><a href=""https://datascience.stackexchange.com/"">Data Science</a>:</p>

<blockquote>
  <p>Data Science Stack Exchange is a question and answer site <strong>for Data science professionals, Machine Learning specialists, and those interested in learning more about the field</strong>. Join them; it only takes a minute</p>
</blockquote>

<p>What should we have in that spot? As <a href=""https://ai.meta.stackexchange.com/a/1198/75"">mentioned by wythagoras</a>, we do have a default already in the tour, but do we need to adjust it after our meta deliberations?</p>

<p>(This is the fourth <a href=""https://meta.stackexchange.com/a/223675/295684"">real essential meta question</a> for private beta sites.)</p>
",AImeta,browse tag meta see scope might entirely obvious site title open public though really important quickly summarize scope everybody patience go meta discussions posting therefore think try boil consensuses sentence suitable putting sign banner example emphasis mine super user question answer site computer enthusiasts power users join takes minute programmers stack exchange question answer site professional programmers interested conceptual questions software development join takes minute data science stack exchange question answer site data science professionals machine learning specialists interested learning field join takes minute spot default already tour need adjust meta deliberations fourth private beta sites
1,"<p>Taking this from the tour and initial Area 51 description:</p>

<blockquote>
  <p>Artificial Intelligence Stack Exchange is a question and answer site for people interested in conceptual questions about life and challenges in a world where ""cognitive"" functions can be mimicked in a purely digital environment.</p>
</blockquote>
",AImeta,taking tour initial area 51 description artificial intelligence stack exchange question answer site people interested conceptual questions life challenges world cognitive functions mimicked purely digital environment
1,"<p>I am in the process of writing up the final review of this site. In it, we discuss the difficulties this site is having with scope &mdash; mostly around the <em>popular fallacies</em> of what AI actually is. Artificial intelligence is very different from how it’s portrayed in the movies. Whenever a problem becomes solvable by a computer, people start arguing that it does not require intelligence at all&hellip; and ""as soon as it works, no one calls it AI anymore"" &mdash; <em>John McCarthy</em></p>

<p>As such, this community is having difficulty navigating that narrow gap of what I'd call ""AI relevance"".</p>

<p>The proposal that created this site was intentionally placed in the <em>'scientific'</em> category. If you accept that we are not creating another programming site, I think we stumbled upon in interesting niche that describes the original premise of this site nicely:</p>

<blockquote>
  <p>Artificial Intelligence Stack Exchange is a site with a social and scientific focus on ""Advanced Computing in Society.""</p>
</blockquote>

<p>Think about it. With autonomous cars, smart surveillance, and ""the next big thing"" capturing the headlines, this isn't a terrible idea for a subject. Draping it in the popular AI label gives it a better focus&hellip; and it completely disambiguate that <strong>this is <em>not</em> a technical implementation or programming site.</strong> We already have that.</p>
",AImeta,process writing final review site discuss difficulties site scope john mccarthy community difficulty navigating narrow gap would call ai relevance proposal created site intentionally placed iscientific category accept creating another programming site think stumbled upon interesting niche describes original premise site nicely artificial intelligence stack exchange site social scientific focus advanced computing society think autonomous cars smart surveillance next big thing capturing headlines terrible idea subject draping popular ai label gives better focus completely disambiguate technical implementation programming site already
1,"<p>When I try to load AI.SE without logging in, I get a </p>

<blockquote>
  <p>Warning: this site is currently in **private beta** for at least 1 more day.</p>
</blockquote>

<p><a href=""https://i.stack.imgur.com/XjLgi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XjLgi.png"" alt=""enter image description here""></a></p>

<p>That **private beta** should be <strong>private beta</strong>, right?</p>
",AImeta,try load aise without logging get warning site currently private beta least 1 day private beta private beta right
1,"<p>The tour says:</p>

<blockquote>
  <p><strong>Artificial Intelligence Stack Exchange</strong> is a question and answer site for people interested in conceptual questions about life and challenges in a world where ""cognitive"" functions can be mimicked in purely digital environment.</p>
</blockquote>

<p>However, it <em>should</em> say:</p>

<blockquote>
  <p><strong>Artificial Intelligence Stack Exchange</strong> is a question and answer site for people interested in conceptual questions about life and challenges in a world where ""cognitive"" functions can be mimicked in a purely digital environment.</p>
</blockquote>

<p>Adding the word 'a' before <em>purely digital environment.</em></p>
",AImeta,tour says artificial intelligence stack exchange question answer site people interested conceptual questions life challenges world cognitive functions mimicked purely digital environment however say artificial intelligence stack exchange question answer site people interested conceptual questions life challenges world cognitive functions mimicked purely digital environment adding word purely digital environment
1,"<p>As you may have noticed from the <a href=""https://ai.stackexchange.com/help/badges/30/beta"">Beta</a> badge being awarded, <a href=""https://ai.stackexchange.com/help/privileges"">privilege thresholds</a> being adjusted, and the <a href=""http://area51.stackexchange.com/proposals/93481/artificial-intelligence"">Area 51 proposal</a> status being updated, <strong>we are now in public beta</strong>!</p>

<p>This is a really special moment because, though we weren't the first to try, we were the first group to succeed in getting an AI-related Stack Exchange site off the ground. I'd like to thank the Stack Exchange team for being willing to try this again and for providing the advice and adjustments needed to keep us on track. Also, thanks to <a href=""https://ai.stackexchange.com/users?tab=Reputation&amp;filter=all"">all our users</a> who have been asking questions, posting answers, and building consensus on meta.</p>

<p>I would be interested to see what notes the community team has on our progress (as <a href=""https://languagelearning.meta.stackexchange.com/a/199"">was shared on another fairly new site</a>). Even if we were a little shaky at times, evidently we're doing well now!</p>
",AImeta,may noticed badge awarded adjusted status updated public beta really special moment though first try first group succeed getting ai related stack exchange site ground would like thank stack exchange team willing try providing advice adjustments needed keep us track also thanks asking questions posting answers building consensus meta would interested see notes community team progress even little shaky times evidently well
1,"<p>Can we please add Cognitive Sciences as a migration target? It only makes sense, since we're bound to have some questions that should probably be migrated there, such as <a href=""https://ai.stackexchange.com/questions/1716/why-was-eliza-able-to-induce-delusional-thinking"">this</a>.</p>

<p>Or at least add the 'Not about AI within the scope of the Help Center' things, so that we can VTC/flag as something other than 'Blatantly off-topic'.</p>
",AImeta,please add cognitive sciences migration target makes sense since bound questions probably migrated least add ai within scope help center things vtc flag something blatantly topic
1,"<p>In <a href=""https://ai.meta.stackexchange.com/questions/1201/add-an-article-in-the-tour"">this question</a>, I asked for an 'A' to be added in the tour, in the site description. It was added. But in the dropdown list of sites, it's still gone!</p>

<p><a href=""https://i.stack.imgur.com/2x1cC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2x1cC.png"" alt=""noa""></a></p>

<p>That should be ""...in <strong>a</strong> purely digital..."".</p>
",AImeta,asked added tour site description added dropdown list sites still gone purely digital
1,"<p>I've the feeling this would be opinion based or too broad, so I come here for community review before writing a more complete question.</p>

<p>The root of the question is where to put the limit between ""automated system"" and ""artificial intelligence"".</p>

<p>For example, would an hybrid car able to start by itself a generator to charge back after a period of use/battery level could be called an artificial intelligence and if not at which point could we start talking about artificial intelligence ? </p>

<p>If this happen to be on-topic, which would be the relevant tags ?</p>
",AImeta,feeling would opinion based broad come community review writing complete question root question put limit automated system artificial intelligence example would hybrid car able start generator charge back period use battery level could called artificial intelligence point could start talking artificial intelligence happen topic would relevant tags
1,"<p>It appears that there is at least one question like this on the site:</p>

<p><a href=""https://ai.stackexchange.com/questions/1461/are-siri-and-cortana-ai-programs"">Are Siri and Cortana AI programs?</a></p>

<p>So I guess it would be okay - as long as you are asking <strong>about one</strong> (or two) <strong>specific thing</strong>(s).</p>

<p>For asking about in general when something is AI, that has already been asked: <a href=""https://ai.stackexchange.com/questions/1507/what-are-the-minimum-requirements-to-call-something-ai"">What are the minimum requirements to call something AI?</a></p>

<p>The tags... Now that's the problem. That might be worth its own Meta post.</p>

<p>And welcome to AI!</p>
",AImeta,appears least one question like site guess would okay long asking one two specific thing asking general something ai already asked tags problem might worth meta post welcome ai
1,"<p>In general, I think that we should allow questions on neural network architecture in order to attract and retain experts who actually build state of the art systems.</p>

<p>But for that specific question, I'm torn and lean towards keeping it closed. It's a novice instead of an expert architecture question; a good answer to it looks more like an explanation of how the necessary number of training examples scales with rule complexity, and how to ensure that the model depth and breadth is sufficient to encode rules of a certain complexity, and maybe also how to 'cheat' on model size and training requirements with convolution layers.</p>

<p>But if we want a question to expound on that sort of 101 material, it should probably be a set of three specific, easily searchable questions rather than the question that actually exists.</p>
",AImeta,general think allow questions neural network architecture order attract retain experts actually build state art systems specific question torn lean towards keeping closed novice instead expert architecture question good answer looks like explanation necessary number training examples scales rule complexity ensure model depth breadth sufficient encode rules certain complexity maybe also cheat model size training requirements convolution layers want question expound sort 101 material probably set three specific easily searchable questions rather question actually exists
1,"<p>There are already plenty of questions on programming AI/NN frameworks on Data science and SO: I don't think we need one more place, SE is fragmented enough.</p>
",AImeta,already plenty questions programming ai nn frameworks data science think need one place se fragmented enough
1,"<p>In addition to what was said by Mithrandir, I would personally say it's best that such a question focus on <strong>only one thing</strong>. In other words, questions that ask about an aspect of each item in a big list of things would be less than ideal. In the case of Siri and Cortana (smart personal assistants, basically), they're very similar products, so it makes sense to have one question for them.</p>

<p>It would be even better if such questions included <strong>specific features</strong> of the objects/products that the question owner suspects may produce AI. That shows research effort, and in discovering the relevant features, the person who asks might stumble upon an interesting insight themselves. It also has the benefit of covering all products that have that feature (having wide applicability yet focused scope tends to mark great questions in my experience), so we might not even need to name Siri and Cortana in the question title.</p>
",AImeta,addition said mithrandir would personally say best question focus one thing words questions ask aspect item big list things would less ideal case siri cortana smart personal assistants basically similar products makes sense one question would even better questions included specific features objects products question owner suspects may produce ai shows research effort discovering relevant features person asks might stumble upon interesting insight also benefit covering products feature wide applicability yet focused scope tends mark great questions experience might even need name siri cortana question title
1,"<p>Our site was created to hold questions about the scientific and social - not technical or programmatical - aspects of artificial intelligence. That's evidenced by its original section in Area 51, and by several posts by Stack Exchange staff. For example, see <a href=""https://ai.meta.stackexchange.com/a/1199/75"">this answer</a> on the question about summarizing our scope (relevant part reproduced here):</p>

<p>The proposal that created this site was intentionally placed in the 'scientific' category. If you accept that we are not creating another programming site, I think we stumbled upon in interesting niche that describes the original premise of this site nicely:</p>

<blockquote>
  <blockquote>
    <p>Artificial Intelligence Stack Exchange is a site with a social and scientific focus on ""Advanced Computing in Society.""</p>
  </blockquote>
  
  <p>Think about it. With autonomous cars, smart surveillance, and ""the next big thing"" capturing the headlines, this isn't a terrible idea for a subject. Draping it in the popular AI label gives it a better focus… and it completely disambiguate [sic] that <strong>this is <em>not</em> a technical implementation or programming site.</strong> We already have that.</p>
</blockquote>

<p>The emphasis was in the original.</p>

<p>Especially when we actually have a pretty cool scope draft (as summarized there), I don't think we should add an extra place in the network for AI-related programming questions.</p>
",AImeta,site created hold questions scientific social technical programmatical aspects artificial intelligence evidenced original section area 51 several posts stack exchange staff example see question summarizing scope relevant part reproduced proposal created site intentionally placed iscientific category accept creating another programming site think stumbled upon interesting niche describes original premise site nicely artificial intelligence stack exchange site social scientific focus advanced computing society think autonomous cars smart surveillance next big thing capturing headlines terrible idea subject draping popular ai label gives better focus completely disambiguate sic technical implementation programming site already emphasis original especially actually pretty cool scope draft summarized think add extra place network ai related programming questions
1,"<blockquote>
  <p>Data Science is an applied site</p>
</blockquote>

<p>Yeah, for <em>data science</em>.  Data science is not artificial intelligence.  There is overlap around the statistical techniques for machine learning, but they just are not identical. </p>

<blockquote>
  <p>Please do close questions that are highly technological or asking for applications.</p>
</blockquote>

<p>I'm sorry, but I think this is very misguided.  Ignoring all aspects of implementation and technology on a se like this, is like a football team fielding an offense, but no defense (or vice versa).  Or maybe I should say, it's like a Reese's Peanut Butter Cup without the chocolate.</p>

<p>The simple truth is, you can say ""programming questions belong on xx.se (or so)"" but there are programming questions which - in principle - would be best suited for this site.  If somebody is asking about an AI specific technique or something highly specialized like rule induction using OPS5, this community is probably a better resource than datascience.se, stats.se, or possibly even so. </p>
",AImeta,data science applied site yeah data science data science artificial intelligence overlap around statistical techniques machine learning identical please close questions highly technological asking applications sorry think misguided ignoring aspects implementation technology se like like football team fielding offense defense vice versa maybe say like reese peanut butter cup without chocolate simple truth say programming questions belong xxse programming questions principle would best suited site somebody asking ai specific technique something highly specialized like rule induction using ops5 community probably better resource datasciencese statsse possibly even
1,"<p>This is the second time I've seen something like this:</p>

<p><a href=""https://i.stack.imgur.com/fdzEk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fdzEk.png"" alt=""bug1""></a></p>

<p><a href=""https://i.stack.imgur.com/RTOW9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RTOW9.png"" alt=""bug2""></a></p>

<p>What's causing these odd line breaks? Why is it only showing up every now and then? Can you fix it?</p>

<p>EDIT: This happened again:</p>

<p><a href=""https://i.stack.imgur.com/pPOlI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pPOlI.png"" alt=""again""></a></p>

<p>Link for above: <a href=""https://ai.stackexchange.com/review/suggested-edits/546"">https://ai.stackexchange.com/review/suggested-edits/546</a></p>

<p>I'm using Google Chrome on Ubuntu.</p>

<p>EDIT: <a href=""https://meta.stackexchange.com/questions/284096/whats-happening-with-these-edit-review-histories"">Now posted on Meta.SE.</a></p>
",AImeta,second time seen something like causing odd line breaks showing every fix edit happened link using google chrome ubuntu edit
1,"<p>As far as I'm concerned, programming questions should be on-topic IF they are highly specific to AI.  That is, if somebody asks ""How do I add an item to a collection in Java"", that would be off-topic even if they were building an AI application.  But if somebody is doing something very specialized like Answer Set Programming in Prolog, etc., then I think this community would be best suited to answer that and, as such, the question should be considered on-topic.</p>
",AImeta,far concerned programming questions topic highly specific ai somebody asks add item collection java would topic even building ai application somebody something specialized like answer set programming prolog etc think community would best suited answer question considered topic
1,"<p>There's been some comment discussion as to whether a couple of questions e.g. <a href=""https://ai.stackexchange.com/questions/1784/using-feature-learning-for-a-medical-text-classification-problem"">this one</a> and <a href=""https://ai.stackexchange.com/questions/1783/how-to-represent-a-large-decision-tree"">this one</a> have been on topic.</p>

<p>In my opinion:</p>

<ol>
<li><p>We should take care not to readily dismiss technical questions
as being 'programming related'. </p></li>
<li><p>It's worth asking whether (even if the question mentions a specific
technique) it could be answered with reference to open issues in AI.</p></li>
</ol>

<p>For example, quite a number of questions (most of which have, in my opinion rightly, been left open without issue) are concerned with how to choose features for learning. In one respect, this is the single biggest issue facing AI: the current vogue for DL approaches is precisely because of the progress they claim in this area.</p>

<p>In particular: <em>the data science community has not solved this problem</em> - they are in general consumers of relatively stable research, rather than at the cutting edge, as is the case for AI.</p>

<p>Hence, we maybe shouldn't dismiss these things as implementation if they can usefully be treated conceptually.</p>

<p>Perhaps we can use ""Is this a solved problem (in research terms)"" as a heuristic to help us here. There's certainly precident for this: it is precisely the distinction between the 'Mathematics' and 'Math Overflow' SE sites.</p>
",AImeta,comment discussion whether couple questions eg topic opinion take care readily dismiss technical questionsas programming related worth asking whether even question mentions specifictechnique could answered reference open issues ai example quite number questions opinion rightly left open without issue concerned choose features learning one respect single biggest issue facing ai current vogue dl approaches precisely progress claim area particular data science community solved problem general consumers relatively stable research rather cutting edge case ai hence maybe dismiss things implementation usefully treated conceptually perhaps use solved problem research terms heuristic help us certainly precident precisely distinction amathematics amath overflow se sites
1,"<p>In this question: <a href=""https://ai.meta.stackexchange.com/questions/18/should-the-deep-network-tag-be-replaced-by-deep-learning"">Should the [deep-network] tag be replaced by [deep-learning]?</a>, it seems that it was agreed upon that the <a href=""https://ai.stackexchange.com/questions/tagged/deep-network"" class=""post-tag"" title=""show questions tagged &#39;deep-network&#39;"" rel=""tag"">deep-network</a> should be replaced by <a href=""https://ai.stackexchange.com/questions/tagged/deep-learning"" class=""post-tag"" title=""show questions tagged &#39;deep-learning&#39;"" rel=""tag"">deep-learning</a>. </p>

<p>However, currently, both tags are used. The <a href=""https://ai.stackexchange.com/questions/tagged/deep-network"" class=""post-tag"" title=""show questions tagged &#39;deep-network&#39;"" rel=""tag"">deep-network</a> is used by 18 questions, the <a href=""https://ai.stackexchange.com/questions/tagged/deep-learning"" class=""post-tag"" title=""show questions tagged &#39;deep-learning&#39;"" rel=""tag"">deep-learning</a> tag by 13 questions. Can we create a tag synonym?</p>
",AImeta,question seems agreed upon replaced however currently tags used used 18 questions tag 13 questions create tag synonym
1,"<blockquote>
  <p>Artificial Intelligence Stack Exchange is a question and answer site <strong>for people interested in conceptual questions about non-biological agents</strong>. Join them; it only takes a minute</p>
</blockquote>
",AImeta,artificial intelligence stack exchange question answer site people interested conceptual questions non biological agents join takes minute
1,"<p>When I think of ""implementation"", things like math and code come to mind, while the larger components of AI construction don't fall under that category. Selecting features to build an AI for a certain purpose would therefore be on-topic, though they could easily be too broad. <a href=""https://ai.stackexchange.com/q/1784/75"">Your first example</a> approaches ""how do I solve this important problem with AI?"", which possibly requires a deep knowledge of that field.</p>

<p>Questions tangentially related to programming, but not actually about the coding of the AI itself, are also OK. <a href=""https://ai.stackexchange.com/q/1783/75"">Your second example</a> asks how to represent part of an AI's state for debugging visualization. It's a pretty neat question in my opinion, landing squarely in the science part of artificial intelligence.</p>

<p>I would be a little wary of allowing questions about the fine details (i.e. the mathematical/statistical mechanics) of yet-to-be-solved research problems, as those are likely to be much better served at one of the math-heavy sites. Conceptual questions about what kinds of things they work on are interesting and well-suited to our site.</p>

<p>Executive summary: if a question has mathematical formulae or computer code as critical elements, the best home for it is <em>possibly</em> a different site. This answer contains a lot of weasel words to emphasize that's it's not at all a rulebook that applies everywhere. Such an answer would be a tome.</p>
",AImeta,think implementation things like math code come mind larger components ai construction fall category selecting features build ai certain purpose would therefore topic though could easily broad approaches solve important problem ai possibly requires deep knowledge field questions tangentially related programming actually coding ai also ok asks represent part ai state debugging visualization pretty neat question opinion landing squarely science part artificial intelligence would little wary allowing questions fine details ie mathematical statistical mechanics yet solved research problems likely much better served one math heavy sites conceptual questions kinds things work interesting well suited site executive summary question mathematical formulae computer code critical elements best home possibly different site answer contains lot weasel words emphasize rulebook applies everywhere answer would tome
1,"<p>I would say that it's a judgment call on a case by case basis.  I don't think there's a simple rule you can implement that can capture all of the nuance involved here.  My feeling is, unless you say with pretty close to <strong>absolute certainty</strong> that a question which includes code would get a better answer somewhere else, it's better to err on the side of leaving it alone.</p>

<p>That a question might contain math is, to me, nearly completely irrelevant to whether a question belongs here or not.  Irrelevant in that it's orthogonal to the issue of whether something is ""conceptual"" or ""implementation"".  After all, math <strong>is</strong> the language of science.  </p>
",AImeta,would say judgment call case case basis think simple rule implement capture nuance involved feeling unless say pretty close absolute certainty question includes code would get better answer somewhere else better err side leaving alone question might contain math nearly completely irrelevant whether question belongs irrelevant orthogonal issue whether something conceptual implementation math language science
1,"<p>Here's one idea:  Search Meetup.com for meetups which are related to artificial intelligence, and post this link to their message boards and / or mailing lists, with a brief note saying ""you may find this of interest"".</p>
",AImeta,one idea search meetupcom meetups related artificial intelligence post link message boards mailing lists brief note saying may find interest
1,"<p>For example:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/1824/8"">Why would an AI need to &#39;wipe out the human race&#39;?</a></li>
</ul>

<p>There is already the website for <a href=""https://philosophy.stackexchange.com/"">philosophical question</a>, however here we can have more direct answers from the AI experts.</p>

<p>Should we allow such questions?</p>
",AImeta,example already website however direct answers ai experts allow questions
1,"<p>Yes. </p>

<p>If we send away everyone asking about philosophy; send everyone asking about feature selection for ANNs to data science and send everyone asking about AI research institutes to chat then there's really not so much left to talk about.</p>
",AImeta,yes send away everyone asking philosophy send everyone asking feature selection anns data science send everyone asking ai research institutes chat really much left talk
1,"<p>I am trying to learn about deep reinforcement learning and using OpenAI's gym but I have doubts in how its python code works. Can I ask about explanation regarding whats happening in the gym programming code implementation here or else I have to ask in data analysis.SE?</p>
",AImeta,trying learn deep reinforcement learning using openai gym doubts python code works ask explanation regarding happening gym programming code implementation else ask data analysisse
1,"<p>Unfortunately, <strong>no.</strong> This has been decided that it is off-topic here. See <a href=""https://ai.meta.stackexchange.com/questions/1141/a-friendly-reminder-that-this-site-comes-from-the-science-category"">this meta post</a>.</p>
",AImeta,unfortunately decided topic see
1,"<p>As we can see the current <a href=""http://area51.stackexchange.com/proposals/93481/artificial-intelligence"">stats of the site</a>: </p>

<p><a href=""https://i.stack.imgur.com/VvdrO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VvdrO.png"" alt=""site statistics""></a></p>

<p>Alos, we've had similar proposal which all went in vain:</p>

<ol>
<li><a href=""http://area51.stackexchange.com/proposals/6607/artificial-intelligence"">Closed after 12 days in beta</a></li>
<li><a href=""http://area51.stackexchange.com/proposals/57719/artificial-intelligence"">Closed after 18 days in beta</a></li>
</ol>

<p>What should be done to maintain a healthy site?  </p>
",AImeta,see current alos similar proposal went vain done maintain healthy site
1,"<p>Don't worry! We've passed the private beta mark, while the sites you mentioned were closed during that stage. That indicates that Stack Exchange reviewed our progress and determined that we're doing well enough to continue into <em>public</em> beta, which is <a href=""https://ai.meta.stackexchange.com/q/1202/75"">where we are now</a>.</p>

<p>Regarding the Area 51 stats: those goals are what you should expect from a site that's about to graduate fully. In days of old, it was expected that graduation would happen at 90 days in or else the site would indeed be closed. Now, sites can stay in beta as long as necessary. For more information, see <a href=""https://meta.stackexchange.com/q/257614/295684"">Graduation, site closure, and a clearer outlook on the health of SE sites</a>.</p>

<p>All that said, we should be promoting this site and growing the community. Asking quality questions and providing great answers is an excellent way to improve the site. We're collecting ideas for site promotion here: <a href=""https://ai.meta.stackexchange.com/q/1/75"">How do we promote this site?</a></p>
",AImeta,worry passed private beta mark sites mentioned closed stage indicates stack exchange reviewed progress determined well enough continue public beta regarding area 51 stats goals expect site graduate fully days old expected graduation would happen 90 days else site would indeed closed sites stay beta long necessary information see said promoting site growing community asking quality questions providing great answers excellent way improve site collecting ideas site promotion
1,"<p>I have been thinking about the <em>""shelf life""</em> of the questions &amp; answers here, and have the following observations:</p>

<p><strong>1.</strong> Artificial Intelligence is a rapidly changing, very active research area. I think there are questions open... I mean without <em>current</em> answer, to say it coarsely. I can imagine, that some answers will turn out to be out-of-date or be outperformed many times. It is possible that in one month or one year we get a very different answer, because <strong>(a)</strong> Some people are researching actively and discovered something amazing, or <strong>(b)</strong> New users come to the site (and knew of a better answer).</p>

<p><strong>2.</strong> AI.SX is definitely different from other sites in stackexchage, because the questions are not like <em>quickies</em>. It is not like <em>I need to solve this urgent issue now, how do I do it?</em>. Many questions have different answers, which often complement themselves. Also, from the comments on an answer (or question), it can be edited to include new points and will be better.</p>

<p><strong>3.</strong> The former point is much more noticeable, since this site is about <em>science</em> and not <em>technology</em>. The topic about specific algorithms or techniques has been discussed here on several meta questions. A side-effect is that the questions tend to be (in my opinion) broader. I personally think that is OK, and wish for a certain discussion rather than <strong>the</strong> answer.</p>

<p>Seeing all that, I think that many questions could be left open for... Well, like forever. Because many are <em>active</em> questions, which cannot be <em>solved</em> like in other sites of the network: </p>

<p><strong>Question → Answer → <code>hasaccepted:yes</code></strong></p>

<p>Perhaps that could lead to more answers in community wiki, to which one comes (next month) after reading some new things or hearing another conference? </p>

<p>Or we just get new answers to questions with an accepted answer and switch (the checkmark) if the new is better?</p>

<p>What do you think will happen?</p>
",AImeta,thinking shelf life questions answers following observations 1 artificial intelligence rapidly changing active research area think questions open mean without current answer say coarsely imagine answers turn date outperformed many times possible one month one year get different answer people researching actively discovered something amazing b new users come site knew better answer 2 aisx definitely different sites stackexchage questions like quickies like need solve urgent issue many questions different answers often complement also comments answer question edited include new points better 3 former point much noticeable since site science technology topic specific algorithms techniques discussed several meta questions side effect questions tend opinion broader personally think ok wish certain discussion rather answer seeing think many questions could left open well like forever many active questions solved like sites network question answer perhaps could lead answers community wiki one comes next month reading new things hearing another conference get new answers questions accepted answer switch checkmark new better think happen
1,"<p>I think that we could try to promote the site with people from a broad range of disciplines. I remember seeing on Area51 what other people committed to, and there were mostly engineering or computer-related sites. Perhaps we need some philosophers, some psychologists, some neuroscientists and linguists here. </p>

<p>Maybe encouraging questions on other sites of the SX-network?</p>

<p>Or social networks posts?</p>

<hr>

<p>I also wanted to add another site which has overlapping topics: <a href=""https://cogsci.stackexchange.com/"">Cognitive Sciences</a></p>
",AImeta,think could try promote site people broad range disciplines remember seeing area51 people committed mostly engineering computer related sites perhaps need philosophers psychologists neuroscientists linguists maybe encouraging questions sites sx network social networks posts also wanted add another site overlapping topics
1,"<blockquote>
  <p>Or we just get new answers to questions with an accepted answer and switch (the checkmark) if the new is better?</p>
</blockquote>

<p><strong>Yes.</strong> That's <em>exactly</em> what we'll do. It makes no sense to do it any other way.</p>

<p>If we have community-wiki answers to everything, than that complicates the reputation system, also - not enough people will reach new privilege levels.</p>

<p>As the field grows and changes, so too the site - we'll have new questions, and new answers to old questions.</p>
",AImeta,get new answers questions accepted answer switch checkmark new better yes exactly makes sense way community wiki answers everything complicates reputation system also enough people reach new privilege levels field grows changes site new questions new answers old questions
1,"<p>This is something to consider even on very technical sites like Stack Overflow. New developments (e.g. new language features) allow new and better solutions to problems. That's yet another reason why questions should allow new answers even after one is accepted. The accept mark indicates that the answer is the best for the question poster at the time. In some cases, the question poster vanishes, never to be seen again on the site. Fortunately, we have something else to measure answer usefulness:</p>

<p><strong>Votes.</strong> Posts accept votes forever (in most cases), and new answers (among other events) push the question back onto the site front page so it can be examined anew. Community members should definitely read new posts and vote on their quality. In an ideal world, better answers would always overtake old decent answers in score, but that doesn't always happen. If you see a really awesome answer going unnoticed, you might consider <a href=""https://ai.stackexchange.com/help/bounty"">placing a bounty</a>!</p>

<p>As Mithrandir mentioned, community wiki isn't ideal for this scenario, since it has the undesired effect of disabling reputation changes. Newer users should add new takes on the issue via new answers (or possibly comments, if the changes are tiny).</p>
",AImeta,something consider even technical sites like stack overflow new developments eg new language features allow new better solutions problems yet another reason questions allow new answers even one accepted accept mark indicates answer best question poster time cases question poster vanishes never seen site fortunately something else measure answer usefulness votes posts accept votes forever cases new answers among events push question back onto site front page examined anew community members definitely read new posts vote quality ideal world better answers would always overtake old decent answers score always happen see really awesome answer going unnoticed might consider mithrandir mentioned community wiki ideal scenario since undesired effect disabling reputation changes newer users add new takes issue via new answers possibly comments changes tiny
1,"<p>Recently we've gone through very critical private stage where 3 attempts since the last 6 years failed to success. See: <a href=""https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/"">No AI in Area51</a>.</p>

<p>Since we've successfully passed the final review process, we've now more time to improve and expand our site to match the healthy state, before graduating to full site (it can take months or even years to achieve that stage).</p>

<p>If you check <a href=""http://stackexchange.com/sites#questionsperday"">All sites statistics</a> and compare to other sites and take into the account that we've just entered the public beta, so it's not so bad as it looks (>30 sites with less questions asked per day). It just takes time for new people to join and starting using the site, not everybody knows about it yet.</p>

<p>As <a href=""https://ai.meta.stackexchange.com/a/1199/8"">@Robert</a> mentioned few weeks ago:</p>

<blockquote>
  <p>we stumbled upon in interesting niche that describes the original premise of this site</p>
</blockquote>

<p>Currently we are in stage of clarifying the scope as per: <a href=""https://ai.meta.stackexchange.com/q/1197/8"">How can we quickly describe our site?</a></p>

<p>Instead of worrying about it, we should ask ourselves: <a href=""https://ai.meta.stackexchange.com/q/1/8"">How do we promote this site?</a></p>
",AImeta,recently gone critical private stage 3 attempts since last 6 years failed success see since successfully passed final review process time improve expand site match healthy state graduating full site take months even years achieve stage check compare sites take account entered public beta bad looks 30 sites less questions asked per day takes time new people join starting using site everybody knows yet mentioned weeks ago stumbled upon interesting niche describes original premise site currently stage clarifying scope per instead worrying ask
1,"<p>I think Stack Exchange A.I. site is self-promoted and it does not need promotion. We just need a bit more time, that's all. I think this site has enough active experts so far, so our <em>answer ratio</em> is fine (1.8 at the time of writing).</p>

<p>Secondly given Stack Exchange higher ranked <a href=""https://en.wikipedia.org/wiki/Search_engine_optimization"" rel=""nofollow noreferrer"">SEO</a> abilities, people looking for A.I. answers will quickly find this place. Especially having in mind that A.I. is more likely to be the next big boom for this century, I believe next year we'll hit the <a href=""https://ai.meta.stackexchange.com/q/1225/8"">site healthy stats</a> without even promoting it.</p>

<p>Although if we decide to promote it, we need to be careful, as promoting this site to the wrong communities, this can result in lot of people asking the broad and opinion based posts.</p>

<p>Artificial promotion isn't a good one, but sharing the AI links to the good answers on relevant forum posts or reddit-like sites is a great start.</p>
",AImeta,think stack exchange ai site self promoted need promotion need bit time think site enough active experts far answer ratio fine 18 time writing secondly given stack exchange higher ranked abilities people looking ai answers quickly find place especially mind ai likely next big boom century believe next year hit without even promoting although decide promote need careful promoting site wrong communities result lot people asking broad opinion based posts artificial promotion good one sharing ai links good answers relevant forum posts reddit like sites great start
1,"<p>Yes, but I think many philosophical questions would be better off on Philosophy SE. It depends on the type of question. Questions that AI experts have mostly thought about (like <a href=""https://ai.stackexchange.com/q/1824/8"">""Why would an AI need to 'wipe out the human race'?""</a>) are better suited here, while questions that are tangentially related to AI but are really referring to ""philosophical concepts"" (<a href=""https://philosophy.stackexchange.com/questions/37442/are-robot-rebellions-even-possible"">robotic free will</a> and <a href=""https://philosophy.stackexchange.com/questions/11450/can-computers-be-programmed-to-be-creative/15617#15617"">AI creativity</a>) are better left to the philosophy experts.</p>
",AImeta,yes think many philosophical questions would better philosophy se depends type question questions ai experts mostly thought like better suited questions tangentially related ai really referring philosophical concepts better left philosophy experts
1,"<p>I'm sorry, but we can't just go with a simple, blanket statement like ""Programming, algorithm, modeling, math, philosophy, and history questions should the off-topic, as they are already on-topic in other SE, such as Stats and Data Science.""  Why? Because not <em>all</em> questions about ""programming, algorithms, modeling..."", vis-a-vis Artificial Intelligence, are on-topic at those other sites!  But they are here.</p>

<p>And what's the distinction that should be in play?  Well, simply, ""programming, algorithms, modeling, math, etc. that are *specific to AI"" are on-topic here.  It really can't be any other way.</p>

<p>I mean, think about it... we claim to be a ""science"" site, but then try to say that ""math"" is off-topic? That's absurd.  Science <em>is</em> math and math <em>is</em> science.  Or to put it another way ""math is the language of science"".  </p>

<p>If we keep pushing this idea that all hard technical questions are off-topic, all we're going to get are vague questions about speculative aspects of AI, with answers that are nothing to speculation and hand-waving.  </p>

<p>What should be on-topic?  Questions about Artificial Intelligence, full-stop. It's right there in the name on the marquee sign, as they say.  </p>
",AImeta,sorry go simple blanket statement like programming algorithm modeling math philosophy history questions topic already topic se stats data science questions programming algorithms modeling vis vis artificial intelligence topic sites distinction play well simply programming algorithms modeling math etc specific ai topic really way mean think claim science site try say math topic absurd science math math science put another way math language science keep pushing idea hard technical questions topic going get vague questions speculative aspects ai answers nothing speculation hand waving topic questions artificial intelligence full stop right name marquee sign say
1,"<p>I think that science without mathematics is usually impossible, science without technology is very difficult (otherwise how to talk about computers for example) but science without programming/implementations is possible.</p>

<p>The emphasis would then be on the concepts and/or abstractions.</p>

<p>So kind of:</p>

<ul>
<li>pseudocode is okay, real code not</li>
<li>algorithms are okay, implementations not</li>
<li>Math is okay as long as the concepts remain abstract.</li>
</ul>

<p>How to put that into a single line? </p>

<blockquote>
  <p>Artificial Intelligence Stack Exchange is a site <strong>for people
  interested in social, conceptual and scientific questions about Advanced
  Computing</strong>. Join them; it only takes a minute</p>
</blockquote>

<p>I feel this tries most to keep away from any implementations. But I also feel the limit should only be implementations, not higher level programming, algorithms, maths or statistics.</p>
",AImeta,think science without mathematics usually impossible science without technology difficult otherwise talk computers example science without programming implementations possible emphasis would concepts andor abstractions kind pseudocode okay real code algorithms okay implementations math okay long concepts remain abstract put single line artificial intelligence stack exchange site people interested social conceptual scientific questions advanced computing join takes minute feel tries keep away implementations also feel limit implementations higher level programming algorithms maths statistics
1,"<p>A for loop is not the same as gradient decent.  Gradient decent is not the same as NN convergence, or generalization.  You cannot do the latter without the former.</p>

<p>Biology is really Chemistry.  Chemistry is really Physics.  Physics is really math.  If we required doctors to work through the math, then the quantum physics and molecular electronics, then the chemistry before they could do medicine they would die of old age first.</p>

<p>I think that we are trying to separate the fields of computer programming, data science, and such into layers of abstractions.  Each layer has to be thick - to stand on its own and properly envelope its content.</p>

<p>Right now, Machine Learning and Artificial intelligence are ""young"" so there is going to be nuts and bolts.  If we don't give clean bridges there then this area gets to be a philosophical wasteland - no engineering allowed.  If we have some courtesy and we are willing to realize that the divisions are not clean yet, then we can make better mileage toward building a richer community.</p>
",AImeta,loop gradient decent gradient decent nn convergence generalization latter without former biology really chemistry chemistry really physics physics really math required doctors work math quantum physics molecular electronics chemistry could medicine would die old age first think trying separate fields computer programming data science layers abstractions layer thick stand properly envelope content right machine learning artificial intelligence young going nuts bolts give clean bridges area gets philosophical wasteland engineering allowed courtesy willing realize divisions clean yet make better mileage toward building richer community
1,"<ol>
<li><p>The <a href=""http://area51.stackexchange.com/proposals/93481/artificial-intelligence"">site proposal</a> on the Area51:</p>

<blockquote>
  <p>""For conceptual questions about life and challenges in a world where
  ""cognitive"" functions can be mimicked in purely digital environment.""</p>
</blockquote>

<p>This very clearly includes the border to the phylosophy.</p></li>
<li><p><em>Don't narrow the site topics.</em></p>

<p>It results only a mass of people leaving the site disappointed after the closure of their first questions. With them, we lose not only their content, but also the content they could have made if their first experiences had been better.</p>

<p>There is a so-named ""common sense"", what belongs to AI. It is what an ordinary people, who doesn't even know that a meta site exists, thinks what is AI. In my opinion, <em>the topic of the site shouldn't ever be narrowed significantly below this ""common sense""</em>.</p></li>
<li><p>Pragmatical reasons.</p>

<p>Currently we are absolutely not in the position where we could have the luxury to close questions. Later it may be better, but (1) and (2) will stay even then.</p></li>
</ol>

<hr>

<p>Note, I don't really like philosophical questions. I think the AI is more like on the engineering/science border as philosophical thing. If the site would seem to sink in the mess of endless philosophical debates, I would suggest to make a <em>little</em> limit (for example, to use the VtC as duplicate votes more rigorously), but this is not the case (now).</p>
",AImeta,area51 conceptual questions life challenges world cognitive functions mimicked purely digital environment clearly includes border phylosophy narrow site topics results mass people leaving site disappointed closure first questions lose content also content could made first experiences better named common sense belongs ai ordinary people even know meta site exists thinks ai opinion topic site ever narrowed significantly common sense pragmatical reasons currently absolutely position could luxury close questions later may better 1 2 stay even note really like philosophical questions think ai like engineering science border philosophical thing site would seem sink mess endless philosophical debates would suggest make little limit example use vtc duplicate votes rigorously case
1,"<p>I would like to save content from them, but I can't find them on the A51. Maybe it is because I don't have a really high reputation there currently.</p>

<p>Could somebody (maybe a 10k+ A51 user) get a link to the old dumps?</p>
",AImeta,would like save content find a51 maybe really high reputation currently could somebody maybe 10k a51 user get link old dumps
1,"<p>I don't think you need 10K on Area 51 to see the data dumps; they seem to work even if you're not signed in. At the top, there's a little banner that says this, with the appropriate link where I have bold:</p>

<blockquote>
  <p>The AI site didn't have enough activity during the beta, and has been closed. You can download the <strong>data dump of all questions here</strong>.</p>
</blockquote>

<p>Here are the links to the two previous AI proposals that I know of:</p>

<ul>
<li><a href=""http://area51.stackexchange.com/proposals/6607/artificial-intelligence"">The original</a>, the subject of <a href=""https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/"">this SE blog post</a>. Possibly <a href=""https://meta.stackexchange.com/questions/279893/include-the-child-metas-of-closed-sites-in-their-data-dump#comment907488_279910"">the first closed SE site</a>, and only the main site's data (not the meta) is available. <strong><a href=""http://sstatic.net/area51/datadumps/122010%20Artificial%20Intelligence.zip"" rel=""nofollow noreferrer"">Direct download.</a></strong></li>
<li><a href=""http://area51.stackexchange.com/proposals/57719/artificial-intelligence"">The second try</a>. This one has both meta and main in the data dump. <strong><a href=""http://sstatic.net/area51/datadumps/022014%20Artificial%20Intelligence.zip"" rel=""nofollow noreferrer"">Direct download.</a></strong></li>
</ul>

<p>Also, there was a <a href=""http://area51.stackexchange.com/proposals/41738/machine-learning"">closed Machine Learning proposal</a>, <strong><a href=""http://sstatic.net/area51/datadumps/082013%20Machine%20Learning.zip"" rel=""nofollow noreferrer"">direct data dump download here</a></strong>. <a href=""http://area51.stackexchange.com/proposals/26434/machine-learning"">Another one</a>, slightly older, is indeed missing the data dump, and unfortunately it <a href=""https://area51.meta.stackexchange.com/q/25354/136466"">probably doesn't exist</a>.</p>
",AImeta,think need 10k area 51 see data dumps seem work even signed top little banner says appropriate link bold ai site enough activity beta closed download data dump questions links two previous ai proposals know subject possibly main site data meta available one meta main data dump also slightly older indeed missing data dump unfortunately
1,"<p>Practical applications should be on topic here, at least at some extend to keep proportion between philosophy and implementations.</p>

<p>This is important in therms of building community. It is hard to change course later, and if you will this place to be one of fantasy-futurology-imaginary world building site of SE then strike out practical application.</p>

<p>this question could be asked on WB as well <a href=""https://ai.stackexchange.com/questions/1897/is-consciousness-necessary-for-any-ai-task"">Is consciousness necessary for any AI task?</a> people there are very exited in discussing consciousness.</p>

<p>This question is definitely low quality <a href=""https://ai.stackexchange.com/questions/1869/deep-neural-network-for-not-so-popular-board-game"">https://ai.stackexchange.com/questions/1869/deep-neural-network-for-not-so-popular-board-game</a> , for obvious reasons, fresh enthusiastic member with practical question - holding it discourages people who where fresh attracted, attracted by super title <em>Artificial Intelligence</em>, not boring <em>Data Science</em> where you do not know what to expect as Science of Data is big field. But there is short and clear AI, yes I wish one, give me two.</p>

<p>At the moment there is no implementations of AI(in movie sense)(known, for me, not a expert)
For that reason to keep track on the ground, practical application should be even if this site is intended to be subset of philosophy about AI.
Maybe change name then to reflect that - based on AI.SE I had expectation to see there useful stuff. From PAI.SE I expect nothing, not interested to know will AI kill humanity or not, how it will change perception of humanity about world, whatever.</p>

<p>At least amateur level implementation should be, at <em>least</em> it is bare minimum what you need.
Probably even that is not enough and will not work out. You should decide is that philosophy site or is that site about AI, if second then everything about AI(creation, theory, implementation, consequences) should be on topic here - all or nothing, have balls people, it is important for mankind, for our future.</p>

<p>You should discuss more which promises name promises - Artificial Intelligence - and whom it attracts.</p>
",AImeta,practical applications topic least extend keep proportion philosophy implementations important therms building community hard change course later place one fantasy futurology imaginary world building site se strike practical application question could asked wb well people exited discussing consciousness question definitely low quality obvious reasons fresh enthusiastic member practical question holding discourages people fresh attracted attracted super title artificial intelligence boring data science know expect science data big field short clear ai yes wish one give two moment implementations aiin movie senseknown expertfor reason keep track ground practical application even site intended subset philosophy aimaybe change name reflect based aise expectation see useful stuff paise expect nothing interested know ai kill humanity change perception humanity world whatever least amateur level implementation least bare minimum needprobably even enough work decide philosophy site site ai second everything aicreation theory implementation consequences topic nothing balls people important mankind future discuss promises name promises artificial intelligence attracts
1,"<p><a href=""https://ai.stackexchange.com/questions/1931/if-people-are-building-ai-systems-will-the-programming-also-be-aggressiveness-o"">This question</a> seems to me to be on-topic, but I can't figure out what it should be tagged.</p>

<p>It's currently tagged <a href=""https://ai.stackexchange.com/questions/tagged/computer-programming"" class=""post-tag"" title=""show questions tagged &#39;computer-programming&#39;"" rel=""tag"">computer-programming</a>, which is obviously incorrect - see the tag wiki (that I wrote :P). I thought about <a href=""https://ai.stackexchange.com/questions/tagged/philosophy"" class=""post-tag"" title=""show questions tagged &#39;philosophy&#39;"" rel=""tag"">philosophy</a>, but that didn't really seem to fit either.</p>

<p>So, <strong>what should this be tagged</strong>?</p>
",AImeta,seems topic figure tagged currently tagged obviously incorrect see tag wiki wrote p thought really seem fit either tagged
1,"<p>One decent option that already exists is <a href=""https://ai.stackexchange.com/questions/tagged/human-like"" class=""post-tag"" title=""show questions tagged &#39;human-like&#39;"" rel=""tag"">human-like</a>. It currently only has two questions: one comparing human brains with neural networks, and one about AIs lying to humans. This question is about whether AIs' personalities can be distinguished into categories like those used for humans'. Since personalities are a human-like thing to have*, it would seem to fit in that tag as it's used so far. I suggested an edit that replaced the incorrect tag with this one, and it was approved by the post owner.</p>

<p>In my understanding, that specific question only applies to general AIs (as opposed to something like an image recognizer). Therefore, <a href=""https://ai.stackexchange.com/questions/tagged/agi"" class=""post-tag"" title=""show questions tagged &#39;agi&#39;"" rel=""tag"">agi</a> could also be relevant.</p>

<p><sup>*Yes, animals can have personalities too. Animals can also <a href=""https://en.wikipedia.org/wiki/Deception_in_animals"" rel=""nofollow noreferrer"">deceive</a>.</sup></p>
",AImeta,one decent option already exists currently two questions one comparing human brains neural networks one ais lying humans question whether ais personalities distinguished categories like used humans since personalities human like thing would seem fit tag used far suggested edit replaced incorrect tag one approved post owner understanding specific question applies general ais opposed something like image recognizer therefore could also relevant yes animals personalities animals also
1,For questions on Meta that relate to a specific question on Artificial Intelligence Stack Exchange.,AImeta,questions meta relate specific question artificial intelligence stack exchange
1,"For questions on whether a question, or category of questions, falls within the site scope.",AImeta,questions whether question category questions falls within site scope
1,"<p>It seems to me that the visit stats have tailed off quite dramatically over the last week or so: upwards of 400 down to 200 or so.</p>

<p>The number of new questions also seems to have diminished, so maybe now is a good time for us all to start asking new ones with the kind of enthusiasm that <a href=""https://ai.meta.stackexchange.com/users/8/kenorb"">kenorb</a> brought to the party when the site launched?</p>

<p>For my part, I'm travelling today and tomorrow, but will attempt to come up with something meaningful thereafter.</p>
",AImeta,seems visit stats tailed quite dramatically last week upwards 400 200 number new questions also seems diminished maybe good time us start asking new ones kind enthusiasm brought party site launched part travelling today tomorrow attempt come something meaningful thereafter
1,"<p>More questions certainly would be great, but a low-activity period (the length of which varies from site to site) after the public beta start is normal. For more information, see <a href=""https://meta.stackexchange.com/q/227007/295684"">What is the typical growth pattern of a new beta site in the first few weeks?</a> </p>

<p>If I perceive correctly, we did get something of an extra boost from ""can a paradox kill an AI?"" being in Hot Network Questions for a few days. It would be great if we could produce more content that's both high-quality and interesting to a lot of people. </p>

<p>So yes, if anyone has additional well-thought-out questions in mind, we would be happy to have them!</p>
",AImeta,questions certainly would great low activity period length varies site site public beta start normal information see perceive correctly get something extra boost paradox kill ai hot network questions days would great could produce content high quality interesting lot people yes anyone additional well thought questions mind would happy
1,"<p>There's definitely been a fall-off, but as others have said, it will take time for people to find the site and become engaged.  I feel like one of the most important thing to do in the meantime is keep asking <em>some</em> quality questions, and/or get additional answers to existing questions, such that first time visitors won't perceive the site as dormant.  From a network science POV, we want a ""preferential attachment"" sort of scenario, where new nodes attach themselves to this node and grow our network.  </p>
",AImeta,definitely fall others said take time people find site become engaged feel like one important thing meantime keep asking quality questions andor get additional answers existing questions first time visitors perceive site dormant network science pov want preferential attachment sort scenario new nodes attach node grow network
1,"<p>What should we have in <em><a href=""https://ai.stackexchange.com/help/asking"">Help Center > Asking</a></em> section regarding <a href=""https://ai.stackexchange.com/help/on-topic"">What topics can I ask about here?</a></p>

<p>For example <a href=""https://stats.stackexchange.com/help/on-topic"">Stats SE</a> has this:</p>

<blockquote>
  <p>CrossValidated is for statisticians, data miners, and anyone else
  doing data analysis or interested in it as a discipline. If you have a
  question about</p>
  
  <ul>
  <li>statistical analysis, applied or theoretical</li>
  <li>designing experiments</li>
  <li>collecting data</li>
  <li>data mining</li>
  <li>machine learning</li>
  <li>visualizing data</li>
  <li>probability theory</li>
  <li>mathematical statistics</li>
  <li>statistical and data-driven computing</li>
  </ul>
</blockquote>

<p>And here is /help/on-topic at <a href=""https://datascience.stackexchange.com/help/on-topic"">Data Science</a>:</p>

<blockquote>
  <p>Examples of questions that are likely to be on-topic for Data Science
  Stack Exchange:</p>
  
  <ul>
  <li>Given process monitoring data arriving every 10ms, what statistical tool should I use to best characterize a change in the process - mean?
  a distribution?</li>
  <li>When is it suitable to apply L1 regularization for feature selection?</li>
  <li>I would like to produce a infographic on the 'Brexit' referendum. Given public opinion data across the UK, what are some meaningful
  techniques to visaualize it in a dashboard?</li>
  <li>When executing an ARIMA model in Spark, what are the pros and cons of using Python instead of R?</li>
  <li>Given Facebook Likes, is there an ML technique to predict age and gender?</li>
  </ul>
</blockquote>

<p>If we would like to differentiate from the above sites, we should have our unique section about the topics which people can ask about here.</p>

<p>What description of <a href=""https://ai.stackexchange.com/help/on-topic"">/help/on-topic page for AI site</a> would you suggest?</p>
",AImeta,section regarding example crossvalidated statisticians data miners anyone else data analysis interested discipline question statistical analysis applied theoretical designing experiments collecting data data mining machine learning visualizing data probability theory mathematical statistics statistical data driven computing help topic examples questions likely topic data science stack exchange given process monitoring data arriving every 10ms statistical tool use best characterize change process mean distribution suitable apply l1 regularization feature selection would like produce infographic brexit referendum given public opinion data across uk meaningful techniques visaualize dashboard executing arima model spark pros cons using python instead r given facebook likes ml technique predict age gender would like differentiate sites unique section topics people ask description would suggest
1,"<p>Drawing on these existing discussions:</p>

<ul>
<li><a href=""https://ai.meta.stackexchange.com/q/1197/75"">How can we quickly describe our site?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1221/75"">Should philosophical questions related to AI be on-topic?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1141/75"">A friendly reminder that this site comes from the Science category</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1123/75"">How this site is different from Cross Validated?</a></li>
</ul>

<p>Also taking some inspiration from <a href=""https://superuser.com/help/on-topic"">the Super User ""on topic"" page</a>, here's my first stab at it:</p>

<blockquote>
  <p>If you have a question about...</p>
  
  <ul>
  <li>social issues in a world where artificial intelligence is common,</li>
  <li>conceptual aspects of AI, or</li>
  <li>human factors in AI development</li>
  </ul>
  
  <p>...and it is <em>not</em> about...</p>
  
  <ul>
  <li>the <a href=""https://ai.meta.stackexchange.com/q/1215/75"">implementation</a> of machine learning, or</li>
  <li>asking for a development tool or career path recommendation</li>
  </ul>
  
  <p>...then you're in the right place to ask your question!</p>
</blockquote>

<p>This is only a draft, but it seems like a good starting point. Please suggest improvements if you see anything that needs adjustment! Specifically, I'm not sure how specific we need to be about what constitutes ""implementation"" in this blurb. If there are other commonly asked kinds of off-topic questions, those could be worth mentioning too.</p>
",AImeta,drawing existing discussions also taking inspiration first stab question social issues world artificial intelligence common conceptual aspects ai human factors ai development machine learning asking development tool career path recommendation right place ask question draft seems like good starting point please suggest improvements see anything needs adjustment specifically sure specific need constitutes implementation blurb commonly asked kinds topic questions could worth mentioning
1,"<p>I feel like the following question is missing a tag:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/2015/8"">https://ai.stackexchange.com/q/2015/8</a></li>
</ul>

<p>that would highlight that this question is about <a href=""https://ai.stackexchange.com/questions/tagged/technology"" class=""post-tag"" title=""show questions tagged &#39;technology&#39;"" rel=""tag"">technology</a> or physical device.</p>

<p>Would you think creating tag like <a href=""https://ai.stackexchange.com/questions/tagged/technology"" class=""post-tag"" title=""show questions tagged &#39;technology&#39;"" rel=""tag"">technology</a> will help? Or it would be too broad, or do you have any better suggestion? Or it is fine as it is?</p>
",AImeta,feel like following question missing tag would highlight question physical device would think creating tag like help would broad better suggestion fine
1,"<p>I don't know if the question you linked is suitably tagged, but I don't think a <code>technology</code> tag will help better categorize content. </p>

<p>""Technology"" is one of those <em>broad</em> terms that can be applied to many many things. I think  a <code>technology</code> tag would be applied inconsistently at best, and it will <em>likely</em> attract a lot of unrelated questions without adding any clarity to what they are about.</p>
",AImeta,know question linked suitably tagged think tag help better categorize content technology one broad terms applied many many things think tag would applied inconsistently best likely attract lot unrelated questions without adding clarity
1,"<p>Throughout the beta, we need members from the site whose focus is to engage the community, both in community-building issues and site management. That's why we select a few members from each community to act as temporary, provisional moderators. You can read about the program here: <a href=""http://blog.stackoverflow.com/2010/07/moderator-pro-tempore/""><strong>Moderators Pro Tempore</strong></a>.</p>
<p>I am pleased to announce that these members have stepped up and generously volunteered their time to help us assure that every community’s issues are properly addressed:</p>
<p><a href=""https://ai.stackexchange.com/users/10""><img src=""https://ai.stackexchange.com/users/flair/10.png"" alt=""Matthew Graves"" /></a>
<a href=""https://ai.stackexchange.com/users/42""><img src=""https://ai.stackexchange.com/users/flair/42.png"" alt=""NietzscheanAI"" /></a>
<a href=""https://ai.stackexchange.com/users/75""><img src=""https://ai.stackexchange.com/users/flair/75.png"" alt=""Ben N"" /></a></p>
<p>We want to make this site a huge success, and these members are great examples of exactly the type of people we need to make this site succeed. Please welcome them and appreciate the hard work and time they will contribute.</p>
<h3>Did I overlook anyone?</h3>
<p>Almost certainly. There are many members here who are actively involved and very deserving of recognition. My failure to account for everyone this early on is in <em>no way</em> a slight against them. Ideally, moderators should elected by the community, and that's why we'll hold elections once the site graduates.</p>
<p>Most of all, be respectful and understanding of the Moderators Pro Tem. Members of your community are volunteering their time and learning on the job. It’s a learning experience for everyone.</p>
",AImeta,throughout beta need members site whose focus engage community community building issues site management select members community act temporary provisional moderators read program pleased announce members stepped generously volunteered time help us assure every community issues properly addressed want make site huge success members great examples exactly type people need make site succeed please welcome appreciate hard work time contribute overlook anyone almost certainly many members actively involved deserving recognition failure account everyone early way slight ideally moderators elected community hold elections site graduates respectful understanding moderators pro tem members community volunteering time learning job learning experience everyone
1,"<p>Congratulations! I am fully confident that our new moderators will be a great team. They have shown themselves to be good users as regular users, and I'm sure that that will carry over to their moderation.</p>
",AImeta,congratulations fully confident new moderators great team shown good users regular users sure carry moderation
1,"<p>Many questions on AI seems to be trying to predict what might be possible in the future. This lend itself to science-fiction speculation (opinions). I think I am mostly provoked by this question:
<a href=""https://ai.stackexchange.com/questions/2048/what-jobs-cannot-be-automatized-by-ai-in-the-future"">What jobs cannot be automatized by AI in the future?</a>, which essentially wants us to make a  prediction about a future scenario (specifically, what AI <em>can't</em> do). Predicting the future is hard, especially if there's no cut-off point (predicting what jobs are killed by AI in the year 2020 is much easier than predicting what jobs are killed by AI in 2100)...and it's not quite clear if there will be much expert opinion on futuristic predictions, or even <em>if</em> experts even are able to make good predictions about the future.</p>

<p>Questions about the future would only solicit personal opinions. I would strongly suggest that these types of questions be closed as opinion-based.</p>
",AImeta,many questions ai seems trying predict might possible future lend science fiction speculation opinions think mostly provoked question essentially wants us make prediction future scenario specifically ai predicting future hard especially cut point predicting jobs killed ai year 2020 much easier predicting jobs killed ai 2100 quite clear much expert opinion futuristic predictions even experts even able make good predictions future questions future would solicit personal opinions would strongly suggest types questions closed opinion based
1,"<p>Such question usually tend to draw a lot of low quality answers which are speculating without giving any backup to their claims. And at the end it's just one person opinion on that topic.</p>

<p>Therefore if the question isn't going to generate any constructive answers, which doesn't have any reliable references or there are no existing research studies in that area (because the topic isn't great or too localized), and question is just asking people to speculate based on their gut instinct, we should vote to close.</p>

<p>Although this particular question about <a href=""https://ai.stackexchange.com/q/2048/8"">automatic human jobs</a> isn't actually bad, since it's possible to assess such probability based on the available employment data and in <a href=""http://www.oxfordmartin.ox.ac.uk/downloads/academic/The_Future_of_Employment.pdf"" rel=""nofollow noreferrer"">2013 Oxford study</a> they managed to estimate it using computer models. So I believe it's actually answerable.</p>
",AImeta,question usually tend draw lot low quality answers speculating without giving backup claims end one person opinion topic therefore question going generate constructive answers reliable references existing research studies area topic great localized question asking people speculate based gut instinct vote close although particular question actually bad since possible assess probability based available employment data managed estimate using computer models believe actually answerable
1,"<p>Some questions about the future will fall squarely under the scope of AI. AI seems to be a sponge that attaches its salience to everything, from depression to eschatology. It's hard for us to say declaratively what parts of life AI will or won't impact.</p>

<p>But I agree that some questions have been inadequately specified. If a given question is so obtuse that we think we will lack sufficient evidence to determine an answer within a decade or two... would some criteria like that be sufficient reason to close the question?</p>

<p>On the other hand, sometimes it may be better to actually explain to a questioner why a particular question is apparently naive, since other people out there may be suffering the same prejudices or misconceptions.</p>
",AImeta,questions future fall squarely scope ai ai seems sponge attaches salience everything depression eschatology hard us say declaratively parts life ai impact agree questions inadequately specified given question obtuse think lack sufficient evidence determine answer within decade two would criteria like sufficient reason close question hand sometimes may better actually explain questioner particular question apparently naive since people may suffering prejudices misconceptions
1,"<p>We already close most of the more concrete questions, with some bullshit verbiage about how they're too ""implementation"" based.  This only leaves room for the science-fiction style questions.  If we start closing the science-fiction questions, there won't be anything left to do.  Might as well close the site.</p>

<p>What we need to do is go back to what I suggested before - close the <strong><em>blatantly</em></strong> off-topic questions (eg, ""How do I rebuild the carburetor on my 1973 Ford Pinto?"") and obvious spam, and rely on the upvote/downvote mechanism for the grey-area stuff, and let the site evolve into what the users want it to become.  The top-down, command-and-control model already isn't working and no amount of doubling-down on that is going to make it a good idea. </p>
",AImeta,already close concrete questions bullshit verbiage implementation based leaves room science fiction style questions start closing science fiction questions anything left might well close site need go back suggested close blatantly topic questions eg rebuild carburetor 1973 ford pinto obvious spam rely upvote downvote mechanism grey area stuff let site evolve users want become top command control model already working amount doubling going make good idea
1,"<p>We should drop any reference to implementation specifically being on or off topic.  That's really orthogonal to the issue and it makes it too easy for people to justify arbitrarily closing good questions.  And as this eliminates so many of the more concrete questions, it makes the site appear as though it's only for science-fiction'ish questions.  </p>
",AImeta,drop reference implementation specifically topic really orthogonal issue makes easy people justify arbitrarily closing good questions eliminates many concrete questions makes site appear though science fictionish questions
1,"<p>This question:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/2141/8"">https://ai.stackexchange.com/q/2141/8</a></li>
</ul>

<p>asks about recommendation of the approach using a set of data in Matlab learner app.</p>

<p>Do you think such question should be on-topic?</p>
",AImeta,question asks recommendation approach using set data matlab learner app think question topic
1,"<p>I think that specific question is off topic, and migrated it to Cross Validated. (As I understood it, had two parts--first, does Matlab's learner do bootstrapping, and second, is there a problem with doing bootstrapping twice, neither of which strike me as deeply relevant for AI.)</p>

<p>For machine learning questions, I'm mostly looking at whether the question is 1) well-understood and 2) relevant to the conceptual, social, or philosophical aspects of AI. The closer it is to a statistical issue, the more likely it is to go to Cross Validated, and the closer it is to a data or programming issue, the more likely it is to go to Data Science or Stack Overflow.</p>

<p>I don't think that the question is about Matlab is relevant except that questions that hinge on a particular language are likely to end up as being too close to programming to fit here.</p>
",AImeta,think specific question topic migrated cross validated understood two parts first matlab learner bootstrapping second problem bootstrapping twice neither strike deeply relevant ai machine learning questions mostly looking whether question 1 well understood 2 relevant conceptual social philosophical aspects ai closer statistical issue likely go cross validated closer data programming issue likely go data science stack overflow think question matlab relevant except questions hinge particular language likely end close programming fit
1,"<p>All the other Stack Exchange sites link to the same username, but for some reason the AI site changed my username to a25bedc5-3d09-41b8-82fb-ea6c353d75ae.</p>

<p>Why did that happen and how can I fix it?</p>
",AImeta,stack exchange sites link username reason ai site changed username a25bedc5 3d09 41b8 82fb ea6c353d75ae happen fix
1,"<p>As mentioned by Rory Alsop, you've run into <a href=""https://meta.stackexchange.com/q/135178/295684"">this Stack Exchange bug</a> or something related. You can manually fix your profile by <a href=""https://ai.stackexchange.com/users/edit/current"">editing it on this site</a>, or by opening your profile settings on a different site and choosing <em>Save and copy changes to all Stack Exchange communities</em>.</p>
",AImeta,mentioned rory alsop run something related manually fix profile opening profile settings different site choosing save copy changes stack exchange communities
1,"<p>I'm noticing that we get quite a few questions asking for recommendations of programming languages or libraries. Unfortunately, I'm not sure that wordsmithing our site description or help center will make it sufficiently clear that such recommendations are off-topic (both because of site scope and the fact that recommendations go out of date fast). Not everyone reads the help center's <a href=""https://ai.stackexchange.com/help/on-topic"">on-topic page</a>; I don't even see a direct link to it from the asking form.</p>

<p>We can keep closing these questions - it feels like we've handled at least a dozen so far - but it would be a better experience for new users if there was something we could point them to. We've <a href=""https://ai.meta.stackexchange.com/a/1074/75"">discussed having a collection of links to such resources</a> before, and it was correctly noted that this site isn't focused on programming anyway. Nevertheless, with a site name like ""Artificial Intelligence"", it's understandable that people will ask how to start AI-related projects.</p>

<p>What, if anything, should we do about this?</p>
",AImeta,noticing get quite questions asking recommendations programming languages libraries unfortunately sure wordsmithing site description help center make sufficiently clear recommendations topic site scope fact recommendations go date fast everyone reads help center even see direct link asking form keep closing questions feels like handled least dozen far would better experience new users something could point correctly noted site focused programming anyway nevertheless site name like artificial intelligence understandable people ask start ai related projects anything
1,"<p>The following question:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/q/2235/8"">How q-learning solves the issue with value iteration in model-free settings</a></li>
</ul>

<p>sounds like a modelling question. Should it be on-topic?</p>
",AImeta,following question sounds like modelling question topic
1,"<p>This Question:</p>

<p><a href=""https://ai.stackexchange.com/questions/2381/what-are-the-parts-and-the-general-framework-of-opencog"">What are the parts and the general framework of OpenCog?</a></p>

<p>Asks for an opinion and a recommendation,that is to say;what the general ideas behind open cog are and whether you would endorse it as a insightful take on AGI</p>

<p>Do you think such question should be asked?</p>
",AImeta,question asks opinion recommendation saywhat general ideas behind open cog whether would endorse insightful take agi think question asked
1,"<h1>No, no, no.</h1>
<p>We have a <em>close reason</em> for opinion-based questions. They are explicitly off-topic on Stack Exchange sites.</p>
<p>When you click on 'Close'<sup>1</sup> (you gain close vote privileges at 500 rep on public Beta sites, 3,000 on graduated sites (1 rep during private beta)), you see something like this:</p>
<p><a href=""https://i.stack.imgur.com/FoMWn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FoMWn.png"" alt=""vtc"" /></a></p>
<p>See that 'primarily opinion-based' down there? That's one of the close reasons. (That blue '1' means that someone has already voted to close it for that reason. It takes 5 votes to close it.)</p>
<hr />
<p><sup>1</sup>If you don't yet have closing privileges, you can <em>flag</em> it as needing to be closed. Click on 'flag', then click on 'should be closed because...' and you'll see something like this:</p>
<p><a href=""https://i.stack.imgur.com/3AkLB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3AkLB.png"" alt=""ftc"" /></a></p>
<p>See '<a href=""https://ai.stackexchange.com/help/dont-ask"">What should I not ask about here?</a>' in the Help Center.</p>
",AImeta,close reason opinion based questions explicitly topic stack exchange sites click close 1 gain close vote privileges 500 rep public beta sites 3000 graduated sites 1 rep private beta see something like see primarily opinion based one close reasons blue 1 means someone already voted close reason takes 5 votes close 1 yet closing privileges flag needing closed click flag click ishould closed see something like see help center
1,"<p>For a few years now, Stack Exchange has put on a Winter Bash event in which users can earn hats by doing various interesting things and then wear said hats on their avatars. (Kind of like badges, but more visible and lasting only for the duration of Winter Bash.) Other site functionality continues as normal.</p>

<p>This will be AI.SE's first winter. Virtually all Stack Exchange sites will be participating in the hat festivities, and by default we will be too. If you're not a fan of the extra decorations, you will have the opportunity to turn them off by clicking the appropriate button in the footer (which will appear when the event starts in a couple weeks). If there are arguments to be made for disabling hats for <em>everyone</em> on this site, please post them as answers here by <strong>December 12</strong>.</p>

<p>Otherwise, prepare for hats!</p>

<p>For more information on Winter Bash, see <a href=""https://stackoverflow.blog/2015/12/Announcing-Winter-Bash-2015/"">last year's blog post</a>. The <a href=""http://winterbash2016.stackexchange.com/"" rel=""nofollow noreferrer"">countdown to this year's</a> is ticking now!</p>
",AImeta,years stack exchange put winter bash event users earn hats various interesting things wear said hats avatars kind like badges visible lasting duration winter bash site functionality continues normal aise first winter virtually stack exchange sites participating hat festivities default fan extra decorations opportunity turn clicking appropriate button footer appear event starts couple weeks arguments made disabling hats everyone site please post answers december 12 otherwise prepare hats information winter bash see ticking
1,"<p>We seem to have a lot of questions about programming showing up now, which are off-topic (and not enough people VTCing!).</p>

<p>Examples: <a href=""https://ai.stackexchange.com/q/2457/145"">(1)</a> <a href=""https://ai.stackexchange.com/q/2462/145"">(2)</a> <a href=""https://ai.stackexchange.com/q/2451/145"">(3)</a></p>

<p>Is it possible to place a banner at the top of the page, stating that these questions are off-topic, such as the one on <a href=""http://judaism.stackexchange.com"">Mi Yodeya</a>? Or is that only available for graduated sites?</p>
",AImeta,seem lot questions programming showing topic enough people vtcing examples possible place banner top page stating questions topic one available graduated sites
1,"<p>Yes, I agree that this is a concerning trend. Though we <a href=""https://ai.meta.stackexchange.com/q/1252/75"">have an on-topic page</a> that categorizes such questions as off-topic, there is not a direct link to that help center article on the asking form. <a href=""https://meta.stackexchange.com/q/213935/295684"">Relevant MSE.</a></p>

<p>Though we put together an on-topic page, the <a href=""https://ai.stackexchange.com/tour"">tour page</a> was neglected. People are encouraged to take the tour when they first sign up; for some, it might be the only topicality-related document they read. Just now, I changed the ""ask"" and ""don't ask"" bulleted lists away from the default generic stuff to something that summarizes our help center guidelines. <strong>Suggestions for improvements are welcome!</strong> Hopefully this change will help our problem; if it doesn't, we can consider more conspicuous help text.</p>

<p>In regard to the examples you brought up (thank you for bringing specifics!):</p>

<ol>
<li>This question was voluntarily removed by its author after receiving some comments about topicality.</li>
<li>This seems interesting to me; I think one could argue that it's asking about ways of thinking as opposed to asking for some code.</li>
<li>This is indeed a question about programming. It is <a href=""https://ai.stackexchange.com/review/close/1135"">in the Close Votes queue</a> at the moment pending review. As you said, it would be very good to have more people reviewing. There are currently 16 non-moderator users with <a href=""https://ai.stackexchange.com/help/privileges/close-questions"">the close/reopen vote privilege</a>; I encourage all such users to <a href=""https://ai.stackexchange.com/review/close/"">have a look at that queue</a>.</li>
</ol>
",AImeta,yes agree concerning trend though categorizes questions topic direct link help center article asking form though put together topic page neglected people encouraged take tour first sign might topicality related document read changed ask ask bulleted lists away default generic stuff something summarizes help center guidelines suggestions improvements welcome hopefully change help problem consider conspicuous help text regard examples brought thank bringing specifics question voluntarily removed author receiving comments topicality seems interesting think one could argue asking ways thinking opposed asking code indeed question programming moment pending review said would good people reviewing currently 16 non moderator users encourage users
1,"<p>It is December 12 now, and since there have been no objections... hats! Everyone enjoy your hats! The Winter Bash 2016 features will appear on <strong>December 19</strong>.</p>
",AImeta,december 12 since objections hats everyone enjoy hats winter bash 2016 features appear december 19
1,"<p>I am trying to post a question in <a href=""https://ai.stackexchange.com/questions/ask"">the Ask Question form</a>, but it always shows ""You can only post once every 40 minutes"" even though it's my first question.</p>

<p>My question is <strong>What are the artificial intelligence frameworks?</strong></p>

<p>May I ask this question?</p>
",AImeta,trying post question always shows post every 40 minutes even though first question question artificial intelligence frameworks may ask question
1,"<p>This applies site-wide.</p>

<p>If you have asked a question <em>anywhere on the Stack Exchange network</em> in the past 40 minutes, you have to wait before asking a question on <em>any site</em>.</p>

<p>See this answer: <a href=""https://meta.stackoverflow.com/questions/322157/arent-new-users-throttled-asking-questions-anymore/322265#322265"">https://meta.stackoverflow.com/questions/322157/arent-new-users-throttled-asking-questions-anymore/322265#322265</a></p>
",AImeta,applies site wide asked question anywhere stack exchange network past 40 minutes wait asking question site see answer
1,"<p>As mentioned by Mithrandir, this is a network-wide measure that applies to all users with less than 125 reputation. Source: <a href=""https://meta.stackexchange.com/a/164900/295684"">The Complete Rate-Limiting Guide</a>. It's designed to slow down spammers. Once the 40-minute window elapses, you'll be able to post another question anywhere on the network. I see that you have <a href=""https://ai.stackexchange.com/q/2471/75"">already done so</a>.</p>

<p>Please note that resource recommendations are off-topic here for two reasons. First, this site is for social and conceptual questions about artificial intelligence. Also (and this applies to most sites on Stack Exchange), collections of off-site resources tend to go out of date very quickly; it takes <a href=""https://ai.meta.stackexchange.com/q/1267/75"">a community effort</a> to keep such a resource up to date. If the <a href=""https://ai.stackexchange.com/help/on-topic"">scope of the site</a> is unclear, please bring up your concern here on meta so we can get it clarified.</p>
",AImeta,mentioned mithrandir network wide measure applies users less 125 reputation source designed slow spammers 40minute window elapses able post another question anywhere network see please note resource recommendations topic two reasons first site social conceptual questions artificial intelligence also applies sites stack exchange collections site resources tend go date quickly takes keep resource date unclear please bring concern meta get clarified
1,"<h1>Place something like what <a href=""https://android.stackexchange.com/tour"">Android</a> has in the tour.</h1>
<p>Android Enthusiasts has a line in their tour:</p>
<blockquote>
<p>Have a programming question? Visit our sister site, <a href=""https://stackoverflow.com/questions/tagged/artificial-intelligence"">Stack Overflow</a>.</p>
</blockquote>
<p>We could put something like that in <em>our</em> tour.</p>
",AImeta,place something like tour android enthusiasts line tour programming question visit sister site could put something like tour
1,"<p>Technical/mathematical/implementation  questions are <a href=""https://ai.meta.stackexchange.com/a/1199/4"">off-topic</a>. However, many of them are not getting closed. E.g., here are the most recent close votes I cast on the grounds the questions were technical, but none of them got closed (e.g. see screenshot below).</p>

<p>Update 2017-01-19: the two answers written so far point out that technical questions may be on-topic in some cases. The issue I intended to raise in this question is that off-topic technical questions are not getting closed. E.g. in the screenshot below the vast majority of the technical questions are off-topic.</p>

<p><a href=""https://i.stack.imgur.com/YEQvk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YEQvk.png"" alt=""enter image description here""></a></p>
",AImeta,technical mathematical implementation questions however many getting closed eg recent close votes cast grounds questions technical none got closed eg see screenshot update 2017 01 19 two answers written far point technical questions may topic cases issue intended raise question topic technical questions getting closed eg screenshot vast majority technical questions topic
1,"<p>Good. There has never been any actual consensus that all ""technical"" questions are off-topic.  And at the end of the day, the community decides what is on-topic, not a bunch of ivory-tower navel-gazers here on meta.  Personally I like where we're at with this.  There are some technical questions, yes, but quite often they're <em>different</em> technical questions than the ones you see on stats or datascience or whatever. That tells me we're providing real value to the world, and that makes me happy.</p>

<p>If anything, I say the only action we might need to ramp us, is migrating some questions to other *.se sites, if they are clearly more suited for a different site (say, stats.se or datascience.se). I'm not entirely sure how migration works though.. can anybody nominate a question to be migrated, or what? Does that come in at a certain karma level, or is that something that only the StackExchange employees can do, or what? </p>
",AImeta,good never actual consensus technical questions topic end day community decides topic bunch ivory tower navel gazers meta personally like technical questions yes quite often different technical questions ones see stats datascience whatever tells providing real value world makes happy anything say action might need ramp us migrating questions se sites clearly suited different site say statsse datasciencese entirely sure migration works though anybody nominate question migrated come certain karma level something stackexchange employees
1,"<p>There's nothing concerning about it.  It's just the community speaking in regards to what they want to talk about.  Let's quit trying to fight a rising tide and accept that AI is an inherently technical topic, and enthusiasts are going to want to ask technical questions.  </p>
",AImeta,nothing concerning community speaking regards want talk let quit trying fight rising tide accept ai inherently technical topic enthusiasts going want ask technical questions
1,"<p>I don't think it's not possible to force people to not ask the technical questions. Once it's asked, community decides whether it's on-topic or not. Closing only because it's a technical question isn't enough. More things needs to be taken into the account before deciding.</p>

<p>To be clear, this <a href=""https://ai.meta.stackexchange.com/q/1141/8"">proposal comes from the Science category</a>, so scientific questions are clearly on-topic (especially <a href=""https://ai.meta.stackexchange.com/a/1144/8"">socio-scientific angle</a>), but some overlap in scope is expected.</p>

<p>Please note that there are over 10 sites across Stack Exchange network where Artificial Intelligence related questions can be also on-topic (such as <a href=""https://stats.stackexchange.com/questions/tagged/artificial-intelligence"">Cross Validated</a>, <a href=""https://datascience.stackexchange.com/questions/tagged/machine-learning"">Data Science</a>, <a href=""https://cs.stackexchange.com/questions/tagged/artificial-intelligence"">Computer Science</a>, <a href=""https://cstheory.stackexchange.com/questions/tagged/ai.artificial-intel"">CSTheory</a>, <a href=""https://cogsci.stackexchange.com/questions/tagged/artificial-intelligence"">Cognitive Sciences</a>, <a href=""https://philosophy.stackexchange.com/questions/tagged/artificial-intelligence"">Philosophy</a>, <a href=""https://worldbuilding.stackexchange.com/questions/tagged/artificial-intelligence"">Worldbuilding</a>, <a href=""https://stackoverflow.com/questions/tagged/artificial-intelligence"">Stack Overflow</a>, <a href=""https://hsm.stackexchange.com/questions/tagged/artificial-intelligence"">History of Science</a>, <a href=""https://robotics.stackexchange.com/questions/tagged/artificial-intelligence"">Robotics</a>, <a href=""https://gamedev.stackexchange.com/questions/tagged/ai"">GameDev</a> and so on), so once the question is asked, it's a matter of speculation where it exactly should belong, unless it's very clear where it belongs. Otherwise claiming the ownership of some question related to AI on other non-AI site which has been asked specifically here or only because it's a technical one, it would be unwise. The point is, that this site is fully dedicated to AI, <em>Cross Validated</em> site has only few tags related to <a href=""https://stats.stackexchange.com/questions/tagged/artificial-intelligence"">AI</a> and <a href=""https://stats.stackexchange.com/questions/tagged/machine-learning"">machine learning</a> and it focuses only on statistical techniques where the questions asked there doesn't have to be related to AI.</p>

<p>Therefore if the question is asking about statistical techniques, then sure, it's more on-topic at <a href=""https://stats.stackexchange.com/"">Cross Validated</a>. Especially if you think it's off-topic here (e.g. nothing to do with AI), and on-topic there, vote to close, so after the closure it can be migrated by the moderators to another site. Similar with question specifically about <a href=""https://datascience.stackexchange.com/"">data science</a> or <a href=""https://stackoverflow.com/questions/tagged/artificial-intelligence"">programming</a>.</p>

<p>In summary, the level of technicality is a matter of speculation. For me as far as it doesn't consist math, asking for formulas, technical implementation or modelling, programming code, it's not a technical question. We should rather ask ourselves, whether it's off-topic here (non-AI), and on-topic somewhere else.</p>

<p>Related discussion: <a href=""https://ai.meta.stackexchange.com/a/1235/8"">What should be on-topic, modelling or implementation, or anything else?</a></p>
",AImeta,think possible force people ask technical questions asked community decides whether topic closing technical question enough things needs taken account deciding clear scientific questions clearly topic especially overlap scope expected please note 10 sites across stack exchange network artificial intelligence related questions also topic question asked matter speculation exactly belong unless clear belongs otherwise claiming ownership question related ai non ai site asked specifically technical one would unwise point site fully dedicated ai cross validated site tags related focuses statistical techniques questions asked related ai therefore question asking statistical techniques sure topic especially think topic eg nothing ai topic vote close closure migrated moderators another site similar question specifically summary level technicality matter speculation far consist math asking formulas technical implementation modelling programming code technical question rather ask whether topic non ai topic somewhere else related discussion
1,"<blockquote>
  <p>I'm getting tired of this site. It's supposed to be a factual site about software development and stuff. But 90% of the questions are sci-fi/fantasy questions like ""If AI becomes sentient......."". The word ""consciousness"" does not refer to any scientifically definable concept. The answer is what ever you want it to be. What are the guide lines for this forum? are these questions even on topic? – Lorry Laurence mcLarry <a href=""https://ai.stackexchange.com/questions/2646/how-to-stop-people-abusing-ai#comment3065_2646"">8 hours ago</a></p>
</blockquote>

<p>I share Lorry's distaste of these type of questions. Speculative questions are easy to ask, easy to answer, and easy to engage with, but they don't necessarily help humans to truly understand the field of AI (especially since many of these speculative questions are not really <em>answerable</em> within a reasonable timeframe). Speculative questions also might degrade into opinion-based questions, which is an obvious no-no. Many of these questions have the potential to be <em>unanswerable</em>.</p>

<p>It's not like these questions are <em>bad</em>. AI and science-fiction have been closely connected to each other, and people do want to speculate about the future. The scope of the site is to answer ""conceptual questions about life and challenges in a world where 'cognitive' functions can be mimicked in purely digital environment"", which seems to suggest that these types of speculative questions might be on-topic.</p>

<p>However, I don't think the site would survive if we were flooded by them.</p>

<p>Non-speculative humanities questions about AI are difficult to come up with and difficult to answer, but they seem to be more useful and applicable in the present-day. I think this is the type of content we want to have...</p>

<p>What can be done to encourage people to ask the latter type of questions?</p>
",AImeta,getting tired site supposed factual site software development stuff 90 questions sci fi fantasy questions like ai becomes sentient word consciousness refer scientifically definable concept answer ever want guide lines forum questions even topic lorry laurence mclarry share lorry distaste type questions speculative questions easy ask easy answer easy engage necessarily help humans truly understand field ai especially since many speculative questions really answerable within reasonable timeframe speculative questions also might degrade opinion based questions obvious many questions potential unanswerable like questions bad ai science fiction closely connected people want speculate future scope site answer conceptual questions life challenges world cognitive functions mimicked purely digital environment seems suggest types speculative questions might topic however think site would survive flooded non speculative humanities questions ai difficult come difficult answer seem useful applicable present day think type content want done encourage people ask latter type questions
1,"<p>I am also concerned about low-effort speculation questions (especially those that are very broad), and even more concerned when they manage to gather several upvotes. To help stop questions you deem low-quality from proliferating, you can exercise your voting rights: <strong>cast downvotes when appropriate</strong>, and optimally leave a comment to help the author improve. Conversely, <strong>upvote good questions</strong>, the kind you want to see more of. Note that close votes and downvotes are different things with different purposes: a question can be on-topic but poorly expressed or unresearched. If a question is in a useful/interesting topic but doesn't yet adhere to our expectations, <strong>edit it into shape</strong>. Try to preserve the original meaning as much as possible.</p>

<p>Our site is by design a little more subjective than, say, Data Science. That said, we don't allow pure speculation; a question that is <em>primarily</em> opinion-based should be closed as such. A somewhat squishy question that can invite facts instead of personal beliefs and wild speculation would be allowed. If an answer is only speculation with no reasoning or sources provided, please downvote.</p>

<p>""You get the site you build,"" said some MSE or blog post, if I remember the quote correctly. New users will take the most salient existing content as precedent, so we want our best content to be the highest-voted. If you're feeling particularly generous, you can add a bounty to reward excellent answers. Alas, there's not a way to give a big reward for an awesome question. You can, however, reward authors of good questions by putting effort into <strong>writing an answer to them</strong>. It's tougher to put together something based in fact than to write up a personal opinion, but it's what we collectively need.</p>
",AImeta,also concerned low effort speculation questions especially broad even concerned manage gather several upvotes help stop questions deem low quality proliferating exercise voting rights cast downvotes appropriate optimally leave comment help author improve conversely upvote good questions kind want see note close votes downvotes different things different purposes question topic poorly expressed unresearched question useful interesting topic yet adhere expectations edit shape try preserve original meaning much possible site design little subjective say data science said allow pure speculation question primarily opinion based closed somewhat squishy question invite facts instead personal beliefs wild speculation would allowed answer speculation reasoning sources provided please downvote get site build said mse blog post remember quote correctly new users take salient existing content precedent want best content highest voted feeling particularly generous add bounty reward excellent answers alas way give big reward awesome question however reward authors good questions putting effort writing answer tougher put together something based fact write personal opinion collectively need
1,"<p>Since <a href=""https://ai.meta.stackexchange.com/q/1283/75"">this site is more subjective than some</a>, we occasionally get answers that are solely based on personal opinion or make claims with no justification/references. Even subjective questions should invite facts (instead of opinions), so such answers are less than ideal.</p>

<p>What should we do with these answers? Here are a few options (though feel free to propose alternatives not in this list):</p>

<ul>
<li>Just leave them alone and let them be downvoted/ignored</li>
<li>Flag them for immediate deletion</li>
<li>Flag them for the application of a post notice (e.g. ""citation needed""), with deletion being the next course of action if the answer is not filled out</li>
</ul>

<p>If you'd like some ideas on how this is handled on other sites, I refer you to <a href=""https://skeptics.meta.stackexchange.com/q/1054"">a Skeptics FAQ</a>.</p>
",AImeta,since occasionally get answers solely based personal opinion make claims justification references even subjective questions invite facts instead opinions answers less ideal answers options though feel free propose alternatives list leave alone let downvoted ignored flag immediate deletion flag application post notice eg citation needed deletion next course action answer filled would like ideas handled sites refer
1,"<p>Here's my proposal. I've tried to have this take into account our quality needs and also the good of the answer OP. This is essentially the same as your last idea.</p>
<ol>
<li><p>Comment and ask for them to provide sources to back up their claims, or stick that moderator notice on.</p>
<p>This tells them that there's something wrong with how they're doing their answers, and gives them an opportunity to improve them.</p>
</li>
<li><p>If they update with the sources, then great - problem solved. If they refuse, or haven't after a period of time, then delete them - they're not reliable or good answers.</p>
</li>
</ol>
<p>As to what the amount of time that we should give them, I don't know at the moment - people can provide suggestions.</p>
",AImeta,proposal tried take account quality needs also good answer op essentially last idea comment ask provide sources back claims stick moderator notice tells something wrong answers gives opportunity improve update sources great problem solved refuse period time delete reliable good answers amount time give know moment people provide suggestions
1,"<p>Some implementation questions like <a href=""https://ai.stackexchange.com/questions/2817/reproduce-firefly-algorithm-experiments-of-original-paper"">this one</a> and <a href=""https://ai.stackexchange.com/questions/2743/how-to-fill-in-missing-transitions-when-sampling-an-mdp-transition-table"">this one</a> are not about Machine Learning. They are getting closed anyway, as the actual topic would rather be on another SE site.</p>

<p>I wonder if the ""not about... the implementation of machine learning"" on the <a href=""https://ai.stackexchange.com/help/on-topic"">help center page</a> is misleading a few people. That phrasing originates in a <a href=""https://ai.meta.stackexchange.com/q/1252/169"">discussion</a> about acceptable topics, and the term ""implementation"" still seems problematic.</p>

<p>How about ""algorithmic or implementation details, software library or specific hardware-related"" kind of phrasing? The idea is to exclude more implementation-related questions, but only the ones that pertain to step-by-step guidance through an implementation or library.</p>

<p>In short, a couple examples under the latter proposal:</p>

<ul>
<li>NG: How to implement A* with TensorFlow?</li>
<li>OK: How to implement Case-Based Reasoning with Neural Networks?</li>
</ul>

<p>Note the intended use of the ""implementation"" word in both questions. If there is something here, I still think there is need for better examples (the OK is too broad yet).</p>

<hr>

<p>Disclaimer: I am a proponent of having <em>some</em> implementation questions here.</p>
",AImeta,implementation questions like machine learning getting closed anyway actual topic would rather another se site wonder implementation machine learning misleading people phrasing originates acceptable topics term implementation still seems problematic algorithmic implementation details software library specific hardware related kind phrasing idea exclude implementation related questions ones pertain step step guidance implementation library short couple examples latter proposal ng implement tensorflow ok implement case based reasoning neural networks note intended use implementation word questions something still think need better examples ok broad yet disclaimer proponent implementation questions
1,"<p><a href=""https://ai.stackexchange.com/revisions/3171/1"">This answer</a> looked like this when it was first posted:</p>

<blockquote>
  <p>Did you mean, technological singularity? <a href=""https://en.wikipedia.org/wiki/Technological_singularity"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Technological_singularity</a></p>
</blockquote>

<p>This looks suspiciously like a link-only answer. Let's look at what <a href=""https://meta.stackexchange.com/questions/225370/your-answer-is-in-another-castle-when-is-an-answer-not-an-answer"">the post about link only answers</a> says:</p>

<blockquote>
  <p>Yes, they're both very short, and yes, they contain links. But strip the markup, and you still get at least a little bit of useful information.</p>
</blockquote>

<p>So if we strip the link, pretending that the last two words were linked - it's acceptable by that post. However, we have a <a href=""https://ai.meta.stackexchange.com/questions/1285/how-should-non-fact-based-answers-be-handled"">policy</a> that answers that don't provide support for themselves are to be removed.</p>

<p>So was this answer okay in its original state?</p>
",AImeta,looked like first posted mean technological singularity looks suspiciously like link answer let look says yes short yes contain links strip markup still get least little bit useful information strip link pretending last two words linked acceptable post however answers provide support removed answer okay original state
1,"<p>I came to ask a basic fundamental question about AI: In a neural network when inputting nerve input to sense a 2D environment, how do you differentiate two types of objects so the neural network can treat them differently?</p>

<p>That's a solid, fundamental, extremely important AI question. It isnt based on writing code, it's about fundamental neural network structure. I was down-voted and told that's off topic. So I look at the on topic scope here:</p>

<ul>
<li>social issues in a world where artificial intelligence is common,</li>
<li>conceptual aspects of AI, or</li>
<li>human factors in AI development</li>
</ul>

<p>Let's address these one by one</p>

<blockquote>
  <p>social issues in a world where artificial intelligence is common</p>
</blockquote>

<p>That's already covered 100% by Worldbuilding Stack Exchange, people have no need to come here for those questions when they could get a response way faster and from a larger and more active community than here. </p>

<blockquote>
  <p>human factors in AI development</p>
</blockquote>

<p>What does that even mean? Seriously, that line means nothing to anyone and should be revised / clarified. </p>

<blockquote>
  <p>conceptual aspects of AI</p>
</blockquote>

<p>This makes sense, but it certainly shouldn't exclude <em>fundamental</em> aspects of AI. In its current state, this site's defined scope makes it useless for anyone who's an expert on AI: all of whom will be interested in creating AI, and will therefore be interested in asking and answering fundamental questions about topics such as structuring and designing AI, which can be asked and answered without involving any code. </p>

<p>To reiterate, no AI experts are going to be drawn to this current scope, it's essentially only useful for the world building audience, which already has a <a href=""https://worldbuilding.stackexchange.com/"">popular SE site</a>. If this is going to be called AI SE, it needs to be a place attractive to actual AI experts in the field, not just science fiction enthusiasts speculating about challenges of a world with AI. Questions about fundamental AI design needs to be on-topic. Not programming questions. Just structural, fundamental design questions.</p>
",AImeta,came ask basic fundamental question ai neural network inputting nerve input sense 2d environment differentiate two types objects neural network treat differently solid fundamental extremely important ai question nt based writing code fundamental neural network structure voted told topic look topic scope social issues world artificial intelligence common conceptual aspects ai human factors ai development let address one one social issues world artificial intelligence common already covered 100 worldbuilding stack exchange people need come questions could get response way faster larger active community human factors ai development even mean seriously line means nothing anyone revised clarified conceptual aspects ai makes sense certainly exclude fundamental aspects ai current state site defined scope makes useless anyone expert ai interested creating ai therefore interested asking answering fundamental questions topics structuring designing ai asked answered without involving code reiterate ai experts going drawn current scope essentially useful world building audience already going called ai se needs place attractive actual ai experts field science fiction enthusiasts speculating challenges world ai questions fundamental ai design needs topic programming questions structural fundamental design questions
1,"<p>You are correct; conceptual aspects of AI are on-topic and <a href=""https://ai.stackexchange.com/q/3329/75"">your question</a> does indeed qualify. I hit Leave Open on it in the review queue, so it should survive. People have somewhat different ideas of what the scope is, and especially what the scope should be, so there will be some spurious scope-related admonishments.</p>

<p>The help center's on-topic page is also subject to revision, and I am always happy to adjust it if it needs clarification. Allow me to expound a bit on the current text:</p>

<ul>
<li>Social issues: while Worldbuilding does indeed explore hypothetical worlds, this site requires that answers to these questions <a href=""https://ai.meta.stackexchange.com/q/1285/75"">have basis in reality</a>. Sci-fi writing is not acceptable here.</li>
<li>Human factors: this line was my attempt to describe questions about humans' role in creating or guiding AIs. It was originally inspired by one interesting question about displaying an AI's configuration/state for human inspection (which I can't find at the moment, sorry). I'll think about how best to express this.</li>
<li>Conceptual aspects: while non-mathematical concepts are definitely on topic, more concrete implementation issues are already better handled by <a href=""https://stats.stackexchange.com/"">Cross Validated</a> or <a href=""http://datascience.stackexchange.com/"">Data Science</a>; diffusing those questions across more Stack Exchange sites would add more confusion and duplication.</li>
</ul>

<p>One thing that isn't captured currently is the academic/humanities arena, as set forth for us <a href=""https://area51.meta.stackexchange.com/a/24016/136466"">back when the site was being considered for private beta</a>. Those questions are definitely also on-topic.</p>

<p>I think our current scope is unique and interesting, though you are right: we could use more experts. Specific proposals for policy changes or wordsmithing are welcome!</p>
",AImeta,correct conceptual aspects ai topic indeed qualify hit leave open review queue survive people somewhat different ideas scope especially scope spurious scope related admonishments help center topic page also subject revision always happy adjust needs clarification allow expound bit current text social issues worldbuilding indeed explore hypothetical worlds site requires answers questions sci fi writing acceptable human factors line attempt describe questions humans role creating guiding ais originally inspired one interesting question displaying ai configuration state human inspection find moment sorry think best express conceptual aspects non mathematical concepts definitely topic concrete implementation issues already better handled diffusing questions across stack exchange sites would add confusion duplication one thing captured currently academic humanities arena set forth us questions definitely also topic think current scope unique interesting though right could use experts specific proposals policy changes wordsmithing welcome
1,"<p>The site is described as ""For people interested in conceptual questions about life and challenges in a world where ""cognitive"" functions can be mimicked in purely digital environment.""</p>

<p>However, this does not seem to be what the questions are actually about. The blurb makes it seem that the site is about the effects of AI on the world, while the questions are actually about the theoretical foundation and implementation of AI technology. I believe the blurb should be changed to reflect the reality of the site's use. This can be done without making the philosophy questions off topic.</p>
",AImeta,site described people interested conceptual questions life challenges world cognitive functions mimicked purely digital environment however seem questions actually blurb makes seem site effects ai world questions actually theoretical foundation implementation ai technology believe blurb changed reflect reality site use done without making philosophy questions topic
1,"<p>If the site description is confusing, you can always propose a new one:</p>

<ul>
<li><a href=""https://ai.meta.stackexchange.com/q/1197/8"">How can we quickly describe our site?</a></li>
</ul>

<p>so it can be voted.</p>

<p>This site comes from the <a href=""https://ai.meta.stackexchange.com/q/1141/8"">'scientific' category</a>, so both conceptual and scientific question are allowed, exempt the technical questions such as <a href=""https://ai.meta.stackexchange.com/q/1078/8"">modelling</a> and <a href=""https://ai.meta.stackexchange.com/q/1081/8"">implementation</a> (e.g. how to do X in the framework Y), where we've dedicated sites for such questions. It's still difficult to draw a line between <a href=""https://ai.meta.stackexchange.com/q/1279/8"">technical vs non-technical</a> , or <a href=""https://ai.stackexchange.com/q/1297/8"">modelling vs implementation</a> questions. However if you've any suggestions which can help, please share.</p>

<p>I think <a href=""https://ai.meta.stackexchange.com/a/1236/8"">this post</a> describes the site in better words:</p>

<blockquote>
  <p>Artificial Intelligence Stack Exchange is a site for people interested in <strong>social, conceptual and scientific questions</strong> about Advanced Computing.</p>
</blockquote>
",AImeta,site description confusing always propose new one voted site comes conceptual scientific question allowed exempt technical questions eg x framework dedicated sites questions still difficult draw line questions however suggestions help please share think describes site better words artificial intelligence stack exchange site people interested social conceptual scientific questions advanced computing
1,"<p>I'm Pops, a Community Manager at Stack Exchange. Though it saddens me to say it, one of your moderators has decided it's time to step down. Fortunately for you, one of your fellow AI Stackers has answered the call to be your new pro tem mod:</p>

<p><a href=""https://ai.stackexchange.com/users/1671""><img src=""https://ai.stackexchange.com/users/flair/1671.png"" alt=""DukeZhou""></a></p>

<p>Please join me in thanking NietzscheanAI for their service and in welcoming DukeZhou!</p>
",AImeta,pops community manager stack exchange though saddens say one moderators decided time step fortunately one fellow ai stackers answered call new pro tem mod please join thanking nietzscheanai service welcoming dukezhou
1,"<p>I take on this responsibility with the assumption I a probably wasn't the first choice, and the awareness that I certainly can't fill NietzscheanAI's shoes.  </p>

<p>That said, I'll do my best to fulfill my duties a <em>pro tem</em> mod <em>(emphasis on pro tem;)</em> taking my lead from the senior mods and our power-user experts, and will try to add value to the forum per my experience on the Humanities side of the AI equation.</p>
",AImeta,take responsibility assumption probably first choice awareness certainly fill nietzscheanai shoes said best fulfill duties pro tem mod emphasis pro tem taking lead senior mods power user experts try add value forum per experience humanities side ai equation
1,"<p>Goodbye, @Niet! I voted for you on the original pro tem nominations, and I was sorry to hear that you were unhappy with what was considered on topic and decided to step down - I hope you decide to still be generally active, even without the diamond.</p>

<p>To @DukeZhou: I've seen you around, here and over on Literature. You weren't active in the private beta, but that's excusable ;). I'm sure that you'll be able to take on your new duties and do them well. Thank you for volunteering for the position!</p>
",AImeta,goodbye niet voted original pro tem nominations sorry hear unhappy considered topic decided step hope decide still generally active even without diamond dukezhou seen around literature active private beta excusable sure able take new duties well thank volunteering position
1,"<p>This is in relation to comments on: <a href=""https://ai.stackexchange.com/q/2526/1671"">Differentiable activation function</a></p>

<p>I made the point that the question seems to fit into the ""conceptual aspects of AI"" covered by this stack, but T.C. countered that Machine Learning questions, in particular, are already quite fractured across several sites.  </p>

<p>How can we reconcile this so that the related Stacks support and add value to each other?    </p>

<p>I personally would welcome guidance from trusted contributors and mods on the related Stacks.</p>

<hr>

<p>As an analogy,there is a relationship between the Humanities Stacks Mythology, Literature, Latin and Philosophy (in addition to others such as History.).  Different aspects of a single topic are best addressed in the forums where contributors have the relevant strengths.  My point is these are subjects where a fuller understanding <em>requires</em> many fields.   </p>

<p>I see this as one of the main strengths of Stack in an information explosion era with so many fields and subfields. Specifically that we can, and should, be walking ""across the hall"" to take advantage of the breadth of competencies Stack offers.  </p>

<p>Part of my inclination may derive from having been in an interdisciplinary studies program as an undergraduate.  In that program, we did not learn Science independently of History, Philosophy, Psychology, Art and Literature.  Rather, these subjects were taught in tandem.</p>
",AImeta,relation comments made point question seems fit conceptual aspects ai covered stack tc countered machine learning questions particular already quite fractured across several sites reconcile related stacks support add value personally would welcome guidance trusted contributors mods related stacks analogy relationship humanities stacks mythology literature latin philosophy addition others history different aspects single topic best addressed forums contributors relevant strengths point subjects fuller understanding requires many fields see one main strengths stack information explosion era many fields subfields specifically walking across hall take advantage breadth competencies stack offers part inclination may derive interdisciplinary studies program undergraduate program learn science independently history philosophy psychology art literature rather subjects taught tandem
1,"<p>In discussion with an experience researcher and developer, it was suggested that: </p>

<blockquote>
  <p>""If there was a focus on how one can practically design an AI system while not being bogged down by programming questions, it would bring in and help many people in the community.""</p>
</blockquote>

<p>As one of the persistent critiques of AI is the relative lack of experienced experts, I think it is incumbent on us to evolve the parameters of this Stack to attract such contributors.  </p>

<p>Is ""architecture"" a sufficient descriptor?</p>
",AImeta,discussion experience researcher developer suggested focus one practically design ai system bogged programming questions would bring help many people community one persistent critiques ai relative lack experienced experts think incumbent us evolve parameters stack attract contributors architecture sufficient descriptor
1,"<p>This site <a href=""https://area51.meta.stackexchange.com/a/24016/136466"">was created</a> to be a space for the academic and conceptual and generally not-super-mathy questions that didn't previously have a good home. I think the architecting aspect of ""how do I actually do a real-life thing with AI?"" (as opposed to ""how do I tune this number cruncher?"") is worthy of a space, and that it fits here. Conveniently, there isn't a lot of overlap with older sites. <a href=""https://stats.stackexchange.com/help/on-topic"">Stats.SE</a> is about statistics (surprise!), and while it looks like the setup of systems to solve problems might on-topic at <a href=""https://datascience.stackexchange.com/help/on-topic"">Data Science</a>, that site also seems to focus on the lower-level details.</p>

<p>I would agree that ""architecture"" seems to describe this aspect well. Architects don't do the manual work of constructing the building, and they certainly don't mix the concrete, rather they make the higher-level plans so the client winds up with a nice house, which is the goal of the whole process.</p>

<p>So, should we expand the scope to include these questions? Personally, I would vote yes.</p>
",AImeta,site space academic conceptual generally super mathy questions previously good home think architecting aspect actually real life thing ai opposed tune number cruncher worthy space fits conveniently lot overlap older sites statistics surprise looks like setup systems solve problems might topic site also seems focus lower level details would agree architecture seems describe aspect well architects manual work constructing building certainly mix concrete rather make higher level plans client winds nice house goal whole process expand scope include questions personally would vote yes
1,"<p>This suggestion came from a comment on <a href=""https://ai.meta.stackexchange.com/q/1291"">another thread</a>, but I thought it was worthy of it's own meta question, so people can vote on and discuss it.</p>

<p>Here is the full comment:</p>

<blockquote>
  <p>""<strong>I came across the site, and expected to be able to ask questions about theory of the AIXI agent (for example), and was very disappointed to find that it was mostly focused on social issues. At the very least, it seems like the history of AI theory should be on-topic, and all of that is very technical.</strong> There's kind of a chicken-and-egg problem here--the site can't be properly defined until it attracts enough experts, and it won't attract experts until there are interesting questions.""</p>
</blockquote>

<p>I left the second part of the comment in to illustrate how this connects to what might be seen as our #1 imperative: to attract experienced experts as contributors.</p>
",AImeta,suggestion came comment thought worthy meta question people vote discuss full comment came across site expected able ask questions theory aixi agent example disappointed find mostly focused social issues least seems like history ai theory topic technical kind chicken egg problem site properly defined attracts enough experts attract experts interesting questions left second part comment illustrate connects might seen 1 imperative attract experienced experts contributors
1,"<p>I definitely understand the concerns about the overlap between CrossValidated, Data Science, and this site. What we need to do, to help the site get more traction, is to define that boundary in a useful way. At a high level, it wouldn't make sense to reject a site about statistics because a perfectly good mathematics site already existed. Statistics has different goals, conventions, notation, and concerns--even though it's almost all mathematics.</p>

<p>I'd argue that the failures of the previous sites were more a question of timing than content. Serious interest in AI is on the horizon again, very recently, precisely because of advances in ML. That doesn't mean, however, that AI proper is the same thing as ML, or needs to be focused on implementation issues. There's a large amount of theory that isn't necessarily data science, either.</p>

<p>We went through some of the same growing pains on Signal Processing. The approach we took there (and I'm not saying it's the right approach for AI), was to concentrate mostly on theory, and avoid implementation details. It's something that didn't exist, and it gave us a way to attract experts who weren't programmers.</p>

<p>Explicitly making the history of AI on-topic, however technical, might be a good starting point to help clarify what a site dedicated to AI can add to the SE network. I'm not saying that it's necessarily off-topic now, but given that MathJax isn't even enabled yet, there's currently a strong bias toward strictly non-technical questions.</p>

<p>I think the <a href=""https://en.wikipedia.org/wiki/AIXI"" rel=""nofollow noreferrer"">AIXI agent</a> is a good example to begin discussing these issues. It's heavily mathematical, based on reinforcement learning, inspired by statistical reasoning (ala. <a href=""https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference"" rel=""nofollow noreferrer"">Solomonoff's Universal Prior</a>), and uses non-computable concepts (i.e. <a href=""https://en.wikipedia.org/wiki/Kolmogorov_complexity"" rel=""nofollow noreferrer"">Kolomogorov Complexity</a>). So, there's a potential overlap with any number of fields, but really it's proper <a href=""https://en.wikipedia.org/wiki/Artificial_general_intelligence"" rel=""nofollow noreferrer"">AGI</a>. It's a much more practical definition of intelligence than, say, the Turing Test--precisely because it's defined mathematically. At the very least, it seems like definitions of intelligence should be on-topic, and we need math for those.</p>

<p>It might warrant a completely separate meta question, but I'll offer one thought on how to help clarify the scope of the site (in addition to including AI history). Let's start with <a href=""https://en.wikipedia.org/wiki/Peter_Norvig"" rel=""nofollow noreferrer"">Peter Norvig's</a> definition of AI (from <a href=""https://ai.meta.stackexchange.com/users/4/franck-dernoncourt"">Frank Dernoncort's</a> <a href=""http://www.francky.me/doc/20120530%20-%20AI%20and%20Business%20-%20CCSF%20Paris.pdf"" rel=""nofollow noreferrer"">slides</a>):</p>

<blockquote>
  <p>We think of AI as understanding the world and deciding how to  make 
  good  decisions. Dealing with uncertainty  but  still  being  able  to
  make  good  decisions  is  what  separates  AI  from  the  rest  of 
  computer science.</p>
</blockquote>

<p>Any discussion of decision making under uncertainty will almost necessarily involve probability and statistics. However, the challenges involved in <em>automating</em> those decisions effectively, in my opinion, are the domain of Artificial Intelligence, whether general or specialized. That definition also includes all of the potential social issues.</p>
",AImeta,definitely understand concerns overlap crossvalidated data science site need help site get traction define boundary useful way high level would make sense reject site statistics perfectly good mathematics site already existed statistics different goals conventions notation concerns even though almost mathematics would argue failures previous sites question timing content serious interest ai horizon recently precisely advances ml mean however ai proper thing ml needs focused implementation issues large amount theory necessarily data science either went growing pains signal processing approach took saying right approach ai concentrate mostly theory avoid implementation details something exist gave us way attract experts programmers explicitly making history ai topic however technical might good starting point help clarify site dedicated ai add se network saying necessarily topic given mathjax even enabled yet currently strong bias toward strictly non technical questions think good example begin discussing issues heavily mathematical based reinforcement learning inspired statistical reasoning ala uses non computable concepts ie potential overlap number fields really proper much practical definition intelligence say turing test precisely defined mathematically least seems like definitions intelligence topic need math might warrant completely separate meta question offer one thought help clarify scope site addition including ai history let start definition ai think ai understanding world deciding make good decisions dealing uncertainty still able make good decisions separates ai rest computer science discussion decision making uncertainty almost necessarily involve probability statistics however challenges involved automating decisions effectively opinion domain artificial intelligence whether general specialized definition also includes potential social issues
1,"<p>I was under the impression that history and theory were already on-topic. Social issues is one new topic we bring to the SE table, but academic questions (about AI as a discipline/science) are also ours to present. Key quote from a community manager <a href=""https://area51.meta.stackexchange.com/a/24016/136466"">in the Area 51 Discussion Zone</a>, emphasis original:</p>

<blockquote>
  <p>Notice that this proposal is in the 'Science' category; <em>not</em> 'Technology'. Despite the creation of a Data Science site to cover this topic, the community made a sufficiently compelling case that there is a swath of <strong>questions in the academic humanities arena</strong> that are not covered by our current sites.</p>
</blockquote>

<p>I realize now that when <a href=""https://ai.meta.stackexchange.com/q/1252/75"">drafting</a> the <a href=""https://ai.stackexchange.com/help/on-topic"">on-topic page</a> I forgot to include a bullet point to cover these questions. I apologize for the oversight and have corrected it. As always, suggestions for improvement to that page's contents are welcome!</p>
",AImeta,impression history theory already topic social issues one new topic bring se table academic questions ai discipline science also present key quote community manager emphasis original notice proposal iscience category notechnology despite creation data science site cover topic community made sufficiently compelling case swath questions academic humanities arena covered current sites realize forgot include bullet point cover questions apologize oversight corrected always suggestions improvement page contents welcome
1,"<p>The tag length limit is now expanded to 35 characters. </p>

<p>This means that <a href=""https://ai.stackexchange.com/questions/tagged/conv-neural-network"" class=""post-tag"" title=""show questions tagged &#39;conv-neural-network&#39;"" rel=""tag"">conv-neural-network</a> can be expanded to <a href=""https://ai.stackexchange.com/questions/tagged/convolutional-neural-networks"" class=""post-tag"" title=""show questions tagged &#39;convolutional-neural-networks&#39;"" rel=""tag"">convolutional-neural-networks</a>.</p>
",AImeta,tag length limit expanded 35 characters means expanded
1,"<p>Currently, we have the tag <a href=""https://ai.stackexchange.com/questions/tagged/nlp"" class=""post-tag"" title=""show questions tagged &#39;nlp&#39;"" rel=""tag"">nlp</a>. Now that we have 35 characters in tags, can we change this to <a href=""https://ai.stackexchange.com/questions/tagged/natural-language-processing"" class=""post-tag"" title=""show questions tagged &#39;natural-language-processing&#39;"" rel=""tag"">natural-language-processing</a>?</p>
",AImeta,currently tag 35 characters tags change
1,"<p>Done - a <a href=""https://ai.stackexchange.com/tags/synonyms"">tag synonym</a> has been created and <a href=""https://ai.stackexchange.com/questions/tagged/conv-neural-network"" class=""post-tag"" title=""show questions tagged &#39;conv-neural-network&#39;"" rel=""tag"">conv-neural-network</a> has been merged into <a href=""https://ai.stackexchange.com/questions/tagged/convolutional-neural-networks"" class=""post-tag"" title=""show questions tagged &#39;convolutional-neural-networks&#39;"" rel=""tag"">convolutional-neural-networks</a>, thereby updating all existing questions. This has the added benefit of making the tag name consistent with all the other pluralized ones.</p>
",AImeta,done created merged thereby updating existing questions added benefit making tag name consistent pluralized ones
1,"<blockquote>
  <p>I made the point that the question seems to fit into the ""conceptual aspects of AI"" covered by this stack, but T.C. countered that Machine Learning questions, in particular, are already quite fractured across several sites.</p>
</blockquote>

<p>I believe most ML questions are on CV. Then DS got created, which has a huge overlap with CV, and a more trendy name. So one way to avoid fracture is not creating new Stacks with huge overlaps (<a href=""https://ai.meta.stackexchange.com/q/4/4"">Are all questions asked on stats and data science SE also on topic here?</a>).</p>

<blockquote>
  <p>How can we reconcile this so that the related Stacks support and add value to each other?</p>
</blockquote>

<p><a href=""https://meta.stackexchange.com/q/199989/178179"">Build and strengthen the Stack Exchange community with ""crossover questions"" between sites</a></p>

<blockquote>
  <p>Part of my inclination may derive from having been in an interdisciplinary studies program as an undergraduate. In that program, we did not learn Science independently of History, Philosophy, Psychology, Art and Literature. Rather, these subjects were taught in tandem.</p>
</blockquote>

<p>In practice, the development of AI models doesn't care much about History, Philosophy, Art and Literature. Most AI experts focus on the models, which tend to be statistical, therefore on-topic on CV. </p>
",AImeta,made point question seems fit conceptual aspects ai covered stack tc countered machine learning questions particular already quite fractured across several sites believe ml questions cv ds got created huge overlap cv trendy name one way avoid fracture creating new stacks huge overlaps reconcile related stacks support add value part inclination may derive interdisciplinary studies program undergraduate program learn science independently history philosophy psychology art literature rather subjects taught tandem practice development ai models care much history philosophy art literature ai experts focus models tend statistical therefore topic cv
1,"<p>I Searched for the PGM tag to subscribe to but could not find it. </p>

<p>IMHO, Probabilistic Graphical model is an essential branch of AI</p>

<p>Thanks </p>
",AImeta,searched pgm tag subscribe could find imho probabilistic graphical model essential branch ai thanks
1,"<p>We currently have both <a href=""https://ai.stackexchange.com/questions/tagged/cnn"" class=""post-tag"" title=""show questions tagged &#39;cnn&#39;"" rel=""tag"">cnn</a> and <a href=""https://ai.stackexchange.com/questions/tagged/convolutional-neural-networks"" class=""post-tag"" title=""show questions tagged &#39;convolutional-neural-networks&#39;"" rel=""tag"">convolutional-neural-networks</a>. </p>

<p>Should <a href=""https://ai.stackexchange.com/questions/tagged/cnn"" class=""post-tag"" title=""show questions tagged &#39;cnn&#39;"" rel=""tag"">cnn</a> be a synonym of <a href=""https://ai.stackexchange.com/questions/tagged/convolutional-neural-networks"" class=""post-tag"" title=""show questions tagged &#39;convolutional-neural-networks&#39;"" rel=""tag"">convolutional-neural-networks</a>?</p>
",AImeta,currently synonym
1,"<h1>Yes.</h1>
<p>They both mean the same thing, so we should have only one tag. They should be synonymized, because if you type <code>cnn</code> the tag <a href=""https://ai.stackexchange.com/questions/tagged/convolutional-neural-networks"" class=""post-tag"" title=""show questions tagged &#39;convolutional-neural-networks&#39;"" rel=""tag"">convolutional-neural-networks</a> does not come up as a suggestion, and vice versa.</p>
",AImeta,yes mean thing one tag synonymized type tag come suggestion vice versa
1,"<p>I did some googling and ""ultraintelligent machine"" seems to derive from a 1965 I.J. Good article.  </p>

<p>My feeling is that such a tag would largely refer to his work, and that superintelligence more current term, possibly favored for its compactness. </p>

<p>To clarify:</p>

<ul>
<li>Wiki search for superintelligence <a href=""https://en.wikipedia.org/wiki/Superintelligence"" rel=""nofollow noreferrer"">leads to a page of that title</a></li>
<li>Wiki search for ultraintelligent machine <a href=""https://en.wikipedia.org/wiki/I._J._Good#Research_and_publications"" rel=""nofollow noreferrer"">leads to I.J. Good page</a></li>
</ul>

<blockquote>
  <p>Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever.
  <br><sub>Good's definition ultraintelligent machine:</sub> </p>
</blockquote>

<p>My thinking is we need <strong><em>both</em></strong>, because Good is quite important, and ultra intelligent machine should refer largely to his work.</p>

<p>By contrast, superintelligence should be used to refer to the concept in general.</p>

<ul>
<li>From a practical standpoint, I suspect superintelligence is more widely used, and likely sought for as a tag.  One who doesn't know Good's work might not think to search for ultraintelligent machine.</li>
</ul>
",AImeta,googling ultraintelligent machine seems derive 1965 ij good article feeling tag would largely refer work superintelligence current term possibly favored compactness clarify wiki search superintelligence wiki search ultraintelligent machine let ultraintelligent machine defined machine far surpass intellectual activities man however clever good definition ultraintelligent machine thinking need good quite important ultra intelligent machine refer largely work contrast superintelligence used refer concept general practical standpoint suspect superintelligence widely used likely sought tag one know good work might think search ultraintelligent machine
1,"<p>Yes, tags with the same meaning should indeed be synonyms. The requested synonym is now in place; <a href=""https://ai.stackexchange.com/questions/tagged/cnn"" class=""post-tag"" title=""show questions tagged &#39;cnn&#39;"" rel=""tag"">cnn</a> was also merged into <a href=""https://ai.stackexchange.com/questions/tagged/convolutional-neural-networks"" class=""post-tag"" title=""show questions tagged &#39;convolutional-neural-networks&#39;"" rel=""tag"">convolutional-neural-networks</a> to update the eight existing <a href=""https://ai.stackexchange.com/questions/tagged/cnn"" class=""post-tag"" title=""show questions tagged &#39;cnn&#39;"" rel=""tag"">cnn</a> questions and deduplicate the tags on the two questions that had both tags.</p>
",AImeta,yes tags meaning indeed synonyms requested synonym place also merged update eight existing questions deduplicate tags two questions tags
1,"<p>Gaming in the computational sense really refers to video games which are distinct from combinatorial games (board games, card games, etc.)  </p>

<p>My feeling is that the approach to these general categories has been distinct, and only recently have algorithms proven on combinatorial games been extended to video games (AlphaGo).</p>

<ul>
<li>Should we add a ""combinatorial-games"" tag and replace the gaming tag on questions relating to Chess or Go, for example? </li>
</ul>
",AImeta,gaming computational sense really refers video games distinct combinatorial games board games card games etc feeling approach general categories distinct recently algorithms proven combinatorial games extended video games alphago add combinatorial games tag replace gaming tag questions relating chess go example
1,"<p>I'm Pops, a Community Manager at Stack Exchange. Though it once again saddens me to say it, one of your moderators has decided it's time to step down. Another of your fellow community members here on AI SE has answered the call to be your new pro tem mod, though:</p>

<p><a href=""https://ai.stackexchange.com/users/4398""><img src=""https://ai.stackexchange.com/users/flair/4398.png"" alt=""Jaden Travnik""></a></p>

<p>Please join me in thanking Matthew Graves for his service and in welcoming Jaden Travnik!</p>

<p>Those who are keeping a close eye on meta may remember <a href=""https://ai.meta.stackexchange.com/questions/1293/please-welcome-your-new-pro-tem-mod"">an announcement similar to this</a> not that long ago. To address some of the issues raised implicitly and explicitly there:</p>

<ul>
<li>Jaden, like your other mods, is a moderator <a href=""https://stackoverflow.blog/2010/07/27/moderator-pro-tempore/""><em>pro tempore</em></a>. All Stack Exchange sites in public beta have moderators appointed by the SE staff (people like me). You'll get to elect moderators on your own if and when your site graduates.</li>
<li>Graduation is, to oversimplify a bit, based primarily on question volume. We ran an analysis a couple years ago to make the process more data-driven and found a correlation between questions per day and site health. For more on that, and our philosophy, see <a href=""https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sites"">Graduation, site closure, and a clearer outlook on the health of SE sites</a> on the network meta site.</li>
</ul>

<p>(If you have questions about graduation, please post a separate meta question.)</p>
",AImeta,pops community manager stack exchange though saddens say one moderators decided time step another fellow community members ai se answered call new pro tem mod though please join thanking matthew graves service welcoming jaden travnik keeping close eye meta may remember long ago address issues raised implicitly explicitly jaden like mods moderator stack exchange sites public beta moderators appointed se staff people like get elect moderators site graduates graduation oversimplify bit based primarily question volume ran analysis couple years ago make process data driven found correlation questions per day site health philosophy see network meta site questions graduation please post separate meta question
1,"<p>I've been active on several different SE sites during the last years and I haven't seen any other community that's so fast with downvoting questions, especially without providing helpful comments.</p>

<p>I am all for strict rules and enforcing high quality content. But with a small site like AI that still <a href=""https://area51.stackexchange.com/proposals/93481/artificial-intelligence"">needs to polish its numbers</a> after over 400 days in beta we should be careful not to go over the top.</p>

<p>In case a question is definitely off-topic or not salvageable quality wise, it needs to be treated accordingly and it should be closed. But when I come here I am often greeted by several new questions with just a few views but the first downvotes already. No explanations are given and (the often new) visitors are left with a bad feeling and no idea what they did wrong. When I go over their questions it is sometimes difficult for me to understand why they have been downvoted. I don't feel like that's the right approach to grow the site and attract new members.</p>

<p>Am I on the right track or do you disagree? Is a strict (and maybe a little hostile) environment necessary to keep the quality high, at the cost of losing potential members who might create valuable content if we give them feedback and time to get accustomed to our community?</p>
",AImeta,active several different se sites last years seen community fast downvoting questions especially without providing helpful comments strict rules enforcing high quality content small site like ai still 400 days beta careful go top case question definitely topic salvageable quality wise needs treated accordingly closed come often greeted several new questions views first downvotes already explanations given often new visitors left bad feeling idea wrong go questions sometimes difficult understand downvoted feel like right approach grow site attract new members right track disagree strict maybe little hostile environment necessary keep quality high cost losing potential members might create valuable content give feedback time get accustomed community
1,"<p>It is indeed a shame when a user comes in, asks a decent question, and gets silently downvoted. Even though the downvote mechanism itself isn't hostile - we vote on content, not people - people will feel frustrated when their posts receive negative feedback for reasons unclear. At the same time, downvotes are critical to quality control and we cannot control users' voting behavior (except in abusive situations like targeted voting).</p>

<p>Fortunately, even though we might not get an explanation from downvoters themselves, we can help new users understand what's going on. The <a href=""https://ai.stackexchange.com/review/first-posts"">First Posts</a> review queue gives you the chance to provide users' first experience on our site. You can also monitor <a href=""https://ai.stackexchange.com/search?tab=newest&amp;q=score%3a..-1%20closed%3a0"">a list of new downvoted questions</a> to check that the downvotes are justified and take all appropriate actions. Specifically, it's very helpful to edit and comment with a welcome and an explanation of how your adjustment will help their post's reception.</p>

<p>Side note for what it's worth: the Area 51 statistics are no longer as critical as their central position advertises them. The Area 51 system <a href=""https://meta.stackexchange.com/a/263506/295684"">is pretty old and pending a reworking</a>, even though it still gets the job done. The comments on <a href=""https://meta.stackexchange.com/a/257720/295684"">this MSE answer</a> are relevant, especially <a href=""https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sites/257639#comment840478_257720"">this one</a> (excerpt: ""The A51 metrics are spectacularly ill-suited for giving an accurate picture of a site's overall health"") and <a href=""https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sites/257639#comment841019_257720"">this other one</a>. It would still be nice to have higher stats, though.</p>

<p>In summary, quality control and welcomingness needn't be mutually exclusive. If we guide users and help adjust their posts, we can be inviting and high-quality at the same time!</p>
",AImeta,indeed shame user comes asks decent question gets silently downvoted even though downvote mechanism hostile vote content people people feel frustrated posts receive negative feedback reasons unclear time downvotes critical quality control control users voting behavior except abusive situations like targeted voting fortunately even though might get explanation downvoters help new users understand going review queue gives chance provide users first experience site also monitor check downvotes justified take appropriate actions specifically helpful edit comment welcome explanation adjustment help post reception side note worth area 51 statistics longer critical central position advertises area 51 system even though still gets job done comments relevant especially excerpt a51 metrics spectacularly ill suited giving accurate picture site overall health would still nice higher stats though summary quality control welcomingness need mutually exclusive guide users help adjust posts inviting high quality time
1,"<p>This could easily be solved by requiring a comment for downvotes on new stacks or on new user questions.</p>
",AImeta,could easily solved requiring comment downvotes new stacks new user questions
1,"<p>I agree with making this change.  As far as can tell, to a first approximation, nobody uses the term ""ultra-intelligence"".  ""Super intelligence"" or ""Artificial super intelligence"" are the terms I see.</p>
",AImeta,agree making change far tell first approximation nobody uses term ultra intelligence super intelligence artificial super intelligence terms see
1,"<p>Folks:</p>

<p>Like it or not, people are going to continue to post variations of the ""How do I get started in AI"" question.  No matter how many get closed and marked off-topic, they're going to keep showing up. And closing them, while arguably ""correct"" in a pedantic sense, is not contributing to a good user experience for users of this site.  It's especially galling that we're going to leave bad taste in the mouth of newbies who are just trying to get started, only to (from a subjective, personal perspective) have a door slammed in their face.</p>

<p>I feel like we need to do something to address this.  An obvious choice would be to write a ""getting started guide"" and link to it somewhere in the sidebar on the right hand side of the page.  Another option might be to pick one of the existing ""getting started"" questions"", pin it to the front-page somehow (might take special support from SE staff??) and make it the one, sole, ""blessed"" newbie thread.</p>

<p>Possibly there are other options, but I strongly feel that we need <em>something</em> in place to address this question.   </p>
",AImeta,folks like people going continue post variations get started ai question matter many get closed marked topic going keep showing closing arguably correct pedantic sense contributing good user experience users site especially galling going leave bad taste mouth newbies trying get started subjective personal perspective door slammed face feel like need something address obvious choice would write getting started guide link somewhere sidebar right hand side page another option might pick one existing getting started questions pin front page somehow might take special support se staff make one sole blessed newbie thread possibly options strongly feel need something place address question
1,"<p>Sites like SuperUser.SE and Physics.SE deal with this by having a set of “canonical” questions. These are usually specific questions/answers that are very specific but very well explained. </p>

<p>I imagine that approach could very well apply here too, and the SE system already provides support for it. </p>

<p><strong>Update</strong></p>

<p>I think this link provides a lot more information. <a href=""https://meta.stackoverflow.com/q/291992/147507"">https://meta.stackoverflow.com/q/291992/147507</a></p>

<p>To sum it up: there's currently thing ""special"" about the canonical questions and answers, aside from being asked and answered very thoroughly, and sometimes with varying levels of detail, so that it handles most users questions.</p>

<p>Into how they are suggested to users: they go through the same process as every other question, by appearing on the sidebar or searches. (See notes <a href=""https://meta.stackexchange.com/a/112438/335458"">here</a>). If the question is properly redacted and the answers are detailed enough, it should pop up among suggested answers, and users should find it relevant to their search/question.</p>

<p>How to generate them? As simple as it sounds: once identified, start a new question, write the hell out of it, which will get it upvoted, and let it sit around. Maybe save the link if we're thinking in closing questions as duplicates to it.</p>
",AImeta,sites like superuserse physicsse deal set canonical questions usually specific questions answers specific well explained imagine approach could well apply se system already provides support update think link provides lot information sum currently thing special canonical questions answers aside asked answered thoroughly sometimes varying levels detail handles users questions suggested users go process every question appearing sidebar searches see notes question properly redacted answers detailed enough pop among suggested answers users find relevant search question generate simple sounds identified start new question write hell get upvoted let sit around maybe save link thinking closing questions duplicates
1,"<p>Here are several questions and answers that would benefit from MathJax support on this website. These are just a few examples I've found in a 5 minutes search. Nevertheless, I think this number is enough to justify a MathJax support on this website.</p>
<h3>Questions</h3>
<ul>
<li><p><s>https://ai.stackexchange.com/a/4710/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/2994/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/4085/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/3758/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/4740/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/4296/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/4140/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/2226/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/2865/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/3458/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/113/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/5580/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/13577/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/5075/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/8240/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/3226/2444</s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/q/5638/2444"">Hand computing feed forward and back propagation of neural network</a></p>
</li>
</ul>
<h3>Answers</h3>
<ul>
<li><p><s>https://ai.stackexchange.com/a/1927/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/4227/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/2292/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/4185/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/4388/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/3906/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/267/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/3162/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/6280/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/5620/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/5079/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/2300/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/4479/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/5597/2444</s> (post deleted)</p>
</li>
<li><p><s>https://ai.stackexchange.com/a/6983/2444</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/a/13216/2444</s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/a/6628/2444"">https://ai.stackexchange.com/a/6628/2444</a></p>
</li>
</ul>
",AImeta,several questions answers would benefit mathjax support website examples found 5 minutes search nevertheless think number enough justify mathjax support website questions httpsaistackexchangecoma47102444 httpsaistackexchangecoma29942444 httpsaistackexchangecomq40852444 httpsaistackexchangecomq37582444 httpsaistackexchangecomq47402444 httpsaistackexchangecomq42962444 httpsaistackexchangecomq41402444 httpsaistackexchangecomq22262444 httpsaistackexchangecomq28652444 httpsaistackexchangecomq34582444 httpsaistackexchangecomq1132444 httpsaistackexchangecomq55802444 httpsaistackexchangecomq135772444 httpsaistackexchangecomq50752444 httpsaistackexchangecomq82402444 httpsaistackexchangecomq32262444 answers httpsaistackexchangecoma19272444 httpsaistackexchangecoma42272444 httpsaistackexchangecoma22922444 httpsaistackexchangecoma41852444 httpsaistackexchangecoma43882444 httpsaistackexchangecoma39062444 httpsaistackexchangecoma2672444 httpsaistackexchangecoma31622444 httpsaistackexchangecoma62802444 httpsaistackexchangecoma56202444 httpsaistackexchangecoma50792444 httpsaistackexchangecoma23002444 httpsaistackexchangecoma44792444 httpsaistackexchangecoma55972444 post deleted httpsaistackexchangecoma69832444 httpsaistackexchangecoma132162444
1,"<p>According to my scope of the subjects. Artificial intelligence in a very strict sense should only contain questions pertaining to how we can create truly intelligent (creative, aware, etc.) machines. Whereas data science is directly the manipulation of data in order to produce tools to make something better (image detection, intrusion detection, etc.). The separation is very blurry and I do not think that intelligence can exist without information/data, and its manipulations. However, most machine learning and deep learning demonstrated are simply conducting complex function approximations.</p>

<p>However, due to the popularization of machine learning and especially deep learning, the manipulation of data has created the impression of intelligent machine due to it being capable of competing with human performance in very targeted tasks (object recognition, segmentation, etc.). Evidently, the name artificial intelligence catches people's attention much more than data science or machine learning. Thus, it is common for news which is essentially generic data science/machine learning to be called artificial intelligence.</p>

<p>This is further demonstrated on the Artificial Intelligence site where the majority of the questions are pertaining more to data science and machine learning than truly discussing possibilities, methods or emerging work pertaining to machines capable of intelligence.</p>

<p>This niche can easily be encapsulated into a site that combines both Artificial Intelligence and Data Science.</p>

<p>Post on Data Science is found <a href=""https://datascience.meta.stackexchange.com/questions/2352/should-this-site-be-combined-with-the-artificial-intelligence-stack-exchange/"">here</a>.</p>
",AImeta,according scope subjects artificial intelligence strict sense contain questions pertaining create truly intelligent creative aware etc machines whereas data science directly manipulation data order produce tools make something better image detection intrusion detection etc separation blurry think intelligence exist without information data manipulations however machine learning deep learning demonstrated simply conducting complex function approximations however due popularization machine learning especially deep learning manipulation data created impression intelligent machine due capable competing human performance targeted tasks object recognition segmentation etc evidently name artificial intelligence catches people attention much data science machine learning thus common news essentially generic data science machine learning called artificial intelligence demonstrated artificial intelligence site majority questions pertaining data science machine learning truly discussing possibilities methods emerging work pertaining machines capable intelligence niche easily encapsulated site combines artificial intelligence data science post data science found
1,"<p>Though we get a lot of (off-topic) questions about data manipulation and implementation issues in general, this site was created to serve questions that aren't so quantitative. For some more info on our scope, see the <a href=""https://ai.stackexchange.com/help/on-topic"">help center</a>. Admittedly, we are currently doing an incomplete job of making the scope clear to new users and handling off-topic questions. Nevertheless, it is clear from <a href=""https://area51.meta.stackexchange.com/a/24016/136466"">this Area 51 Discussion Zone post</a> by a Stack Exchange community manager that this site is for AI as a science, not as a technology to be implemented:</p>

<blockquote>
  <p>Notice that this proposal is in the 'Science' category; <em>not</em> 'Technology'.  Despite the creation of a Data Science site to cover this topic, the community made a sufficiently compelling case that there is a swath of <strong>questions in the academic humanities arena</strong> that are <em>not</em> covered by our current sites.</p>
</blockquote>

<p>Social, conceptual, and philosophical aspects of AI are on-topic here, but not on Data Science, which is a more technical site. There is some overlap in architectural questions, but there is much precedent for sites' topics not being fully disjoint &mdash; Stack Overflow and Super User on PowerShell questions, for example. Combining our slightly subjective questions with Data Science's technicality would be mixing two different types of questions (and two different communities).</p>

<p>In short, this site and Data Science are looking at different aspects of artificial intelligence. Both sites are valuable, each with its own knowledgeable people, and it would be good to preserve the distinction.</p>

<p>Relevant MSE: <a href=""https://meta.stackexchange.com/q/68214/295684"">Can Stack Exchange follow a more generic approach?</a></p>
",AImeta,though get lot topic questions data manipulation implementation issues general site created serve questions quantitative info scope see admittedly currently incomplete job making scope clear new users handling topic questions nevertheless clear stack exchange community manager site ai science technology implemented notice proposal iscience category notechnology despite creation data science site cover topic community made sufficiently compelling case swath questions academic humanities arena covered current sites social conceptual philosophical aspects ai topic data science technical site overlap architectural questions much precedent sites topics fully disjoint stack overflow super user powershell questions example combining slightly subjective questions data science technicality would mixing two different types questions two different communities short site data science looking different aspects artificial intelligence sites valuable knowledgeable people would good preserve distinction relevant mse
1,"<p>I, for one, would love its inclusion. I do not believe it is possible to divorce AI from mathematics on many levels. For instance, I wanted to ask a question regarding the use of backpropagation with regards to the ANFIS model but had to do so in a clumsy way as I was not able to include the proper notation for partial derivatives. It would surprise me to think that this site is just for ""high level"" philosophical discussions on AI.</p>
",AImeta,one would love inclusion believe possible divorce ai mathematics many levels instance wanted ask question regarding use backpropagation regards anfis model clumsy way able include proper notation partial derivatives would surprise think site high level philosophical discussions ai
1,"<p>My first opinion has been ""nooo!"". However, skipping points as if this site must include applied AI or only strong AI, what is AI and what is data processing, ... my opinion is now ""yes, just find a good name for the combined site"". </p>

<p>The reason: this site has a low volume of questions and answers (if all off-topic was directly closed, activity will be epsilon), low number views per day, and,  sorry to say that, low quality of questions and answers. Join two sites will increase the activity and the number of experts, improving all these aspects.</p>

<p>A good usage of tags in the new site will solve all practical aspects.</p>
",AImeta,first opinion nooo however skipping points site must include applied ai strong ai ai data processing opinion yes find good name combined site reason site low volume questions answers topic directly closed activity epsilon low number views per day sorry say low quality questions answers join two sites increase activity number experts improving aspects good usage tags new site solve practical aspects
1,"<p>Hellz No!  Where would people ask philosophical questions related to AI, or discuss theoretical topics?  What about the Mythology of AI?  (Off-topic at Stack:Mythology, but is the predominant influence re the public's perception of AI.)</p>

<p><strong>Morality of AI applications is a critical issue, only increasing, as are social impacts of AI.  This Stack is the forum to discuss them.</strong></p>

<p><strong>This is also the Stack for Game Theory as it relates to AI, and combinatorial games, which are inextricably related to AI, in that they are still used for AI proving.</strong></p>

<p>I'd propose, as the Cross Validated community has, that Data Science should probably be rolled into that Stack, and CV should probably adopt the name ""Data Science"" so people know where to go for those questions.  (i.e. ""CV"" is cool, but it's insider-ey, and noobs don't know that's the place to ask Data Science questions related to AI, and come to SE:AI.)</p>

<p>Do I don't think the problem is with the AI Stack at all.  The humanities size of the equation, which is the core of this stack, should not be handled on a Data Science forum.</p>

<p>I think the solution would be to revise our ""Community Guidelines"" to be very clear about which questions should go to CV/DS, reposting their guidelines as a sub-section to AI's guidelines, and try to get some involvement from the CV/DS forums on which questions to migrate, so we don't accidentally migrate questions they don't want. </p>
",AImeta,hellz would people ask philosophical questions related ai discuss theoretical topics mythology ai topic stack mythology predominant influence public perception ai morality ai applications critical issue increasing social impacts ai stack forum discuss also stack game theory relates ai combinatorial games inextricably related ai still used ai proving would propose cross validated community data science probably rolled stack cv probably adopt name data science people know go questions ie cv cool insider ey noobs know place ask data science questions related ai come se ai think problem ai stack humanities size equation core stack handled data science forum think solution would revise community guidelines clear questions go cv ds reposting guidelines sub section ai guidelines try get involvement cv ds forums questions migrate accidentally migrate questions want
1,"<p>My personal position is we should indeed take basic questions on any aspect of AI, so I'm not suggesting we end our experiment accepting implementation questions, but, where these questions haven't attracted an answer on AI, should we migrate to SE:Data Science or SE:Cross Validated?</p>
",AImeta,personal position indeed take basic questions aspect ai suggesting end experiment accepting implementation questions questions attracted answer ai migrate se data science se cross validated
1,"<h1>No.</h1>
<p>If a question is on topic, then it should stay here. Migrating is for <em>high-quality, but off topic</em> questions. This is why migrating a question involves closing as &quot;off-topic&quot;. In this case, they're <em>not</em> off topic - they just haven't gotten an answer.</p>
<p>Now, <em>why</em> don't they have an answer? Probably because there's nobody on the site who knows how to answer it... or the right person just hasn't seen it. If nobody on the site knows how to answer a question, then the best thing to do would be to <strong>attract users who <em>do</em> know how to answer the questions</strong>, namely, &quot;experts&quot;.</p>
<p>How do these &quot;experts&quot; find the site, though? Usually through <em>content already on the site</em> - it'll come up in a Google search or something. So to attract the experts, you need content, and if you send all the content away, then AI.SE won't get new users and the site will stagnate.</p>
<p>There's nothing wrong with having some unanswered questions around, as long as not <em>all</em> questions are unanswered. And if that happens, the site's got a big problem.</p>
<p>See also <a href=""https://meta.stackexchange.com/a/212271/294691"">Meta.SE guidance on migrations</a>.</p>
",AImeta,question topic stay migrating high quality topic questions migrating question involves closing case topic gotten answer answer probably nobody site knows answer right person seen nobody site knows answer question best thing would attract users know answer questions namely find site though usually content already site come google search something attract experts need content send content away aise get new users site stagnate nothing wrong unanswered questions around long questions unanswered happens site got big problem see also
1,"<p>If we look at the curriculum of AI in any university, we will find as topics: agents, neural nets, supervised/unsupervised learning ... . In a few ones, an small part about AGI or mind.</p>

<p>It is not surprising that this site receives (and answers) a lot of questions about previous subjects. All the more because only a 0.0001% of people (not me) will thing in a site called ""cross validated"" to ask about neural nets.</p>

<p>However, the description of this site talks about ""conceptual questions about life and challenges in a world where cognitive functions can be mimicked in purely digital environment."" that not only excludes all previous, but even AGI seems off-topic.</p>

<p>This fact means that we should reject 99% of the questions and flag them as off-topic instead of answer them doing in this way an off-topic answer. </p>

<p>In my opinion, there are a disagreement between name and site description. More opinions are welcome ...</p>
",AImeta,look curriculum ai university find topics agents neural nets supervised unsupervised learning ones small part agi mind surprising site receives answers lot questions previous subjects 00001 people thing site called cross validated ask neural nets however description site talks conceptual questions life challenges world cognitive functions mimicked purely digital environment excludes previous even agi seems topic fact means reject 99 questions flag topic instead answer way topic answer opinion disagreement name site description opinions welcome
1,"<p>This might seem a bit opinionated, but since I joined AI.SE I have seen a lack of biological questions on this site. Neurobiology was one of the main influence of AI, but I don't see questions on the same. Questions on topics like brain, neurons, swarm-intelligence, etc. What can be done to explore the biological side of AI on this site?</p>
",AImeta,might seem bit opinionated since joined aise seen lack biological questions site neurobiology one main influence ai see questions questions topics like brain neurons swarm intelligence etc done explore biological side ai site
1,"<p>This is done now, sorry for the delay.</p>

<p>We still have <a href=""https://ai.stackexchange.com/questions/tagged/natural-language"" class=""post-tag"" title=""show questions tagged &#39;natural-language&#39;"" rel=""tag"">natural-language</a> and <a href=""https://ai.stackexchange.com/questions/tagged/language-processing"" class=""post-tag"" title=""show questions tagged &#39;language-processing&#39;"" rel=""tag"">language-processing</a>, which sound pretty similar to <a href=""https://ai.stackexchange.com/questions/tagged/natural-language-processing"" class=""post-tag"" title=""show questions tagged &#39;natural-language-processing&#39;"" rel=""tag"">natural-language-processing</a> &mdash; it might be worth revisiting <a href=""https://ai.meta.stackexchange.com/q/1182/75"">this NLP tag discussion</a>.</p>
",AImeta,done sorry delay still sound pretty similar might worth revisiting
1,"<p>Simple:</p>

<p>Ask more questions on the biological side of AI</p>

<p>That is pretty much it. </p>
",AImeta,simple ask questions biological side ai pretty much
1,"<p>I came across these tags. Are these tags synonymous?</p>

<ul>
<li><a href=""https://ai.stackexchange.com/questions/tagged/spanish-language"">spanish-language</a></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/language-processing"">language-processing</a></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/natural-language"">natural-language</a></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/natural-language-processing"">natural-language-processing</a></li>
</ul>

<p>The Spanish language tag is not synonymous, but I don't find what purpose it serves.</p>

<p>Also I think these time should be a subset of optimization:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/questions/tagged/optimization"">optimization</a></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/time"">time</a></li>
</ul>
",AImeta,came across tags tags synonymous spanish language tag synonymous find purpose serves also think time subset optimization
1,"<p>Re: The 3 NLP tags</p>

<p>This has been on my radar for a little while.  I've just briefly re-reviewed the questions for these three tags and see no reason not to merge.</p>

<p><strong>If anyone has any reason these tags should not be merged, speak now or forever hold your peace</strong></p>

<hr>

<p>Re: ""spanish-language"" tag</p>

<p>This is one I decided to test out, related to a question asking for both English and Spanish language resources.  Spanish is the #2 language in the US, so it might be worthwhile to see if this tag gets any additional use.  (If not, we can always delete.)</p>

<hr>

<p>Re: ""time"" tag</p>

<p>I've replaced the ""time"" tag with a new ""time-complexity"" tag on this question: <a href=""https://ai.stackexchange.com/questions/2874/neural-networks-efficiently-solve-traveling-salesmen-problems"">Neural networks efficiently solve traveling salesmen problems?</a></p>

<p><a href=""https://ai.stackexchange.com/q/184/1671"">This question</a>, however, seems to be about automata learning the concept of time.  Based on a linked research paper, I've tentatively updated the ""time"" tag to refer to perceptual time.</p>
",AImeta,3 nlp tags radar little briefly reviewed questions three tags see reason merge anyone reason tags merged speak forever hold peace spanish language tag one decided test related question asking english spanish language resources spanish 2 language us might worthwhile see tag gets additional use always delete time tag replaced time tag new time complexity tag question however seems automata learning concept time based linked research paper tentatively updated time tag refer perceptual time
1,"<p>This has been proposed:</p>

<blockquote>
  <p>For questions about current affairs about various types of contributions/theories proposed by different groups/communities identifying themselves as AI researchers/practitioners/enthusiasts.</p>
</blockquote>

<p>This is not a subject I've given much thought to, but it's important in that it defines what we mean by ""AI community"" in context so <strong>please post any thoughts, suggestions, revisions or alternate proposals.</strong></p>
",AImeta,proposed questions current affairs various types contributions theories proposed different groups communities identifying ai researchers practitioners enthusiasts subject given much thought important defines mean ai community context please post thoughts suggestions revisions alternate proposals
1,"<p>So, I have seen each stack exchange sites have their own stylized badge style. For example CrossValidated has a leaf like symbol, Biology has a genetic symbol. It definitely helps to add uniqueness to the site. Someone pointed out few benefits of having customized badges on Stackoverflow. I cannot find the link now. So should we have a new badge (something like a robot or a brain)?</p>
",AImeta,seen stack exchange sites stylized badge style example crossvalidated leaf like symbol biology genetic symbol definitely helps add uniqueness site someone pointed benefits customized badges stackoverflow find link new badge something like robot brain
1,"<p>This site is currently in beta. Beta sites do not normally have custom design elements. </p>

<p>Furthermore, <a href=""https://meta.stackexchange.com/questions/307862/ch-ch-ch-changes-left-nav-responsive-design-themes"">Stack Exchange are ch-ch-ch-changing</a> their approach to site design, and as a part of that, badges will be standardized: one badge design to rule them all. </p>

<blockquote>
  <p>Standardized items will include:</p>
  
  <ul>
  <li>Navigation  </li>
  <li>Fonts  </li>
  <li>Buttons/Icons  </li>
  <li>Badges  </li>
  <li>Tags  </li>
  <li>Newsletter ads  </li>
  </ul>
</blockquote>
",AImeta,site currently beta beta sites normally custom design elements furthermore approach site design part badges standardized one badge design rule standardized items include navigation fonts buttons icons badges tags newsletter ads
1,"<p>I guess this is my field. I'm researching the evolutionary development of human intelligence from non-intelligent roundworms. This is one part within the broader research on developing a general theory of intelligence and duplicating it non-biologically. This work seems to be unusual here since everyone else I've come across seems to assume that human reasoning is definable within Church-Turing.</p>

<p>I can't provide a lot of technical detail because it is unpublished and because it would take entire chapters to explain, but I can give general answers about what I know.</p>
",AImeta,guess field researching evolutionary development human intelligence non intelligent roundworms one part within broader research developing general theory intelligence duplicating non biologically work seems unusual since everyone else come across seems assume human reasoning definable within church turing provide lot technical detail unpublished would take entire chapters explain give general answers know
1,"<p>I have some information that is not publically available based on research that I've been doing for the past several years. I can't cite it since it isn't published. Yet it is considerably more advanced and in agreement with observed evidence than theories that usually get mentioned like Integrated Information Theory or Global Workspace (both of which can be disproved). It won't be published until it is completed and no earlier than 2021. So, I can either withhold what I know (which would be quite odd considering that proton decay was talked about for years before it was disproved), or I can answer without citations.</p>
",AImeta,information publically available based research past several years cite since published yet considerably advanced agreement observed evidence theories usually get mentioned like integrated information theory global workspace disproved published completed earlier 2021 either withhold know would quite odd considering proton decay talked years disproved answer without citations
1,"<p>I recently replied to a post on ai stackexchange, and I noticed that it is not possible to insert equations, unlike other websites like crypto stackexchange for example. I believe the library used on the latter to create mathematical equations is MathJax. Why is not there a similar tool on ai stackexchange? Wouldn't this be a very useful tool to use in posts?</p>
",AImeta,recently replied post ai stackexchange noticed possible insert equations unlike websites like crypto stackexchange example believe library used latter create mathematical equations mathjax similar tool ai stackexchange would useful tool use posts
1,"<p>I have programmed a chatbot which can enter sourcecode on AI.stackexchange. The problem is that the button for insert a codesnippet doesn't work, because the chatbot isn't able to find the correct location of the icon. Is it possible to use a different HTML form than the normal one of Stackexchange to simplify the edits?</p>

<p><em>original message</em></p>

<p>I just noticed something in AI stackexchange. Apparently we cannot insert pieces of code in the question or the answer i.e the java-script/HTML/CSS snippet. Why so?</p>

<p>I understand this site does not try to entertain implementation details, but still it would be a useful feature to have, to write algorithms in a beautiful way. What is the community's opinion on this and what should be done?</p>
",AImeta,programmed chatbot enter sourcecode aistackexchange problem button insert codesnippet work chatbot able find correct location icon possible use different html form normal one stackexchange simplify edits original message noticed something ai stackexchange apparently insert pieces code question answer ie java script html css snippet understand site try entertain implementation details still would useful feature write algorithms beautiful way community opinion done
1,"<p>I have recently noticed that even the oldest questions have small errors in them. I think that this could be improved for future generations, both to improve readability and as a record. </p>

<p>First of all, I want the mods/reviewers to know this is going on, and that I will be correcting the following:</p>

<ul>
<li>Spelling</li>
<li>Grammar</li>
<li>Word choice </li>
<li>Moving links to inline when they only appear once (Not a reason for editing by itself)</li>
</ul>

<p>I, of course, don't want all of the rep, so I welcome other users to participate.</p>

<p>Also, I want input from a few mods <strong>♦</strong>   on this.</p>
",AImeta,recently noticed even oldest questions small errors think could improved future generations improve readability record first want mods reviewers know going correcting following spelling grammar word choice moving links inline appear reason editing course want rep welcome users participate also want input mods
1,"<p>That sounds good to me. </p>

<p>A couple things to keep in mind: Especially when submitting suggested edits, please make sure to fix <em>all</em> problems with the post &mdash; this saves reviewer time and minimizes bumps. I'm not entirely certain what you mean by ""moving links to inline when they only appear once,"" but if you're referring to the Markdown inline link style (as opposed to footnote style), please submit only edits that make improvements to the rendered post. Cleaning up the Markdown in the process of making helpful visual changes is good, though. Starting from the oldest posts and proceeding to the newest is a good idea because it keeps newer content nearer the top of the front page.</p>

<p>Thanks for helping improve AI.SE!</p>
",AImeta,sounds good couple things keep mind especially submitting suggested edits please make sure fix problems post saves reviewer time minimizes bumps entirely certain mean moving links inline appear referring markdown inline link style opposed footnote style please submit edits make improvements rendered post cleaning markdown process making helpful visual changes good though starting oldest posts proceeding newest good idea keeps newer content nearer top front page thanks helping improve aise
1,"<p>I am thinking this could be in part of the variety of computers we could be on, the variety of the computing powers of said computers, and the variety of computation power required for various types of Neural Nets and such.</p>

<p>Say a specific piece of code works just fine on your Chromebook. This piece of code would also work just fine on any other device that can do parallel computations. This piece of code may still work on a RaspPi 3, but take 15-times longer to set up, train, test, etc.</p>

<p>What gets even worse is when the Library you use only supports a specific set of OS. You don't know what anyone seeing your question/answer uses. </p>

<p>So the main issue is the variety of computers out today, the variety of computation power supplied by those computers, and the variety of computation power required by various implementations of AI.</p>

<p>Therefore, not much can be done but test a piece of code on every device possible, and <em>then and only</em> then post the code. This becomes an issue when newcomers do not know about this. They may post a piece of code that works just fine on their computer, but results in disaster on others.</p>
",AImeta,thinking could part variety computers could variety computing powers said computers variety computation power required various types neural nets say specific piece code works fine chromebook piece code would also work fine device parallel computations piece code may still work rasppi 3 take 15times longer set train test etc gets even worse library use supports specific set os know anyone seeing question answer uses main issue variety computers today variety computation power supplied computers variety computation power required various implementations ai therefore much done test piece code every device possible post code becomes issue newcomers know may post piece code works fine computer results disaster others
1,"<p>When AI.SE was about to be created, there was a divide. A few wanted ML and implementation details to be part of the site; most wanted to exclude them. The final agreement was to exclude---so the current topic list excluding explicitly implementation details and so on.</p>

<p>The reasoning back then was that popular frameworks like Tensorflow, etc. were explicitly asking to question on SO. Questions about Data Science were perceived as much better fits for Cross Validated, etc. So no need to duplicate them here, and take the risk of killing AI.SE before it gets momentum. That was an interesting thinking, and I think the result is okay.</p>

<p>Now it seems that many AI.SE questions are about ANN, including popular subcategories like CNN, DNN, RNN, etc. The community here seems to expect xNN Q&amp;A, so the description and topic list do seem like a mismatch---I concur (and that is how I found your question, searching for such a discussion). Another way to put it: How can we ""make a mind™"" without talking about techniques and tools we have at present?</p>

<p>IMHO it may be time to update description and topic list, to define <em>a posteriori</em> the scope of AI.SE.</p>

<hr>

<p>Note:</p>

<ul>
<li>The current description does include AGI, though. Terminology is quite vague, but an AGI could be a ""set"" of ""cognitive functions [...] mimicked in purely digital environment."" As for theory, models, notions, concepts, the current scope has been carefuly thought through, IMO.</li>
<li>Let's keep in mind that AI.SE is the 3rd attempt to create an AI-related SE site, and the most successfull so far (the previous attempts topped at 6 months before closing). This AI.SE is on something (and the current ""market"" makes it easier with the DL wave).</li>
</ul>

<hr>

<p>Disclaimer: I was part of the first group, so I am biased in my agreement. However the sheer volume of xNN questions might be a data-backed confirmation the site needs an update (I did not go beyond lazily listing and eye-balling unanswered questions).</p>
",AImeta,aise created divide wanted ml implementation details part site wanted exclude final agreement exclude current topic list excluding explicitly implementation details reasoning back popular frameworks like tensorflow etc explicitly asking question questions data science perceived much better fits cross validated etc need duplicate take risk killing aise gets momentum interesting thinking think result okay seems many aise questions ann including popular subcategories like cnn dnn rnn etc community seems expect xnn q description topic list seem like mismatch concur found question searching discussion another way put make mind without talking techniques tools present imho may time update description topic list define posteriori scope aise note current description include agi though terminology quite vague agi could set cognitive functions mimicked purely digital environment theory models notions concepts current scope carefuly thought imo let keep mind aise 3rd attempt create ai related se site successfull far previous attempts topped 6 months closing aise something current market makes easier dl wave disclaimer part first group biased agreement however sheer volume xnn questions might data backed confirmation site needs update go beyond lazily listing eye balling unanswered questions
1,"<p>So I don't know why but suddenly there is a spurt of ""Close Vote"" revies in my queue. It probably has something to do with the mass editing of posts by @Pheo. What exactly is the community policy for this matter? Because most of the question are pretty highly up-voted like:</p>

<p><a href=""https://ai.stackexchange.com/questions/3965/deducing-the-features-from-the-data-set"">Deducing features from the data-set</a></p>

<p><a href=""https://ai.stackexchange.com/questions/5981/computing-resources-needed-for-reinforcement-learning-machine-imagery"">Computing resources needed for Reinforcement Learning/Machine Imagery</a></p>

<p>I want to know what is the suitable action in few of these example questions. Should the mods do something?</p>
",AImeta,know suddenly spurt close vote revies queue probably something mass editing posts pheo exactly community policy matter question pretty highly voted like want know suitable action example questions mods something
1,"<p>Edits don't cause things to head to the close vote queue. Edits on a closed question will sometimes push a question into the <em>reopen</em> queue, but never the close vote queue.</p>

<p>So for some reason, someone must have gone through and manually cast close votes/flags, pushing it into the queue.</p>

<p>Votes shouldn't affect the action you take on the post - if it was highly voted but then determined to be off topic, close it. If it's not close-worthy, leave it open. Each question should be judged on its own - if the standing policy on a specific type of question is that it should be closed, review it and pick the appropriate close reason. If you don't, pick Leave Open.</p>

<p>Unless someone is flooding the Close Votes queue with a mass of on topic questions, I don't think that any moderator action is necessary. There's nothing wrong with going through old questions that should be closed (although some would consider it a waste of time).</p>
",AImeta,edits cause things head close vote queue edits closed question sometimes push question reopen queue never close vote queue reason someone must gone manually cast close votes flags pushing queue votes affect action take post highly voted determined topic close close worthy leave open question judged standing policy specific type question closed review pick appropriate close reason pick leave open unless someone flooding close votes queue mass topic questions think moderator action necessary nothing wrong going old questions closed although would consider waste time
1,"<p><a href=""https://meta.stackexchange.com/q/151890/295684"">Questions older than 60 days cannot be migrated</a>, even by moderators. I don't think we can expect questions to always be answered in two months &mdash; from my experience on Super User, it's not at all unusual for months to pass before the right expert stumbles upon the question and solves it. We therefore have a bit of a catch-22 here. Even if we could ship out old unanswered questions, that's probably less than ideal for site growth; see <a href=""https://ai.meta.stackexchange.com/a/1327/75"">Mithrandir's answer</a> for more on that.</p>
",AImeta,even moderators think expect questions always answered two months see
1,"<p>There is definitely an uncommon surge in close votes in the queue at present.  (Typically we see serial downvoting, but no so many close vote.)</p>

<p>It's useful information, in the sense of getting user opinions re: what's in scope, but we tend not to actually close unless the question is egregiously off-topic, unsuitable, or unsalvagable.</p>

<p>It's possible it is due to all the edits, bringing buried questions to light...</p>
",AImeta,definitely uncommon surge close votes queue present typically see serial downvoting many close vote useful information sense getting user opinions scope tend actually close unless question egregiously topic unsuitable unsalvagable possible due edits bringing buried questions light
1,"<p>I am not asking this question to criticize or nullify someone's effort. I have been noticing that since the last few days, when @Pheo started editing (which is a good thing) that new questions which are being asked by ""new"" users are getting minimum views. </p>

<p>My question is should the ""moderators"" accept so many edits at a single time so that new questions get buried among the old questions? The old questions have a clear advantage in terms of reputation of the OP, views, upvotes, and general title. So what does the moderators think is a solution to the problem? </p>
",AImeta,asking question criticize nullify someone effort noticing since last days pheo started editing good thing new questions asked new users getting minimum views question moderators accept many edits single time new questions get buried among old questions old questions clear advantage terms reputation op views upvotes general title moderators think solution problem
1,"<p>I think I have found a solution to this. </p>

<p>Until I attain edit privileges, I am only going to do a few posts a week - Making sure that everything on them is as it should be (Taking critical issues into consideration first). As much as this is going to slow the progress down, the quality will go up greatly. As a plus, I will have more practice and a lot more time for feedback per capita per post.</p>

<p>I hope the majority of you stand with me, but regardless, I am going to do this. Please note, I have not drawn into the shell of seclusion, but merely been scolded and found a corner for myself to sit in for a while.</p>

<h3>TL;DR</h3>

<p>I am going to be cutting back on the number of time per post and increasing the time spent on each post. In other words, keeping the impact down.</p>
",AImeta,think found solution attain edit privileges going posts week making sure everything taking critical issues consideration first much going slow progress quality go greatly plus practice lot time feedback per capita per post hope majority stand regardless going please note drawn shell seclusion merely scolded found corner sit tldr going cutting back number time per post increasing time spent post words keeping impact
1,"<p>For years, users have asked Stack Exchange to add an option not to bump a question/answer when it gets edited. Until this gets implemented, there will be some awkward balance between keeping imperfect content that could be edited and not burying new questions.</p>
",AImeta,years users asked stack exchange add option bump question answer gets edited gets implemented awkward balance keeping imperfect content could edited burying new questions
1,"<p>Recently, a user asked a <a href=""https://ai.stackexchange.com/questions/6116/neural-network-returns-about-the-same-outputmean-for-every-input"">question</a> in which I am unable to help (Or even refer) the OP as I do not know which language is being used. </p>

<p>So, my question is, should we make language tags (""python"", ""javascript"", ""java"", etc) to help users in answering the question? I know we attempt to avoid implementation details, but every now and then one comes up, and some users are unable to help as they do not know what language the OP is using. </p>

<h3>TL;DR</h3>

<p>Should we implement language tags to help answer a question?</p>
",AImeta,recently user asked unable help even refer op know language used question make language tags python javascript java etc help users answering question know attempt avoid implementation details every one comes users unable help know language op using tldr implement language tags help answer question
1,"<p>I worry about the confusion between StackExchange AI and Stackoverflow. But as the code refers to Artificial Intelligence and these languages are becoming the tool of Data Scientists, I believe it is quite valid.</p>
",AImeta,worry confusion stackexchange ai stackoverflow code refers artificial intelligence languages becoming tool data scientists believe quite valid
1,"<p>A week or two ago, this site was at around 1000 visitors / day.  Just now I saw that it was showing 2 visitors / day.  Huh?  I can't imagine traffic just magically dried up for no apparent reason. Is there a problem with the collection of the metrics data, or is something else going on?</p>
",AImeta,week two ago site around 1000 visitors day saw showing 2 visitors day huh imagine traffic magically dried apparent reason problem collection metrics data something else going
1,"<p>This is a known issue with all Stack Exchange sites currently: <a href=""https://meta.stackexchange.com/questions/308966/traffic-views-visits-isnt-correctly-registered-on-site-analytics-or-area-51"">Traffic (views, visits) isn&#39;t correctly registered on Site Analytics or Area 51</a>. SE employees are aware of it, but apparently it takes some time to fix the analytics.</p>
",AImeta,known issue stack exchange sites currently se employees aware apparently takes time fix analytics
1,"<p>We've been informally allowing ML implementation questions, software &amp; hardware evaluation questions, and the scope of the humanities side of the field has expanded also...</p>

<p>My sense is, the expansion of scope has been helpful and, in aggregate, welcomed. </p>

<ul>
<li>We're the general AI site, so I feel like pretty much anything we have a tag for, when it's related to AI, is within scope</li>
</ul>

<p>For example:</p>

<p><strong>terminology</strong> should <em>definitely</em> be on-topic and mentioned</p>

<p><strong>hardware evaluation</strong> and <strong>software evaluation</strong> (libraries, frameworks, etc.) questions can be answered objectively and provide valuable information </p>

<p><strong>game theory</strong> and extensions I'd personally like to see mentioned </p>

<p><strong>logic</strong> seems to me to be fundamental, as does <strong>probability</strong></p>

<p>The caveat is that we do want to work in conjunction with the communities with which we have overlap, and support those communities. </p>

<p>We feel firmly that there needs to be a Stack:AI, but we're still in the process of figuring out how to make that permanent, and so we also depend on the support of these related communities. </p>

<h2>-----------------------</h2>

<p><strong>Because we also deal with the humanities, I'd want to have an explanation of what constitutes a good ""soft question"".</strong> </p>

<p>These are cases where there is not an objective answer, but answers that are sufficiently supported, ideally with citations, are legitimate. </p>

<p>These types of questions are a great opportunity to introduce OP's to fundamental concepts.</p>
",AImeta,informally allowing ml implementation questions software hardware evaluation questions scope humanities side field expanded also sense expansion scope helpful aggregate welcomed general ai site feel like pretty much anything tag related ai within scope example terminology definitely topic mentioned hardware evaluation software evaluation libraries frameworks etc questions answered objectively provide valuable information game theory extensions would personally like see mentioned logic seems fundamental probability caveat want work conjunction communities overlap support communities feel firmly needs stack ai still process figuring make permanent also depend support related communities also deal humanities would want explanation constitutes good soft question cases objective answer answers sufficiently supported ideally citations legitimate types questions great opportunity introduce op fundamental concepts
1,"<p>This site is about Artificial Intelligence (AI) which generalizes Machine Learning and Deep Learning:</p>

<p><a href=""https://i.stack.imgur.com/1scCQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1scCQ.png"" alt=""enter image description here""></a></p>

<p>Hence, I think, the site should embrace and be the home questions about any of those. Both practical and theoretical, science and engineering.<br>
In order to do so and bring this great audience we should:</p>

<ol>
<li>Change the name of the community into <strong>Artificial Intelligence and Machine Learning</strong>.</li>
<li>Write explicitly in the site description that it deals with those subjects and welcome questions about them.</li>
</ol>

<p>Doing so, I believe, will fill the void in the SE communities which doesn't dedicate any community to gather people which are experts on those.</p>

<p><strong>Remark</strong><br>
Image taken from the book <a href=""https://rads.stackoverflow.com/amzn/click/1617294438"" rel=""nofollow noreferrer"">Francois Chollet - Deep Learning with Python</a>.</p>
",AImeta,site artificial intelligence ai generalizes machine learning deep learning hence think site embrace home questions practical theoretical science engineering order bring great audience change name community artificial intelligence machine learning write explicitly site description deals subjects welcome questions believe fill void se communities dedicate community gather people experts remark image taken book
1,"<p>Well, I just got downvoted because I tried to make sense of a question that was somewhat unclear. And the person doing it left a comment saying that an answer to a bad question was still a wrong answer. This is exactly the kind of attitude that makes people leave this site.</p>

<p>There are a lot of questions from people who haven't got a clue about AI, and often express themselves not very clearly, as English is obviously not their first language. I am really taken aback by how unfriendly the community on here is, as most of these questions immediately get downvoted.</p>

<p>I don't know what the solution is, as even requiring a comment is not really solving this issue.</p>
",AImeta,well got downvoted tried make sense question somewhat unclear person left comment saying answer bad question still wrong answer exactly kind attitude makes people leave site lot questions people got clue ai often express clearly english obviously first language really taken aback unfriendly community questions immediately get downvoted know solution even requiring comment really solving issue
1,"<p>If a question must be flag as ""off-topic"" due to ""This question belongs on another site in the Stack Exchange network"", the only current possibility is ""belongs on ai.meta.stackexchange.com"". No possibility to redirect to ""stack overflow"", ""computer science"", etc . It is not allowed neither to flag it without say a related site.</p>

<p>I thing a possibility of ""others"" or, at least, add the most usuals stack exchanges sites should be add to the current option.</p>
",AImeta,question must flag topic due question belongs another site stack exchange network current possibility belongs aimetastackexchangecom possibility redirect stack overflow computer science etc allowed neither flag without say related site thing possibility others least add usuals stack exchanges sites add current option
1,"<p>This is a good idea. We'll need to wait, though, until our site graduates &mdash; a site generally <a href=""https://meta.stackexchange.com/a/178463/295684"">doesn't become available</a> as a migration source (except to its own meta) or target until the beta label is removed.</p>

<p>Moderators can migrate questions to any site, but I would guess that most off-topic questions are not suitable for migration because they don't yet meet the standards of the most relevant site. Such questions should instead be closed here with a helpful comment about the other site and a suggestion to review that site's guidance before posting.</p>
",AImeta,good idea need wait though site graduates site generally migration source except meta target beta label removed moderators migrate questions site would guess topic questions suitable migration yet meet standards relevant site questions instead closed helpful comment site suggestion review site guidance posting
1,"<p>Similar questions come back on Meta, but no convergence.</p>

<p>I am a proponent of technical questions since before the exchange creation. The hairy issue is to clearly define the boundary.</p>

<p>Any kind of technical question will lead to an overflow of simple programming questions on how to do something with Tensorflow or Pytorch. Such questions are (in my opinion) better answered on StackOverflow. These frameworks are still complex enough so as many questions are really about syntax and framework-specific understanding (e.g. I concieve it is hard to use TensorFlow if you have never used graphs or data flows).</p>

<p>Technical questions like ""how many layers to do something?"", ""what architecture is best for mushroom recognition?"", or ""why SVM here and ANN there?"" seem fine to me.</p>

<p>All in all, I expect the community manages to still attract questions about consciousness, AGI, ethics, etc. A tsunami of small technical questions is good for traffic, but causes a low signal/noise ratio.</p>
",AImeta,similar questions come back meta convergence proponent technical questions since exchange creation hairy issue clearly define boundary kind technical question lead overflow simple programming questions something tensorflow pytorch questions opinion better answered stackoverflow frameworks still complex enough many questions really syntax framework specific understanding eg concieve hard use tensorflow never used graphs data flows technical questions like many layers something architecture best mushroom recognition svm ann seem fine expect community manages still attract questions consciousness agi ethics etc tsunami small technical questions good traffic causes low signal noise ratio
1,"<p>The Data Science site already covers such topics. It is in my opinion that the Artificial Intelligence site and the Data Science site should be merged where the scope would include</p>

<ul>
<li>The humanities of artificial intelligence (ethics, morality, etc.)</li>
<li>The humanities of data collection and privacy (ethics, morality, etc.)</li>
<li>The discussion of state-of-the art research in the field of artificial intelligence, machine learning and data science.</li>
<li>Questions pertaining to the implementation of techniques and methods that can be used to achieve artificial intelligence (there are very few of these).</li>
<li>Questions pertaining to the implementation of machine learning techniques and methods (Bayesian models, trees, neural networks, deep learning, etc.).</li>
</ul>

<hr>

<p>A site which combines both Artificial Intelligence and Data Science would have many <strong>benefits</strong>:</p>

<ul>
<li><p>A wider audience of potential answerers such that individuals may have a higher probability of find resolutions to their queries. For example a deep learning question asked on either of the sites only, will not reach as many answerers, this hurts the questioner's chances of getting the best possible answer.</p></li>
<li><p>The possibility of people with a strong implementation background whom are more likely to peruse Data Science, to also be involved in discussions regarding the ethics and morality of artificial intelligence. </p></li>
<li><p>The possibility of those more interested in the humanities of artificial intelligence to see the kinds of problems that machine learning algorithms are capable of solving and forging stronger arguments about the ethical use and morality of artificial intelligence.</p></li>
</ul>

<hr>

<p>In my opinion, artificial intelligence does not yet exist, very fancy computational models which are essentially hyper-plane separators are not intelligent. However, due to the misnomer used in the medias for machine learning, artificial intelligence is used to describe these techniques. </p>

<p>As a result, many questions on the Artificial Intelligence site do not match the intended guidelines of the site. Most questions on any particular day do not belong on this site and should be migrated to Data Science. I propose the sites be merged into a single site.</p>

<p>I really do like the questions asked on the Artificial Intelligence site and I would love to partake in them. However reading through Stack Overflow and Data Science usually occupies most of the time I want to spend on my couch. Furthermore, I often see questions in Artificial Intelligence that are almost mirrors of those that have already been answered in great lengths in Data Science. Specifically those relating to neural networks, backpropagtion or gradient descent.</p>

<p>I would ask kindly for the mods of this site to consider that in unity we are all stronger, in division we fall.</p>
",AImeta,data science site already covers topics opinion artificial intelligence site data science site merged scope would include humanities artificial intelligence ethics morality etc humanities data collection privacy ethics morality etc discussion state art research field artificial intelligence machine learning data science questions pertaining implementation techniques methods used achieve artificial intelligence questions pertaining implementation machine learning techniques methods bayesian models trees neural networks deep learning etc site combines artificial intelligence data science would many benefits wider audience potential answerers individuals may higher probability find resolutions queries example deep learning question asked either sites reach many answerers hurts questioner chances getting best possible answer possibility people strong implementation background likely peruse data science also involved discussions regarding ethics morality artificial intelligence possibility interested humanities artificial intelligence see kinds problems machine learning algorithms capable solving forging stronger arguments ethical use morality artificial intelligence opinion artificial intelligence yet exist fancy computational models essentially hyper plane separators intelligent however due misnomer used medias machine learning artificial intelligence used describe techniques result many questions artificial intelligence site match intended guidelines site questions particular day belong site migrated data science propose sites merged single site really like questions asked artificial intelligence site would love partake however reading stack overflow data science usually occupies time want spend couch furthermore often see questions artificial intelligence almost mirrors already answered great lengths data science specifically relating neural networks backpropagtion gradient descent would ask kindly mods site consider unity stronger division fall
1,"<p>I'd personally like to expand the guidelines to formally include:</p>

<ul>
<li>a specific <strong>AI</strong> programming problem, or <br></li>
<li>an <strong>AI</strong> software algorithm, or <br></li>
<li><strong>AI</strong> software tools commonly used by programmers; and is <br></li>
<li>a practical, answerable problem that is unique to <strong>AI</strong> software development <br></li>
</ul>

<p>which is basically Overflow with ""AI"" added to each line.</p>

<p><strong>WHY?</strong></p>

<p>My main competency is in the humanities side of the AI equation, but I don't think it's possible we'd going to be able to sustain the level of activity to graduate from Beta on philosophical and conceptual questions alone.  And, I'm inclined to believe that AI is a field where the humanities and sciences intersect.  </p>

<p>When I first came on as mod, there was a flood of Python question related to AI development.  It seemed clear that these endeavors constitute a relatively new sub-field.  So while I'd point someone with a general Python question to Overflow of Computer Science, if that question relates to AI, I think it belongs here. That's just one example.</p>
",AImeta,would personally like expand guidelines formally include specific ai programming problem ai software algorithm ai software tools commonly used programmers practical answerable problem unique ai software development basically overflow ai added line main competency humanities side ai equation think possible would going able sustain level activity graduate beta philosophical conceptual questions alone inclined believe ai field humanities sciences intersect first came mod flood python question related ai development seemed clear endeavors constitute relatively new sub field would point someone general python question overflow computer science question relates ai think belongs one example
1,"<p>I preemptively modified the guidelines just now to make it clear that <strong>reference requests</strong> are on-topic.  (We have a tag for it, and reference requests have utility and traffic-drawing value.)  The idea is that experienced contributors can suggest reference materials with some vetting and, ideally, context and synopsis.</p>

<p>We also have <strong>software evaluation</strong> and <strong>hardware evaluation</strong> tags, and I'd like to add these officially as well because here there can be a great deal of objectivity.  (i.e. processor performance can be precisely quantified, and functions related to AI development explained.  Likewise, with software utilities, functions and capabilities can be accurately listed and broken down.)</p>

<p><strong>AI Career Advice</strong>
I strongly feel this should be on-topic.  While it's typically the type of thing one undertakes on chat, most chat participation is low, and good luck finding someone who can give you advice in any given span.  But AI has never been more burgeoning as a field, with opportunities for the average programmer in addition to PhD's.  A lot of people want to get into the field, and advice from professionals and scholars would be salient, beneficial, and potentially boost activity/engagement with answerable questions.</p>
",AImeta,preemptively modified guidelines make clear reference requests topic tag reference requests utility traffic drawing value idea experienced contributors suggest reference materials vetting ideally context synopsis also software evaluation hardware evaluation tags would like add officially well great deal objectivity ie processor performance precisely quantified functions related ai development explained likewise software utilities functions capabilities accurately listed broken ai career advice strongly feel topic typically type thing one undertakes chat chat participation low good luck finding someone give advice given span ai never burgeoning field opportunities average programmer addition phd lot people want get field advice professionals scholars would salient beneficial potentially boost activity engagement answerable questions
1,"<p>I love that people are coming here to answer some of them, and I think we should encourage that for basic questions, and try to emphasize the conceptual aspects, and point to Data Science for more advanced followups, but</p>

<blockquote>
  <p>We need to start migrating new DS questions to DS</p>
</blockquote>

<p>None of us AI mods have mod privileges on DS, which is why I, at least, have been reluctant to migrate.  </p>

<ul>
<li><strong>At present, the ""data-science"" tag has only 11 instances on SE:AI</strong></li>
</ul>

<blockquote>
  <p>We need Data Science users with high rep to start tagging the questions to be migrated.  If you're a trusted member of that community, I will migrate the questions for you.</p>
</blockquote>

<p>We currently have only <a href=""https://ai.stackexchange.com/questions/tagged/data-science"">11 data-science tags</a>, with 3 unanswered:</p>

<p><a href=""https://ai.stackexchange.com/questions/6050/performance-evaluation-metrics-used-in-training-validation-and-testing"">Performance Evaluation Metrics used in Training, Validation and Testing</a></p>

<p><sub><em>the above one I actually like for AI because it's asking about the concepts.  I'd want to see the answer, ideally with links to Data Science questions.</em></sub></p>

<p><a href=""https://ai.stackexchange.com/questions/5448/deep-nn-architecture-for-predicting-a-matrix-from-two-matrices"">Deep NN architecture for predicting a matrix from two matrices</a></p>

<p><a href=""https://ai.stackexchange.com/questions/4291/forecasting-and-predict-using-matlab-artificial-neural-network"">Forecasting and predict using matlab Artificial Neural Network</a></p>

<p>Should we try to get these answered, and point to DS?  </p>
",AImeta,love people coming answer think encourage basic questions try emphasize conceptual aspects point data science advanced followups need start migrating new ds questions ds none us ai mods mod privileges ds least reluctant migrate present data science tag 11 instances se ai need data science users high rep start tagging questions migrated trusted member community migrate questions currently 3 unanswered one actually like ai asking concepts would want see answer ideally links data science questions try get answered point ds
1,"<p>If the example questions are not on-topic here, then I do not think any of them are unique, interesting and high enough quality to be worth migrating to Data Science stack exchange as they stand now.</p>

<p>As a long-term contributor to Data Science, my thoughts on the questions are:</p>

<ul>
<li><p><a href=""https://ai.stackexchange.com/questions/6050/performance-evaluation-metrics-used-in-training-validation-and-testing"">Performance Evaluation Metrics used in Training, Validation and Testing</a> is too vague and broad. Comments attempting to clarify with OP have not really resolved it. IMO, this <em>might</em> get answered on Data Science, but equally could be left abandoned as it is here, or closed as ""Too broad"" or ""Unclear"".</p></li>
<li><p><a href=""https://ai.stackexchange.com/questions/4291/forecasting-and-predict-using-matlab-artificial-neural-network"">Forecasting and predict using matlab Artificial Neural Network</a> looks like OP is trying to apply a regression model to a classification problem. However, there is nowhere near enough detail in the question to answer it well. Unless the OP was willing to get involved in clarifying how they are using the data set, this would likely get closed with ""Unclear"" on Data Science.</p></li>
<li><p><a href=""https://ai.stackexchange.com/questions/5448/deep-nn-architecture-for-predicting-a-matrix-from-two-matrices"">Deep NN architecture for predicting a matrix from two matrices</a> could potentially be answered (I suggest a possible work around for OP in comments), and might be OK on Data Science if clarifying comments by OP were included. Data Science does get a lot of ""I have a data set with this special trait, and I'm stuck about what to try"" questions. Some are good, many are not clear, most just need the OP to go ahead and try stuff*. IMO, the question here is borderline - not quite enough information to make a good answer, but it can probably be answered. As such though, I'm not sure of the value of migrating it so long after it was asked. I think migrating a similar question in future would be well received.</p></li>
</ul>

<hr>

<p>* This is an ongoing issue on Data Science and I <a href=""https://datascience.meta.stackexchange.com/questions/2267/what-to-do-about-are-my-model-ideas-for-this-problem-good-or-what-is-best-mo"">suggested we need to do something about it</a> on Data Science meta a while ago. Maybe Data Science needs a help advice similar to Stack Overflow's excellent <a href=""https://stackoverflow.com/help/mcve"">https://stackoverflow.com/help/mcve</a></p>
",AImeta,example questions topic think unique interesting high enough quality worth migrating data science stack exchange stand long term contributor data science thoughts questions vague broad comments attempting clarify op really resolved imo might get answered data science equally could left abandoned closed broad unclear looks like op trying apply regression model classification problem however nowhere near enough detail question answer well unless op willing get involved clarifying using data set would likely get closed unclear data science could potentially answered suggest possible work around op comments might ok data science clarifying comments op included data science get lot data set special trait stuck try questions good many clear need op go ahead try stuff imo question borderline quite enough information make good answer probably answered though sure value migrating long asked think migrating similar question future would well received ongoing issue data science data science meta ago maybe data science needs help advice similar stack overflow excellent
1,"<p>I'd like to be notified when new questions arise. Would it be feasible? Receive notifications from a specific feed (in my case the Artificial Intelligence community)?</p>

<p>When I say ""Notifications"" I mean Push Notification (browser / mobile)</p>
",AImeta,would like notified new questions arise would feasible receive notifications specific feed case artificial intelligence community say notifications mean push notification browser mobile
1,"<p>The closest thing that currently exists is the main Stack Exchange site's <a href=""https://stackexchange.com/filters/"">filter/subscription feature</a>. It doesn't do top bar push notifications as far as I know, but it can send new questions on a site to your e-mail as fast as every 15 minutes. You can also include multiple sites and filter by tags, if you like.</p>
",AImeta,closest thing currently exists main stack exchange site top bar push notifications far know send new questions site e mail fast every 15 minutes also include multiple sites filter tags like
1,"<p><strong>Starting a new list of math questions to expand on <a href=""https://ai.meta.stackexchange.com/a/1319/1671"">nbro's list</a>:</strong></p>
<ul>
<li><p><s>https://ai.stackexchange.com/questions/6633/back-propagation-in-nn-with-sigmoid-activation-function-division-by-0</s> (post deleted)</p>
</li>
<li><p><s>https://ai.stackexchange.com/questions/5057/k-armed-bandit-and-reinforcement-learning</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/q/7032/1671</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/questions/7147/gradient-of-boltzmann-policy-over-reward-function</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/questions/7182/small-multinomial-naive-bayes-text-classification-probabilities</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/questions/7207/mathematical-modelling-of-a-i-algorithms</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/questions/6308/linucb-with-hybrid-linear-models</s></p>
</li>
<li><p><s>https://ai.stackexchange.com/questions/1925/are-ffnn-mlp-lipschitz-functions</s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/6914/how-does-this-sigma-workharris-algorithm"">How does this sigma work?(Harris algorithm)</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/6640/defining-formula-for-fuzzy-equation"">Defining formula for fuzzy equation</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/6030/how-to-calculate-gradient-of-filter-in-convolution-network"">How to calculate gradient of filter in convolution network</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/a/5380/2444"">https://ai.stackexchange.com/a/5380/2444</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/a/5179/2444"">https://ai.stackexchange.com/a/5179/2444</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/6995/simple-question-about-hs-algorithms-formuloptical-flow"">Simple question about HS algorithm&#39;s formul(Optical flow)</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/a/7034/1671"">https://ai.stackexchange.com/a/7034/1671</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/q/7003/1671"">Why do we have to solve MDP in each iteration of Maximum Entropy Inverse Reinforcement Learning?</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/6990/matrix-dimension-for-linear-regression-coefficients"">Matrix Dimension for Linear regression coefficients</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/a/7103/2444"">https://ai.stackexchange.com/a/7103/2444</a></p>
</li>
</ul>
",AImeta,starting new list math questions expand httpsaistackexchangecomquestions6633backpropagationinnnwithsigmoidactivationfunctiondivisionby0 post deleted httpsaistackexchangecomquestions5057karmedbanditandreinforcementlearning httpsaistackexchangecomq70321671 httpsaistackexchangecomquestions7147gradientofboltzmannpolicyoverrewardfunction httpsaistackexchangecomquestions7182smallmultinomialnaivebayestextclassificationprobabilities httpsaistackexchangecomquestions7207mathematicalmodellingofaialgorithms httpsaistackexchangecomquestions6308linucbwithhybridlinearmodels httpsaistackexchangecomquestions1925areffnnmlplipschitzfunctions
1,"<p>I've been active on SE from some time and only recently entered in ai.SE community. In very large communities like SO questions about resources are not welcomed and usually are closed after a short while. In smallest or not very large communities are usually welcomed since they could be helpful to beginners.</p>

<p>So, are this type of questions welcomed here?</p>

<p>For the sake of the question, I've already posted a <a href=""https://ai.stackexchange.com/questions/7146/comprehensive-list-of-moocs-and-books-on-reinforcement-learning"">question</a> but then the doubt comes up and I thought that it was better to ask instead of closing in advance my question. The post itself isn't opinion based or too broad but, as I said, not all communities welcome list type question.</p>

<hr>

<p>Just to be clear, what I means for resources isn't links to external sites that could easily expire. I mean books, articles and so on. Of course links to external resources like tensorflow/keras/caffe/etc. manuals, tutorials or documentation are welcomed.</p>
",AImeta,active se time recently entered aise community large communities like questions resources welcomed usually closed short smallest large communities usually welcomed since could helpful beginners type questions welcomed sake question already posted doubt comes thought better ask instead closing advance question post opinion based broad said communities welcome list type question clear means resources links external sites could easily expire mean books articles course links external resources like tensorflow keras caffe etc manuals tutorials documentation welcomed
1,"<p>The problems with generic external resource requests don't really change due to the size of the site.</p>

<ul>
<li><p>Links can fail, or go out of date. An answer that is mostly links could degrade so that it is not usable, unless it was actively maintained. This is also why link-only answers are discouraged. </p></li>
<li><p>A ""correct"" answer is hard to assess.</p></li>
<li><p>There is a strong element of opinion on what to include or exclude when compiling ""comprehensive"" lists. There is an implied ""and the list should be reviewed for relevance and curated"" which is hard to objectify, but if it wasn't present then clearly just Googling e.g. ""Reinforcement Learning tutorials and MOOCs"" would be enough for the OP.</p></li>
<li><p>No-one will actually read or use a comprehensive list of introductory material. It becomes like a restaurant menu where a reader has to attempt to pick out the 2 or 3 items from the answer that would be most useful to them.</p></li>
<li><p>I don't think that technical avoidance of actual hyperlinks, and use of ISBNs, course codes etc changes the nature of this at all. <em>Some</em> external references have a long shelf life. E.g. ""Origin of Species"" is still relevant today. But this does not apply to all books, just because they are books.</p></li>
</ul>

<blockquote>
  <p>Just to be clear, what I means for resources isn't links to external sites that could easily expire.</p>
</blockquote>

<p>Perhaps if you made it clear what the nature of these non-link resources would look like in an answer, it could help move it out of being a request for generic resources, and become a more focused question. E.g. ""What are the must have introductory books in <em>subject area</em>, and what prior knowledge do they assume?"" is a lot more focused than ""I'm looking for a comprehensive list of MOOCs, books, tutorial and good resources"" which is essentially asking for anything and everything that <em>might</em> be useful, without bounds.</p>
",AImeta,problems generic external resource requests really change due size site links fail go date answer mostly links could degrade usable unless actively maintained also link answers discouraged correct answer hard assess strong element opinion include exclude compiling comprehensive lists implied list reviewed relevance curated hard objectify present clearly googling eg reinforcement learning tutorials moocs would enough op one actually read use comprehensive list introductory material becomes like restaurant menu reader attempt pick 2 3 items answer would useful think technical avoidance actual hyperlinks use isbns course codes etc changes nature external references long shelf life eg origin species still relevant today apply books books clear means resources links external sites could easily expire perhaps made clear nature non link resources would look like answer could help move request generic resources become focused question eg must introductory books subject area prior knowledge assume lot focused looking comprehensive list moocs books tutorial good resources essentially asking anything everything might useful without bounds
1,"<p>After a week and after reading your comments and answers I still think that ai.SE could benefit from resource request questions. However, I think that my original question on main ai.SE is badly posed.</p>

<p>Some reasons why ai.SE could benefit from resource request questions are:</p>

<ul>
<li>They attract visitors. This type of questions have usually a lot of views and could attract new visitors from web search engines.</li>
<li>They could prevent some users to post dumb questions. This could be only a personal thought but one of the main reasons why I choose to join this community is that, as a self-thought beginner, I don't know which sources I should consider trustworthy.</li>
<li>They could be helpful even for non-beginners. Even at the semi-professional level, one could find new resources interesting.</li>
<li>They could condense a lot of similar questions that ask for resources about some topic.</li>
</ul>

<p>Of course, there are some disadvantages to this type of question. One of them is how to choose which answer should be accepted. I think that we could have one answer for each resource suggested and one accepted community answer that keeps track of the top resources linked. The community answer could be edit by anyone that has a certain reputation. </p>
",AImeta,week reading comments answers still think aise could benefit resource request questions however think original question main aise badly posed reasons aise could benefit resource request questions attract visitors type questions usually lot views could attract new visitors web search engines could prevent users post dumb questions could personal thought one main reasons choose join community self thought beginner know sources consider trustworthy could helpful even non beginners even semi professional level one could find new resources interesting could condense lot similar questions ask resources topic course disadvantages type question one choose answer accepted think could one answer resource suggested one accepted community answer keeps track top resources linked community answer could edit anyone certain reputation
1,"<p>When I think about this question in the context of research papers, for instance, I can't see a real issue.  </p>

<p>Ideally, when posting research papers links, the title of the paper will be used in addition to the link, so if the link goes bad, people can still search for the paper. </p>

<p>Russel &amp; Norvig's <em><a href=""https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach"" rel=""nofollow noreferrer"">Artificial Intelligence: A Modern Approach</a></em> is heavily cited on SE:AI, and the text was originally published in 1995.  The book is in its 3rd edition now, (which is not always noted when cited,) but even the 3rd edition dates from 2009, earlier than the recent Machine Learning milestones (~2016) yet the textbook is still relevant and heavily utilized.</p>

<p>List questions do have some issues (see <a href=""https://ai.meta.stackexchange.com/a/1371/1671"">Neil Slater's answer</a>) and seem to be off-topic in general across Stack exchange. </p>

<p>However, I'd still think lists of research papers on a given topic, ideally peer-reviewed, would provide utility and carry archival value.  In the same way, lists of well-regarded textbooks could be useful. </p>

<hr>

<p>Second Consideration: Contemporary Hacker Culture and Youtube</p>

<p>In some sense we're the ""General AI"" site, covering the full scope of the field, as opposed to focusing on any given specific aspect (distinct from stacks like Data Science.)  </p>

<p>We seem to be the stack where beginners typically come to first.  I created a <a href=""https://ai.stackexchange.com/questions/tagged/getting-started"">getting-started</a> tag because there are so many of these questions. </p>

<p>Many people today are learning the basics today via youtube videos. Where the videos are solid, they seem to provide benefit, but they tend to be more ephemeral, especially when they come from non-academic sources.  (Erik Demaine's lectures on <a href=""https://www.youtube.com/watch?v=moPtwq_cVH8"" rel=""nofollow noreferrer"">Time Complexity</a> will likely be available for a very long time indeed, where a random youtuber using click-baitey titles subject matter to generate ad-revenues may not be.)</p>

<p>My feeling is, re: videos, is that anything commercial should be avoided, but anything coming from accredited academic institutions is reliable and suitable.</p>
",AImeta,think question context research papers instance see real issue ideally posting research papers links title paper used addition link link goes bad people still search paper russel norvig heavily cited se ai text originally published 1995 book 3rd edition always noted cited even 3rd edition dates 2009 earlier recent machine learning milestones 2016 yet textbook still relevant heavily utilized list questions issues see seem topic general across stack exchange however would still think lists research papers given topic ideally peer reviewed would provide utility carry archival value way lists well regarded textbooks could useful second consideration contemporary hacker culture youtube sense general ai site covering full scope field opposed focusing given specific aspect distinct stacks like data science seem stack beginners typically come first created tag many questions many people today learning basics today via youtube videos videos solid seem provide benefit tend ephemeral especially come non academic sources erik demaine lectures likely available long time indeed random youtuber using click baitey titles subject matter generate ad revenues may feeling videos anything commercial avoided anything coming accredited academic institutions reliable suitable
1,"<p>AI StackExchange is still a beta site, still has growing to do, and appears to still be relatively small/niche. I have gotten the impression that it is more vulnerable than huge sites (like Stackoverflow) to people trying to game the system (for example by running multiple accounts themselves). This increased vulnerability appears to be due to:</p>

<ol>
<li><p>More difficult to detect. Due to the small nature of the site, it's quite natural that you see the same accounts interacting in multiple questions if they just happen to be very active users. On a huge site like Stackoverflow, it would be a much larger coincidence if the same two accounts kept repeatedly interacting with each other.</p></li>
<li><p>More negative impact. If two accounts (operated by the same person or by close friends for example) are consistently upvoting each other and double-downvoting ""competing"" answers, that has a huge impact on a small site like AI StackExchange where there generally are only a handful of votes to begin with. On a larger site like StackOverflow, such votes would more easily get drowned out by ""real"" votes.</p></li>
</ol>

<hr>

<p><strong>My question</strong>: do others agree that AI StackExchange may indeed be extra vulnerable, and if so, should additional actions be taken? </p>

<hr>

<p>There is indeed a concrete case of two rather active accounts on the AI StackExchange from which I've seen so much suspicious stuff happening that I can't believe it's a coincidence anymore as described in my first point above (and googling for their names actually lead to additional off-site evidence that they're both the same person as well). Because there is really only a rather small number of new questions on the site every day, this has lead to a tangible negative impact on the site in my opinion.</p>

<p>I have already reported this case to StackExchange using the Contact Us link, <a href=""https://meta.stackexchange.com/a/206997/376651"">as should be done in general on StackExchange</a>. Therefore, I'm not reproducing the evidence here / calling the accounts out by name, but I can of course still do that in an edit if that would be deemed useful. <strong>Nevertheless, I have no idea how long it's going to take for action to be taken in response to my report, and am curious if anything else should be done to speed things up on a small site like AI StackExchange since this behaviour appears to have a disproportionally large negative impact on the site in my experience</strong>?</p>
",AImeta,ai stackexchange still beta site still growing appears still relatively small niche gotten impression vulnerable huge sites like stackoverflow people trying game system example running multiple accounts increased vulnerability appears due difficult detect due small nature site quite natural see accounts interacting multiple questions happen active users huge site like stackoverflow would much larger coincidence two accounts kept repeatedly interacting negative impact two accounts operated person close friends example consistently upvoting double downvoting competing answers huge impact small site like ai stackexchange generally handful votes begin larger site like stackoverflow votes would easily get drowned real votes question others agree ai stackexchange may indeed extra vulnerable additional actions taken indeed concrete case two rather active accounts ai stackexchange seen much suspicious stuff happening believe coincidence anymore described first point googling names actually lead additional site evidence person well really rather small number new questions site every day lead tangible negative impact site opinion already reported case stackexchange using contact us link therefore reproducing evidence calling accounts name course still edit would deemed useful nevertheless idea long going take action taken response report curious anything else done speed things small site like ai stackexchange since behaviour appears disproportionally large negative impact site experience
1,"<p>I do agree that the impact of shenanigans on a small site is greater because of the smaller size of our rep economy and the lower beta privilege thresholds.  This is partially balanced out by there being fewer users to keep track of, but as you said, that can also make it difficult to tell organic interaction apart from problematic behavior.</p>

<p>The ""contact us"" link goes to Stack Exchange the company; moderators never see those requests. I imagine the Stack Exchange community management team is pretty busy (they oversee all 174 SE sites), so it might take a while for them to get to your request. In many cases, though, site moderators can do the job. In a sense, this site can respond with more agility than larger ones because the mod workload is far lighter. </p>

<p>To reach a moderator about suspicious patterns, <strong>cast a custom flag on any post</strong>. If you need more space than the flag box affords, I can create a private chatroom for you to share your findings with the mods. Thank you for your vigilance.</p>
",AImeta,agree impact shenanigans small site greater smaller size rep economy lower beta privilege thresholds partially balanced fewer users keep track said also make difficult tell organic interaction apart problematic behavior contact us link goes stack exchange company moderators never see requests imagine stack exchange community management team pretty busy oversee 174 se sites might take get request many cases though site moderators job sense site respond agility larger ones mod workload far lighter reach moderator suspicious patterns cast custom flag post need space flag box affords create private chatroom share findings mods thank vigilance
1,"<p>I think the <code>monte-carlo-search</code> tag is currently ambiguous. The <a href=""https://ai.stackexchange.com/tags/monte-carlo-search/info"">tag info page</a> currently says:</p>

<blockquote>
  <blockquote>
    <p>For questions about clarifications/applications/implementation of the Monte Carlo Search algorithm used especially in Artificial Intelligence/Combinatorial games. </p>
  </blockquote>
  
  <p>In computer science, Monte Carlo tree search (MCTS) is a heuristic search algorithm for some kinds of decision processes, most notably those employed in game play.</p>
  
  <p><a href=""https://en.wikipedia.org/wiki/Monte_Carlo_tree_search"" rel=""nofollow noreferrer"">Monte Carlo Search - Wikipedia</a></p>
</blockquote>

<p>which implies that the tag is just about MCTS. However, the tag name itself (excluding the word ""tree"") implies that it is either:</p>

<ol>
<li>solely about plain ""Monte Carlo Search"" (which is, among game AI researchers, generally understood as a straightforward algorithm that evaluates children of the root by generating (semi-)random rollouts from the root node without any additional element of tree-building like in MCTS), or</li>
<li>more generally about search techniques that somehow involve Monte-Carlo methods in whatever way you can think of.</li>
</ol>

<p>The <a href=""https://ai.stackexchange.com/questions/tagged/monte-carlo-search"">current usage</a> of the tag appears to be (almost) exclusively about MCTS.</p>

<hr>

<p><strong>I propose</strong> one of the following two should happen:</p>

<ol>
<li><p>Rename the tag to <code>monte-carlo-tree-search</code>. This would remove ambiguity, and does not appear to conflict much (if at all) with usage of the tag so far.</p></li>
<li><p>Edit the tag info to be more generally about Monte-Carlo methods. Optionally, considering the popularity of the specific MCTS algorithm, I suppose a dedicated <code>monte-carlo-tree-search</code> tag could still be created as well.</p></li>
</ol>
",AImeta,think tag currently ambiguous currently says questions clarifications applications implementation monte carlo search algorithm used especially artificial intelligence combinatorial games computer science monte carlo tree search mcts heuristic search algorithm kinds decision processes notably employed game play implies tag mcts however tag name excluding word tree implies either solely plain monte carlo search among game ai researchers generally understood straightforward algorithm evaluates children root generating semirandom rollouts root node without additional element tree building like mcts generally search techniques somehow involve monte carlo methods whatever way think tag appears almost exclusively mcts propose one following two happen rename tag would remove ambiguity appear conflict much usage tag far edit tag info generally monte carlo methods optionally considering popularity specific mcts algorithm suppose dedicated tag could still created well
1,"<p>The question has been addressed (see comments to the question). We now have a <a href=""https://ai.stackexchange.com/questions/tagged/monte-carlo-tree-search"">monte-carlo-tree-search tag</a>.</p>
",AImeta,question addressed see comments question
1,"<p><strong>Vulnerability</strong></p>

<p>The primary vulnerability of a publication systems with a large global readership runs in another direction than the one mentioned.</p>

<p>Members can post information in a way that appears to be well grounded in theoretical proofs or empirical study when the information may in fact be invented to sound good.  The information may be authentically reproduced from the results of a web search and that information may too sound good but lack rigor or peer review.</p>

<p>The classic example of this later case is Wikipedia.  The oversight of that site is well aware of the fact that many Wikipedia pages and sections lack peer review or reflect popular trends that have not been properly tested or very deeply considered.  Most universities have departmental policies to not allow sources that are essentially blogs in theses.</p>

<p>Another example that I've seen in this AI beta and the SE sub-sites is the referencing of a sentence from the abstract or conclusion of a paper accompanied by an interpretation that conflicts with the facts in the body of the paper.  I'm aware that people want to support their views and do searches, and I've done that on occasion too.  However, we all must be aware that the quality of the site is highest when we all work to investigate the reliability of what we are quoting or referencing.</p>

<p>People are vulnerable to misinformation, even if accidental, and this is an information disseminating community.  That's the concern of greatest importance, but that vulnerability is not a vulnerability of the SE system.  It is a vulnerability of the readership.</p>

<p><strong>Example of Negative Global Impact</strong></p>

<p>The SO site and associated SE sub-sites are powerful.  For instance, some semantic impressions have formed in SO that design questions are too broad.  That may have been done for reasons that seemed wise, but the result is that SO has a corresponding impact on the global development community: Dismissal of design.  Again, a vulnerability of the readership.</p>

<p><strong>Size and the Influence of an Individual or Small Group</strong></p>

<p>Regarding the correlation between size and the impact of activity of an individual or those who work together in a team in a workplace or lab, yes that is true.  The larger the group, the lesser the relative impact of one or a few people.  For that very reason, some prefer smaller groups because they feel more relevant, which is why the sub-sites are growing.</p>

<p>However, the correlation flips when considering detection.</p>

<p>It is actually more difficult to detect especially large impact from one or a small group in the larger group.  A few people who just happen to have similar backgrounds or have read a similar set of material for work related reasons will stand out more in smaller communities than in larger ones.</p>

<p>The question has that aspect backward.</p>

<p><strong>Defining Positive Impact</strong></p>

<p>Whether that impact is positive or negative is reflected (and should be reflected) in the up votes or down votes, not the opinions of those that may notice what appears to them like excessive corroboration.  When scrutinizing game-play, the developers of the system will naturally examine questions about trends.  Regarding individual accounts or groups that work or live together, the question should be ...</p>

<ul>
<li>Are there any votes that appeared that are without merit?</li>
<li>Were there any published member rules broken?</li>
<li>Are members collaborating to trounce on others?</li>
<li>Are members trolling to crush other individual members or ganging up on them to remove what they imagine to be a threat?</li>
</ul>

<p>Those are the questions I have too.</p>

<p><strong>Game Play</strong></p>

<p>The question mentions gaming, where in fact all SO and SE sub-site members are in game play.  The system is deliberately set up as a game.  It is a zero sum game in that the point scores are relative as in some sports, therefore the increased success of one member may threaten the success of another.  The game system is not the design of the member.</p>

<p>What is the choice of the member is intent.  Some are here to compete; others to contribute.</p>

<p>That privileges must be earned is the more fixed point, and less relative, so there is some communal value to those who have decades of experience and tend to apply mathematical rigor and interest in social responsibility to questions to game out sufficient point score to positively impact the larger parameters of game-play.  That too is how the system is set up.</p>

<p>The best leaders in this community (as with the larger community of humanity) are the ones that are willing to engage in the silliness of game play without particular interest in winning but to game well enough to get more factual and productive information out to people so they can make wiser decisions.</p>

<p><strong>Actions to be Taken</strong></p>

<p>The actions to be taken are the rules of the game.  Of course, as in tennis, appealing to the umpire is permitted, but not always productive, especially if the umpire tips the scales against a contributor as a result of the appeal in such a way as to suppress or censor useful perspectives that contain needed qualities.</p>

<p><strong>Censorship</strong></p>

<p>Mathematical rigor is not always appreciated by those who don't value it, yet it is objectively useful, especially in science and technology.  Those with decades of experience are not always appreciated by those that cannot speak from experience as easily.  Because this is natural, those with more experience should respect the need of novices to gain experience gradually as they once did.  So the experienced and the novice should yield to one another.</p>

<p>Minority views are by their very nature unappreciated.  When they are repeatedly expressed with vigor and they have a disruptive quality or challenge the status quo, the reaction can be a mob scene.  The mob is usually made up those that have used the status quo or trendy ideas to gain reputation.</p>

<p>Of course, SE AI members are above that.</p>

<p><strong>Multiple Accounts in One Household, Workplace, or Laboratory</strong></p>

<p>Although it is true that in communities, local ones, FaceBook groups, and SO ones, there are people who know each other and work together so that they have similar patterns of speech when talking on the topics in which they collaborate for family life, activism, or work.  It does not mean they are cheating in some way.  To those in the group working together, what they do is collaborate, which is no threat to an SO or SE site because they have thrived with couples, work teams, and many other collaborating groups interacting.</p>

<p>Truth be told, those who appear in public to always be in agreement may not always be in agreement privately.  Families, laboratory teams, and those who work closely in the industry have just learned to withhold argumentation with their close friends, family, and work and laboratory associates.</p>

<p><strong>Summary</strong></p>

<p>In summary, others may have legitimacy or malice in their intent, but score based systems are technically games, and we all play together.  The power and importance of AI is substantial and some will enter game-play reluctantly solely for higher purposes than points.</p>

<ul>
<li>Infusing mathematical rigor where lacking</li>
<li>Encouraging backing facts with proper academic references and attribution</li>
<li>Encouraging proper analysis of papers and articles</li>
<li>Exposing the misuse of terminology</li>
<li>Scrutinizing practice that, while common, may be detrimental</li>
<li>Questioning blind futurism when it may realistically lead to mayhem</li>
<li>Asking any of the larger questions that should be asked</li>
</ul>
",AImeta,vulnerability primary vulnerability publication systems large global readership runs another direction one mentioned members post information way appears well grounded theoretical proofs empirical study information may fact invented sound good information may authentically reproduced results web search information may sound good lack rigor peer review classic example later case wikipedia oversight site well aware fact many wikipedia pages sections lack peer review reflect popular trends properly tested deeply considered universities departmental policies allow sources essentially blogs another example seen ai beta se sub sites referencing sentence abstract conclusion paper accompanied interpretation conflicts facts body paper aware people want support views searches done occasion however must aware quality site highest work investigate reliability quoting referencing people vulnerable misinformation even accidental information disseminating community concern greatest importance vulnerability vulnerability se system vulnerability readership example negative global impact site associated se sub sites powerful instance semantic impressions formed design questions broad may done reasons seemed wise result corresponding impact global development community dismissal design vulnerability readership size influence individual small group regarding correlation size impact activity individual work together team workplace lab yes true larger group lesser relative impact one people reason prefer smaller groups feel relevant sub sites growing however correlation flips considering detection actually difficult detect especially large impact one small group larger group people happen similar backgrounds read similar set material work related reasons stand smaller communities larger ones question aspect backward defining positive impact whether impact positive negative reflected reflected votes votes opinions may notice appears like excessive corroboration scrutinizing game play developers system naturally examine questions trends regarding individual accounts groups work live together question votes appeared without merit published member rules broken members collaborating trounce others members trolling crush individual members ganging remove imagine threat questions game play question mentions gaming fact se sub site members game play system deliberately set game zero sum game point scores relative sports therefore increased success one member may threaten success another game system design member choice member intent compete others contribute privileges must earned fixed point less relative communal value decades experience tend apply mathematical rigor interest social responsibility questions game sufficient point score positively impact larger parameters game play system set best leaders community larger community humanity ones willing engage silliness game play without particular interest winning game well enough get factual productive information people make wiser decisions actions taken actions taken rules game course tennis appealing umpire permitted always productive especially umpire tips scales contributor result appeal way suppress censor useful perspectives contain needed qualities censorship mathematical rigor always appreciated value yet objectively useful especially science technology decades experience always appreciated speak experience easily natural experience respect need novices gain experience gradually experienced novice yield one another minority views nature unappreciated repeatedly expressed vigor disruptive quality challenge status quo reaction mob scene mob usually made used status quo trendy ideas gain reputation course se ai members multiple accounts one household workplace laboratory although true communities local ones facebook groups ones people know work together similar patterns speech talking topics collaborate family life activism work mean cheating way group working together collaborate threat se site thrived couples work teams many collaborating groups interacting truth told appear public always agreement may always agreement privately families laboratory teams work closely industry learned withhold argumentation close friends family work laboratory associates summary summary others may legitimacy malice intent score based systems technically games play together power importance ai substantial enter game play reluctantly solely higher purposes points infusing mathematical rigor lacking encouraging backing facts proper academic references attribution encouraging proper analysis papers articles exposing misuse terminology scrutinizing practice common may detrimental questioning blind futurism may realistically lead mayhem asking larger questions asked
1,"<p>Because of a comment added to someone else's question about it being off topic, I looked up the definition of what is on topic for the AI beta.<sup>1</sup></p>

<p>I was startled to find that the current Artificial Intelligence SE site description is this.</p>

<blockquote>
  <p>Q&amp;A for people interested in conceptual questions about life and challenges in a world where ""cognitive"" functions can be mimicked in purely digital environment</p>
</blockquote>

<p>What I would have guessed it to be based on actual Q&amp;A content is this.</p>

<blockquote>
  <p>Q&amp;A for people interested in conceptual, mathematical, design, and approach questions related to the creation, use, and cultural impact of artificial intelligence and cybernetics</p>
</blockquote>

<p>Below are reasons why that second phrase is more descriptive of what is actually discussed and accepted as Q&amp;A.  The evidence for the below reasons is clearly evident not only in the titles and bodies of the most popular questions and answers but also in tag usage, the top ten being these.</p>

<ul>
<li>Neural networks</li>
<li>Machine learning</li>
<li>Deep learning</li>
<li>CNNs</li>
<li>Reinforcement</li>
<li>AI design</li>
<li>Image recognition</li>
<li>Algorithm</li>
<li>Classification</li>
<li>Training</li>
</ul>

<p>Less than 1% of the content is about life and challenges in world where cognitive automation is emerging.  It is likely that many of our members couldn't distinguish a cognitive function from either first order predicate logic or learned routine.  The later two can be simulated in many respects with current digital systems, but it is unclear whether, in this century, cognition will be simulated.  I know that's not the popular conception, but those with the greater experience that have been watching AI and working in the field for decades know it to be the truth.</p>

<p>Here are my reasons why I think the current AI meta site definition is not consistent with either expectation, actual content, or the real interests of the membership.</p>

<ul>
<li>A large proportion of the most active and interesting questions are about what can and has been done in the area of machine learning.</li>
<li>Robotics appears and should appear in the content for the AI beta.  To begin with, the field of AI was as much born out of the need for control systems faster than humans to defend against attacking aircraft and intercontinental ballistic missiles than as a way to do proofs using formal logic.  More importantly, the long awaited for emergence of autonomous vehicles, automated vacuum cleaners, and a host of other non-military intelligent control systems is no longer held back by the prices of control system components (CPU, motor drivers, memory, operating system) and the applicable machine learning strategies are now on GitHub and packaged in Python and Java libraries.</li>
<li>Many of the current AI beta Q&amp;A are lacking in scientific rigor even though the AI beta is in the <strong>Science</strong> SE category.  The use of mathematics is a quality factor in a science site as much as inclusion of academic references or narrowness of the problems set forth in the questions.  I think it is correct to assemble AI under <strong>Science</strong> and not <strong>Technology</strong> because the technology side is covered under SE sites such as Arduino and Data Science, which are properly placed in the <strong>Technology</strong> category.</li>
<li>I don't see a membership-wide interest in, ""Questions about life and challenges in a world where ""cognitive"" functions can be mimicked in purely digital environment.""  People are aware that some job functions get replaced in the human job market by machines, and we've been, as a culture, adapting to it since the late 19th century.  Industrialization saw the emergence automated cotton picking, textile manufacture, type setting, and electronics assembly.  Most people, myself included, will actually be happy when office worker and programming is automated.  It's boring and no more psychologically healthy than coal mining was healthy for breathing.  Our members are not here not to ask questions about how to live or face the changes but to engage in right-now-present-day adaptation to what is so obviously the nearing of another big job market swing.</li>
<li>For reasons given above, ""Cognition,"" is not the best choice of words to describe the relevant AI research and development under way today.  Notice that the word cognition or questions surrounding it are rare in tagging, titling, and discussion.  What is currently being synthesized is the lower mammalian functions that do not take place in the cerebral cortex and have no relationship with comprehension, discernment, or insight.  AI beta Q&amp;A does not fit into the cognitive science definition of cognition or the dictionary definition of it.  For instance, character recognition, visual collision detection, identity recognition, and such are not cognitive functions.  Artificial analysis of large data sets, not for training but for feature extraction, is not cognitive either.</li>
</ul>

<p>There's much more pointing to the inadequacy of the current description but I'll stop there.  Back to the central question.</p>

<p><strong>Is the current out-facing description of the AI meta descriptive of what it is?</strong></p>

<p>The co-question is this.</p>

<p><strong>Is discussion about life in a changing world really what is relevant to most people who would search for <em>Artificial Intelligence</em> in the search field of SE?  And if not, shouldn't we adapt to the real interests of our membership?</strong></p>

<p>There was an <a href=""http://area51.stackexchange.com/proposals/57719/artificial-intelligence"">older AI beta</a> that had a great description for what the current AI beta does, which failed as an SE beta probably only because it was before its time.</p>

<blockquote>
  <p>Q&amp;A site for theorists, system architects and analysts of intelligent machines and software</p>
</blockquote>

<hr>

<p><strong>Footnotes</strong></p>

<p>[1] I had to log off to find the AI beta description, which is a bug report I might make, but not directly related to this question.  It can be seen when one acts as a non-member and looks up ""Artificial"" in the SE site list using the search field.</p>
",AImeta,comment added someone else question topic looked definition topic ai beta 1 startled find current artificial intelligence se site description q people interested conceptual questions life challenges world cognitive functions mimicked purely digital environment would guessed based actual q content q people interested conceptual mathematical design approach questions related creation use cultural impact artificial intelligence cybernetics reasons second phrase descriptive actually discussed accepted q evidence reasons clearly evident titles bodies popular questions answers also tag usage top ten neural networks machine learning deep learning cnns reinforcement ai design image recognition algorithm classification training less 1 content life challenges world cognitive automation emerging likely many members could distinguish cognitive function either first order predicate logic learned routine later two simulated many respects current digital systems unclear whether century cognition simulated know popular conception greater experience watching ai working field decades know truth reasons think current ai meta site definition consistent either expectation actual content real interests membership large proportion active interesting questions done area machine learning robotics appears appear content ai beta begin field ai much born need control systems faster humans defend attacking aircraft intercontinental ballistic missiles way proofs using formal logic importantly long awaited emergence autonomous vehicles automated vacuum cleaners host non military intelligent control systems longer held back prices control system components cpu motor drivers memory operating system applicable machine learning strategies github packaged python java libraries many current ai beta q lacking scientific rigor even though ai beta science se category use mathematics quality factor science site much inclusion academic references narrowness problems set forth questions think correct assemble ai science technology technology side covered se sites arduino data science properly placed technology category see membership wide interest questions life challenges world cognitive functions mimicked purely digital environment people aware job functions get replaced human job market machines culture adapting since late 19th century industrialization saw emergence automated cotton picking textile manufacture type setting electronics assembly people included actually happy office worker programming automated boring psychologically healthy coal mining healthy breathing members ask questions live face changes engage right present day adaptation obviously nearing another big job market swing reasons given cognition best choice words describe relevant ai research development way today notice word cognition questions surrounding rare tagging titling discussion currently synthesized lower mammalian functions take place cerebral cortex relationship comprehension discernment insight ai beta q fit cognitive science definition cognition dictionary definition instance character recognition visual collision detection identity recognition cognitive functions artificial analysis large data sets training feature extraction cognitive either much pointing inadequacy current description stop back central question current facing description ai meta descriptive co question discussion life changing world really relevant people would search artificial intelligence search field se adapt real interests membership great description current ai beta failed se beta probably time q site theorists system architects analysts intelligent machines software footnotes 1 log find ai beta description bug report might make directly related question seen one acts non member looks artificial se site list using search field
1,"<blockquote>
  <p><strong>Is the current out-facing description of the AI meta descriptive of what it is?</strong></p>
</blockquote>

<p>I think the answer to this is a fairly obvious ""no"" at this point in time.</p>

<blockquote>
  <p>The co-question is this.</p>
  
  <p><strong>Is discussion about life in a changing world really what is relevant to most people who would search for Artificial Intelligence in the search field of SE? And if not, shouldn't we adapt to the real interests of our membership?</strong></p>
</blockquote>

<p>This is in my opinion the much more important question. Again, I think the answer is ""no"". Those topics may be interesting and relevant for some, and it's fine to allow them, but I suspect that much more detailed questions about specific little things in AI are more relevant to more people that happen to find their way onto this site. In my opinion, the description should indeed be adapted to allow more ""technical"" questions... basically, allow the kinds of questions we see many of. Not necessarily technical in the sense of ""why doesn't this snippet of code work"", but technical in the sense of ""how/why/in what cases should this part of an algorithm work?""</p>

<hr>

<p>A few minor nitpickings from me:</p>

<blockquote>
  <p>Many of the current AI beta Q&amp;A are lacking in scientific rigor even though the AI beta is in the Science SE category. The use of mathematics is a quality factor in a science site as much as inclusion of academic references or narrowness of the problems set forth in the questions.</p>
</blockquote>

<p>I don't agree that this is a problem. StackExchange as a whole (all sites across the entire network) tends to be primarily about ""quick"" questions and answers, about building a site that people can easily reach through google searches, quickly see a question relevant to their search terms, and quickly find an answer that addresses their needs. </p>

<p>Most questions really don't need answers with a thorough literature review, like a scientific paper would. Some do, sometimes there'll a really great question that is best addressed with a great answer containing interesting references to literature, etc... kind of like how, on StackOverflow, you'll sometimes find great answers with lots of different possible solutions, a lot of work put into timing the different implementations, explaining observed performance differences, etc. </p>

<p>That's certainly not necessary for the majority of questions though. Many more questions are asked by non-experts, or first-year or second-year students for example. They might use slightly incorrect terminology, not be aware of all kinds of other potential solutions, etc. But when they have a clear question about an algorithm they're learning about, they just need an answer to that, they don't need a thorough literature review.</p>

<blockquote>
  <p>I think it is correct to assemble AI under Science and not Technology because <strong>the technology side is covered under SE sites such as Arduino and Data Science</strong>, which are properly placed in the Technology category.</p>
</blockquote>

<p>I don't agree with the bolded part there. I've personally never heard of Arduino, but a quick google search does not tell me how that covers a major part of AI at all, it seems really specific and niche. AI is also much much more than just Data Science. AI includes things like search algorithms, planning, pathfinding, and probably much more stuff that is not Data Science. People need a place to ask questions about all that, and it's not covered by any other StackExchange site.</p>
",AImeta,current facing description ai meta descriptive think answer fairly obvious point time co question discussion life changing world really relevant people would search artificial intelligence search field se adapt real interests membership opinion much important question think answer topics may interesting relevant fine allow suspect much detailed questions specific little things ai relevant people happen find way onto site opinion description indeed adapted allow technical questions basically allow kinds questions see many necessarily technical sense snippet code work technical sense cases part algorithm work minor nitpickings many current ai beta q lacking scientific rigor even though ai beta science se category use mathematics quality factor science site much inclusion academic references narrowness problems set forth questions agree problem stackexchange whole sites across entire network tends primarily quick questions answers building site people easily reach google searches quickly see question relevant search terms quickly find answer addresses needs questions really need answers thorough literature review like scientific paper would sometimes really great question best addressed great answer containing interesting references literature etc kind like stackoverflow sometimes find great answers lots different possible solutions lot work put timing different implementations explaining observed performance differences etc certainly necessary majority questions though many questions asked non experts first year second year students example might use slightly incorrect terminology aware kinds potential solutions etc clear question algorithm learning need answer need thorough literature review think correct assemble ai science technology technology side covered se sites arduino data science properly placed technology category agree bolded part personally never heard arduino quick google search tell covers major part ai seems really specific niche ai also much much data science ai includes things like search algorithms planning pathfinding probably much stuff data science people need place ask questions covered stackexchange site
1,"<p>I would like to add to the calls for LaTeX support with a specific topic. </p>

<p>In my opinion, the AI Stack Exchange should be <strong>the</strong> home for questions about <em>Reinforcement Learning</em>.</p>

<p>RL questions actually appear in larger numbers on Data Science and Cross Validated Stack Exchange sites. That makes little sense to me, when AI, robotics and other better homes in a conceptual sense exist for this topic.</p>

<p>RL is a technical subject requiring solid understanding of underlying maths, especially for anyone wanting to engage in algorithm design. I would like to be able to write equations and maths-based pseudo code when writing questions or answers about RL. It is a shame that this site presents a barrier to doing that. Along with the larger audience for other Stack Exchange sites, this one is losing out IMO on a current hot topic that could provide much traffic. And in part that is due to barriers when writing content.</p>
",AImeta,would like add calls latex support specific topic opinion ai stack exchange home questions reinforcement learning rl questions actually appear larger numbers data science cross validated stack exchange sites makes little sense ai robotics better homes conceptual sense exist topic rl technical subject requiring solid understanding underlying maths especially anyone wanting engage algorithm design would like able write equations maths based pseudo code writing questions answers rl shame site presents barrier along larger audience stack exchange sites one losing imo current hot topic could provide much traffic part due barriers writing content
1,"<p><em>A knowledgeable user graciously submitted this edit for the topology tag, but the scope of the content is such that I wanted to bring it to the community for discussion:</em></p>

<p><BR></p>

<blockquote>
  <p><strong>USAGE GUIDANCE</strong>
  Topology is the study of geometric constructs and whether they can or cannot arise from other geometric constructs solely from stretching, contracting, bending, or twisting. In the context of AI, the topology correlates closely with the categorical capabilities of the system.</p>
</blockquote>

<p><br></p>

<blockquote>
  <p><strong>TAG WIKI</strong> Topology is the study of geometric constructs as to whether they can or cannot arise from other geometric constructs solely from stretching, contracting, bending, or twisting.  See the Miriam-Webster online dictionary definition of <em>topology</em> below.</p>
  
  <p>In the context of AI, the topology correlates closely with the categorical capabilities of the system.</p>
  
  <p><strong>Correct Use</strong></p>
  
  <p>The feedback of signals from the output of a network or a layer to a previous point in signal flow is a topological feature involving splitting and joining which matches the use of the term in mechanics, mathematics, semantic web analysis, and IT network provisioning.</p>
  
  <p>Gating and Attention organelles are topological.</p>
  
  <p>The signal paths that create the adversarial balance between generative and discriminative networks in the GAN design create a topology that is unique to collaborative circuit pairing.</p>
  
  <p><strong>Misuse</strong></p>
  
  <p>Although the term <em>topology</em> has been used in relation to the number of activation elements in a neural network layer, there is an undeniable semantic flaw with that usage:</p>
  
  <p>Neural networks form a geometry of discrete elements without meaningful size attributes.  Activations and input attenuation parameters cannot be stretched, contracted, bent, or twisted meaningfully.  Moving a vertex with the edges still attached in the graphic representation also lacks functional meaning.</p>
  
  <p>The only possible meaning of morphing a neural network layer is to change the quantity of its array elements, which means that the artificial neuron counts in the layers CANNOT be part of a network's topology if the word topology is to delineate anything at all.</p>
  
  <p><strong>Only Possible Logical Conclusion</strong></p>
  
  <p>If topology is to be applied to AI design, only features that cannot be changed solely by modifying the dimensionality of one or more arrays in the design can qualify as topological features.</p>
</blockquote>

<hr>

<blockquote>
  <p><a href=""https://www.merriam-webster.com/dictionary/topology"" rel=""nofollow noreferrer"">The Miriam-Webster online dictionary definition of Topology</a></p>
</blockquote>

<pre><code>a :
    1. a branch of mathematics concerned with those properties of geometric configurations (such as point sets) which are unaltered by elastic deformations (such as a stretching or a twisting) that are homeomorphisms
    2. the set of all open subsets of a topological space

b : configuration — topology of a molecule topology of a magnetic field
</code></pre>
",AImeta,knowledgeable user graciously submitted edit topology tag scope content wanted bring community discussion usage guidance topology study geometric constructs whether arise geometric constructs solely stretching contracting bending twisting context ai topology correlates closely categorical capabilities system tag wiki topology study geometric constructs whether arise geometric constructs solely stretching contracting bending twisting see miriam webster online dictionary definition topology context ai topology correlates closely categorical capabilities system correct use feedback signals output network layer previous point signal flow topological feature involving splitting joining matches use term mechanics mathematics semantic web analysis network provisioning gating attention organelles topological signal paths create adversarial balance generative discriminative networks gan design create topology unique collaborative circuit pairing misuse although term topology used relation number activation elements neural network layer undeniable semantic flaw usage neural networks form geometry discrete elements without meaningful size attributes activations input attenuation parameters stretched contracted bent twisted meaningfully moving vertex edges still attached graphic representation also lacks functional meaning possible meaning morphing neural network layer change quantity array elements means artificial neuron counts layers part network topology word topology delineate anything possible logical conclusion topology applied ai design features changed solely modifying dimensionality one arrays design qualify topological features 1 branch mathematics concerned properties geometric configurations point sets unaltered elastic deformations stretching twisting homeomorphisms 2 set open subsets topological spaceb configuration topology molecule topology magnetic field
1,"<p><em>Disclaimer: NNs are not my area, and I only have a general grasp of General Topology.  I come to AI via combinatorics and combinatorial games which influences my perspective.</em></p>

<ul>
<li>Wondering if we should mention/emphasize ""<a href=""https://en.wikipedia.org/wiki/Network_topology"" rel=""nofollow noreferrer"">network topology</a>"" </li>
</ul>

<p>When researching the field of topology, I noticed it did not deal with certain aspects of geometrical game boards, which are more in line with the ""proto-topology"" pioneered by Euler with the <a href=""https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg"" rel=""nofollow noreferrer"">Bridges of Königsberg</a>.  (For instance, you can add or remove playable cells from a Chess or Go board, which alters the structure in terms of number of connections <em>(the network topology. From this standpoint, topological alterations to game boards potentially break game solutions, which may have an impact on AI performance/strength.)</em></p>

<p>Also wondering how similar the network topology usage is re: NNs</p>
",AImeta,disclaimer nns area general grasp general topology come ai via combinatorics combinatorial games influences perspective wondering mention emphasize researching field topology noticed deal certain aspects geometrical game boards line proto topology pioneered euler instance add remove playable cells chess go board alters structure terms number connections network topology standpoint topological alterations game boards potentially break game solutions may impact ai performance strength also wondering similar network topology usage nns
1,"<p>I <strong>strongly recommend against</strong> using this tag info, for the following reasons:</p>

<ol>
<li>Tag info should be <strong>easily understandable</strong>, provide <strong>clear information</strong> that tells a user whether or not to use that tag / whether or not it's relevant for their question. </li>
<li>Tag info should be <strong>unambiguous</strong>, <strong>correct</strong>, and <strong>not be up for debate</strong>. The information in there should be ""generally agreed upon"" by people familiar with the relevant field(s) to be true.</li>
</ol>

<p>I don't think either of these points are satisfied here.</p>

<hr>

<p>For the <strong>first point</strong>, try reading through that text once, from top to bottom. Do you feel like you're now well aware of when the tag is or isn't applicable, what it's about? I certainly don't. I have the following concerns here:</p>

<ul>
<li>Usage guidance doesn't really tell us for which questions it should or shouldn't be used. It starts out with a bunch of fancy words that don't tell me anything about its relation to AI. It ends by telling us that ""topology"" is supposedly ""closely related"" to something, but still don't know <strong>what it is</strong>.</li>
<li>Again, the main text / tag wiki doesn't provide clear information either. Again, lots of fancy words, but not much real information (definitely not <strong>clear</strong> information).</li>
<li>The tag wiki gives some examples of things that are ""features of topology"" or are ""topological"", but we still don't have a clear description of what it's supposed to be.</li>
</ul>

<hr>

<p>For the <strong>second point</strong>, I have the following concern:</p>

<ul>
<li>It dives straight into ""Correct Use"" and ""Misuse"" headers, which is already hinting at the definition being up for debate, having multiple uses, being potentially ambiguous or not generally agreed upon. More importantly, <strong>as someone familiar with Neural Networks this might be plain incorrect according to my experiences</strong>. I say ""might be"" rather than ""is"" because the text is so incomprehensibly complicated that I can't tell for sure what it's actually saying.</li>
</ul>

<p>In general, in AI, when people are talking about ""topology"" in the context of Neural Networks, it's used to describe the ""architecture"" of the Network; how many layers, what types of layers, how large is each layer, what activation functions do we put in between, where are the connections (typically a feature of layer type). That's basically it, and that can be explained very clearly in language that can be understood easily. Some sources:</p>

<ul>
<li><a href=""https://www.quora.com/What-is-the-difference-between-neural-network-architecture-and-topology"" rel=""nofollow noreferrer"">A quora question</a></li>
<li><a href=""http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf"" rel=""nofollow noreferrer"">A well-known paper on using evolutionary search to optimize a Neural Network's topology</a> (indeed, it's evolving the ""structure"" of the neural network).</li>
</ul>

<p>Many more similar sources can be found through a google search for ""Neural Network topology"".</p>

<p>That is specifically in the <strong>context of Neural Networks</strong>. This will likely be the most common natural usage of the tag on this site. However, as also mentioned in the proposed tag wiki, <strong>topology is also a completely different field of mathematics</strong>. And <a href=""https://www.quora.com/What-has-topology-got-to-do-with-machine-learning"" rel=""nofollow noreferrer"">that field of mathematics may sometimes be relevant in a completely different manner in the field of AI</a>. So, ""topology"" can be <strong>ambiguous</strong>, and <strong>probably should not be restricted only to the usage in the context of Neural Networks</strong>.</p>

<hr>

<p>As a final concern, I am wondering what a header saying <strong>""Only Possible Logical Conclusion""</strong> is doing in a tag wiki. That's a header I'd expect in an opinion piece, or maybe as an overly-sensationalized header after a mathematical proof. This is not a header that belongs in a neutral, informative Tag Wiki.</p>

<hr>

<p>Now, given the use of language, I know immediately precisely which person proposed that tag wiki edit. For context, I think it's important to note that <strong>I've previously had a long discussion with this user concerning terminology</strong>, <a href=""https://chat.stackexchange.com/transcript/81180"">which can be read here</a>.</p>

<p>Note that, in that discussion, it becomes very clear that this particular user is knowingly and <strong>actively trying to push the usage of new terminology that he personally believes to be ""better"" than commonly-used terminology across the entire field</strong>. That is fine, he can do that if he likes, even on this site by e.g. asking questions like ""Wouldn't X be a better term instead of Y because reasons Z?"" But this should not be done through tag wikis. <strong>Tag wikis should be consistent with language used commonly across the field</strong>, otherwise every single non-expert user visiting the site (and maybe even expert users) is going to be confused.</p>
",AImeta,strongly recommend using tag info following reasons tag info easily understandable provide clear information tells user whether use tag whether relevant question tag info unambiguous correct debate information generally agreed upon people familiar relevant fields true think either points satisfied first point try reading text top bottom feel like well aware tag applicable certainly following concerns usage guidance really tell us questions used starts bunch fancy words tell anything relation ai ends telling us topology supposedly closely related something still know main text tag wiki provide clear information either lots fancy words much real information definitely clear information tag wiki gives examples things features topology topological still clear description supposed second point following concern dives straight correct use misuse headers already hinting definition debate multiple uses potentially ambiguous generally agreed upon importantly someone familiar neural networks might plain incorrect according experiences say might rather text incomprehensibly complicated tell sure actually saying general ai people talking topology context neural networks used describe architecture network many layers types layers large layer activation functions put connections typically feature layer type basically explained clearly language understood easily sources indeed evolving structure neural network many similar sources found google search neural network topology specifically context neural networks likely common natural usage tag site however also mentioned proposed tag wiki topology also completely different field mathematics topology ambiguous probably restricted usage context neural networks final concern wondering header saying possible logical conclusion tag wiki header would expect opinion piece maybe overly sensationalized header mathematical proof header belongs neutral informative tag wiki given use language know immediately precisely person proposed tag wiki edit context think important note previously long discussion user concerning terminology note discussion becomes clear particular user knowingly actively trying push usage new terminology personally believes better commonly used terminology across entire field fine likes even site eg asking questions like would x better term instead reasons z done tag wikis tag wikis consistent language used commonly across field otherwise every single non expert user visiting site maybe even expert users going confused
1,"<blockquote>
  <p>The evidence for the below reasons is clearly evident not only in the
  titles and bodies of the most popular questions and answers but also
  in tag usage, the top ten being these.</p>
  
  <ul>
  <li>Neural networks</li>
  <li>Machine learning</li>
  <li>Deep learning</li>
  <li>CNNs</li>
  <li>Reinforcement</li>
  <li>AI design</li>
  <li>Image recognition</li>
  <li>Algorithm</li>
  <li>Classification</li>
  <li>Training</li>
  </ul>
</blockquote>

<p>All these topics are on-topic on <a href=""http://stats.stackexchange.com"">http://stats.stackexchange.com</a> and <a href=""https://datascience.stackexchange.com"">https://datascience.stackexchange.com</a>. I don't see any point in having <a href=""https://ai.stackexchange.com"">https://ai.stackexchange.com</a> covering them as well.</p>
",AImeta,evidence reasons clearly evident titles bodies popular questions answers also tag usage top ten neural networks machine learning deep learning cnns reinforcement ai design image recognition algorithm classification training topics topic see point covering well
1,"<p>To give some background, recently I came across an answer which used some religious stories to explain a question. I reported it as spam as it contained link to a personal blog (it got consequently removed).</p>

<p>The answer in itself was faulty as it did not properly cite the sources of the religious stories. I would not have raised a flag if the person had cited the sources correctly.</p>

<p>My question should we allow answers based on religious sources in this stack? My opinion is since we ourselves have no real true understanding of  AI one should allow the religious sources to be counted as philosophy, since it is speculative. What are your thoughts on this matter?</p>
",AImeta,give background recently came across answer used religious stories explain question reported spam contained link personal blog got consequently removed answer faulty properly cite sources religious stories would raised flag person cited sources correctly question allow answers based religious sources stack opinion since real true understanding ai one allow religious sources counted philosophy since speculative thoughts matter
1,"<p>Our <a href=""https://ai.meta.stackexchange.com/q/1285/75"">justification policy</a> requires that speculative answers give some justification or reasoning for their assertions. I originally intended it for things like this hypothetical (and somewhat hyperbolic) exchange:</p>

<blockquote>
  <p>Q: What is the risk from widespread deployment of self-driving cars?</p>
  
  <p>A: Self-driving cars will work fine for a while, gain sentience, turn malevolent, wait for a perfect opportunity, and kill us all. This sequence of events is 100% certain.</p>
</blockquote>

<p>Wild speculation requires some sort of justification. It still might not be correct (votes can indicate accuracy/reasonableness), but there must be some explanation of how the answer author arrived at their conclusion. Citing sources is a great way, but not the only way, to provide that. It seems to me like drawing on philosophy/religion is a decent method to explain one's position.</p>

<p>Regarding the specific answer you discuss: I deleted it not for lack of explanation but because &mdash; despite its considerable length &mdash; it didn't actually address artificial intelligence.</p>
",AImeta,requires speculative answers give justification reasoning assertions originally intended things like hypothetical somewhat hyperbolic exchange q risk widespread deployment self driving cars self driving cars work fine gain sentience turn malevolent wait perfect opportunity kill us sequence events 100 certain wild speculation requires sort justification still might correct votes indicate accuracy reasonableness must explanation answer author arrived conclusion citing sources great way way provide seems like drawing philosophy religion decent method explain one position regarding specific answer discuss deleted lack explanation actually address artificial intelligence
1,"<p>I just noticed that <a href=""https://ai.meta.stackexchange.com/q/35/1641"">$\LaTeX$ support has been enabled on the site</a>. In this meta discussion where that feature was requested, large lists of existing questions and answers that would benefit from $\LaTeX$ support have already been compiled.</p>

<p>What is the best way to go about editing all of those to use $\LaTeX$ for properly formatted math? <strong>I suppose that we will not want to edit them all right away</strong>, because that will drown out any new questions appearing on the frontpage. Are we going to be editing them slowly, one per day or something like that? Or all at once anyway?</p>
",AImeta,noticed meta discussion feature requested large lists existing questions answers would benefit latex support already compiled best way go editing use latex properly formatted math suppose want edit right away drown new questions appearing frontpage going editing slowly one per day something like anyway
1,"<p>Depending on individual inclination, however</p>

<ul>
<li>Restricting edits to just a few per day would be optimal</li>
</ul>
",AImeta,depending individual inclination however restricting edits per day would optimal
1,"<p>Recently I <a href=""https://ai.stackexchange.com/questions/7602/how-can-i-train-model-to-extract-custom-entities-from-text"">flagged</a> a question as more suitable for Data Science Stack Exchange and should be migrated there. However it was declined. To me this is clearly a Data Science question (no ambiguity). Did I make a mistake in my judgement or are we entertaining Data Science questions also?</p>
",AImeta,recently question suitable data science stack exchange migrated however declined clearly data science question ambiguity make mistake judgement entertaining data science questions also
1,"<p>I personally feel like most Data Science questions would be just fine on AI too, Data Science and AI simply are very closely related. The only argument against having Data Science questions on AI.se that I'm aware of basically boils down to trying to avoid as much overlap as possible.</p>

<p>From my point of view, that kind of overlap really isn't too much of a problem. The topic in the question (entity recognition from text) is certainly a topic that could be described as being a part of ""Artificial Intelligence"", and it would be just as correct as saying it's a ""Data Science"" topic. So I personally really wouldn't mind if it's allowed on either site, I can see it fitting in either just fine. I understand that StackExchange as a complete network might find it more problematic if there's too much overlap, and if that's the case their opinion is probably more important than mine, I just don't experience it as problematic personally.</p>

<p>The only sentence in the question you linked to that is maybe a bit questionable in my opinion is the following:</p>

<blockquote>
  <p>I have tried Spacy and NLTK for entity extraction but that doesn't suffice above requirements.</p>
</blockquote>

<p>That sentence is describing specific tools/frameworks, and implies the question-asker might be looking for more names of similarly specific tools/frameworks. I do feel those kinds of questions would be a better fit for Data Science. </p>

<p>But the same question, especially if you ignore that one sentence, can easily be interpreted as being of a more conceptual nature, asking more generally about techniques/algorithms that would be applicable. It looks to me like both of the current answers also interpret the question in that way. Such ""conceptual"" questions would be just fine here in my opinion.</p>
",AImeta,personally feel like data science questions would fine ai data science ai simply closely related argument data science questions aise aware basically boils trying avoid much overlap possible point view kind overlap really much problem topic question entity recognition text certainly topic could described part artificial intelligence would correct saying data science topic personally really would mind allowed either site see fitting either fine understand stackexchange complete network might find problematic much overlap case opinion probably important mine experience problematic personally sentence question linked maybe bit questionable opinion following tried spacy nltk entity extraction suffice requirements sentence describing specific tools frameworks implies question asker might looking names similarly specific tools frameworks feel kinds questions would better fit data science question especially ignore one sentence easily interpreted conceptual nature asking generally techniques algorithms would applicable looks like current answers also interpret question way conceptual questions would fine opinion
1,"<p>The subtext of the question was, that any kind of content moderation in a forum distorts the normal user interaction. According to this assumption the ideal forum doesn't contain any kind of moderators under fake accounts. Let us describe what the purpose of content moderation is. The aim is to delegate tasks into the workgroup. It is the same principle used in companies for improving group working. The main purpose of content moderation is a service for the group. That means, management doesn't hurt the social community it makes it stronger. </p>

<p>AI StackExchange doesn't have to much people who are trying to gaming the system and influence the group but too little. The result of missing moderation is, that the group is not attractive for the environment and that the group members are not communicating efficient.</p>
",AImeta,subtext question kind content moderation forum distorts normal user interaction according assumption ideal forum contain kind moderators fake accounts let us describe purpose content moderation aim delegate tasks workgroup principle used companies improving group working main purpose content moderation service group means management hurt social community makes stronger ai stackexchange much people trying gaming system influence group little result missing moderation group attractive environment group members communicating efficient
1,"<p>So I came across this tag <code>neuromorphic-computing</code> while editing a question. This is a quite misleading  name. I suggest the moderators change the name to <code>neuromorphic-engineering</code> which covers the entire field of chip design and not just computation, which was the main purpose for the emergence field.</p>
",AImeta,came across tag editing question quite misleading name suggest moderators change name covers entire field chip design computation main purpose emergence field
1,"<p>I agree with this because <a href=""https://en.wikipedia.org/wiki/Neuromorphic_engineering"" rel=""nofollow noreferrer"">it is consistent with the wiki article</a> for the field.</p>
",AImeta,agree field
1,"<p>If you take a look at our states on Area51, the two big areas that are still a problem for the beta are the rate of unanswered questions (which is close to 25%), and the average number of answers per question (which is about 1). These are related statistics.</p>

<p>Looking through our queue of unanswered questions, there are some that might be answerable, but that I cannot answer, and many that look unanswerable or very low quality. Many of the questions are very old.</p>

<p>Should we make a more concerted effort to close questions that are old <strong>and</strong> unanswerable? What criteria should we use to decide if a question meets that standard?</p>
",AImeta,take look states area51 two big areas still problem beta rate unanswered questions close 25 average number answers per question 1 related statistics looking queue unanswered questions might answerable answer many look unanswerable low quality many questions old make concerted effort close questions old unanswerable criteria use decide question meets standard
1,"<p>To second Dennis Soemers' answer:</p>

<p>Much, but not all, of Data Science relies on AI tools. When the question relates to AI, we should answer it.</p>

<p>Some examples of Data Science topics that are <em>not</em> about AI, and which we should migrate are:</p>

<ul>
<li>Questions about scraping data from the web.</li>
<li>Questions about hypothesis testing or other conventional techniques from statistics (unless about the evaluation of ML methods).</li>
<li>Questions about programming languages or toolkits within those languages, that focus on syntax or programming rather than AI/ML algorithms.</li>
</ul>
",AImeta,second dennis soemers answer much data science relies ai tools question relates ai answer examples data science topics ai migrate questions scraping data web questions hypothesis testing conventional techniques statistics unless evaluation ml methods questions programming languages toolkits within languages focus syntax programming rather ai ml algorithms
1,"<p>I don't see a discussion of what constitutes a good ""Soft Question"", but @DukeZhou's suggestions make sense:</p>

<ul>
<li>Questions should be rooted in existing AI research, or research by serious philosophers on AI related topics, not in popular non-fiction books. (i.e. favour Moshe Verdi or Nick Bostrom over Ray Kurzweil). 

<ul>
<li>Rationale: Popular non-fiction tends to exaggerate AI's capabilities, and tends to be written by people with little actual knowledge of the field, despite reaching a broad audience. Questions rooted in this material will tend to elicit wildly speculative answers, or to be unanswerable. </li>
</ul></li>
<li>Soft questions and their answers should include supporting citations to scholarly works, and should be rooted in empirically supported facts whenever possible. 

<ul>
<li>Rationale: A good example was a recent question on automation. It's easy to speculate, but there's actually lots of good data, both about what financial markets think will be automated, and what AI experts as a whole think can be automated. These estimates are likely to be far more reliable than an individual user's opinions, or even any philosopher's opinions.</li>
</ul></li>
</ul>
",AImeta,see discussion constitutes good soft question dukezhou suggestions make sense questions rooted existing ai research research serious philosophers ai related topics popular non fiction books ie favour moshe verdi nick bostrom ray kurzweil rationale popular non fiction tends exaggerate ai capabilities tends written people little actual knowledge field despite reaching broad audience questions rooted material tend elicit wildly speculative answers unanswerable soft questions answers include supporting citations scholarly works rooted empirically supported facts whenever possible rationale good example recent question automation easy speculate actually lots good data financial markets think automated ai experts whole think automated estimates likely far reliable individual user opinions even philosopher opinions
1,"<p>If a question is unanswerable, it should be closed, be it old or new. This is more or less what closing is for. </p>

<p>But don't do it for the sake of Area 51 statistics. Those statistics outlived their usefulness, as did Area 51 itself. The post <a href=""https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sites"">Graduation, site closure, and a clearer outlook on the health of SE sites</a> explains that already in 2015, those stats did not really matter for site graduation or closure.</p>
",AImeta,question unanswerable closed old new less closing sake area 51 statistics statistics outlived usefulness area 51 post explains already 2015 stats really matter site graduation closure
1,"<p>Speaking as a pro tem mod, we see a lot of single close votes, but tend to give the OP the benefit of the doubt, and err on the side of caution.</p>

<p>My feeling is the best method to increase closure of these ""grey area"" questions is to keep attracting knowledgeable contributors, and supporting those contributors by upvoting good questions and answers, so that more users have informal moderator privileges.  (i.e. I'm personally more comfortable with closures being consensus-based because, as JD notes, it can be a difficult determination, even for qualified individuals.)</p>

<p>That said, I'd like to prune away as much of the noise and dead-weight as possible to improve our stats.  I'm wondering if we might start a chat thread to address questions in limbo, so that if contributors make a strong case for closure, the moderators can more confidently take action.</p>
",AImeta,speaking pro tem mod see lot single close votes tend give op benefit doubt err side caution feeling best method increase closure grey area questions keep attracting knowledgeable contributors supporting contributors upvoting good questions answers users informal moderator privileges ie personally comfortable closures consensus based jd notes difficult determination even qualified individuals said would like prune away much noise dead weight possible improve stats wondering might start chat thread address questions limbo contributors make strong case closure moderators confidently take action
1,"<p>A good starting point is, that a statistics about the facts is available. That means, we can predict how long it will take for a new question until it get answered and how many answers it will generate. The bad news is a high rate of unanswered question is equal to a low service quality.</p>

<p>SE.AI is the frontend of AI in the internet. That means, there is no other forum out there which is better. If SE.AI has a low quality, AI in general has a problem. It is some kind of bottleneck. Bypassing the bottleneck is simple, it is only a question of resources. I'm with you that in the current status the resources are not here. The number of moderators is limited, the number of users who answering questions is limited. On the other hand, people who are familiar with Artificial Intelligence are available in the world, they are only not here in the forum. Why?</p>

<p>I think it is time to ask people who are familiar with neural networks, machine learning, NLP and robotics what they are doing with their time, if they are not contributing to this website here. Do they have holiday? Are they are interested anymore in AI? Are they are involved in projects with greater importance? We need them here at the frontline.</p>
",AImeta,good starting point statistics facts available means predict long take new question get answered many answers generate bad news high rate unanswered question equal low service quality seai frontend ai internet means forum better seai low quality ai general problem kind bottleneck bypassing bottleneck simple question resources current status resources number moderators limited number users answering questions limited hand people familiar artificial intelligence available world forum think time ask people familiar neural networks machine learning nlp robotics time contributing website holiday interested anymore ai involved projects greater importance need frontline
1,"<p>Stackoverflow has also an Artificial Intelligence tag. But posting a question there is often not the best choice, because AI-related questions are too complex for Stackoverflow. I would guess that it is question of which questions fits to Stackoverflow and which to AI.SE. At the end, one of both websites is always right. If somebody has an issue with Python, Neural Networks or C++, it is only a question of which of both forums is the right choice. It is correct, the machine learning implementation problems with Tensorflow and Co are exactly on the border. And a framework like OpenAI gym can be discussed on SE.AI but also on Stackoverflow. I would say, that AI.SE can allow any question and this one with a low academic impact should be migrated to Stackoverflow.</p>

<p><a href=""https://i.stack.imgur.com/ld2nM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ld2nM.png"" alt=""SO vs. AI.SE""></a></p>

<p><strong>One remark to Datascience</strong></p>

<p>I see the point, that Datascience has a tendency to overwhelm AI.SE. If someone is using a three layer peceptron for creating a mathematical model in Matlab he is forwmost not interested in Artificial Intelligence but it is plain old statistics question. On the other hand, neural networks were clearly invented in the AI domain, so it is wrong to answer this question with: “You're in the wrong forum”. In contrast to the majority here in the forum, I do not believe that we should migrate such questions to Datascience, because it allows us to explain the AI-related point of view to neural networks and how this technology can be used to implement intelligent machines.</p>
",AImeta,stackoverflow also artificial intelligence tag posting question often best choice ai related questions complex stackoverflow would guess question questions fits stackoverflow aise end one websites always right somebody issue python neural networks c question forums right choice correct machine learning implementation problems tensorflow co exactly border framework like openai gym discussed seai also stackoverflow would say aise allow question one low academic impact migrated stackoverflow one remark datascience see point datascience tendency overwhelm aise someone using three layer peceptron creating mathematical model matlab forwmost interested artificial intelligence plain old statistics question hand neural networks clearly invented ai domain wrong answer question wrong forum contrast majority forum believe migrate questions datascience allows us explain ai related point view neural networks technology used implement intelligent machines
1,"<p><sub><em>Earlier this year we announced a &quot;site sponsorship&quot; program aimed at bringing in industry and project-team leaders to help support these sites. A lot of your questions about this program can be answered through the posts and comments there:</em></sub></p>
<p><em><strong><a href=""https://meta.stackexchange.com/questions/307861/sponsorship-pilot-bringing-resources-back-to-stack-exchange"">Site Sponsporships — Bringing Resources Back to Stack Exchange</a></strong></em></p>
<hr />
<p>Today I am excited to announce that <strong>IBM has generously agreed to sponsor the Artificial Intelligence site</strong>  by becoming a partner with the AI community — to encourage innovation within this space by helping developers solve the complex problems facing this field.</p>
<p>The primary focus of a sponsorship is to help bring more resources to this site. IBM is currently working with Stack Exchange to promote this site at their <a href=""https://www.ibm.com/analytics/win-with-ai/"" rel=""nofollow noreferrer""><strong>Winning with AI conference</strong></a> on September 13, 2018 in New York City. IBM will also be advertising on Stack Overflow to drive further traffic and usage back to the AI site. IBM will also bring various dev teams throughout their organization (many with communities of their own) to participate on the AI site, and to help expand awareness of the industry itself.</p>
<h2>How does a sponsorship affect this site?</h2>
<p>Site sponsorships are administered much like the &quot;tag sponsorships&quot; you may have seen on other sites. Apart from the visual updates and site promotion, you should not see any significant changes in the scope or the operation of this site. Site sponsorship is essentially &quot;strategic philanthropy&quot; where industry partners like IBM can give back to developer communities by having a presence on the site, and to provide a place to help ask and answer questions.</p>
<h2>Let's get a few immediate concerns out of the way</h2>
<p>First — sponsors do not &quot;own&quot; these Q&amp;A sites. Sponsors work <em>alongside</em> our communities who ultimately build these sites. Communities ask the questions; communities create the tags; communities conduct elections as they do now. Any ads a sponsor might submit still has to go through our crazy-strict ad editorial process… as it has always been. Companies do not have access to personal data, and all Q&amp;A content remains irrevocably licensed under Creative Commons for sharing and attribution.</p>
<p>I am energized about the potential for working with companies like IBM as a way to expand our sites' growth and to help bring in new communities, and maybe even build out some new features for Q&amp;A sites like this. Every site will ultimately benefit.</p>
<p>On a personal note, I continue to be impressed by just how attuned our marketing team and partners have been to the concerns of our Q&amp;A sites. We will work hard to find organizations who are willing to cede so much control back to the community. It can be difficult to anticipate all the hiccups we might encounter along the way, but we remain steadfast in the guiding principle that these ideas should NOT interfere with the main experience of the Q&amp;A, and IBM seems to fit that relationship and expectation to a T.</p>
<p><em>Enjoy!</em></p>
<p><img src=""https://i.stack.imgur.com/F3MOI.png"" alt="""" /></p>
",AImeta,earlier year announced program aimed bringing industry project team leaders help support sites lot questions program answered posts comments today excited announce ibm generously agreed sponsor artificial intelligence site becoming partner ai community encourage innovation within space helping developers solve complex problems facing field primary focus sponsorship help bring resources site ibm currently working stack exchange promote site september 13 2018 new york city ibm also advertising stack overflow drive traffic usage back ai site ibm also bring various dev teams throughout organization many communities participate ai site help expand awareness industry sponsorship affect site site sponsorships administered much like industry partners like ibm give back developer communities presence site provide place help ask answer questions let get immediate concerns way first sponsors content remains irrevocably licensed creative commons sharing attribution energized potential working companies like ibm way expand sites growth help bring new communities maybe even build new features q sites like every site ultimately benefit personal note continue impressed attuned marketing team partners concerns q ibm seems fit relationship expectation enjoy
1,"<p>This is great news.  We may still be in Beta, but hopefully not for much longer!  I'm taking it as a good omen that a foundational company in the field of AI wants to be associated with our dynamic and growing Artificial Intelligence stack!</p>
",AImeta,great news may still beta hopefully much longer taking good omen foundational company field ai wants associated dynamic growing artificial intelligence stack
1,"<p>I do appreciate the IBM work!
However; <em>How do this newly sponsored AI site differ from the other sites that have been parterned with SE,like AskUbuntu</em></p>

<p>Is creating a new site only in this case, as a proof of concept? And then if it works, in the future existing sites will be sponsored? Otherwise I don't think I understand how sponsorship equates to ""bringing resources back""; creating more sites sounds like spreading resources out or else this is more of a ""we want to advance knowledge in our field for altruistic reasons"" thing for companies, or is this supposed to give them a profit eventually. </p>

<p>According to my analysis,basing on the snapshot of the site in the question body,A sponsorship generally entails enabling ads relevant to the subject and affixing a small ""sponsored by..."" logo in the upper-right corner, and i do think  that's why <em>ibm</em>  is here!</p>

<p><strong>Anyways,appreciated approximately.</strong></p>
",AImeta,appreciate ibm workhowever newly sponsored ai site differ sites parterned se like askubuntu creating new site case proof concept works future existing sites sponsored otherwise think understand sponsorship equates bringing resources back creating sites sounds like spreading resources else want advance knowledge field altruistic reasons thing companies supposed give profit eventually according analysis basing snapshot site question body sponsorship generally entails enabling ads relevant subject affixing small sponsored logo upper right corner think ibm anyways appreciated approximately
1,"<p>I make a point of visiting the unanswered queue on all sites that I am active on. It's possible to earn an <a href=""https://ai.stackexchange.com/help/badges/90/explainer"">Explainer</a>, <a href=""https://ai.stackexchange.com/help/badges/64/revival"">Revival</a>, <a href=""https://ai.stackexchange.com/help/badges/17/necromancer"">Necromancer</a> or other badge available to new questions.</p>
<p>We should run through the queue when we visit here.</p>
<p>The site <a href=""https://interpersonal.stackexchange.com/questions?sort=unanswered"">Interpersonal.SE</a> has an unanswered queue style similar to ours (single tab), while <a href=""https://lifehacks.stackexchange.com/unanswered/tagged/?tab=noanswers"">LifeHacks.SE</a> has the advantage of a multi-level Unanswered Questions queue; with additional tabs for &quot;my tags&quot;, &quot;newest&quot;, &quot;votes&quot; and &quot;no answers&quot; permitting better differentiation. Both those sites have a similar total number of questions as we do, yet the number of unanswered questions is near zero.</p>
<p>The remaining question is do we want a multi-level queue like LifeHacks has? I'm new to AI.SE, so I'd prefer a senior member put in a feature request over at <a href=""https://meta.stackexchange.com/search?q=unanswered%20questions"">meta.SE</a>.</p>
<p>Be certain to improve and better these similar requests that became ignored or status-declined:</p>
<ul>
<li><p><a href=""https://meta.stackexchange.com/questions/8506/improving-navigation-around-unanswered-questions"">Improving navigation around unanswered questions</a></p>
</li>
<li><p><a href=""https://meta.stackexchange.com/questions/16542/how-to-search-unanswered-questions"">How to search unanswered questions</a></p>
</li>
<li><p><a href=""https://meta.stackexchange.com/questions/11563/tab-for-questions-that-are-labeled-with-favorite-tags"">Tab for questions that are labeled with favorite tags</a></p>
</li>
<li><p><a href=""https://meta.stackexchange.com/questions/143113/are-unanswered-questions-a-problem-yet"">Are unanswered questions a problem yet?</a></p>
</li>
<li><p><a href=""https://meta.stackexchange.com/questions/159964/how-should-users-handle-unanswered-questions"">How should users handle unanswered questions?</a></p>
</li>
</ul>
<p>Fortunately, <a href=""https://meta.stackexchange.com/a/92006/282094"">automatic deletions</a> are performed on old questions:</p>
<blockquote>
<p>If the question is more than 365 days old, and ...</p>
<ul>
<li><p>has a score of 0 or less, or a score of 1 or less in case the owner's account is deleted</p>
</li>
<li><p>has no answers</p>
</li>
<li><p>is not locked</p>
</li>
<li><p>has view count &lt;= the age of the question in days times 1.5</p>
</li>
<li><p>has 1 or 0 comments</p>
</li>
<li><p>isn't on a meta site</p>
</li>
</ul>
<p>... it will be automatically deleted.</p>
</blockquote>
",AImeta,make point visiting unanswered queue sites active possible earn badge available new questions run queue visit site unanswered queue style similar single tab advantage multi level unanswered questions queue additional tabs permitting better differentiation sites similar total number questions yet number unanswered questions near zero remaining question want multi level queue like lifehacks new aise would prefer senior member put feature request certain improve better similar requests became ignored status declined fortunately performed old questions question 365 days old score 0 less score 1 less case owner account deleted answers locked view count age question days times 15 1 0 comments meta site automatically deleted
1,"<p>Slight concern: Does this mean that a new moderator will be appointed in AI.SE? Some of us here are beginners and may ask apparently stupid questions and answers. The new moderator might close or delete such questions and answers. </p>

<p>The current moderators understand these concerns and have a very good moderating policy on such type of questions and answers.</p>

<p>Thought I would add some links:</p>

<p><a href=""https://ai.meta.stackexchange.com/questions/1313/are-we-too-fast-downvoting-questions-especially-for-newcomers"">Are we too fast downvoting questions, especially for newcomers?</a></p>

<p><a href=""https://ai.meta.stackexchange.com/questions/1289/13-out-of-the-15-questions-on-the-front-page-right-now-are-1-or-lower-score-th"">13 out of the 15 questions on the front page right now are -1 or lower score: This site needs a broader scope or it's doomed</a></p>
",AImeta,slight concern mean new moderator appointed aise us beginners may ask apparently stupid questions answers new moderator might close delete questions answers current moderators understand concerns good moderating policy type questions answers thought would add links
1,"<p>While the new logo looks great at higher resolutions (e.g. in the title just under the navigation bar), it's really 'vague' (sorry, I don't know how to phrase it) in e.g. the Hot Network Questions list and the hamburger menu:</p>

<p><a href=""https://i.stack.imgur.com/urOJX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/urOJX.png"" alt=""enter image description here""></a> <a href=""https://i.stack.imgur.com/PwGvv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PwGvv.png"" alt=""enter image description here""></a></p>

<p>For starters, the black background should probably be removed; also, a lower number of lines probably suffices to convey the idea that it's a fingerprint.</p>
",AImeta,new logo looks great higher resolutions eg title navigation bar really vague sorry know phrase eg hot network questions list hamburger menu starters black background probably removed also lower number lines probably suffices convey idea fingerprint
1,"<p><a href=""https://ai.stackexchange.com/questions/3343/what-are-the-latest-methods-to-train-a-chat-bot"">This question</a> was recently bumped to the front page. On some other SEs, the words ""latest methods"" would be a red flag and potentially cause it to be closed because any answer would have to be updated to continue to be true. The general philosophy on those other sites is that questions should be answerable in a fashion that is going to be useful not just to the questioner, but also to future visitors to the site. Indeed, one of the major uses of the SE network is as a long-standing repository of knowledge for future questioners.</p>

<p>Although new things can always be discovered that invalidate old answers that pre-date them, questions like the one I link to are going to attract answers that are always going to be going out of date. There is no way for an answerer to answer this question in a way that will be useful and true for a reader in six months or a year.</p>

<p>Is that an issue here, or are we fine with questions whose answers will inevitably become out of date?</p>
",AImeta,recently bumped front page ses words latest methods would red flag potentially cause closed answer would updated continue true general philosophy sites questions answerable fashion going useful questioner also future visitors site indeed one major uses se network long standing repository knowledge future questioners although new things always discovered invalidate old answers pre date questions like one link going attract answers always going going date way answerer answer question way useful true reader six months year issue fine questions whose answers inevitably become date
1,"<p>Right now, we have a tag called [theorics].</p>

<p>""Theorics"" is kind of a dubious word. I've never heard the word used anywhere but this very site. <a href=""https://en.wiktionary.org/wiki/theoric#English"" rel=""nofollow noreferrer"">Wiktionary says</a> that the word is ""obsolete"". <a href=""https://books.google.com/ngrams/graph?content=theory%2Ctheorics&amp;year_start=1800&amp;year_end=2000"" rel=""nofollow noreferrer"">Google Ngram Viewer</a> shows that the word ""theory"" is <em>over one hundred thousand times</em> as common as ""theorics"".</p>

<p>Should we change it to ""theory"" or something?</p>
",AImeta,right tag called theorics theorics kind dubious word never heard word used anywhere site word obsolete shows word theory one hundred thousand times common theorics change theory something
1,"<p>I like <strong>theory</strong>.</p>

<p>I recently <a href=""https://ai.stackexchange.com/questions/7861/what-does-hard-for-ai-look-like"">made a post</a> and was highly surprised to find out that ""theory"" wasn't a tag option. I have never heard of the word ""theorics"" before in my life and only found it by looking at the list of tags. <strong>Edit:</strong> I didn’t even realize it was “theorics,” I thought it was “theoretics” which sounds more like a word to me.</p>

<p>Speaking as a native English speaker whose degrees are in <em>math</em> and <em>philosophy</em> I feel quite inclined to say that a word for “theory” that I’ve never heard in my life is unlikely to be widely known :P</p>
",AImeta,like theory recently highly surprised find theory tag option never heard word theorics life found looking list tags edit nt even realize theorics thought theoretics sounds like word speaking native english speaker whose degrees math philosophy feel quite inclined say word theory never heard life unlikely widely known p
1,"<p>This would indeed seem to be problematic.  Although the icon is unique, it does appear to be a muddy blob of color at the smaller size.  Aside from the aesthetic, it's difficult to make an association to a stack when the image is not clear. </p>
",AImeta,would indeed seem problematic although icon unique appear muddy blob color smaller size aside aesthetic difficult make association stack image clear
1,"<p>I'd personally hesitate to declare questions off-topic just because the ""correct"" answers to them are highly likely to change over time. Indeed, this is going to be the case for ""state-of-the-art"" questions, especially considering how rapidly research in the field is moving and how rapidly the state of the art changes. I personally still feel like such questions aren't overly problematic because:</p>

<ol>
<li><p>They are likely a class of questions that is the most interesting for some people. In a field that moves this rapidly, and where young people are newly entering the field also at increasing rates, there is a lot of interest in knowing ""what is the state of the art right now?"". If there is a lot of demand for such questions, it makes sense to have a place where they can be asked to me.</p></li>
<li><p>The web interface of the site already puts timestamps (dates) on questions and answers. Future visitors will be able to see (if they pay attention) if an answer they've run into is rather old.</p></li>
<li><p>In the future, if the state of the art has significantly changed, people are free to provide new answers or add comments to existing (outdated) answers. If the people who wrote the original outdated answers are still around, they can also edit them. See, for example, <a href=""https://stackoverflow.com/q/6542274/6735980"">this old question on stackoverflow</a>. It was originally asked 7 years ago, and was about the feasibility of training an Artificial Neural Network to play a complex video game like Diablo 2. At the time, this was highly unlikely to be feasible. However, we see some answers being written a few years later, and also see many edits in the question itself and in older answers, to reflect progress in the field.</p></li>
</ol>
",AImeta,would personally hesitate declare questions topic correct answers highly likely change time indeed going case state art questions especially considering rapidly research field moving rapidly state art changes personally still feel like questions overly problematic likely class questions interesting people field moves rapidly young people newly entering field also increasing rates lot interest knowing state art right lot demand questions makes sense place asked web interface site already puts timestamps dates questions answers future visitors able see pay attention answer run rather old future state art significantly changed people free provide new answers add comments existing outdated answers people wrote original outdated answers still around also edit see example originally asked 7 years ago feasibility training artificial neural network play complex video game like diablo 2 time highly unlikely feasible however see answers written years later also see many edits question older answers reflect progress field
1,"<p>I am new to the field of Artificial Intelligence. And so are many. I searched for answers and there are many questions on this site about how to start learning AI. </p>

<p>Examples:
<a href=""https://ai.stackexchange.com/questions/3374/how-does-one-start-learning-artificial-intelligence"">How does one start learning artificial intelligence?</a></p>

<p><a href=""https://ai.stackexchange.com/questions/1913/steps-to-learn-artificial-intelligence-for-beginners"">Steps to learn Artificial Intelligence for beginners</a></p>

<p><a href=""https://ai.stackexchange.com/questions/2077/what-is-good-way-of-start-learning-ai-step-by-step"">What is good way of start learning AI step by step?</a></p>

<p><a href=""https://ai.stackexchange.com/questions/2253/where-should-i-start-learning-about-ai"">Where should I start learning about AI?</a></p>

<p><a href=""https://ai.stackexchange.com/questions/3291/how-can-i-start-learning-maths-for-machine-learning"">How can I start learning maths for machine learning?</a></p>

<p><a href=""https://ai.stackexchange.com/questions/4457/i-want-to-learn-ai-engineering-but-dont-know-where-to-start"">I want to learn AI Engineering but don&#39;t know where to start</a></p>

<p>Can all those questions be answered in a single question. I am requesting to the community members to take the initiative for asking a well framed question about it and contributing answers as well. </p>

<p>Thanks!</p>
",AImeta,new field artificial intelligence many searched answers many questions site start learning ai examples questions answered single question requesting community members take initiative asking well framed question contributing answers well thanks
1,"<p>Yeah, changing it to ""theory"" sounds good to me.</p>
",AImeta,yeah changing theory sounds good
1,"<p>There is a difference between disproven and out of vogue.  What is proven false, if the proof stands up to thorough scrutiny is unlikely to have any future value other than to demonstrate how some things that were once widely believed may be later disproven.  These are some examples.</p>

<ul>
<li>The sun travels around the earth.</li>
<li>Air, earth, water, and fire are the four elements.</li>
<li>All propositions within a mathematical system can be proven or disproven.</li>
<li>All natural phenomena can be placed in algebraic closed form.</li>
</ul>

<p>Many things that were thought absurd have been proven.</p>

<ul>
<li>Mercury is travelling too fast for its orbital path to be predicted by Newton's laws.</li>
<li>Humans can survive in space and return alive.</li>
<li>Computers can accurately and reliably sort mail with handwritten addresses.</li>
<li>Computers can be trained to generate pictures of interior designs.</li>
</ul>

<p>However, very little in a Q&amp;A community are theorem that can be proven or disproven though.  Much of what is discussed is technique (in the Jaques Ellul sense of the word) that may fall into voge and then out of vogue more than once.  Something that is thought to be obsolete (but not formally disproven) may rise back to common use or may return slowly from obsolescence over decades.  Here are just a few examples of this toggling evident today.</p>

<ul>
<li>Earth is round -> earth is flat -> earth is round</li>
<li>Vector graphics -> raster graphics -> vector graphics</li>
<li>Ether -> no ether -> ether</li>
<li>Turmeric -> chemotherapy -> turmeric</li>
<li>AI via imitating biology -> AI via logic -> AI via imitating biology</li>
</ul>

<p>Given the history of science and technology, unless we can flat out disprove an answer we cannot, solely on the basis of its current apparent obsolescence, assert that it will never return to the forefront.  It is rather highly probable that some thing we now consider obsolete will become a key element in the furtherance of one of the sub-fields of Artificial Intelligence.</p>

<p>Others in the future may look back and consider us ignorant for our current belief that some solution or approach is obsolete.</p>
",AImeta,difference disproven vogue proven false proof stands thorough scrutiny unlikely future value demonstrate things widely believed may later disproven examples sun travels around earth air earth water fire four elements propositions within mathematical system proven disproven natural phenomena placed algebraic closed form many things thought absurd proven mercury travelling fast orbital path predicted newton laws humans survive space return alive computers accurately reliably sort mail handwritten addresses computers trained generate pictures interior designs however little q community theorem proven disproven though much discussed technique jaques ellul sense word may fall voge vogue something thought obsolete formally disproven may rise back common use may return slowly obsolescence decades examples toggling evident today earth round earth flat earth round vector graphics raster graphics vector graphics ether ether ether turmeric chemotherapy turmeric ai via imitating biology ai via logic ai via imitating biology given history science technology unless flat disprove answer solely basis current apparent obsolescence assert never return forefront rather highly probable thing consider obsolete become key element furtherance one sub fields artificial intelligence others future may look back consider us ignorant current belief solution approach obsolete
1,"<p>SE.AI is a crowdsourcing platform comparable to Stackoverflow with an academic approach to discuss topics from Artificial Intelligence. It is open for everyone and the users can gain reputation by answering AI-related questions, for example about machine learning, algorithm theory and NLP. On the other side, the Arxiv website is a so called preprint server in which no discussion takes place, but the authors are uploading short papers of around 10 pages in the PDF format. The topics are the same like on SE.AI, that means it is about Artificial Intelligence. The problem with Arxiv is, that the website is restricted to the academic community.</p>

<p>Between SE.AI and Arxiv there is a gap. The postings in the online forum are short, in most cases only some paragraphs long, while the papers on Arxiv are the result of longer work. Become a member of SE.AI is easy, it is enough to press the “signup” button, but become an author in Arxiv is only possible for Phd students which have at least a 10 years career in Academia completed. The problem in Artificial Intelligence is, that most subjects are too complicated to discuss them without using the classical PDF format which contains of 20 pages and more. SE.AI is using URL references to papers on Arxiv, but it is not possible for SE.AI users to upload these papers.</p>

<p>So my question is: how to overcome the gap? Is it possible to lower the entry barrier in Arxiv, or is it possible to extend SE.AI with a preprint server for uploading papers?</p>
",AImeta,seai crowdsourcing platform comparable stackoverflow academic approach discuss topics artificial intelligence open everyone users gain reputation answering ai related questions example machine learning algorithm theory nlp side arxiv website called preprint server discussion takes place authors uploading short papers around 10 pages pdf format topics like seai means artificial intelligence problem arxiv website restricted academic community seai arxiv gap postings online forum short cases paragraphs long papers arxiv result longer work become member seai easy enough press signup button become author arxiv possible phd students least 10 years career academia completed problem artificial intelligence subjects complicated discuss without using classical pdf format contains 20 pages seai using url references papers arxiv possible seai users upload papers question overcome gap possible lower entry barrier arxiv possible extend seai preprint server uploading papers
1,"<p>I think the short answer is to look for solutions outside either AI Stack Exchange or Arxiv, and publish in some other form.</p>

<p>Blogging is a reasonable compromise. It is a longer-form format than Q&amp;A, less subject to rules to entry like Arxiv, and hosting services like <a href=""https://medium.com/"" rel=""nofollow noreferrer"">Medium</a> will get commonly-searched-for terms in front of interested people. Medium already has a strong presence of data science and reinforcement learning advice, with sample experiments and presentations of original ideas.</p>

<blockquote>
  <p>Is it possible to lower the entry barrier in Arxiv</p>
</blockquote>

<p>That's definitely beyond the remit of the AI Stack Exchange community. </p>

<p>Also, in my opinion, there would be a large risk to the reputation of Arxiv. For every well-meaning researcher that would try hard to be thorough, read the existing literature, and actually have something to contribute, there will be many people with other motivations, other levels of conscientiousness and other levels of ability. It would drown out the useful articles, and there are already far more articles than it is possible to read.</p>

<blockquote>
  <p>is it possible to extend SE.AI with a preprint server for uploading papers?</p>
</blockquote>

<p>Whilst it is technically possible, I'm not sure what it would add. For it to be meaningful, something has to happen to the ""papers"" after they are uploaded. Stack Exchange as it stands would allow for some comments/discussion about papers, and upvoting/downvoting them. </p>

<p>I think you may find yourself, out of the Stack Exchange community, in a small minority in wanting such a feature.</p>

<p>You could test this - it should be possible to create an Area 51 proposal which is about creating a beta site purely about reviewing semi-academic and pre-print academic ""papers"". Propose something such as the question text would be a synopsis plus a link to hosted PDF of the paper (perhaps uploaded/hosted by Stack Exchange), and answers would be critique of the paper using academic terminology - assessing it for presentation, technical merit, originality, potential impact. This could be framed as similar to <a href=""https://codereview.stackexchange.com/"">Code Review Stack Exchange</a> which made it out of Beta, so it seems workable.</p>

<p>There's a slight mismatch between Stack Exchange UI and what might work best for such pseudo-academic sharing and reviews. However, if you propose an idea like this, you can get some vague idea of support for it by responses in Area 51, even if they point out technical flaws but think the core idea has merit. Won't necessarily get what you want, but you'd get a sense of whether there are enough people interested that such a service could function. After all, there's no point you publishing your work if no-one is reading it.</p>

<p>Personally, I'd just blog about whatever you were researching. It's easy and the tools seem to fit what you want to do.</p>
",AImeta,think short answer look solutions outside either ai stack exchange arxiv publish form blogging reasonable compromise longer form format q less subject rules entry like arxiv hosting services like get commonly searched terms front interested people medium already strong presence data science reinforcement learning advice sample experiments presentations original ideas possible lower entry barrier arxiv definitely beyond remit ai stack exchange community also opinion would large risk reputation arxiv every well meaning researcher would try hard thorough read existing literature actually something contribute many people motivations levels conscientiousness levels ability would drown useful articles already far articles possible read possible extend seai preprint server uploading papers whilst technically possible sure would add meaningful something happen papers uploaded stack exchange stands would allow comments discussion papers upvoting downvoting think may find stack exchange community small minority wanting feature could test possible create area 51 proposal creating beta site purely reviewing semi academic pre print academic papers propose something question text would synopsis plus link hosted pdf paper perhaps uploaded hosted stack exchange answers would critique paper using academic terminology assessing presentation technical merit originality potential impact could framed similar made beta seems workable slight mismatch stack exchange ui might work best pseudo academic sharing reviews however propose idea like get vague idea support responses area 51 even point technical flaws think core idea merit necessarily get want would get sense whether enough people interested service could function point publishing work one reading personally would blog whatever researching easy tools seem fit want
1,"<p>Not sure if this is a bug, or maybe an improvement opportunity, but with my current settings I find the colours to be similar enough to cause confusion, I haven't experienced this in other sites. Could this be changed a little?</p>

<p>The visited link is the one from meta (congrats BTW).</p>

<p><a href=""https://i.stack.imgur.com/ZYwAR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZYwAR.png"" alt=""enter image description here""></a></p>
",AImeta,sure bug maybe improvement opportunity current settings find colours similar enough cause confusion experienced sites could changed little visited link one meta congrats btw
1,"<p>The current description for the AI.SE site is:</p>

<blockquote>
  <p>Q&amp;A for people interested in conceptual questions about life and
  challenges in a world where ""cognitive"" functions can be mimicked in
  purely digital environment</p>
</blockquote>

<p>Two years ago, the meta site <a href=""https://ai.meta.stackexchange.com/questions/1197/how-can-we-quickly-describe-our-site"">voted on site descriptions</a>. The current text is at 2 votes. There are other texts that have many more.</p>

<p>Further, the current text is out of sync with our votes on other factors, like <a href=""https://ai.meta.stackexchange.com/questions/1078/what-should-be-on-topic-modelling-or-implementation-or-anything-else"">whether modeling and implementation details should be on-topic or not</a>. </p>

<p>Someone has even <a href=""https://ai.meta.stackexchange.com/questions/1291/the-description-of-the-site-seems-incorrect"">pointed out this strangeness already</a>, with 9 upvotes, to no avail. Others asked for grammatical changes, and were told they <a href=""https://ai.meta.stackexchange.com/questions/1204/the-a-was-added-in-the-tour-but-not-in-the-site-description"">weren't needed</a> because we were about to change the site description. That was 2 years ago, and today it looks like this:</p>

<p><a href=""https://i.stack.imgur.com/PqPwo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PqPwo.png"" alt=""enter image description here""></a></p>

<ul>
<li><p>Is it possible to change the description at all? </p></li>
<li><p>If so, who can do it?</p></li>
<li><p>If so, what is required before those people will actually make the change?</p></li>
</ul>
",AImeta,current description aise site q people interested conceptual questions life challenges world cognitive functions mimicked purely digital environment two years ago meta site current text 2 votes texts many current text sync votes factors like someone even 9 upvotes avail others asked grammatical changes told change site description 2 years ago today looks like possible change description required people actually make change
1,"<p>I just looked around a bit and it turns out that moderators can edit that tour text. Our scope has changed and widened markedly from two years ago - those discussions were held before we even had our own moderators - so I think it'd be good to get fresh eyes and new thoughts on the tour blurb. Once we reach a consensus, I (and I'm sure my fellow mods too) would be happy to replace the current outdated text. As for the site description that appears in <a href=""https://stackexchange.com/sites#name"">the sites list</a>, we'll need to poke Stack Exchange staff to get that adjusted once we've decided on a replacement.</p>
",AImeta,looked around bit turns moderators edit tour text scope changed widened markedly two years ago discussions held even moderators think would good get fresh eyes new thoughts tour blurb reach consensus sure fellow mods would happy replace current outdated text site description appears need poke stack exchange staff get adjusted decided replacement
1,"<p>That would allow this structure, instead of trying to build tables with ASCII or UTF-8 characters, tedious to say the least.</p>

<pre><code>\begin{tabular}{ l c r }
  1 &amp; 2 &amp; 3 \\
  4 &amp; 5 &amp; 6 \\
  7 &amp; 8 &amp; 9 \\
\end{tabular}
</code></pre>

<p>The chosen answer below uses the following code, which works for non-numeric cell values as well.</p>

<pre><code>\begin{array} \\
  a &amp; b &amp; c \\
  4 &amp; 5 &amp; 6 \\
  7 &amp; 8 &amp; 9 \\
\end{array}
</code></pre>

<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;</p>

<p>\begin{array} \\
  a &amp; b &amp; c \\
  4 &amp; 5 &amp; 6 \\
  7 &amp; 8 &amp; 9 \\
\end{array}</p>

<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;</p>
",AImeta,would allow structure instead trying build tables ascii utf8 characters tedious say least begintabular l c r 1 3 4 6 7 9 endtabular chosen answer uses following code works non numeric cell values well beginarray c 4 6 7 9 endarray beginarray c 4 6 7 9 endarray
1,"<p>MathJax <a href=""https://github.com/mathjax/MathJax-docs/wiki/LaTeX-Tabular-environment"" rel=""nofollow noreferrer"">does not implement tabular</a>. One can <a href=""https://math.meta.stackexchange.com/a/6737"">use <code>array</code> instead</a>:
\begin{array}{ l c r }
  1 &amp; 2 &amp; 3 \\
  4 &amp; 5 &amp; 6 \\
  7 &amp; 8 &amp; 9 \\
\end{array}</p>

<p>But I usually prefer <a href=""https://senseful.github.io/text-table/"" rel=""nofollow noreferrer"">text to table</a> tool by Senseful, to avoid relying on JavaScript for rendering. </p>

<pre><code>+---+---+---+
| 1 | 2 | 3 |
| 4 | 5 | 6 |
| 7 | 8 | 9 |
+---+---+---+
</code></pre>
",AImeta,mathjax one beginarray l c r 1 3 4 6 7 9 endarray usually prefer tool senseful avoid relying javascript rendering 1 2 3 4 5 6 7 8 9
1,"<p>This is a question to ask the social engineers employed by those who own SE and SO, but I would like to vet it here before doing that.</p>
<p><strong>Background</strong></p>
<p>Consider that the SE/SO structure is, from one perspective, a game, whether or not it was intended to be. In the context of the best of the social networking models that have obtained some success on today's web, all of which were derived from or influenced by Morgenstern and von Neuman's <em>Game Theory</em>, gaming the system is what contributors to the content of the site do.</p>
<p>From a systems analysis perspective, whether their intention is any of the following or some proportional combination of them, playing for some objective can be proven as the prime motivator for all SE engagement.</p>
<ul>
<li>Obtaining an answer for use in a project or to satisfy an interest</li>
<li>Educating one's self by writing and evaluating responses</li>
<li>Educating others out of purpose driven or altruistic motivation</li>
<li>Gaining reputation to be seen in a community as an expert</li>
<li>Writing because of satisfaction in writing</li>
<li>Interest in public affirmation of intelligence or expertise</li>
<li>Intrinsic value of high numeric reputation resulting from good PR</li>
<li>Addictive compulsion lacking a cognitive cause</li>
<li>Some other reason</li>
</ul>
<p>The SE/SO system has adapted for the purposes of growth, and it works as is.  The original domain stackoverflow.com is rated 64th globally by Alexa, and the AI beta's main domain stackexchange.com is rated 127th.</p>
<p>In this context, the deltas aggregated in member reputation incentivizes behaviors that cause the increased growth of SE and SO through the system.</p>
<p><strong>How This Social Model Applies to Down Voting</strong></p>
<p>There are two distinct types of down votes.</p>
<ul>
<li>Anonymous down vote</li>
<li>Down vote with associated reasoning for it</li>
</ul>
<p>Both have purpose in that the identify a perceived error or inappropriateness of the Q or A.  Both currently have the same negative affect on the voter's reputation.</p>
<p>Is this optimal?</p>
<p><strong>Critique from a Social Network Equilibrium Perspective</strong></p>
<p>The advantage of the SE/SO system's game objective to humanity is that it helps the global development and dissemination of subject specific knowledge.  From a house (SE/SO business) perspective, it is to improve the domain's rating globally.</p>
<p>With regard to both of those game objectives, a down vote with an associated reason has greater value than an anonymous one in two respects.</p>
<ul>
<li>Anonymity decouples the down vote from an ethical incentive.</li>
<li>The expression of reasons provides additional information to both writer and the entire public readership.</li>
</ul>
<p>The current SE system merely indicates to the down voter that a reason in the comments is preferred.  It makes much more sense from an optimization point of view to use the reputation system to simultaneously.</p>
<ul>
<li>Incentivize against down voting with ulterior motives.</li>
<li>Incentivize <em>for</em> information transparency.</li>
</ul>
<p>The first is part of civilization in that those indicted can face their critic in academia and face their accuser in court.  The legal ethics behind this has much to do with the necessary checks and balances in civilized social structure.  The asymmetry of accountability in being able to dispute an answer and not being required to specify why leads to uncivilized behavior, which is why academia and ethically evolved legal systems do not permit it.</p>
<p><strong>Potentially Beneficial Change</strong></p>
<p>The overall metrics of satisfaction, positive impact on global understanding, and the value of the two domains (SO and SE) would likely be improved if transparency was not sacrificed for the sake of anonymity.</p>
<p>This is a potentially beneficial change.</p>
<blockquote>
<p>Anonymous down votes would still be permitted but a higher integer value would be subtracted from the voter's reputation than 1.</p>
<p>Reason associated down votes would not subtract anything from the voter's reputation, since the action has as much a reason to incentivize as a reason to incentivize against.</p>
</blockquote>
<p><strong>A Possible Implementation</strong></p>
<p>To implement such, in addition to the verbal encouragement of adding a comment when a down vote is cast, the comment field labeled, &quot;Reason for down vote,&quot; could be added with a minimum required number of words, the provision of which differentiates the two cases so that reputation adjustment could reflect the more optimal incentive model regarding down voting.</p>
<p><strong>Transparency With Anonymity</strong></p>
<p>Down voting transparency and anonymity could easily be achieved concurrently by creating an Anonymous user for such purposes.  This solves the problem of retaliatory conduct, but it may not solve the problem of asymmetric accountability, where one can harm another without any risk of consequences, which is a policy not found in well developed systems outside the SE/SO space.</p>
<p>The question then becomes, why did academia and ethical judicial systems require transparency without anonymity except when a child or undercover public servant is involved?</p>
",AImeta,question ask social engineers employed se would like vet background consider se structure one perspective game whether intended context best social networking models obtained success today web derived influenced morgenstern von neuman game theory gaming system contributors content site systems analysis perspective whether intention following proportional combination playing objective proven prime motivator se engagement obtaining answer use project satisfy interest educating one self writing evaluating responses educating others purpose driven altruistic motivation gaining reputation seen community expert writing satisfaction writing interest public affirmation intelligence expertise intrinsic value high numeric reputation resulting good pr addictive compulsion lacking cognitive cause reason se system adapted purposes growth works original domain stackoverflowcom rated 64th globally alexa ai beta main domain stackexchangecom rated 127th context deltas aggregated member reputation incentivizes behaviors cause increased growth se system social model applies voting two distinct types votes anonymous vote vote associated reasoning purpose identify perceived error inappropriateness q currently negative affect voter reputation optimal critique social network equilibrium perspective advantage se system game objective humanity helps global development dissemination subject specific knowledge house se business perspective improve domain rating globally regard game objectives vote associated reason greater value anonymous one two respects anonymity decouples vote ethical incentive expression reasons provides additional information writer entire public readership current se system merely indicates voter reason comments preferred makes much sense optimization point view use reputation system simultaneously incentivize voting ulterior motives incentivize information transparency first part civilization indicted face critic academia face accuser court legal ethics behind much necessary checks balances civilized social structure asymmetry accountability able dispute answer required specify leads uncivilized behavior academia ethically evolved legal systems permit potentially beneficial change overall metrics satisfaction positive impact global understanding value two domains se would likely improved transparency sacrificed sake anonymity potentially beneficial change anonymous votes would still permitted higher integer value would subtracted voter reputation 1 reason associated votes would subtract anything voter reputation since action much reason incentivize reason incentivize possible implementation implement addition verbal encouragement adding comment vote cast comment field labeled could added minimum required number words provision differentiates two cases reputation adjustment could reflect optimal incentive model regarding voting transparency anonymity voting transparency anonymity could easily achieved concurrently creating anonymous user purposes solves problem retaliatory conduct may solve problem asymmetric accountability one harm another without risk consequences policy found well developed systems outside se space question becomes academia ethical judicial systems require transparency without anonymity except child undercover public servant involved
1,"<p>I and many others would be very happy if people explained their downvotes more often. Essentially this request has been <a href=""https://meta.stackexchange.com/q/135/295684"">already been discussed on Meta Stack Exchange</a>. As a result, the ""please consider adding a comment if you think this post can be improved"" pop-up was added. However, adding an impact on reputation to commenting would damage anonymity and/or produce a spew of useless comments:</p>

<blockquote>
  <p>I enjoy being able to down-vote posts I don't care for without worrying about retaliation. And I really enjoy being able to leave honest comments without worrying that they'll be justifiably interpreted as evidence that I've down-voted. I would not like to see the two systems linked.</p>
</blockquote>

<p>&mdash;<a href=""https://meta.stackexchange.com/questions/135/encouraging-people-to-explain-downvotes/2373#comment313_135"">Shog9</a></p>

<blockquote>
  <p>The so-far-insurmountable problem is preventing users from just keyboard bashing ""aassdgfd"" if forced to type something.</p>
</blockquote>

<p>&mdash;<a href=""https://meta.stackexchange.com/questions/135/encouraging-people-to-explain-downvotes/2373#comment1384_135"">bananakata</a></p>

<p>Therefore, Stack Exchange seems to have decided not to implement further changes, and will probably not do so in the future.</p>

<p>Anonymity is important to allow people to vote as they believe without fear of retaliation (in the form of revenge downvoting). Stack Exchange's model has always been that people can vote however they like as long as they're not targeting specific users. A single user's votes might not be very illuminating, wisely cast, or <a href=""https://meta.stackexchange.com/a/215397/295684"">explicable at all</a>, but at scale votes usually average out to good rankings.</p>
",AImeta,many others would happy people explained downvotes often essentially request result please consider adding comment think post improved pop added however adding impact reputation commenting would damage anonymity andor produce spew useless comments enjoy able vote posts care without worrying retaliation really enjoy able leave honest comments without worrying justifiably interpreted evidence voted would like see two systems linked far insurmountable problem preventing users keyboard bashing aassdgfd forced type something therefore stack exchange seems decided implement changes probably future anonymity important allow people vote believe without fear retaliation form revenge downvoting stack exchange model always people vote however like long targeting specific users single user votes might illuminating wisely cast scale votes usually average good rankings
1,"<p>Per Moderator @BenN's request in <a href=""https://ai.meta.stackexchange.com/questions/1422/how-can-we-change-the-site-description-to-match-our-current-topic-guidelines-an/1423?noredirect=1#comment1708_1423"">this thread</a> to change the site description, we need to open a new thread and vote on new suggestions.</p>

<p>Please propose site description texts exactly as past users did in <a href=""https://ai.meta.stackexchange.com/questions/1197/how-can-we-quickly-describe-our-site"">this</a> older thread, and vote on the suggestions of other users. After a reasonable consensus is reached, the moderators will update the site descriptions to match the top voted answer.</p>

<p>For people new to this process, most of the AI SE suggestions in the past follow the convention of the descriptions of most SE sites and start with something like, ""Artificial Intelligence Stack Exchange is a question and answer site for ...""</p>
",AImeta,per moderator benn request change site description need open new thread vote new suggestions please propose site description texts exactly past users older thread vote suggestions users reasonable consensus reached moderators update site descriptions match top voted answer people new process ai se suggestions past follow convention descriptions se sites start something like artificial intelligence stack exchange question answer site
1,"<p>Artificial Intelligence Stack Exchange is a question and answer site for ...</p>
<blockquote>
<p>people interested in artificial intelligence theory, design, development and policy.</p>
<p> </p>
</blockquote>
<p>—————————</p>
<p><strong>GENERAL INFO FROM PAST DISCUSSION</strong></p>
<p><strong>Description Writing and Selection Criteria</strong></p>
<p>Some good points from others during 2016 through 2018 discussions.</p>
<ol>
<li>Keep the description concise (short but descriptive)</li>
<li>Capture the real interests of members</li>
<li>Consider new trends in Q&amp;A content (below)</li>
<li>Don't step into Data Sciences territory</li>
<li>Incorporate knowledge of tag use (below)</li>
</ol>
<p><strong>Top Tags</strong></p>
<ul>
<li>neural-networks</li>
<li>machine-learning</li>
<li>deep-learning</li>
<li>convolutional-neural-networks</li>
<li>reinforcement-learning</li>
<li>ai-design</li>
<li>image-recognition</li>
<li>algorithm</li>
<li>classification</li>
<li>training</li>
<li>natural-language-processing</li>
<li>game-ai</li>
</ul>
<p><strong>Fast Growing Newer Tags</strong></p>
<ul>
<li>neuromorphic-engineering</li>
<li>natural-language</li>
<li>lstm</li>
</ul>
<p><strong>Some AI Trends in Recent Q&amp;A</strong></p>
<ul>
<li>Hardware parallelism with clusters, GPUs, and AI cores</li>
<li>Embedded AI for robotics</li>
<li>Neuromorphic and spiking network libraries and VLSI chips</li>
<li>Smart surveillance</li>
<li>Autonomous vehicles</li>
<li>Policy is forming around labor concerns and AI deployment</li>
</ul>
",AImeta,artificial intelligence stack exchange question answer site people interested artificial intelligence theory design development policy general info past discussion description writing selection criteria good points others 2016 2018 discussions keep description concise short descriptive capture real interests members consider new trends q content step data sciences territory incorporate knowledge tag use top tags neural networks machine learning deep learning convolutional neural networks reinforcement learning ai design image recognition algorithm classification training natural language processing game ai fast growing newer tags neuromorphic engineering natural language lstm ai trends recent q hardware parallelism clusters gpus ai cores embedded ai robotics neuromorphic spiking network libraries vlsi chips smart surveillance autonomous vehicles policy forming around labor concerns ai deployment
1,"<p>Artificial Intelligence Stack Exchange is a question and answer site for ...</p>

<blockquote>
  <p>people interested in artificial intelligence theory, design,
  development, <strong>practice</strong>, <strong>research</strong>, and policy.</p>
</blockquote>

<p>I like @DouglasDaseeco's answer, but I'm among the users who think that practice, <em>and even code</em>, have a place here. Presently users post questions containing code, and I and others answer them, so I think this description is more accurate.</p>

<p>While the founding moderators' intent was to exclude questions that overlapped with other sites (notably Data Science &amp; Programmers.SE), the boundaries are quite porous in practice, and if we want to claim to be a useful place for AI related Q&amp;A on the web, I think we need to accept practical questions as well.</p>

<p>Some examples of coding questions with no other place to go include:</p>

<p><a href=""https://ai.stackexchange.com/questions/7555/keeping-track-of-visited-states-in-breadth-first-search/7560#7560"">Keeping track of visited states in Breadth-first Search</a>, which is about the proper data structures to use in a search algorithm. It doesn't belong in Data Science, since it is related to GOFAI and not machine learning. It doesn't really belong in Programmers.SE, because it isn't a generic question about programming, it's related to understanding the algorithm. It seems to clearly belong on this site, and yet it includes code and is about practice.</p>

<p><a href=""https://ai.stackexchange.com/questions/7940/snake-game-snake-converges-to-going-in-the-same-direction-every-time/7941#7941"">Snake game: snake converges to going in the same direction every time</a> This question was about the implementation of a reinforcement learning algorithm. The question again has nothing to do with Data Science. It involves programming, but the users' problems were not related to understanding how to program, but to understanding the algorithm (and, as it turned out, the exact behaviour of a particular algorithm for training neural networks). This user is not likely to get useful answers on Programmers.SE. It seems to clearly belong on this site, and yet it also includes code and is about practice.</p>
",AImeta,artificial intelligence stack exchange question answer site people interested artificial intelligence theory design development practice research policy like douglasdaseeco answer among users think practice even code place presently users post questions containing code others answer think description accurate founding moderators intent exclude questions overlapped sites notably data science web think need accept practical questions well examples coding questions place go include proper data structures use search algorithm belong data science since related gofai machine learning really belong programmersse generic question programming related understanding algorithm seems clearly belong site yet includes code practice question implementation reinforcement learning algorithm question nothing data science involves programming users problems related understanding program understanding algorithm turned exact behaviour particular algorithm training neural networks user likely get useful answers programmersse seems clearly belong site yet also includes code practice
1,"<p>I'd like it short and simple:</p>

<blockquote>
  <p>Artificial Intelligence Stack Exchange is a question and answer site
  for people interested in thinking machines. Join them; it only takes a
  minute:</p>
</blockquote>
",AImeta,would like short simple artificial intelligence stack exchange question answer site people interested thinking machines join takes minute
1,"<p>I think the number of votes is also a factor.  Right now, on SE:AI, we have relatively low voting participation.  This makes us a tough stack to build rep on, but it also makes the solo downvotes stick out.  </p>

<p>Compare to a stack where there questions and answers receive a large number of votes quickly. When voting activity is high, the random downvotes have less of an impact.</p>

<p>So, in some sense, the solution is to keep working to attract users, and boost the voting levels.</p>

<hr>

<p>I have seen what I believe to be pro forma, serial downvoting in the past on SE:AI.  My remedy for that has been to look at all new questions every day <em>(been slacking lately, admittedly,)</em> and make a point of upvoting questions I think have been unfairly downvoted.</p>

<p>With answers, it's a little tougher b/c one doesn't want to up or downvote without a high degree of confidence.  </p>
",AImeta,think number votes also factor right se ai relatively low voting participation makes us tough stack build rep also makes solo downvotes stick compare stack questions answers receive large number votes quickly voting activity high random downvotes less impact sense solution keep working attract users boost voting levels seen believe pro forma serial downvoting past se ai remedy look new questions every day slacking lately admittedly make point upvoting questions think unfairly downvoted answers little tougher b c one want downvote without high degree confidence
1,"<p>Artificial Intelligence Stack Exchange is a question and answer site for ...</p>

<blockquote>
  <p>people interested in artificial intelligence research, theory, algorithms, application, evaluation, policy, and global impact.</p>
</blockquote>

<p>The earlier answer that led to this option had ""Those involved with,"" in place of, ""People interested in.""  The difference is how much involvement we imply members have.  There would be no actual restriction.  The only actual difference between these is whether we encourage Q&amp;A to be contributed by people that are somehow involved with AI or just watching the news about it and have naturally become curious.  It relates to the quality of content and the care in posting, not policy or exclusiveness.</p>

<ul>
<li>Those involved with</li>
<li>People interested in</li>
</ul>
",AImeta,artificial intelligence stack exchange question answer site people interested artificial intelligence research theory algorithms application evaluation policy global impact earlier answer led option involved place people interested difference much involvement imply members would actual restriction actual difference whether encourage q contributed people somehow involved ai watching news naturally become curious relates quality content care posting policy exclusiveness involved people interested
1,"<p>I think we should also provide guidance to users about which questions may be more suitable for Data Science, Overflow, etc.  </p>
",AImeta,think also provide guidance users questions may suitable data science overflow etc
1,"<p><strong>Realities of Overlap</strong></p>
<p>There are two sub-sites of stackexchange.com with overlapping topic space with Artificial Intelligence.</p>
<ul>
<li>Cross Validated at <a href=""https://stats.stackexchange.com"">https://stats.stackexchange.com</a></li>
<li>Data Science at <a href=""https://datascience.stackexchange.com"">https://datascience.stackexchange.com</a></li>
</ul>
<p>The spread of data-centrism<sup>1</sup> throughout multiple Stack Exchange sub-sites should not be surprising given its rise in funding, and some have noted that overlap is inevitable.  Still, Franck Dernoncourt and Robert Cartaino expressed concern about this overlap in the past Q&amp;A posts referenced in this question text.</p>
<p><strong>Distinctions</strong></p>
<p>However data intelligence is a subset of smaller proportion in relation to the entire field of artificial intelligence than public media and SE discourse suggest.  The flow of funding and actual research is not all public.</p>
<p>Also of note is that others have suggested throughout the Artificial Intelligence Q&amp;A that machine learning is distinct from artificial intelligence.  Although there is obvious overlap in the literature and in practice, one can easily argue that point.</p>
<ul>
<li>There are things machines learn that to use the term intelligence would be a gross stretch of the meaning of the term</li>
<li>There are elements of artificial intelligence systems that are deliberately and effectively not mechanical</li>
<li>There are elements of both biological and artificial systems that have inherited intelligence, DNA based in biology, hard coded learning software, and likely VLSI algorithm realization in the near future</li>
</ul>
<p><strong>AI Foundations Rest in Theory and Action Rather Than Data</strong></p>
<p>The foundation of AI is not data-centrism but rather cybernetics, kick started by cold war funding of ICBM countermeasures under Reagan. Concurrent with data-centrism is the serious investment into real time embedded AI for transportation, factory defect reduction, and smart home robotics.</p>
<p>Automated mathematics (Leibniz) is also well funded &amp; lacks data in the conventional sense.</p>
<p>In the (by far) <a href=""https://ai.meta.stackexchange.com/questions/1197/how-can-we-quickly-describe-our-site/1199#1199"">most popular answer on this topic</a>, Robert Cartaino wrote,</p>
<blockquote>
<p>&quot;With autonomous cars, smart surveillance, and 'the next big thing' capturing the headlines, this isn't a terrible idea for a subject. Draping it in the popular AI label gives it a better focus, and it completely disambiguate[s] that this is not a technical implementation or programming site. We already have that.&quot;</p>
</blockquote>
<p><strong>Possible Shift May be Indicated</strong></p>
<p>For the above reasons and the plethora of truly distinctive questions dating to the initial proposal of this site<sup>2</sup>, it is important to also list the following categorically different (and therefore probably unpopular) possible direction in the site description.</p>
<hr />
<p><strong>Artificial Intelligence Stack Exchange is a question and answer site for ...</strong></p>
<blockquote>
<p><strong>people interested in embedded, mathematical, cognitive, and discovery centered artificial intelligence research and development.</strong></p>
</blockquote>
<p>There would be much less overlap and, in case the data-centrism craze dies down, which many in the absence of any historical perspective assume would never occur, this AI sub-site would have much stronger long term viability.</p>
<hr />
<p><strong>Footnote</strong></p>
<p>[1] Data-centrism, the belief that in data lies the truth, strongly supported by statistics and probability and criticized as pointing human activity randomly and without progressive objective, is increasingly the dominant perspective of the cultures of developed regions.  Success with mining, ranking, and indexing and the power that practitioners such as Google Inc. have gained globally through the realization of what was once a card catalog in the local library drive this philosophic paradigm shift.</p>
<p>[2] An example of one of the many early questions that are not data-centric but classical and of enduring importance to the development of artificial intelligence is this one from the proposal phase of the AI sub-site: <a href=""https://ai.stackexchange.com/questions/15/is-the-turing-test-or-any-of-its-variants-a-reliable-test-of-artificial-intell"">Is the Turing Test, or any of its variants, a reliable test of artificial intelligence?</a></p>
",AImeta,realities overlap two sub sites stackexchangecom overlapping topic space artificial intelligence cross validated data science spread data centrism 1 throughout multiple stack exchange sub sites surprising given rise funding noted overlap inevitable still franck dernoncourt robert cartaino expressed concern overlap past q posts referenced question text distinctions however data intelligence subset smaller proportion relation entire field artificial intelligence public media se discourse suggest flow funding actual research public also note others suggested throughout artificial intelligence q machine learning distinct artificial intelligence although obvious overlap literature practice one easily argue point things machines learn use term intelligence would gross stretch meaning term elements artificial intelligence systems deliberately effectively mechanical elements biological artificial systems inherited intelligence dna based biology hard coded learning software likely vlsi algorithm realization near future ai foundations rest theory action rather data foundation ai data centrism rather cybernetics kick started cold war funding icbm countermeasures reagan concurrent data centrism serious investment real time embedded ai transportation factory defect reduction smart home robotics automated mathematics leibniz also well funded lacks data conventional sense far robert cartaino wrote possible shift may indicated reasons plethora truly distinctive questions dating initial proposal site 2 important also list following categorically different therefore probably unpopular possible direction site description artificial intelligence stack exchange question answer site people interested embedded mathematical cognitive discovery centered artificial intelligence research development would much less overlap case data centrism craze dies many absence historical perspective assume would never occur ai sub site would much stronger long term viability footnote 1 data centrism belief data lies truth strongly supported statistics probability criticized pointing human activity randomly without progressive objective increasingly dominant perspective cultures developed regions success mining ranking indexing power practitioners google inc gained globally realization card catalog local library drive philosophic paradigm shift 2 example one many early questions data centric classical enduring importance development artificial intelligence one proposal phase ai sub site
1,"<p>I'm wondering if this should be a single tag.  However, if we do keep them as separate tags, how do we disambiguate?</p>

<p><a href=""https://ai.stackexchange.com/questions/tagged/natural-language"">natural-language</a></p>

<p><a href=""https://ai.stackexchange.com/questions/tagged/natural-language-processing"">natural-language-processing</a></p>
",AImeta,wondering single tag however keep separate tags disambiguate
1,"<p>It looks to me like they are both used for similar questions, and based on the current Tag Info for the two tags they don't really appear to be different either. So, based on current tag usage, I'd argue that they should be combined into a single tag (which, in my opinion, should be <code>natural-language-processing</code> because that's the full term that everyone in the field uses in my experience).</p>

<p>I suppose that, in theory, <code>natural-language</code> could refer to something else than NLP... like, it could be for questions about language itself, rather than questions about processing (generating and/or understanding) language. I have a very difficult time imagining any such questions would actually be on-topic for AI though.</p>
",AImeta,looks like used similar questions based current tag info two tags really appear different either based current tag usage would argue combined single tag opinion full term everyone field uses experience suppose theory could refer something else nlp like could questions language rather questions processing generating andor understanding language difficult time imagining questions would actually topic ai though
1,"<p>There is a key difference between the two terms.  Whether this finer level of granularity is useful in the tags, I have no opinion.</p>

<p>Natural language is concerned with the general idea of conveying ideas via vocalization and the comprehension of the idea by a listener.</p>

<p>Natural language processing sounds more well defined, but it is actually poorly defined and the definitions in the literature are scattered between these two extremes:</p>

<ol>
<li>Parsing text into linguistic structures.</li>
<li>Linguistic processing components in chat-bots designed to replace human experts.</li>
</ol>

<p>What is included in NLP?</p>

<ul>
<li>Talking?</li>
<li>Generating text?</li>
<li>Generating linguistic associations?</li>
<li>Parsing text?</li>
<li>Hearing?</li>
<li>Listening?</li>
<li>Dialog?</li>
<li>Topic detection?</li>
<li>Cognition?</li>
<li>Story invocation? &mdash; See Schank.</li>
<li>Translation?</li>
</ul>

<p>Depends on who is teaching and when.  I don't even see any consistency between the same person's view of NLP over time.</p>

<p>If addressing the terms literally, natural language is simply the field of linguistics minus the addition of formal languages.  NLP would then become the action that occurs when some system deals with natural language at either its input, its output, or both.</p>

<p>I saw those two tags earlier today.  I don't have a recommendation as to whether to combine them or leave them alone.</p>
",AImeta,key difference two terms whether finer level granularity useful tags opinion natural language concerned general idea conveying ideas via vocalization comprehension idea listener natural language processing sounds well defined actually poorly defined definitions literature scattered two extremes parsing text linguistic structures linguistic processing components chat bots designed replace human experts included nlp talking generating text generating linguistic associations parsing text hearing listening dialog topic detection cognition story invocation see schank translation depends teaching even see consistency person view nlp time addressing terms literally natural language simply field linguistics minus addition formal languages nlp would become action occurs system deals natural language either input output saw two tags earlier today recommendation whether combine leave alone
1,"<p>The two leaders are ...</p>

<blockquote>
  <p>people interested in artificial intelligence theory, design, development, practice, research, and policy.</p>
</blockquote>

<p>... and ...</p>

<blockquote>
  <p>people interested in embedded, mathematical, cognitive, and discovery centered artificial intelligence research and development.</p>
</blockquote>

<p>... so I propose the union.</p>

<blockquote>
  <p><strong>people interested in AI theory, mathematics, research, discovery, design, development, practice, embedded uses, cognition, policy, and impact.</strong></p>
</blockquote>

<hr>

<p>This one is inclusive and dodges the terms <em>statistics</em> and <em>data science</em> which are the explicit domains of established SE siblings.</p>
",AImeta,two leaders people interested artificial intelligence theory design development practice research policy people interested embedded mathematical cognitive discovery centered artificial intelligence research development propose union people interested ai theory mathematics research discovery design development practice embedded uses cognition policy impact one inclusive dodges terms statistics data science explicit domains established se siblings
1,"<p>Has anyone tried to approximate the percentage of questions posted here that are also on-topic on Cross Validated and Data Science?</p>
",AImeta,anyone tried approximate percentage questions posted also topic cross validated data science
1,"<p>That's as subjective as asking any of these four.</p>

<ul>
<li>What % of cross validated questions are also on topic on data science?</li>
<li>What % of data science questions are also on topic on cross validated?</li>
<li>What % of cross validated questions fit better into the wider AI field?</li>
<li>What % of data science questions fit better into the wider AI field?</li>
</ul>

<p>If we asked a thousand people these five questions independently, we'd probably not get a single exact duplicate.  If we ran the tuples of five answers from each of the thousand as one input vector per example into an auto-encoder, we'd probably get a few dozen distinct groupings out of the thousand examples.</p>

<p>If someone donated a few hundred thousand to set up the focus group, we'd probably be able to draw some more objective conclusion.</p>
",AImeta,subjective asking four cross validated questions also topic data science data science questions also topic cross validated cross validated questions fit better wider ai field data science questions fit better wider ai field asked thousand people five questions independently would probably get single exact duplicate ran tuples five answers thousand one input vector per example auto encoder would probably get dozen distinct groupings thousand examples someone donated hundred thousand set focus group would probably able draw objective conclusion
1,"<p>If I put quotes around the two terms and do a web search, the documents in the search results are very different, and the definitions of the terms don't match either.  Natural language is mostly used as part of the social sciences, and NLP is mostly used in computer science and programming.</p>
",AImeta,put quotes around two terms web search documents search results different definitions terms match either natural language mostly used part social sciences nlp mostly used computer science programming
1,"<p>The condition is related to the beta process definition and incentives built into the back end rules and user interface rules.  These are created and maintained based on the analysis of trends and the projections of that analysis by the owners of the system upon which the domains stackexchange.com and stackoverflow.com sit.</p>

<p>Members, especially moderators and even more so diamond moderators, can mitigate the inevitable chaos that forms in any large account based network by choosing names and definitions that are likely to disambiguate options that users have.  People can also request features and enhancements that may modify incentives in positive ways.</p>

<p>To meaningfully do any of these things it is important to understand that knowledge is segmented in some ways and homogeneous in other ways.  Forcing questions into clean compartments is not even done at universities with curricula.  In fact, trends toward interdisciplinary work are usually found at the most progressive universities and offered to the highest performing students.</p>

<p>The natural overlap of human discovery and achievement cannot be changed by any web site incentives system.  Even the extreme measures of totalitarianism, jihad, or martial law are unlikely to bring about compartmentalized knowledge, mostly because smart people won't put up with it and will literally shoot back if pushed too far.</p>

<p>Artificial intelligence was born of interdisciplinary thinking, and is bound only by two things.</p>

<ul>
<li>It concerns primarily what can be artificially created</li>
<li>It concerns primarily how to make choices that produce better results than arbitrary selection</li>
</ul>

<p>Some may argue this.  I won't because I've heard all the arguments otherwise, and they lack merit to the degree that further response is ... .</p>

<p>Regarding the current machine learning trend, it is primarily social and economic phenomenon that may or may not sustain.  Recognizing that what goes up often comes down is another key to making choices today that we don't regret later.</p>

<p>At one time, stone work was a technology that bled into every topic.  In 100 years,  one may not be able to find the phrase, ""Machine learning,"" in a recent piece of media.  Perhaps nanotech-genetic portals might have become the craze, where people are id-based swallowed by their cars and homes instead of unlocking doors and keying alarm codes.  Or not.</p>

<p>It could go the other way where people write ML algorithms that write poems instead of writing poems.  People might go to art museums and plug their mind into the Salvador Dali machine and their friends might laugh at their Dali-ized creative thoughts seen on a 4 dimensional canvas.</p>

<p>In today's SE/SO reality, the best we can do is to consider naming and defining sites and tags based on a balance between currently common use of terms, the literal meaning of the words that comprise the term, and the overarching pattern of academics, publication, and terminology in those two places and on the web.</p>

<p>My gut feel is that excessive control will do the exact opposite of balance and push everyone with a brain away from the entire SE/SO engagement model and other sites with more incentive and less control will capture those emigrants.</p>
",AImeta,condition related beta process definition incentives built back end rules user interface rules created maintained based analysis trends projections analysis owners system upon domains stackexchangecom stackoverflowcom sit members especially moderators even diamond moderators mitigate inevitable chaos forms large account based network choosing names definitions likely disambiguate options users people also request features enhancements may modify incentives positive ways meaningfully things important understand knowledge segmented ways homogeneous ways forcing questions clean compartments even done universities curricula fact trends toward interdisciplinary work usually found progressive universities offered highest performing students natural overlap human discovery achievement changed web site incentives system even extreme measures totalitarianism jihad martial law unlikely bring compartmentalized knowledge mostly smart people put literally shoot back pushed far artificial intelligence born interdisciplinary thinking bound two things concerns primarily artificially created concerns primarily make choices produce better results arbitrary selection may argue heard arguments otherwise lack merit degree response regarding current machine learning trend primarily social economic phenomenon may may sustain recognizing goes often comes another key making choices today regret later one time stone work technology bled every topic 100 years one may able find phrase machine learning recent piece media perhaps nanotech genetic portals might become craze people id based swallowed cars homes instead unlocking doors keying alarm codes could go way people write ml algorithms write poems instead writing poems people might go art museums plug mind salvador dali machine friends might laugh dali ized creative thoughts seen 4 dimensional canvas today se reality best consider naming defining sites tags based balance currently common use terms literal meaning words comprise term overarching pattern academics publication terminology two places web gut feel excessive control exact opposite balance push everyone brain away entire se engagement model sites incentive less control capture emigrants
1,"<p>I was quite surprised to see this question migrated from AI Stack Exchange to Data Science:</p>

<ul>
<li><a href=""https://datascience.stackexchange.com/questions/39279/dqn-cannot-learn-or-converge"">https://datascience.stackexchange.com/questions/39279/dqn-cannot-learn-or-converge</a></li>
</ul>

<p>There are two reasons that I am surprised:</p>

<ul>
<li><p>In my opinion, Reinforcement Learning is not really a data science or statistics subject. Some of the toolkit is the same (mainly neural networks), but the resulting system is different.</p></li>
<li><p>In my opinion, the AI stack exchange is where I would <em>expect</em> to see practical discussions of agents that learn how to behave rationally in environments. This encompasses RL and other approaches to creating behaviours or policies, such as NEAT.</p></li>
</ul>

<p>In fact I have just encouraged a recent poster with a practical RL question on Cross Validated (why is a Q learning on Towers of Hanoi not working) to post here . . . should I have done? Do we want that kind of question?</p>

<p>I would like to open a discussion:</p>

<blockquote>
  <p>What makes a question which is obviously about Reinforcement Learning on or off topic at AI Stack Exchange?</p>
</blockquote>

<p>Some thoughts:</p>

<ul>
<li><p>Are questions about implementing RL algorithms with code snippets on-topic here (assuming code problems are not trivial such as Python syntax errors)?</p>

<ul>
<li>The example question that was migrated to DataScience is in this category.</li>
</ul></li>
<li><p>Are questions about theory of maths behind RL on topic here, such as understanding proof of the Policy Improvement Theory or deriving Policy Gradients? </p>

<ul>
<li>The maths of RL is easily as complex as anything discussed on CrossValidated. In fact Cross Validated already has many RL questions about these topics. Are they really statistics questions though - should they in fact be migrated <em>here</em>?</li>
</ul></li>
</ul>

<p>My personal opinion is that both kinds of questions should be on-topic here. In fact I am hard pushed to come up with an RL question which would not be on topic. That doesn't prevent some subset of RL questions being on-topic elsewhere too. But here is where I would expect them <em>all</em> to be on-topic. That is not to say that I would expect them all to remain open or get answers - some might be low quality or not answerable for other reasons.</p>

<p>But is my opinion out of step with others on the site? Have I made some incorrect assumption about the scope of this stack?</p>
",AImeta,quite surprised see question migrated ai stack exchange data science two reasons surprised opinion reinforcement learning really data science statistics subject toolkit mainly neural networks resulting system different opinion ai stack exchange would expect see practical discussions agents learn behave rationally environments encompasses rl approaches creating behaviours policies neat fact encouraged recent poster practical rl question cross validated q learning towers hanoi working post done want kind question would like open discussion makes question obviously reinforcement learning topic ai stack exchange thoughts questions implementing rl algorithms code snippets topic assuming code problems trivial python syntax errors example question migrated datascience category questions theory maths behind rl topic understanding proof policy improvement theory deriving policy gradients maths rl easily complex anything discussed crossvalidated fact cross validated already many rl questions topics really statistics questions though fact migrated personal opinion kinds questions topic fact hard pushed come rl question would topic prevent subset rl questions topic elsewhere would expect topic say would expect remain open get answers might low quality answerable reasons opinion step others site made incorrect assumption scope stack
1,"<p>I like the question “DQN can't learn or converge” very much. Because it shows the limits of a neural network. Somebody has trained a network, has done everything right with Python and OpenAI gym, gets the resulting errorplot of his model and doesn't understand why his agent is not improving anymore.</p>

<p>But in which forum fits this question, in AI.SE or somewhere else? I think, that any question can be migrated to datascience because this helps to reduce the load in SE.AI. And if the traffic is low we can shutdown the website as soon as possible. I'd like to a see a status message that AI.SE is no longer available because of technical problems.</p>
",AImeta,like question dqn learn converge much shows limits neural network somebody trained network done everything right python openai gym gets resulting errorplot model understand agent improving anymore forum fits question aise somewhere else think question migrated datascience helps reduce load seai traffic low shutdown website soon possible would like see status message aise longer available technical problems
1,"<p>The migration of this question to datascience seems <strong>really strange</strong> to me. Like you said, RL really is pretty much <strong>the furthest removed from data science out of all Machine Learning topics</strong>, even if it were off-topic on AI for whatever reason, it certainly wouldn't be on-topic on Data Science.</p>

<p>To address specifically the question in the title, the I'd say pretty much any Reinforcement Learning question is on-topic on AI.se (AI certainly seems a better fit for RL questions than either stats.se or datascience.se), <strong>except maybe</strong> questions that are 100% clearly about programming issues/bugs. For example, a question like ""My RL algorithm is crashing, here is the stack trace, what's wrong?"" Such questions might be a better fit on StackOverflow (still <strong>not</strong> datascience).</p>

<p>This particular question that got migrated <strong>might</strong> fit that description... but it's not certain. The question-asker is not certain if it's a bug in their code, or if there is some issue in choice of algorithm for this particular environment or something along those lines. In my opinion, whenever there is that level of uncertainty, the question is likely to require expertise in AI (specifically, in RL), not just programming expertise because it might not be just a programming issue. That makes, in my opinion, AI.se a better fit than StackOverflow.se (or any other site).</p>
",AImeta,migration question datascience seems really strange like said rl really pretty much furthest removed data science machine learning topics even topic ai whatever reason certainly would topic data science address specifically question title would say pretty much reinforcement learning question topic aise ai certainly seems better fit rl questions either statsse datasciencese except maybe questions 100 clearly programming issues bugs example question like rl algorithm crashing stack trace wrong questions might better fit stackoverflow still datascience particular question got migrated might fit description certain question asker certain bug code issue choice algorithm particular environment something along lines opinion whenever level uncertainty question likely require expertise ai specifically rl programming expertise might programming issue makes opinion aise better fit stackoverflowse site
1,"<p>When I voted to close a purely data science question that appeared in the First Question queue and selected the option that it was more appropriate for another site, the AI meta was listed as the only option in the subsequent page.  Neither data science nor cross validated were listed.  Can configuration be updated to facilitate what it seems to be somewhat unanimously believed, that data science questions are better located in DS than AI?</p>

<p>REF: <a href=""https://ai.stackexchange.com/questions/8298/keras-get-back-labels-from-a-model"">Keras : get back labels from a model</a></p>
",AImeta,voted close purely data science question appeared first question queue selected option appropriate another site ai meta listed option subsequent page neither data science cross validated listed configuration updated facilitate seems somewhat unanimously believed data science questions better located ds ai ref
1,"<p><strong>More Specifically</strong></p>
<blockquote>
<p>Should a new question, <span class=""math-container"">$Q_2$</span>, be posted when question <span class=""math-container"">$Q_1$</span> has already been answered and there is a distinctly new question that draws substantially on the content of <span class=""math-container"">$Q_1$</span>, or should <span class=""math-container"">$Q_1$</span> be extended to keep the content together?</p>
</blockquote>
<p><strong>Most Recent of Several Similar Examples</strong></p>
<p>In a <a href=""https://ai.stackexchange.com/questions/8128/difficulty-in-understanding-identifiability-in-dueling-network-paper"">recently active AI SE question</a>, moderator BartoszKP commented.</p>
<blockquote>
<p>SE format is not a discussion board. You should not keep updating the question, and thus mutating the topic. If you have another question, just post a follow-up as a separate Q&amp;A.</p>
</blockquote>
<p>The question author disagreed with that comment, stating that the content was closely related and should be kept together.  BartoszKP further commented as follows.</p>
<blockquote>
<p>Yes, the purpose of the site is to create a knowledge base for everyone. It should however be a knowledge base consisting of specific questions and specific answers, not chat history between you and the one who answers.</p>
</blockquote>
<p>I edited the question referenced above to remove all the conversation with those that answered (which became a small project, much to my dismay), but the previous versions in combination with the discussion in comments displays much dialog and two distinct and significant extensions of the original question requirements.</p>
<p><strong>Related Stack Exchange and Overflow Positions</strong></p>
<p>I notice that the <a href=""https://ai.stackexchange.com/tour"">AI Tour</a> sets forth some related principles.</p>
<blockquote>
<p>This site is all about getting answers. It's not a discussion forum, ...</p>
<p>Use edits to fix mistakes, improve formatting, or clarify the meaning of a post.</p>
</blockquote>
<p><strong>Not Just The Example Above</strong></p>
<p>Several Q&amp;A scenarios in AI SE have gone through sequential changes in this way so that all those who answer had to choose between these two somewhat counterproductive options.</p>
<ol>
<li>Let their answer go stale in relation to a much extended question</li>
<li>Be dragged along by those in the SO meta term a <em>Help Vampire</em></li>
</ol>
<p>Editing a question to ask additional questions renders all the answers stale and effectively drags all those who worked to answer your original question to keep their answers aligned.</p>
<p><strong>Back to the This Main Question</strong></p>
<blockquote>
<p>Should a new question, <span class=""math-container"">$Q_2$</span>, be posted when question <span class=""math-container"">$Q_1$</span> has already been answered and there is a distinctly new question that draws substantially on the content of <span class=""math-container"">$Q_1$</span>, or should <span class=""math-container"">$Q_1$</span> be extended to keep the content together?</p>
</blockquote>
<p><strong>Some SO Meta Wisdom</strong></p>
<p>It seems the SO wisdom<sup>1, 2</sup> is that a new question <span class=""math-container"">$Q_2$</span> should be posted.  That would also solve the issue of choosing between stale answers and help vampirism, but it may not be popular with a Q author and A author that are essentially collaborating on a small project together and are fully engaged in an extended helping process.</p>
<p><strong>References</strong></p>
<p>[1] <a href=""https://meta.stackoverflow.com/questions/252113/how-to-deal-with-constant-changing-questions"">https://meta.stackoverflow.com/questions/252113/how-to-deal-with-constant-changing-questions</a></p>
<p>[2] <a href=""https://meta.stackoverflow.com/questions/300966/dealing-with-solutions-that-end-with-a-new-error"">https://meta.stackoverflow.com/questions/300966/dealing-with-solutions-that-end-with-a-new-error</a></p>
",AImeta,specifically new question q_2 posted question q_1 already answered distinctly new question draws substantially content q_1 q_1 extended keep content together recent several similar examples moderator bartoszkp commented se format discussion board keep updating question thus mutating topic another question post follow separate q question author disagreed comment stating content closely related kept together bartoszkp commented follows yes purpose site create knowledge base everyone however knowledge base consisting specific questions specific answers chat history one answers edited question referenced remove conversation answered became small project much dismay previous versions combination discussion comments displays much dialog two distinct significant extensions original question requirements related stack exchange overflow positions notice sets forth related principles site getting answers discussion forum use edits fix mistakes improve formatting clarify meaning post example several q scenarios ai se gone sequential changes way answer choose two somewhat counterproductive options let answer go stale relation much extended question dragged along meta term help vampire editing question ask additional questions renders answers stale effectively drags worked answer original question keep answers aligned back main question new question q_2 posted question q_1 already answered distinctly new question draws substantially content q_1 q_1 extended keep content together meta wisdom seems wisdom 1 2 new question q_2 posted would also solve issue choosing stale answers help vampirism may popular q author author essentially collaborating small project together fully engaged extended helping process references 1 2
1,"<p>We had this here: <a href=""https://ai.stackexchange.com/questions/8408/is-there-any-pretrained-model-for-emotion-detection/8409#8409"">Is there any pretrained model for emotion detection?</a></p>

<p><a href=""https://i.stack.imgur.com/a5Xmq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/a5Xmq.png"" alt=""enter image description here""></a></p>
",AImeta,
1,"<p>I don't think the problem here is specific to open source authors. In fact I think that is a dangerous starting point: When it comes to free software resources, we will get a split opinion base - engineers that create free software are volunteers creating value for all in the real world, much like site contributors here. In many ways they are heroes that should be celebrated.</p>

<p>The trouble with focusing on the value equation is that it puts the site voters into position of voting based on judging the worthiness of the product. I would fully expect a question placed by a Google employee about pre-trained image classifiers and answered with links to inception networks would get shut down as spam. So what is the difference?</p>

<p>The linked question is the example of what can go wrong with allowing <strong>resource request</strong> questions on a Stack Exchange site. Most new sites struggle with what to allow when someone has a problem to solve but all they want is a link to something off-site that solves the problem directly. It is very useful to have links to the site subject's introductory material. However, such questions can quickly bring in contributions to the site that have agendas to promote some product or idea. Even when the product is free, the promotion typically has an agenda to increase reputation of the contributor off site - converting Stack Exchange answers into incoming links to the product.</p>

<p>The nature of the question should set the scope for an acceptable answer - if the most appropriate answer is just a list of properties of the project plus a link and disclaimer, then <em>the problem is with the question</em>.</p>

<p>We should start getting stricter about resource requests on AI Stack Exchange:</p>

<ul>
<li><p>Vote to close questions that ask for links to completed AI services, software products or projects, in order to just use them (as opposed to understand how they work)</p></li>
<li><p>Downvote ""Gimme an AI that does X"" questions.</p></li>
</ul>

<p>I think we can still accept questions about papers on subjects as there is no real history of academic paper writers self-promoting via Stack Exchange. But  other resource requests need to be accepted more cautiously.</p>

<p>The OP of <a href=""https://ai.stackexchange.com/questions/8408/is-there-any-pretrained-model-for-emotion-detection/8409#8409"">the question</a> should look for <em>existing</em> questions about emotion classification in video, and answer accordingly. That would be a valuable contribution. A basic but good question about emotion recognition on AI could be asking whether neural networks are the only high-performing model, or whether NN models represent anything interpretable, whether they can be reversed to generate images that show ""archetype"" emotional faces, what the loss function should be to <em>discover</em> emotional responses instead of classifying them using supervised learning etc. All those questions would require more than just a link to a project - a brief link (with the disclaimer, but without listing traits unrelated to the question) would be appropriate if the project could be used as an example. </p>
",AImeta,think problem specific open source authors fact think dangerous starting point comes free software resources get split opinion base engineers create free software volunteers creating value real world much like site contributors many ways heroes celebrated trouble focusing value equation puts site voters position voting based judging worthiness product would fully expect question placed google employee pre trained image classifiers answered links inception networks would get shut spam difference linked question example go wrong allowing resource request questions stack exchange site new sites struggle allow someone problem solve want link something site solves problem directly useful links site subject introductory material however questions quickly bring contributions site agendas promote product idea even product free promotion typically agenda increase reputation contributor site converting stack exchange answers incoming links product nature question set scope acceptable answer appropriate answer list properties project plus link disclaimer problem question start getting stricter resource requests ai stack exchange vote close questions ask links completed ai services software products projects order use opposed understand work downvote gimme ai x questions think still accept questions papers subjects real history academic paper writers self promoting via stack exchange resource requests need accepted cautiously op look existing questions emotion classification video answer accordingly would valuable contribution basic good question emotion recognition ai could asking whether neural networks high performing model whether nn models represent anything interpretable whether reversed generate images show archetype emotional faces loss function discover emotional responses instead classifying using supervised learning etc questions would require link project brief link disclaimer without listing traits unrelated question would appropriate project could used example
1,"<p>Whether the outgoing link leads to open source, GNU freeware, or a consulting service landing page has nothing to do with what the policy should be concerning placed questions and answers.  Items offered with open source licenses and as free services on the Internet just a few years ago are some of the largest multinational corporations in the world.  GitHub was not bought by Microsoft for cheap, but what money goes or doesn't go where shouldn't be the main policy driver.  </p>

<p>There's nothing wrong with selling products and services (unless you're a Luddite or a follower of Richard Stallman).  I don't think there's anything wrong with offering up free downloads that are tied to our own career success if the need for it occurs in the normal flow of SE Q&amp;A.</p>

<p>The case mentioned is not that.  It is exploiting the rising popularity of SE to drive web traffic, something that could potentially appeal to ten million other code repository contributors.  I'm not sure it matters that much if people use SE to post click bait like this and funnel traffic from Google through SE to GitHub, although the SE staff doing server capacity planning might think it matters.</p>

<p>The main concern for the AI stack is that it waters down the value of the Q&amp;A to a relay for marketers rather than an AI site with a more think-tank feel, which would improve the stack and its member activity.</p>
",AImeta,whether outgoing link leads open source gnu freeware consulting service landing page nothing policy concerning placed questions answers items offered open source licenses free services internet years ago largest multinational corporations world github bought microsoft cheap money goes go main policy driver nothing wrong selling products services unless luddite follower richard stallman think anything wrong offering free downloads tied career success need occurs normal flow se q case mentioned exploiting rising popularity se drive web traffic something could potentially appeal ten million code repository contributors sure matters much people use se post click bait like funnel traffic google se github although se staff server capacity planning might think matters main concern ai stack waters value q relay marketers rather ai site think tank feel would improve stack member activity
1,"<p>Linear algebra fits clearly into the field of mathematics and doesn't have anything particular to do with AI except that linear algebra might be used as part of an approach, but only to the extend that set theory or vector multiplication might.</p>

<p>Linear regression is a Statistics 101 curve fitting method, with simple formulae for slope, intercept, and correlation coefficient.  A basic 1980 pocket calculator has a button for it.</p>

<p>Neither of these tags are particularly AI centric.</p>
",AImeta,linear algebra fits clearly field mathematics anything particular ai except linear algebra might used part approach extend set theory vector multiplication might linear regression statistics 101 curve fitting method simple formulae slope intercept correlation coefficient basic 1980 pocket calculator button neither tags particularly ai centric
1,"<p>They're both core topics that are important to understand well, very important basics, before people can move on to a plethora of more advanced topics in AI. So yes, they absolutely should be tags in AI.se.</p>
",AImeta,core topics important understand well important basics people move plethora advanced topics ai yes absolutely tags aise
1,"<p>If somebody puts self-promotion in an answer, it violates the Stackoverflow guidelines, <a href=""https://stackoverflow.com/help/promotion"">https://stackoverflow.com/help/promotion</a> They have a very strict attitude and flag an answer as spam if somebody has posted a link to his own website/repository. The situation is more complicated, if such a promotion is done in the question, because the asker is always king. Direct flagging as spam is the wrong way. The better idea is some kind or ironic flag with a +100 bounty to motivate the community to search really hard for an answer. But I'm not sure what the official meta.stackexchange position is in such a case, I've found with Google no clear guideline.</p>
",AImeta,somebody puts self promotion answer violates stackoverflow guidelines strict attitude flag answer spam somebody posted link website repository situation complicated promotion done question asker always king direct flagging spam wrong way better idea kind ironic flag 100 bounty motivate community search really hard answer sure official metastackexchange position case found google clear guideline
1,"<p>After <a href=""https://ai.meta.stackexchange.com/search?q=description+-tag+-recommendation+-reinforcement"">two years of effort and patience</a> in developing a sensible consensus about the AI SE sub-site's description, taking care to be respectful of other established SE sub-sites and insuring a faithful representation of the content contributions and voting choices of members, we seem to remain once again in limbo.</p>

<p>Is it possible to change the description, or are we stuck with the current pathetically narrow and unrepresentative one?</p>

<p>Perhaps, rather than let this recent vote become stale and start all over again next year, it would be functionally wise and ethically correct if those who have power just told us frankly what the deal is.</p>

<p>Is it fixed or variable?  If variable, has SE been notified of <a href=""https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be"">the selected one</a>?</p>

<blockquote>
  <p>Artificial Intelligence Stack Exchange is a question and answer site for people interested in AI theory, mathematics, research, discovery, design, development, practice, embedded uses, cognition, policy, and impact.</p>
</blockquote>

<p>If fixed, let's not, going forward, enter into some democratic process and waste everyone's time proposing and voting on descriptions that can never be.</p>
",AImeta,developing sensible consensus ai se sub site description taking care respectful established se sub sites insuring faithful representation content contributions voting choices members seem remain limbo possible change description stuck current pathetically narrow unrepresentative one perhaps rather let recent vote become stale start next year would functionally wise ethically correct power told us frankly deal fixed variable variable se notified artificial intelligence stack exchange question answer site people interested ai theory mathematics research discovery design development practice embedded uses cognition policy impact fixed let going forward enter democratic process waste everyone time proposing voting descriptions never
1,"<p>I don't see why AI should be different to SO in this respect. Updates to questions should be limited to clarifying, improving layout, spelling and grammar. They should not add new insights from or progress of the questioner, once answers to the original have been written.</p>

<p>In general, this process needs to be more friendly to question answerers that askers. It is more expedient to get the OP of the question to take the extra effort to frame their problem as multiple separate questions, instead of having volunteers answering questions track changes and try to follow a conversation (and in the meantime often dilute the purpose of the original question).</p>

<p>If someone tries to alter their question or ask lots of extensions in comments, then in my experience, a gentle/friendly push back and suggestion to ask a separate question is often all that is required. It is more helpful to show what the question OP <em>should do</em> as opposed to telling them that they are doing something wrong. </p>

<p>If the OP of the question ignores such a suggestion, then the best next step is to walk away. There is no point arguing with them if they think they know better how the site should work. Just let their extensions to the question go unanswered. If that is disappointing to you (because you found the question a really good fit to the site, and were excited to answer it), then perhaps help the OP further by opening the new question yourself and pointing them at it - although I personally would not go that far, there are always other good questions.</p>

<p>Regarding this scenario:</p>

<blockquote>
  <p>it may not be popular with a Q author and A author that are essentially collaborating on a small project together and are fully engaged in an extended helping process</p>
</blockquote>

<p>It's not really what the site is for. I would either:</p>

<ul>
<li><p>Downvote or close the question, if it was clearly too long/confusing and broad to meet site guidelines.</p></li>
<li><p>Ignore the question if it kept changing, as it would be a waste of time to get involved, and it is only one question. This is not common behaviour.</p></li>
</ul>

<p>Given how little rep both the asker and answerer would get for their efforts, as the content becomes too dense for anyone else to work with, it is in some ways self-limiting. I note that as it stands today, the OP questioner got 10 rep in your linked question <a href=""https://ai.stackexchange.com/questions/8128/difficulty-in-understanding-identifiability-in-dueling-network-paper"">difficulty in understanding identifiability in Dueling Network paper</a> and the four answers got a total of -2 rep between them. The resulting content is all but incomprehensible to me.</p>

<p>In this case I notice you are one of the affected answerers. I don't think there is much you can do at this stage but chalk it up to experience. There is no way to force <em>collaborating</em> site users to behave according to above - the only tools SE has for moderation at that level are too heavy-handed to apply when the discussion is still technical, on-topic and polite. If you spot the behaviour early enough you can comment that you prefer it another way (and IMO the ""correct"" Stack Exchange way would be separate questions as you suggest), but if the whole thing has momentum with updates to both questions and answers, just leave the others involved in their discussion. </p>

<hr>

<p>Some clarifications <em>might</em> still make significant changes, if to answer a question accurately (as opposed to answers with general advice that might apply), the OP needs to add details about their specific situation, including code, data etc. Sometimes this unfortunately can invalidate answers that attack the question in a general sense. This is a tricky area to judge correctly. I think the line is most clearly drawn when the OP unilaterally adds new data, or is obviously changing their question in response to an answer which has already helped them.</p>
",AImeta,see ai different respect updates questions limited clarifying improving layout spelling grammar add new insights progress questioner answers original written general process needs friendly question answerers askers expedient get op question take extra effort frame problem multiple separate questions instead volunteers answering questions track changes try follow conversation meantime often dilute purpose original question someone tries alter question ask lots extensions comments experience gentle friendly push back suggestion ask separate question often required helpful show question op opposed telling something wrong op question ignores suggestion best next step walk away point arguing think know better site work let extensions question go unanswered disappointing found question really good fit site excited answer perhaps help op opening new question pointing although personally would go far always good questions regarding scenario may popular q author author essentially collaborating small project together fully engaged extended helping process really site would either downvote close question clearly long confusing broad meet site guidelines ignore question kept changing would waste time get involved one question common behaviour given little rep asker answerer would get efforts content becomes dense anyone else work ways self limiting note stands today op questioner got 10 rep linked question four answers got total 2 rep resulting content incomprehensible case notice one affected answerers think much stage chalk experience way force collaborating site users behave according tools se moderation level heavy handed apply discussion still technical topic polite spot behaviour early enough comment prefer another way imo correct stack exchange way would separate questions suggest whole thing momentum updates questions answers leave others involved discussion clarifications might still make significant changes answer question accurately opposed answers general advice might apply op needs add details specific situation including code data etc sometimes unfortunately invalidate answers attack question general sense tricky area judge correctly think line clearly drawn op unilaterally adds new data obviously changing question response answer already helped
1,"<p>OK, this is partially done now, sorry for the delay. <a href=""https://ai.meta.stackexchange.com/a/1443/75"">This proposal</a> (lightly edited for length) has now been used to update the blurb at the top of our <a href=""https://ai.stackexchange.com/tour"">tour page</a>! To get various other instances of the text updated, we'll need to contact Stack Exchange. They're pretty busy at the moment, but hopefully something will happen here within a couple weeks.</p>
",AImeta,ok partially done sorry delay lightly edited length used update blurb top get various instances text updated need contact stack exchange pretty busy moment hopefully something happen within couple weeks
1,"<p>A newbie in Artificial Intelligence can do the following:</p>

<ol>
<li><p>Read the Wikipedia article which is a good overview <a href=""https://en.wikipedia.org/wiki/Artificial_intelligence"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Artificial_intelligence</a></p></li>
<li><p>Read the standard book from academic AI which is “Russell/Norvig: Artificial intelligence: a modern approach. 2016”</p></li>
<li><p>Read the standard book from Game AI which is “Millington / Funge: Artificial intelligence for games. 2009”</p></li>
</ol>
",AImeta,newbie artificial intelligence following read wikipedia article good overview read standard book academic ai russell norvig artificial intelligence modern approach 2016 read standard book game ai millington funge artificial intelligence games 2009
1,"<p>On this site, I see a couple of algorithmic questions in the direction ""a vs b: what is the difference"". They usually show no effort in asking the question and are hard to answer because it is not totally clear which variant of the algorithm / which facts about the algorithm the OP knows.</p>

<p>Hence I would demand either pseudo code or at least a reference to a document where the algorithm is described.</p>
",AImeta,site see couple algorithmic questions direction vs b difference usually show effort asking question hard answer totally clear variant algorithm facts algorithm op knows hence would demand either pseudo code least reference document algorithm described
1,"<p>Currently there are 127 questions with the tag “algorithm” available <a href=""https://ai.stackexchange.com/questions/tagged/algorithm"">https://ai.stackexchange.com/questions/tagged/algorithm</a> In most cases, the questions are well formulated. The asker provides images, screenshots and even mathematical formulas. That means, there is a pressure to SE.AI from the outside in which people with a huge background knowledge and lot of energy are posting a question. And yes, this is a problem because SE.AI has to answer these questions.</p>

<p>Let us investigate how algorithm with an Artificial Intelligence background are handled upstream by scientists. Usually this is done by writing a paper. About every possible algorithm like A* or BFS are many papers available. Sometimes from a theoretical point of view which is called discrete mathematics, sometimes with the idea to implementing the algorithm in sourcecode. I think it's not possible to describe a best practice method in handling such questions, it depends strongly on the background knowledge of the people who are posting an answer. IMHO the current situation is acceptable. Some questions have 0 answers, some 1 and other more. I would encourage in posting more algorithm question, because they are the core of computer science.</p>
",AImeta,currently 127 questions tag algorithm available cases questions well formulated asker provides images screenshots even mathematical formulas means pressure seai outside people huge background knowledge lot energy posting question yes problem seai answer questions let us investigate algorithm artificial intelligence background handled upstream scientists usually done writing paper every possible algorithm like bfs many papers available sometimes theoretical point view called discrete mathematics sometimes idea implementing algorithm sourcecode think possible describe best practice method handling questions depends strongly background knowledge people posting answer imho current situation acceptable questions 0 answers 1 would encourage posting algorithm question core computer science
1,"<p>I agree that such questions are low-quality. I think the current options take care of these cases pretty well:</p>

<blockquote>
  <p>They usually show no effort in asking the question</p>
</blockquote>

<p>Downvoting is appropriate for such questions. In fact, the first part of the downvote arrow's tooltip is ""this question does not show any research effort."" Note that it's possible for a question to be entirely on-topic and well-phrased (therefore not being a good candidate for closure) but still be of poor quality.</p>

<blockquote>
  <p>They [...] are hard to answer because it is not totally clear which variant of the algorithm / which facts about the algorithm the OP knows.</p>
</blockquote>

<p>These are a perfect application for the ""unclear what you're asking"" close reason, which asks the author to clarify. Note that it's possible for a question to be on-topic but still unclear or overly broad.</p>
",AImeta,agree questions low quality think current options take care cases pretty well usually show effort asking question downvoting appropriate questions fact first part downvote arrow tooltip question show research effort note possible question entirely topic well phrased therefore good candidate closure still poor quality hard answer totally clear variant algorithm facts algorithm op knows perfect application unclear asking close reason asks author clarify note possible question topic still unclear overly broad
1,"<p>In the last days, I have been quite active on this website. I tried to do my best to improve the quality of the content of this website. This includes downvoting clearly bad answers (which, IMHO, also includes answers which are highly opinionated, where the author has not put any effort in writing them well, missing citations, etc.). I have been commenting under answers and questions, so as to provide feedback. For example, I have, in particular, provided feedback <a href=""https://ai.stackexchange.com/a/6797/2444"">here</a>, <a href=""https://ai.stackexchange.com/a/8941/2444"">here</a> and <a href=""https://ai.stackexchange.com/q/7838/2444"">here</a>. Under this last post, I wrote the comment:</p>

<blockquote>
  <p>I spent a significant amount of reputation (for the good of the this community) to downvote almost all answers below, which, unfortunately, I find very unsatisfactory. You guys, especially people in the field (like me), should do the same.</p>
</blockquote>

<p>Any person that has obtained a bachelor's or master's of science in computer science or AI would definitely agree with my comment above. The original question is ""What is AI?"". Now, undoubtedly, this is one of the most important questions that could be asked on this website.</p>

<p>In certain answers, we see statements like</p>

<blockquote>
  <p>I am going one step further (controversial!). If you remove A non-human entity from the first definition, that is the definition for human intelligence, for me.</p>
</blockquote>

<p>or </p>

<blockquote>
  <p>In my opinion, one of the crucial things about AI is the ability to understand and make the right conclusions in a changing environment.</p>
</blockquote>

<p>or</p>

<blockquote>
  <p>Artificial Intelligence is a field which deals with scientific study,design, research and development/engineering,which aims at simulating human intelligence(natural intelligence) into software programs(Intelligent Computerised Systems).Thus based on ComputerScience/Robotics, Neuroscience, Psychology..to mention but a few.</p>
</blockquote>

<p>(You can also observe how much effort has been put in writing this answer well. Sarcasm.)</p>

<p>or </p>

<blockquote>
  <p>AI is a field that uses computation techniques to approximate complex decisions.</p>
</blockquote>

<p>I could go on and on. The list of statements that are very arguably, opinionated, ambiguous, etc., goes on and on. Now, given that this is one of the most important question that could have been asked on this website, I decided to publicly say that I downvoted almost all of them, for the good of the community. I believe that good answers to this question would cite the definitions that have been given throughout the years by the experts in the field. For me, there are already too many opinions, we don't need the opinion of someone that does not even have a full understanding and view of the whole field. It is unproductive to keep sharing your opinions in this case, which are difficult to merge in a full well-accepted definition. Furthermore, in general, it is difficult to define a whole field, as the field often evolves over time or, anyway, the boundaries are not sharp. So, a historical perspective would also be interesting, instead of all these opinions.</p>

<p>But, in this post, I don't just want to express my opinion regarding these answers. I wanted, in particular, to report the revengeful behaviour of certain users of this website. Since I have publicly given these comments, my answers <a href=""https://ai.stackexchange.com/a/8909/2444"">https://ai.stackexchange.com/a/8909/2444</a>, <a href=""https://ai.stackexchange.com/a/8907/2444"">https://ai.stackexchange.com/a/8907/2444</a>, <a href=""https://ai.stackexchange.com/a/3227/2444"">https://ai.stackexchange.com/a/3227/2444</a> have been downvoted. Now, can someone explain to me why?</p>
",AImeta,last days quite active website tried best improve quality content website includes downvoting clearly bad answers imho also includes answers highly opinionated author put effort writing well missing citations etc commenting answers questions provide feedback example particular provided feedback last post wrote comment spent significant amount reputation good community downvote almost answers unfortunately find unsatisfactory guys especially people field like person obtained bachelor master science computer science ai would definitely agree comment original question ai undoubtedly one important questions could asked website certain answers see statements like going one step controversial remove non human entity first definition definition human intelligence opinion one crucial things ai ability understand make right conclusions changing environment artificial intelligence field deals scientific study design research development engineering aims simulating human intelligencenatural intelligence software programsintelligent computerised systemsthus based computerscience robotics neuroscience psychology mention also observe much effort put writing answer well sarcasm ai field uses computation techniques approximate complex decisions could go list statements arguably opinionated ambiguous etc goes given one important question could asked website decided publicly say downvoted almost good community believe good answers question would cite definitions given throughout years experts field already many opinions need opinion someone even full understanding view whole field unproductive keep sharing opinions case difficult merge full well accepted definition furthermore general difficult define whole field field often evolves time anyway boundaries sharp historical perspective would also interesting instead opinions post want express opinion regarding answers wanted particular report revengeful behaviour certain users website since publicly given comments answers downvoted someone explain
1,"<p>So I have privileges to approve and reject edits. I have seen new users tend to provide some background about either their knowledge/previous work (in a very layman way). For example : "" So I am a beginner in AI and I do not have much understanding of calculus and so ......Actual question......"". </p>

<p>Now some users want to remove this introductory part. My question is what are the general rules in this case? Should the intro be removed? Or does it serve some purpose in answering a question?</p>
",AImeta,privileges approve reject edits seen new users tend provide background either knowledge previous work layman way example beginner ai much understanding calculus actual question users want remove introductory part question general rules case intro removed serve purpose answering question
1,"<p>The question becomes whether that information and the context it provides might be relevant in understanding the source of confusion or how the question might be answered (i.e. write for your audience).</p>
<p>Certainly, someone saying:</p>
<blockquote>
<p>&quot;I am an {x} year student who is/is not familar with {x}; can you explain this to me in a way that others like me will understand?&quot;* ← <em>USEFUL CONTEXT</em></p>
</blockquote>
<p>Of course, that doesn't necessarily forgive a question exhibiting insufficient understanding of the problem to bring it to a site like this (&quot;too soon, where are you  stuck specifically? what have you tried?&quot;).</p>
<p>But where &quot;needless introductions&quot; can be stripped away is where it becomes chatty filler not really relevant to the post:</p>
<blockquote>
<p>&quot;Hi, guys. I love this site and y'all are great and I've been here for 3 years and now I have a question and I hope you all can help me yada yada ...</p>
<p>&lt;actual question&gt;</p>
<p>Thank you so much. I really appreciate your help. Important, important. Hopefully I can get an answer soon.</p>
<p>signed &lt;username&gt; &lt;smiley emoji&gt;<br />
&lt;list of credentials&gt;<br />
&lt;list of favorite tomes&gt;<br />
&lt;meme cartoon&gt;</p>
</blockquote>
<p>Of course, you don't have to become overly head-strong and vigilant in stripping away <em>every</em> incidental nicety. The overall goal is to make the content <em>demonstrably</em> more clear for those who come after. Use your judgement with those goals in mind and most of those leave-it/remove-it questions should become a bit more self-evident.</p>
",AImeta,question becomes whether information context provides might relevant understanding source confusion question might answered ie write audience certainly someone saying useful context course necessarily forgive question exhibiting insufficient understanding problem bring site like stripped away becomes chatty filler really relevant post hi guys love site great 3 years question hope help yada yada thank much really appreciate help important important hopefully get answer soon signed course become overly head strong vigilant stripping away every incidental nicety overall goal make content demonstrably clear come use judgement goals mind leave remove questions become bit self evident
1,"<p>In some papers, it is discussed how to use Total quality management in higher education. I want to summarize the current research and give some advice how to adapt this technique into the management of SE.AI. The TQM idea was original invented in business context to manage large companies. It is very similar to total customer orientation which is a bottom up ideology. The principle is sometimes called market-driven management and is used for agile companies who have to adapt to changing situations quickly. Instead of planning the organization strategy from topdown the idea is to control the organization from the outside, that means by the customer.</p>

<p>Let us transfer this principle for SE.AI. The outside world is everything around the website. That means it is the internet which is full of people which have questions about SE.AI. What these people will do is hard to predict, but some of them are visiting our nice looking website and posting a question. The idea behind total customer orientation is to declare these question as management objectives. That means, what the OP is asking is the most important thing and every user in the forum has to follow these needs.</p>

<p>What the users in the forum are doing is simply to obey to the market. That means, to follow the needs of the asker and to question everyday if an answer fits to this needs. I have seen, that some users here are asking if a certain answer fits to the question. This kind of critique is right and should be repeated over and over again. The principle is comparable with managing a restaurant. At the beginning, a new customer comes in and asks for something. For example he has a question like “L0 sparsification of DNNs”. The waiter has to identify the question and put some tags around it. Then the cook in the kitchen is asked. In the case of SE.AI the cook is not a single person but a group of them. I'm one of them, but many other user in the forum here are also familiar with Artificial Intelligence. All users have to work together until the asker is happy. He will set the “accept” button if he believes, that one of the answer fits to his needs.</p>

<p>The communication structure until this will happen is a bit complicated. Often the needed information is not located within a single user, but is the result of many people who are working together. That means, each user in the forum has a different kind of knowledge which can be combined with the skills of other. Identify weaknesses and strengths is an interactive process which takes a lot of experience. But I'm optimistic that it will work great.</p>
",AImeta,papers discussed use total quality management higher education want summarize current research give advice adapt technique management seai tqm idea original invented business context manage large companies similar total customer orientation bottom ideology principle sometimes called market driven management used agile companies adapt changing situations quickly instead planning organization strategy topdown idea control organization outside means customer let us transfer principle seai outside world everything around website means internet full people questions seai people hard predict visiting nice looking website posting question idea behind total customer orientation declare question management objectives means op asking important thing every user forum follow needs users forum simply obey market means follow needs asker question everyday answer fits needs seen users asking certain answer fits question kind critique right repeated principle comparable managing restaurant beginning new customer comes asks something example question like l0 sparsification dnns waiter identify question put tags around cook kitchen asked case seai cook single person group one many user forum also familiar artificial intelligence users work together asker happy set accept button believes one answer fits needs communication structure happen bit complicated often needed information located within single user result many people working together means user forum different kind knowledge combined skills identify weaknesses strengths interactive process takes lot experience optimistic work great
1,"<p>I read ""Recursive best first search algorithm"" but I couldn't be able to understand this.Can I ask these type of questions here?</p>
",AImeta,read recursive best first search algorithm could able understand thiscan ask type questions
1,"<p>Right now, we have three questions available which have to do with the topic, <a href=""https://ai.stackexchange.com/search?q=recursive+best-first+search+"">https://ai.stackexchange.com/search?q=recursive+best-first+search+</a> In one of them a short introduction was given: </p>

<blockquote>
  <p>“Recursive best-first search is a best-first search that runs in space
  that is linear with respect to the maximum search depth.”</p>
</blockquote>

<p>If a certain type of question gets answered depends on many factors. According to a chat from last week, algorithm related questions are often asked but are difficult to answer. The reason is, that everybody interprets the application of an algorithm a bit different. User1 is interested in theoretical foundations, while user2 has practical purposes to implement an advanced stackbased algorithm on his robot. A general advice in asking good questions is to formulate a longer text of at least two paragraphs which are written in an academic style. This will produce upvotes for the question and motivates the forum the find an answer.</p>
",AImeta,right three questions available topic one short introduction given recursive best first search best first search runs space linear respect maximum search depth certain type question gets answered depends many factors according chat last week algorithm related questions often asked difficult answer reason everybody interprets application algorithm bit different user1 interested theoretical foundations user2 practical purposes implement advanced stackbased algorithm robot general advice asking good questions formulate longer text least two paragraphs written academic style produce upvotes question motivates forum find answer
1,"<p>With the help of archive.org it is possible to measure how many questions were asked each day at SE.AI. In the early 2017 only 1.6 questions were added per day, in late 2017 the number has increased to 2.5 and in late 2018 around 5 questions were asked each day. Compared to other Stackexchange websites the total amount of questions is low (2676 questions are in the system today). So my question is, can this chart be extrapolated into the future? How much questions will be in the system at the end of next year (2019)?</p>

<p><a href=""https://i.stack.imgur.com/9liFx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9liFx.png"" alt=""enter image description here""></a></p>
",AImeta,help archiveorg possible measure many questions asked day seai early 2017 16 questions added per day late 2017 number increased 25 late 2018 around 5 questions asked day compared stackexchange websites total amount questions low 2676 questions system today question chart extrapolated future much questions system end next year 2019
1,"<p>This topic has an entirely different dimension than on any other online forum I can think of, and so should be regarded not as a purely negative prospect (informal Turing testing and so forth.)</p>

<p>I'm not saying that we have bots semi-passing, but I do see a high percentage of the questions on the stack, and I have been seeing questions that <em>could have</em> been asked by a bot.</p>

<p>These questions tend to be flagged for low quality, which is accurate from if asked by a human.  If asked by a bot though, they're not bad--cogent and fewer and fewer grammatical errors. </p>
",AImeta,topic entirely different dimension online forum think regarded purely negative prospect informal turing testing forth saying bots semi passing see high percentage questions stack seeing questions could asked bot questions tend flagged low quality accurate asked human asked bot though bad cogent fewer fewer grammatical errors
1,"<p>A certain question can be created by a bot, but it can also be legitimate question of a new user who isn't familiar with a subject. If we are treating questions from bots, as a normal request it will occupy too much resources to answer which is missing for the real important questions. To identify “friend vs. foo” a simple word count looks promising. If the question has less than 100 words, the question is under-specified. That means, the asker has invested only a little of time in describing the problem. It can be bot or it can be lazy human. If the question has more than 100 words, the energy invested in the question is higher. It was either a user with a high priority problem or it was a human-level AI chatbot comparable to Watson AI. (Only to give an example, the last paragraph contains of 150 words).</p>
",AImeta,certain question created bot also legitimate question new user familiar subject treating questions bots normal request occupy much resources answer missing real important questions identify friend vs foo simple word count looks promising question less 100 words question specified means asker invested little time describing problem bot lazy human question 100 words energy invested question higher either user high priority problem human level ai chatbot comparable watson ai give example last paragraph contains 150 words
1,"<p>Early in this site's life, I spent a lot of time staring at the site analytics and the sketch in <a href=""https://meta.stackexchange.com/a/227016/295684"">this MSE post</a>:</p>

<p><img src=""https://i.stack.imgur.com/LUOS5.png"" alt=""exponential growth""></p>

<p>Looking at our analytics <em>currently</em>, here are some interesting facts (I'll consider all posts, both questions and answers):</p>

<ul>
<li>The posts-per-week graph looks very much like the tub on the left side of the above sketch</li>
<li>Over most of the site's life, posts per time went up overall with some fluctuation, but over the past three months it steadily increased and <em>doubled</em> in value</li>
<li>Post activity now is at pretty much the same level as the first (private beta) week</li>
<li>The visits graph is shaped much differently, but doubled over the past nine months, with most of the increase in the past three months</li>
</ul>

<p>""Three months"" came up a lot there - that's probably from <a href=""https://ai.meta.stackexchange.com/q/1404/75"">IBM's sponsorship</a>, which started in early September.</p>

<p>The posts-per-time graph looks pretty linear to me in the last three months when smoothed by taking the five-week average around each point. Over the 11 weeks since the sponsorship announcement, activity increased by 2.3 posts per week per week. I can't know whether that will always be reasonable, but for the sake of getting a rough estimate let's assume the growth pattern past that point continues. Taking into account last week's rate of 59.8 posts per week and the presently existing 6942 posts then doing a bit of simple integration produces a number of <strong>approximately 13,000 posts</strong> existing after 52 more weeks. 38.5% of currently existing posts are questions, so in a year we might have a little over <strong>5,000 questions</strong>.</p>

<p>This model actually assumes quadratic growth rather than exponential. Hopefully things pick up even more and we switch to an exponential pattern!</p>
",AImeta,early site life spent lot time staring site analytics sketch looking analytics currently interesting facts consider posts questions answers posts per week graph looks much like tub left side sketch site life posts per time went overall fluctuation past three months steadily increased doubled value post activity pretty much level first private beta week visits graph shaped much differently doubled past nine months increase past three months three months came lot probably started early september posts per time graph looks pretty linear last three months smoothed taking five week average around point 11 weeks since sponsorship announcement activity increased 23 posts per week per week know whether always reasonable sake getting rough estimate let assume growth pattern past point continues taking account last week rate 598 posts per week presently existing 6942 posts bit simple integration produces number approximately 13000 posts existing 52 weeks 385 currently existing posts questions year might little 5000 questions model actually assumes quadratic growth rather exponential hopefully things pick even switch exponential pattern
1,"<p>It was unanimously agreed that the current AI Stack Exchange description in the below depicted drop down and search for <em>MORE STACK EXCHANGE COMMUNITIES</em> is a misrepresentation for two reasons.</p>

<ul>
<li>Not nearly descriptive of current Q&amp;A content</li>
<li>Not aligned with the current interests of active members</li>
</ul>

<p><a href=""https://i.stack.imgur.com/Bgp1M.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Bgp1M.png"" alt=""AI Description in Dropdown""></a></p>

<p>Worse that that, the text being somewhat technophobic in the mentioning of <em>life and challenges</em> related to AI, the description is not attractive to those qualified to write answers to the many legitimate questions about AI research, design, and use not yet answered well. In short, leaving the above drop down text is counterproductive and damaging to the growth of the beta.</p>

<p>The technophobic nature of the current public description is not philosophically aligned with IBM's Watson lab, which is problematic for IBM, our current sponsor. Technophibia may be brand erosive for IBM.</p>

<p>A previous vote was taken in 2016, but the result of the vote was not acted upon and was this year dismissed as stale, so a new vote was taken two months ago. <a href=""https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be"">This year's vote</a> was <a href=""https://ai.meta.stackexchange.com/questions/1422/how-can-we-change-the-site-description-to-match-our-current-topic-guidelines-an/1423?noredirect=1#comment1708_1423"">initiated by a moderator</a>, conducted democratically, and is both valid and fresh. The description in <a href=""https://ai.stackexchange.com/tour"">the Tour</a> has been <a href=""https://ai.meta.stackexchange.com/questions/1461/is-the-artificial-intelligence-beta-stuck-with-its-current-out-facing-descriptio/1463#1463"">updated by Ben</a>, but the CMS value for the <em>MORE COMMUNITIES</em> drop down shown above <a href=""https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be/1437#comment1860_1437"">can only be altered by SE employees</a>, and it remains stuck with a misrepresentative and technophobic description instead of the result of the democratic process.</p>

<p>The unusual delay in updating a simple CMS text value probably qualifies this shortcoming as a bug or feature request. Please make the modification so that we can attract qualified contributors capable of answering the many unanswered questions that have been accumulating.</p>
",AImeta,unanimously agreed current ai stack exchange description depicted drop search stack exchange communities misrepresentation two reasons nearly descriptive current q content aligned current interests active members worse text somewhat technophobic mentioning life challenges related ai description attractive qualified write answers many legitimate questions ai research design use yet answered well short leaving drop text counterproductive damaging growth beta technophobic nature current public description philosophically aligned ibm watson lab problematic ibm current sponsor technophibia may brand erosive ibm previous vote taken 2016 result vote acted upon year dismissed stale new vote taken two months ago conducted democratically valid fresh description cms value communities drop shown remains stuck misrepresentative technophobic description instead result democratic process unusual delay updating simple cms text value probably qualifies shortcoming bug feature request please make modification attract qualified contributors capable answering many unanswered questions accumulating
1,"<p>Likely it's going to be a while.  I emailed the ""powers that be"", noting that we're starting to get traction and that we have a prestigious sponsor, but no reply as yet.  I'll ping them again after the New Year and update my answer as I get more information.</p>
",AImeta,likely going emailed powers noting starting get traction prestigious sponsor reply yet ping new year update answer get information
1,"<p>I haven't ever posted here, but I've been intermittently lurking for some time, in order to understand which kind of questions get asked here. In particular, I see that <a href=""https://ai.stackexchange.com/help/on-topic"">implementation questions are off-topic</a>, but I've seen a few implementation-related questions such as this one:</p>

<p><a href=""https://ai.stackexchange.com/questions/9700/rnn-lstm-not-converging-with-adam"">RNN LSTM not converging with Adam</a></p>

<p><strong>EDIT</strong>: I rephrase my question to avoid misunderstandings. Your help pages says that questions about ""[..]the <em>implementation</em> of machine learning"" are off-topic here, however it seems to me that a few questions with code are accepted (but I may be wrong! Please let me know if this is the case). So, do you accept questions containing code, as long as they are not exceedingly focused on implementation details?</p>
",AImeta,ever posted intermittently lurking time order understand kind questions get asked particular see seen implementation related questions one edit rephrase question avoid misunderstandings help pages says questions implementation machine learning topic however seems questions code accepted may wrong please let know case accept questions containing code long exceedingly focused implementation details
1,"<p>If i understood your question right, you're building a prediction model to anticipate the reaction of SE.AI to certain events. For example, if a user is posting a text about problems in the error-rate in the RNN network into the form, the following reaction can be there. First, the question is ignored ot a moderator can flag it as offtopic, the posting gets lots of upvotes or the posting gets an answer which brings the forum forward.</p>

<p>Creating such a prediction model for an online-discussion room is an important step because it helps to avoids pitfalls. If somebody is sure, that questions about Artificial Intelligence in movies (only an example) are off-topic on this website, he can adapt his behavior and won't post such questions. If the prediction model is right, the user can increase his score and avoid off-topic flags given by others. So the question is: what is the community doing in reaction to a post? are rules available for saying so in advance?</p>

<p>There are some measurements available. At first, every online-forum has an archive which allows to understand reactions in the past, secondly every forum has a certain form of users interacting with the forum. In the case of SE.AI most users are interested in new technology which is Artificial Intelligence and they come with a background in computer science. But, other users are not focused on academic AI, instead they have listen to the AI Influencer Sirai Raval, who is marketing neural networks to everybody.</p>
",AImeta,understood question right building prediction model anticipate reaction seai certain events example user posting text problems error rate rnn network form following reaction first question ignored ot moderator flag offtopic posting gets lots upvotes posting gets answer brings forum forward creating prediction model online discussion room important step helps avoids pitfalls somebody sure questions artificial intelligence movies example topic website adapt behavior post questions prediction model right user increase score avoid topic flags given others question community reaction post rules available saying advance measurements available first every online forum archive allows understand reactions past secondly every forum certain form users interacting forum case seai users interested new technology artificial intelligence come background computer science users focused academic ai instead listen ai influencer sirai raval marketing neural networks everybody
1,"<p>It's New Year's Day in <a href=""https://en.wikipedia.org/wiki/Zulu_Time"" rel=""nofollow noreferrer"">Stack Exchange land</a>...</p>
<p>A distinguishing characteristic of these sites is how they are moderated:</p>
<blockquote>
<p>We designed the Stack Exchange network engine to be mostly self-regulating, in that we amortize the overall moderation cost of the system across thousands of teeny-tiny slices of effort contributed by regular, everyday users.<br />
-- <a href=""http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/"">A Theory of Moderation</a></p>
</blockquote>
<p>While there certainly are <a href=""https://stackoverflow.blog/2018/11/21/our-theory-of-moderation-re-visited/"">Moderators</a> here, a significant amount of the <em>moderation</em> is done by ordinary people, using the privileges
they've earned by virtue of their contributions to the site. Each of you contributes a little bit of time and effort, and together you accomplish much.</p>
<p>As we enter a new year, let's pause and reflect, taking a moment to appreciate the work that we do here together.
To that end, here is how the moderation done here on Artificial Intelligence breaks down by activity over the past 12 months:</p>
<pre><code>                 Action                  Moderators Community¹
---------------------------------------- ---------- ----------
Users suspended²                                  3         12
Users destroyed                                   8          0
Users contacted                                   7          0
Tasks reviewed³: Suggested Edit queue           477        816
Tasks reviewed³: Reopen Vote queue               10         23
Tasks reviewed³: Low Quality Posts queue        103         85
Tasks reviewed³: Late Answer queue               71        140
Tasks reviewed³: First Post queue               504        953
Tasks reviewed³: Close Votes queue              221        317
Tags merged                                       6          0
Tag synonyms proposed                             5          0
Tag synonyms created                              4          0
Questions reopened                               16          0
Questions protected                               1          4
Questions migrated                               38          0
Questions flagged⁴                                3        448
Questions closed                                161         18
Question flags handled⁴                         325        126
Posts unlocked                                    0          3
Posts undeleted                                   4         29
Posts locked                                      0         71
Posts deleted⁵                                  157        493
Posts bumped                                      0      1,032
Escalations to the CM team                        2          0
Comments undeleted                                5          0
Comments flagged                                  0        336
Comments deleted⁶                               565        946
Comment flags handled                           228        108
Answers flagged                                   9        369
Answer flags handled                            309         69
All comments on a post moved to chat              8          0
</code></pre>
<h3>Footnotes</h3>
<p>¹ &quot;Community&quot; here refers both to <a href=""https://ai.stackexchange.com/users"">the membership of Artificial Intelligence</a> <em>without</em> <a href=""https://ai.stackexchange.com/users?tab=moderators"">diamonds next to their names</a>, and to the automated systems otherwise known as <a href=""https://ai.stackexchange.com/users/-1"">user #-1</a>.</p>
<p>² The system will suspend users under three circumstances: when a user is recreated after being previously suspended, when a user is recreated after being destroyed for spam or abuse, and when a network-wide suspension is in effect on an account.</p>
<p>³ This counts every review that was submitted (not skipped) - so the 3 suggested edits reviews needed to approve an edit would count as 3, the goal being to indicate the frequency of moderation actions. This also applies to flags, etc.</p>
<p>⁴ Includes close flags (but <em>not</em> close or reopen votes).</p>
<p>⁵ This ignores numerous deletions that happen automatically in response to some other action.</p>
<p>⁶ This includes comments deleted by their own authors (which also account for some number of handled comment flags).</p>
<p>Wishing you all a happy new year...</p>
",AImeta,new year day distinguishing characteristic sites moderated designed stack exchange network engine mostly self regulating amortize overall moderation cost system across thousands teeny tiny slices effort contributed regular everyday users certainly significant amount moderation done ordinary people using privilegesthey earned virtue contributions site contributes little bit time effort together accomplish much enter new year let pause reflect taking moment appreciate work togetherto end moderation done artificial intelligence breaks activity past 12 months action moderators community¹ users suspended² 3 12users destroyed 8 0users contacted 7 0tasks reviewed³ suggested edit queue 477 816tasks reviewed³ reopen vote queue 10 23tasks reviewed³ low quality posts queue 103 85tasks reviewed³ late answer queue 71 140tasks reviewed³ first post queue 504 953tasks reviewed³ close votes queue 221 317tags merged 6 0tag synonyms proposed 5 0tag synonyms created 4 0questions reopened 16 0questions protected 1 4questions migrated 38 0questions flagged⁴ 3 448questions closed 161 18question flags handled⁴ 325 126posts unlocked 0 3posts undeleted 4 29posts locked 0 71posts deleted⁵ 157 493posts bumped 0 1032escalations cm team 2 0comments undeleted 5 0comments flagged 0 336comments deleted⁶ 565 946comment flags handled 228 108answers flagged 9 369answer flags handled 309 69all comments post moved chat 8 0 footnotes ¹ refers without automated systems otherwise known ² system suspend users three circumstances user recreated previously suspended user recreated destroyed spam abuse network wide suspension effect account ³ counts every review submitted skipped 3 suggested edits reviews needed approve edit would count 3 goal indicate frequency moderation actions also applies flags etc ⁴ includes close flags close reopen votes ⁵ ignores numerous deletions happen automatically response action ⁶ includes comments deleted authors also account number handled comment flags wishing happy new year
1,Unanswered questions are those questions which have no up-voted or accepted answers.,AImeta,unanswered questions questions voted accepted answers
1,"<p>Speaking as a mod, I tend to use a light touch in regard to migrating many of these potentially out-of-scope questions.  (Similar to avoiding closing questions by fiat, in all but the most egregious, preferring to follow the will of the community.)</p>
",AImeta,speaking mod tend use light touch regard migrating many potentially scope questions similar avoiding closing questions fiat egregious preferring follow community
1,"<p>The current culture is that post details have priority over the long range objective regarding site content quality. This is perhaps not an optimal approach, and it deserves some discussion.</p>

<p>The general question of priority is particularly noticeable in a few categories of cases. These are two examples..</p>

<ul>
<li>Aspects of the question are excellent in terms of coverage of Q&amp;A on this site and applicability to research and practice, but votes to close are accumulating</li>
<li>The post is old and, although provably incorrect or at least grossly inaccurate, has a high reputation simply because of the length of time it has been published along with an absence of evidence-based answers from which members could choose</li>
</ul>

<p>The pointing out of these issues in the interest of the long term goal of content excellence is neither popular nor functional at this time. But that may be a mistake in cultural convention. Logically, reorientation to prioritize the long range goal of content quality is indicated.</p>

<p>Should we adapt to this longer term vision?</p>

<p>should content quality be given a high value when balancing priorities with regard to questions that seem to be headed for closure and those that can be shown to have high reputation because of their duration of publication only?</p>

<p>How can we adapt as a community to a more long range content-first objective?</p>

<p>It may be that we have avoided this perspective out of respect to veteran and new members, but it may be appropriate to give them more credit. If the reason for the shift in priorities is made clear, most members are smart enough to get these rationale.</p>

<ul>
<li>""Welcome to AI SE. We are modifying your question to save it from closure. Our intention is to bring it within the guidelines in the Tour and concensus in the meta. If the result of the change is not satisfactory to serve your needs, please read the reasons given for closure and correct its phraseology appropriately so that it both serves your needs and those of the community.""</li>
<li>""This answer, although it had accumulated much reputation, is misleading because of ___. See article ___ for the basis for the correction. If you feel the change is in error, please modify it to resolve the issue leading to our edit and yet convey your perspective if possible. We intend only to have answers with high reputation to be as accurate and conceptually solid as possible.""</li>
</ul>

<p>Examples are deliberately excluded. When examples are given, people tend to justify why this or that was done to that particular example, whereas this is a question about intent, priorities, and balancing them. It is not about any particular question or answer but general trend and how those trends might be modified to produce a more optimal result over a period of years.</p>
",AImeta,current culture post details priority long range objective regarding site content quality perhaps optimal approach deserves discussion general question priority particularly noticeable categories cases two examples aspects question excellent terms coverage q site applicability research practice votes close accumulating post old although provably incorrect least grossly inaccurate high reputation simply length time published along absence evidence based answers members could choose pointing issues interest long term goal content excellence neither popular functional time may mistake cultural convention logically reorientation prioritize long range goal content quality indicated adapt longer term vision content quality given high value balancing priorities regard questions seem headed closure shown high reputation duration publication adapt community long range content first objective may avoided perspective respect veteran new members may appropriate give credit reason shift priorities made clear members smart enough get rationale welcome ai se modifying question save closure intention bring within guidelines tour concensus meta result change satisfactory serve needs please read reasons given closure correct phraseology appropriately serves needs community answer although accumulated much reputation misleading _ _ _ see article _ _ _ basis correction feel change error please modify resolve issue leading edit yet convey perspective possible intend answers high reputation accurate conceptually solid possible examples deliberately excluded examples given people tend justify done particular example whereas question intent priorities balancing particular question answer general trend trends might modified produce optimal result period years
1,"<p>From a quality incentive point of view, questions become most dysfunctionally off topic when they either</p>

<ul>
<li>Interfere with inter-SE community peace by disrespecting the boundaries of naturally overlapping site betas or</li>
<li>Present hacked code with dozens of conceptual and code level bugs for others to pile through and debug for the question author (who is essentially looking for free teacher-slaves on our site).</li>
</ul>

<p>These people are not wrong or bad, just children of the community and should be provided with our reasoning in a compassionate and rational way. If they are responsive to compassion and logic, they will get it and likely become more contributive.</p>
",AImeta,quality incentive point view questions become dysfunctionally topic either interfere inter se community peace disrespecting boundaries naturally overlapping site betas present hacked code dozens conceptual code level bugs others pile debug question author essentially looking free teacher slaves site people wrong bad children community provided reasoning compassionate rational way responsive compassion logic get likely become contributive
1,"<p>Community self-regulation is not new with SO/SE's model. It is in accordance with the same theoretical objectives of economic growth through legislative and judicial constraint in combination with enlightened creation of healthy economic incentives. We're really not talking about automated moderation as much as an e-republic within a fixed scope of public activities that include questions, answers, comments, and rating events.</p>

<p>I think it works nicely in many ways, which is why I suspend my usual skepticism and contribute.</p>

<p>Nonetheless, I would be negligent as a meta-contributor if I didn't mention some incentivization flaws that affect long term content quality objectives most of us would unanimously affirm as useful. I'm specifically talking about two important cases that affect long term quality of site content.</p>

<ol>
<li>Saving the best aspects of questions that may be otherwise closed. This condition frequently presents because of the current cultural sense of duty to avoid changing details of the original author's intent. The question is almost never edited by the original author, who may get discouraged by the vote to close, and attempts to preserve the positive aspects of the question by discarding the offensive ones by veterans on this site seem to often be reverted.</li>
<li>Imbalance in the scale of reputation, where questions that have been around a long time might have high reputation and provably low quality. This condition persists largely because posting alongside an answer with a super high reputation seems futile. This is the bigger problem when answers with seriously flawed presentations of theory have accumulated extremely high reputations resulting mostly because they sound good and there are zero alternatives.</li>
</ol>

<p>See <a href=""https://ai.meta.stackexchange.com/questions/1487/how-can-we-adopt-a-more-long-range-quality-first-vision"">How can we adopt a more long range, quality first vision?</a>? for a call to meta-contributors and readers to think about these.</p>

<p>There are many ways to modify incentives slightly to resolve both these problems, but they are incentive imbalances that may only be balanced through modification of the SE/SO social engineering model and corresponding modifications of the server framework that implements it.</p>
",AImeta,community self regulation new se model accordance theoretical objectives economic growth legislative judicial constraint combination enlightened creation healthy economic incentives really talking automated moderation much e republic within fixed scope public activities include questions answers comments rating events think works nicely many ways suspend usual skepticism contribute nonetheless would negligent meta contributor mention incentivization flaws affect long term content quality objectives us would unanimously affirm useful specifically talking two important cases affect long term quality site content saving best aspects questions may otherwise closed condition frequently presents current cultural sense duty avoid changing details original author intent question almost never edited original author may get discouraged vote close attempts preserve positive aspects question discarding offensive ones veterans site seem often reverted imbalance scale reputation questions around long time might high reputation provably low quality condition persists largely posting alongside answer super high reputation seems futile bigger problem answers seriously flawed presentations theory accumulated extremely high reputations resulting mostly sound good zero alternatives see call meta contributors readers think many ways modify incentives slightly resolve problems incentive imbalances may balanced modification se social engineering model corresponding modifications server framework implements
1,"<p>I came across this <a href=""https://ai.stackexchange.com/questions/10396/artificial-intelligence-and-its-unlawful-use"">question</a>. Clearly the question is badly formatted, but besides that its speculative and based on overhyped information about AI. </p>

<p>Are my conclusions on this question wrong? If not how can we make beginners in AI aware about the amount of false information floating around(Basically I am asking what is the remedial measures to such questions keeping in mind we don't want to scare away new visitors)?</p>
",AImeta,came across clearly question badly formatted besides speculative based overhyped information ai conclusions question wrong make beginners ai aware amount false information floating aroundbasically asking remedial measures questions keeping mind want scare away new visitors
1,"<p>First, badly formatted posts should be fixed; that is what the wiki-style editing is for. </p>

<p>But that specific question should be closed as <code>primarily opinion-based</code> because it is soliciting arguments and debate centered around a vague premise built on a hypothetical future which does not currently exist. Please don't let this site become <a href=""https://worldbuilding.stackexchange.com/help/on-topic"">Worldbuilding</a>. It is not a good fit for this site. </p>

<p>But to answer your question more generally, if the premise of a question is wrong or misleading &mdash; whether by misunderstanding or pop culture hype &mdash; you should answer in a way that dispels the mistaken belief. Head off the incorrect information or assumption with a cohesive answer explaining the issue correctly. </p>

<p>Folks around the Internet are searching for this (mis)information wherever they can find it. It would nice if they landed <strong><em>here</em></strong> to straighten out the issue authoritatively.</p>
",AImeta,first badly formatted posts fixed wiki style editing specific question closed soliciting arguments debate centered around vague premise built hypothetical future currently exist please let site become good fit site answer question generally premise question wrong misleading answer way dispels mistaken belief head incorrect information assumption cohesive answer explaining issue correctly folks around internet searching misinformation wherever find would nice landed straighten issue authoritatively
1,"<p>There's actually a great deal of debate about this subject in general in the wider AI community (ethics re: implementation of AI).  </p>

<p>That said, the question is poorly worded, and overly focuses on the proffered scenario, as opposed to the underlying general issue.</p>

<p>I've retagged (ethics, social, legal) and have provisionally closed the question, pending clarification.  </p>
",AImeta,actually great deal debate subject general wider ai community ethics implementation ai said question poorly worded overly focuses proffered scenario opposed underlying general issue retagged ethics social legal provisionally closed question pending clarification
1,"<p>It depends on how the questions are asked.  Linear Regression is the foundation for many different machine learning and artificial intelligence algorithms.  If someone were to ask a question on how their problem could be formatted as a regression, then I would argue that it's perfectly relevant to this SE.  Technically, linear regression alone is one of the simplest forms of machine learning.  Now, if you were to ask to prove the bounding condtions of certain types of optimizations under purely theoretical conditions, it may not be as relevant to this SE as cross validated for example.</p>

<p>In short, it depends on how the question is asked.  If it deals more with the application side of AI, then yes.  I think it is perfectly reasonable to ask on the AI SE.</p>
",AImeta,depends questions asked linear regression foundation many different machine learning artificial intelligence algorithms someone ask question problem could formatted regression would argue perfectly relevant se technically linear regression alone one simplest forms machine learning ask prove bounding condtions certain types optimizations purely theoretical conditions may relevant se cross validated example short depends question asked deals application side ai yes think perfectly reasonable ask ai se
1,"<p>I've been intensively visiting and contributing to this community in the last days/weeks. However, there are periods where I'm not able to visit this community as often as I've been recently, but, in general, I think I'm quite active here.</p>

<p>I have the impression that the moderators of this community have not been very active, which is understandable in that time and attention can wax and wane.</p>

<p>However, I believe that moderators should also be the people that more frequently visit and contribute to the website. Therefore, I think that we should hold new moderator elections.</p>
",AImeta,intensively visiting contributing community last days weeks however periods able visit community often recently general think quite active impression moderators community active understandable time attention wax wane however believe moderators also people frequently visit contribute website therefore think hold new moderator elections
1,"<p>I asked <a href=""https://ai.stackexchange.com/questions/10539/should-facebook-safety-check-work-if-an-account-is-stuck-at-a-name-change-checkp""><strong>ai.stack</strong>exchange.com/questions/10539/should-facebook-safety-check-work-if-an-account-is-stuck-at-a-name-change-checkp</a> after <a href=""https://webapps.stackexchange.com/questions/103217/will-facebook-safety-check-work-if-my-account-is-stuck-at-a-checkpoint-page""><strong>webapps.stack</strong>exchange.com/questions/103217/will-facebook-safety-check-work-if-my-account-is-stuck-at-a-checkpoint-page</a> and each time the reason is that question does not seem to fit, so the asker is personally verbally antagonized because of repeating the specific grammar/<a href=""https://en.wikipedia.org/wiki/Search_engine_optimization"" rel=""nofollow noreferrer"">SEO</a> of Mark's (@zuck's) exact dictated verbatim use of code/language?</p>

<p>To quote and repeat their apparently questionable (judging by the quick <em>solved-same-day-every-time-nobody-else-could-help-better-if-they-read-too</em> moderator responses of Stack's encouragement) wording again, <em>""Zuckerberg didn’t seem to have any specifics, but he went out of his way to tell me he thought <strong>artificial intelligence</strong> was going to play a big role in identifying moments of crisis on the network.""</em> from <a href=""https://www.wired.com/2016/11/facebook-disaster-response"" rel=""nofollow noreferrer"">https://www.wired.com/2016/11/facebook-disaster-response</a> an AI/computer site.</p>

<p>I asked about the <strong><em>fact</em></strong> of if a user still gets safety notifications.</p>
",AImeta,asked time reason question seem fit asker personally verbally antagonized repeating specific grammar mark zuck exact dictated verbatim use code language quote repeat apparently questionable judging quick solved day every time nobody else could help better read moderator responses stack encouragement wording zuckerberg nt seem specifics went way tell thought artificial intelligence going play big role identifying moments crisis network ai computer site asked fact user still gets safety notifications
1,"<p>Neither of those questions, nor this one make any sense to me. I have read and re-read trying to understand what you mean, and I honestly have no idea.</p>

<p>I would vote either of those ones as unclear what you are asking, or possible offtopic, and have to also vote this one as unclear.</p>

<p>There seems to be a language challenge here. The body of your questions doesn't align with the titles. The titles seem like off topic questions, but the body of the questions is all over the place.</p>
",AImeta,neither questions one make sense read read trying understand mean honestly idea would vote either ones unclear asking possible offtopic also vote one unclear seems language challenge body questions align titles titles seem like topic questions body questions place
1,"<p><a href=""https://ai.stackexchange.com/revisions/10539/7"">At the time</a> I read the question for the first time, this is what I interpreted:</p>

<ul>
<li><p><strong>Title</strong>: ""Should"" suggests that the question was eliciting opinions of the readers, whether ""yes"", ""no"", ""doesn't matter"", etc., which is opinion-based (off-topic) because there's no one correct answer, or every answers are correct.</p></li>
<li><p><strong>1st paragraph</strong>: According to your personal experience, ""Safety Check"" doesn't seem to work when you're stuck on ""Name Change Checkpoint"" page.</p></li>
<li><strong>2nd paragraph</strong>: According to Zuckerberg, ""Safety Check"" is using AI.</li>
<li><strong>3rd paragraph</strong>: More explanation about ""Safety Check"", particularly about it not being able to be moderated by public users (i.e. fully automatic)?</li>
<li><strong>4th paragraph</strong>:  Explanation about checkpoint page and Name Change Checkpoint page</li>
<li><strong>2 list items</strong>: Meta commentary that there are no related questions about ""Safety Check"" on AI.SE</li>
<li><strong>5th paragraph</strong>: Meta commentary, and a slight hint of another question (""<em>what is important for a question about safety</em>""), and a comment about ""911 case"" (globally recognized), ""211 case"" (I never heard about that until I googled it), and ""911 API"" (also not sure, but based on googling, perhaps an emergency reporting system)</li>
</ul>

<p>So, after finished reading this, the question left me with the impression that it is opinion-based (title) and too-broad (5th paragraph).</p>

<hr>

<p>Regarding the title of the meta discussion,</p>

<blockquote>
  <p>Is FB.com's “Safety Check/”Crisis Response"" for AI.stack or WebApp.stack if @zuck called it Artificial Intelligence?</p>
</blockquote>

<p>As I'm not a regular of this community, I don't have enough knowledge to determine if it's on-topic or not.</p>

<p><em>Perhaps</em> the inside work/mechanic of the feature <em>might</em> be on-topic, e.g. ""<em>How does Facebook's 'Safety Check' recognize a crisis and alert the relevant user?</em>"" looks like AI-related. (Note again, whether it's really acceptable question or not, I can't answer that as I'm not a regular)</p>

<p>However, for your specific question on AI.SE, reading from the title and the non-existence of the explicit question on the body made me assuming that you're asking if Facebook <em>should</em> work or not on a particular case. Most possibly due to language barrier/misunderstanding (note: I'm not a native English speaker), I read the question as a moral question (""is it right/wrong if FB is not doing this?"") or a company's policy question (""does FB do this?""), which is certainly off-topic on this site, because <em>the core question</em> is not related to AI at all.</p>

<p>This is an example case of <a href=""https://meta.stackexchange.com/q/14470/241919"">""boat programming""</a>, i.e. just because Zuckerberg stated that FB's ""Safety Check"" is done by AI, doesn't mean this question is automatically on-topic on AI.SE.</p>

<hr>

<p>After the back-and-forth comments on this meta question and <a href=""https://ai.meta.stackexchange.com/revisions/1495/2"">the revision to it</a>, looks like the real question is</p>

<blockquote>
  <p>I asked about the fact of if a user [currently stuck on checkpoint] still gets safety notifications.</p>
</blockquote>

<p>This is a clear question about <em>the current policy of Facebook</em>. While this is off-topic on AI.SE, this looks like on-topic on WebApps.SE based on their meta discussion: <a href=""https://webapps.meta.stackexchange.com/q/97"">Are questions regarding website policies on-topic?</a></p>

<p>Apparently, you have <a href=""https://webapps.stackexchange.com/questions/103217/will-facebook-safety-check-work-if-my-account-is-stuck-at-a-checkpoint-page"">posted the question on WebApps.SE</a> before posting here, but it's been deleted, and according to you, you got angry comments. I believe the core question is on-topic on WebApps.SE, but perhaps the wording gave the readers wrong impression. While I can't see deleted posts on there (so I won't judge anything), the correct place to discuss and request for feedback on how to improve your question is on their meta site, <a href=""https://webapps.meta.stackexchange.com/"">Web Applications Meta</a>.</p>
",AImeta,read question first time interpreted title suggests question eliciting opinions readers whether yes matter etc opinion based topic one correct answer every answers correct 1st paragraph according personal experience safety check seem work stuck name change checkpoint page 2nd paragraph according zuckerberg safety check using ai 3rd paragraph explanation safety check particularly able moderated public users ie fully automatic 4th paragraph explanation checkpoint page name change checkpoint page 2 list items meta commentary related questions safety check aise 5th paragraph meta commentary slight hint another question important question safety comment 911 case globally recognized 211 case never heard googled 911 api also sure based googling perhaps emergency reporting system finished reading question left impression opinion based title broad 5th paragraph regarding title meta discussion fbcom safety checkcrisis response aistack webappstack zuck called artificial intelligence regular community enough knowledge determine topic perhaps inside work mechanic feature might topic eg facebook isafety check recognize crisis alert relevant user looks like ai related note whether really acceptable question answer regular however specific question aise reading title non existence explicit question body made assuming asking facebook work particular case possibly due language barrier misunderstanding note native english speaker read question moral question right wrong fb company policy question fb certainly topic site core question related ai example case ie zuckerberg stated fb safety check done ai mean question automatically topic aise back forth comments meta question looks like real question asked fact user currently stuck checkpoint still gets safety notifications clear question current policy facebook topic aise looks like topic webappsse based meta discussion apparently posting deleted according got angry comments believe core question topic webappsse perhaps wording gave readers wrong impression see deleted posts judge anything correct place discuss request feedback improve question meta site
1,"<p>Recently a <a href=""https://ai.stackexchange.com/questions/10603/how-is-it-that-ai-can-become-biased-and-what-are-the-proposals-to-mitigate-this?noredirect=1#comment16412_10603"">question</a> was asked in this stack. In brief the question was about wrong generalisation by Google search engine. As @Neil has put it, it is probably due to:</p>
<blockquote>
<p>There is obviously a deep set reason for this, as it has appeared from non-prejudiced statistical analysis of billions of words of text from all sorts of sources.</p>
</blockquote>
<p>The problem I find with this question is:</p>
<ul>
<li>We do not know how Google's search engine generalises so it is really tough to give a sure shot answer.</li>
<li>The OP does not provide whether biases might have crept in through other credible sources.</li>
</ul>
<p>My question is how do we exactly do we answer these question keeping in mind:</p>
<ul>
<li>We have incomplete understanding of how the process works.</li>
<li>The OP is a beginner who is unlikely to have any idea that statistical bias has nothing to do with racism.</li>
<li>The OP already has a sort of rooted idea based on past experiences that the OP is being subject to prejudice, which might not be the case (quite ironic since the OPs generally tend to have strong opinions against generalisation).</li>
</ul>
<p>So what should be the general approach to answer such questions?</p>
<p><strong>NOTE:</strong> I am not talking about this specific OP, but I have seen such questions on other sites also (generally provided with wrong answer which further degrades the cause of racism). Although @Neil's answer is excellent I have said in my very first point why I thought the question was problematic.</p>
",AImeta,recently asked stack brief question wrong generalisation google search engine neil put probably due obviously deep set reason appeared non prejudiced statistical analysis billions words text sorts sources problem find question know google search engine generalises really tough give sure shot answer op provide whether biases might crept credible sources question exactly answer question keeping mind incomplete understanding process works op beginner unlikely idea statistical bias nothing racism op already sort rooted idea based past experiences op subject prejudice might case quite ironic since ops generally tend strong opinions generalisation general approach answer questions note talking specific op seen questions sites also generally provided wrong answer degrades cause racism although neil answer excellent said first point thought question problematic
1,"<p>I remember that one, and the first thing I did was edit the question to make the wording more suitable.</p>

<p>So ""Why are AI models so racist and how can we actually reverse this?"" became ""How is it that AI can become <em>biased</em>, and what are the proposals to mitigate this?""</p>

<p>Now, if this had been a question about chatbot Tay, racism would have been the relevant term, because there it's not statistical bias, but an algorithm learning and replicating racist human behavior in an NLP context.</p>

<p>In terms of answers, we need to clarify the issue or method or application, in service of disambiguation, demystification and demythification.  </p>

<hr>

<p>Bear in mind we are likely to only see questions on issues of algorithmic bias increase—it is a major issue, involving data and statistics.  (Neo-luddism seems to be rearing it's head in that the effects reported on are initially unforeseen.)  </p>

<p>If we're not lucky as a society, we are likely to also get increasing questions about procedurally generated racism.  Malicious bot activity in relation to politics I suspect will only ever increase. </p>
",AImeta,remember one first thing edit question make wording suitable ai models racist actually reverse became ai become biased proposals mitigate question chatbot tay racism would relevant term statistical bias algorithm learning replicating racist human behavior nlp context terms answers need clarify issue method application service disambiguation demystification demythification bear mind likely see questions issues algorithmic bias increase major issue involving data statistics neo luddism seems rearing head effects reported initially unforeseen lucky society likely also get increasing questions procedurally generated racism malicious bot activity relation politics suspect ever increase
1,"<p>Came across a <a href=""https://ai.stackexchange.com/a/11136/1671"">messy link-only answer today</a>, and had to edit to include the titles for the papers with embedded links. </p>

<p>Web addresses reduce readability, and links can expire, limiting future utility.  (Ideally, we would also cite the authors, but my experience is title-only works fine for search.)   </p>

<ul>
<li>Should we do a section in the ""<a href=""https://ai.stackexchange.com/help/on-topic"">What can I ask about here?</a>"" and/or else where to specify how links to research should be handled?</li>
</ul>
",AImeta,came across edit include titles papers embedded links web addresses reduce readability links expire limiting future utility ideally would also cite authors experience title works fine search section andor else specify links research handled
1,"<p>Even if someone provides a full bibliographic record in the form of “author, title, journal” this is not equal to a full reference to existing knowledge. Identify existing papers is the art of using magic keywords. If someone knows, that he needs information about “OWL-S process model”, he is able to retrieve the relevant literature easily. So the question is, which kind of keywords should be entered into the searchbox?</p>

<p>Unfortunately, I don't know. But it's true, that this is an issue on SE.AI and it make sense to discuss if a URL link is the right answer to the problem. Perhaps some kind of AI-related mindmap which provides semantic information to all the sub disciplines would solve the issue.</p>
",AImeta,even someone provides full bibliographic record form author title journal equal full reference existing knowledge identify existing papers art using magic keywords someone knows needs information owl process model able retrieve relevant literature easily question kind keywords entered searchbox unfortunately know true issue seai make sense discuss url link right answer problem perhaps kind ai related mindmap provides semantic information sub disciplines would solve issue
1,"<p>I was about to post to Meta about something similar, so I'm glad I discovered this question first. I also have some concerns about content quality. These concerns are due to what I consider systematic weaknesses rather than specific posts. </p>

<p>Because this community is so small, there's less of a reason to trust the upvote count as a measure of answer quality. To combat this, it might be worth considering requiring answers to cite sources. </p>

<p>This might be a bit harsh, though. I'm a new member of the community and probably not aware of many of the friendlier ways of incentivizing behavior. However we accomplish it, I think we should rely less on upvote count to measure answer quality. </p>
",AImeta,post meta something similar glad discovered question first also concerns content quality concerns due consider systematic weaknesses rather specific posts community small less reason trust upvote count measure answer quality combat might worth considering requiring answers cite sources might bit harsh though new member community probably aware many friendlier ways incentivizing behavior however accomplish think rely less upvote count measure answer quality
1,"<p>I also think every RL question should be on-topic here. Funnily enough, I've been flagging posts for migration to DataScience or CrossValidated according to the <a href=""https://ai.stackexchange.com/help/on-topic"">help page</a> that defines what is off-topic. But it seems like not everyone really abides by those definitions! I regularly see both implementation and mathematics questions here, related to RL and otherwise. I've stopped flagging these questions because I enjoyed reading and answering them.</p>

<p>So. If no one wants to abide by our current definition of 'on-topic' (including me), we should change it, right?</p>
",AImeta,also think every rl question topic funnily enough flagging posts migration datascience crossvalidated according defines topic seems like everyone really abides definitions regularly see implementation mathematics questions related rl otherwise stopped flagging questions enjoyed reading answering one wants abide current definition topic including change right
1,"<p>With surprise, I've noticed that the user count in SE.AI is very low. According to the statistics page <a href=""https://stackexchange.com/leagues/658/year/ai"">https://stackexchange.com/leagues/658/year/ai</a> in the last year only 28 users have increased their score by more than 100 points. The total amount of users is higher, but i would guess that per average SE.AI consists of only 50 people worldwide. This includes the European continent with 1 billion inhabitants, China+India with together 2.8 billion people and the United States which has 8 million people in New York alone.</p>

<p>Why are these people not interested in attending our nice forum? I would guess, something is wrong in SE.AI with the language. Many longterm users are proud of a dedicated vocabulary which they have learned from academic papers. Typical words used in the forum are convolutional-neural-networks, q-learning, state-space or action graph. The probability is high that the vocabulary acts as a deterrent. My recommendation is to use a more simpler vocabulary which is nearer to the mainstream audience. For example, we should replace the term neural network with “thought network” and avoid to use the word “graph search” at all. It's possible to explain a typical breadth-first search algorithm without mentioned complicated words. In a simpler English it can be reformulated as “finding an answer with a rule of thumb”. This would make the SE.AI forum more readable to the public and after a while the amount of users will grow.</p>
",AImeta,surprise noticed user count seai low according statistics page last year 28 users increased score 100 points total amount users higher would guess per average seai consists 50 people worldwide includes european continent 1 billion inhabitants chinaindia together 28 billion people united states 8 million people new york alone people interested attending nice forum would guess something wrong seai language many longterm users proud dedicated vocabulary learned academic papers typical words used forum convolutional neural networks q learning state space action graph probability high vocabulary acts deterrent recommendation use simpler vocabulary nearer mainstream audience example replace term neural network thought network avoid use word graph search possible explain typical breadth first search algorithm without mentioned complicated words simpler english reformulated finding answer rule thumb would make seai forum readable public amount users grow
1,"<p>I think this website is good for:</p>

<ol>
<li><p>Clarifying/explaining/discussing theoretical AI concepts (including concepts described in AI research papers, books, etc.), notation and terminology</p></li>
<li><p>Discussing philosophical issues related to AI (risks, safety, AGI, super-intelligence, etc)</p></li>
<li><p>Discussing the history (e.g. AI winters) and the future of AI and how it relates to other fields</p></li>
</ol>

<p>Based on all topics described in the box on the right side of the <a href=""https://en.wikipedia.org/wiki/Artificial_intelligence"" rel=""nofollow noreferrer"">AI Wikipedia page</a>, theoretical AI concepts/goals comprise:</p>

<ul>
<li>Knowledge reasoning</li>
<li>Machine learning 

<ul>
<li>Reinforcement learning</li>
<li>Supervised learning</li>
<li>Unsupervised learning</li>
<li>Online learning</li>
<li>Continual, lifelong or incremental learning</li>
<li>Active learning</li>
<li>...</li>
</ul></li>
<li>Planning</li>
<li>Natural language processing</li>
<li>Computer vision</li>
<li>Robotics</li>
<li>AGI</li>
</ul>

<p>The approaches are</p>

<ul>
<li>Symbolic (GOFAI)</li>
<li>Deep learning</li>
<li>Bayesian networks</li>
<li>Causal inference</li>
<li>Evolutionary algorithms

<ul>
<li>genetic algorithms</li>
</ul></li>
<li>Swarm intelligence

<ul>
<li>Ant colony optimization algorithms</li>
<li>Artificial bee colony algorithm </li>
<li>Particle swarm optimization</li>
</ul></li>
<li>...</li>
</ul>

<p>Some philosophical and social issues include:</p>

<ul>
<li>Ethics</li>
<li>Existential risk</li>
<li>AI tests</li>
<li>Definitions of AI</li>
<li>Chinese room</li>
<li>Weak vs strong AI</li>
<li>Super-intelligence</li>
<li>Friendly AI</li>
<li>Emotional AI</li>
<li>Explainable AI</li>
<li>...</li>
</ul>

<p>Currently, the <a href=""https://ai.stackexchange.com/help/on-topic"">Help Center</a> does not explicitly state that these topics are suited for this website, but I think it should. I think we should clarify which topics are on-topic here. In general, we can use the linked Wikipedia page to help us clarify which topics are suited for the website.</p>

<p>Furthermore, I would say that every implementation-related question should always be considered off-topic here, given that there's already Stack Overflow (and Data Science SE) for this. Which other topics are off-topic here? Should we also be more strict regarding primarily opinion-based questions? I think so, but given that philosophical questions are allowed here, we need to be careful when defining the borderline.</p>

<p>What about hardware questions related to neuromorphic chips? We actually have a <a href=""https://ai.stackexchange.com/questions/tagged/neuromorphic-engineering"" class=""post-tag"" title=""show questions tagged &#39;neuromorphic-engineering&#39;"" rel=""tag"">neuromorphic-engineering</a> tag. If they are about theoretical properties and not implementation issues, can they be considered on-topic?</p>

<p>Furthermore, it would be useful if every new user was ""forced"" to read this on and off-topic pages (before posting a new question), to avoid them to post off-topic questions. It would also be useful to have an automatic way to guide them to the more appropriate website, in those cases. Is this possible to do?</p>

<p>We should spend a few paragraphs to describe our community to new users and how it is different from (or similar to) other communities (in particular, Data Science SE, Cross Validated SE and Stack Overflow).</p>

<p>Several related questions have been asked in the past </p>

<ul>
<li><a href=""https://ai.meta.stackexchange.com/q/1252/2444"">What topics can I ask about here?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1356/2444"">Is it time to modify our site guidelines?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1215/2444"">How to distinguish between &#39;programming&#39; and &#39;conceptual&#39; questions?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1279/2444"">Technical questions are not getting closed</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1559/2444"">Why aren&#39;t implementation based questions welcome on this stack?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1287/2444"">What is in scope under the &quot;implementation of machine learning&quot; exclusion?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1081/2444"">What kind of implementation questions should be off-topic?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1430/2444"">What should the AI.SE Site Description be?</a></li>
</ul>
",AImeta,think website good clarifying explaining discussing theoretical ai concepts including concepts described ai research papers books etc notation terminology discussing philosophical issues related ai risks safety agi super intelligence etc discussing history eg ai winters future ai relates fields based topics described box right side theoretical ai concepts goals comprise knowledge reasoning machine learning reinforcement learning supervised learning unsupervised learning online learning continual lifelong incremental learning active learning planning natural language processing computer vision robotics agi approaches symbolic gofai deep learning bayesian networks causal inference evolutionary algorithms genetic algorithms swarm intelligence ant colony optimization algorithms artificial bee colony algorithm particle swarm optimization philosophical social issues include ethics existential risk ai tests definitions ai chinese room weak vs strong ai super intelligence friendly ai emotional ai explainable ai currently explicitly state topics suited website think think clarify topics topic general use linked wikipedia page help us clarify topics suited website furthermore would say every implementation related question always considered topic given already stack overflow data science se topics topic also strict regarding primarily opinion based questions think given philosophical questions allowed need careful defining borderline hardware questions related neuromorphic chips actually tag theoretical properties implementation issues considered topic furthermore would useful every new user forced read topic pages posting new question avoid post topic questions would also useful automatic way guide appropriate website cases possible spend paragraphs describe community new users different similar communities particular data science se cross validated se stack overflow several related questions asked past
1,"<p>I agree strongly and think this is necessary, especially now that we're getting a good number of questions, and need to raise out stats on having multiple answers.</p>

<p>2 suggested additions:</p>

<ul>
<li><p>Clear guidance on when to ask on Data Science and Overflow.</p></li>
<li><p>""Social impacts"" as a separate sub-category</p></li>
</ul>

<p>re: social impacts, I think it's distinct from philosophy, because it deals with tangible effects.  It would also cover ""mythology of AI"" (singularity, robot takeover, etc.) and ""AI journalism"", which I think is an increasingly important topic--policing misleading reporting.</p>
",AImeta,agree strongly think necessary especially getting good number questions need raise stats multiple answers 2 suggested additions clear guidance ask data science overflow social impacts separate sub category social impacts think distinct philosophy deals tangible effects would also cover mythology ai singularity robot takeover etc ai journalism think increasingly important topic policing misleading reporting
1,"<p>My biggest issue when I first came to SE:AI was disambiguating all of the terminology.  There are so many forms of Neural Networks, it was hard to know the distinctions for any given acronym.  SE:AI helped clarify, <em>precisely because</em> we have users with academic and industry backgrounds who can explain things is plain language.</p>

<p>Changing terminologies on a web forum, even a Q&amp;A forum strikes me as a bad idea.  One of the functions of research papers is to formalize terms, and industry jargon arises naturally from that field. </p>
",AImeta,biggest issue first came se ai disambiguating terminology many forms neural networks hard know distinctions given acronym se ai helped clarify precisely users academic industry backgrounds explain things plain language changing terminologies web forum even q forum strikes bad idea one functions research papers formalize terms industry jargon arises naturally field
1,"<p>I mostly agree with the guidelines for on-topic topics proposed in the OP. The only possibly gray area for me is in this:</p>

<blockquote>
  <p>Furthermore, I would say that every implementation-related question should always be considered off-topic here, given that there's already Stack Overflow (and Data Science SE) for this.</p>
</blockquote>

<p>Now in most cases I do agree implementation-only questions are better suited for StackOverflow (especially Tensorflow ones, since Stackoverflow is the official place for Tensorflow questions). However, a recent implementation question that I feel like may be better suited here was this one:</p>

<p><a href=""https://ai.stackexchange.com/q/11433/1641"">Expressing Arbitrary Reward Functions as Potential-Based Advice (PBA)</a></p>

<p>It technically is just an implementation / bugfixing question, which I'd usually feel like should be off-topic... but it is about a rather specific, non-trivial, relatively recent AI publication. I was personally already familiar with the paper (maybe because I spent a couple of years working in the same lab that these publications came from earlier, with some of the same people), but I think very few people on StackOverflow would be familiar with the paper or feel like reading it just to make sure they'd be able to answer the question correctly.</p>

<p>Would such implementation questions about very specific, relatively uncommon approaches still be considered on-topic here? I'm not talking about common stuff, like implementing ""Neural Networks"" or ""an image classifier"", plenty of people on SO know about that too.</p>
",AImeta,mostly agree guidelines topic topics proposed op possibly gray area furthermore would say every implementation related question always considered topic given already stack overflow data science se cases agree implementation questions better suited stackoverflow especially tensorflow ones since stackoverflow official place tensorflow questions however recent implementation question feel like may better suited one technically implementation bugfixing question would usually feel like topic rather specific non trivial relatively recent ai publication personally already familiar paper maybe spent couple years working lab publications came earlier people think people stackoverflow would familiar paper feel like reading make sure would able answer question correctly would implementation questions specific relatively uncommon approaches still considered topic talking common stuff like implementing neural networks image classifier plenty people know
1,"<p>Recently, there have been several low quality questions, with respect to the topics of this website. For example</p>

<ul>
<li><p><s><a href=""https://ai.stackexchange.com/q/11951/2444"">https://ai.stackexchange.com/q/11951/2444</a></s> (deleted) </p></li>
<li><p><s><a href=""https://ai.stackexchange.com/q/11950/2444"">https://ai.stackexchange.com/q/11950/2444</a></s> (deleted) </p></li>
<li><p><a href=""https://ai.stackexchange.com/q/11956/2444"">How do I choose the search algorithm for a particular task?</a></p></li>
<li><p><s><a href=""https://ai.stackexchange.com/q/11938/2444"">https://ai.stackexchange.com/q/11938/2444</a></s> (deleted) </p></li>
</ul>

<p>The reputation points should also be used to downvote the posts that deserve to be down-voted (like the mentioned ones), where the asker (or answerer) has put very little (or no) effort in writing an understandable post or has not performed some research before asking, so that to discourage them to do it again next time. It surprises me that these questions do not have more downvotes, which should be the first and fastest visual measure of the quality of the post. </p>

<p>Why is this community too tolerant or often not compliant with the Stack Exchange ""standards"" (of ""good"" posts)?</p>
",AImeta,recently several low quality questions respect topics website example deleted deleted deleted reputation points also used downvote posts deserve voted like mentioned ones asker answerer put little effort writing understandable post performed research asking discourage next time surprises questions downvotes first fastest visual measure quality post community tolerant often compliant stack exchange standards good posts
1,"<p>I posted two questions in AI site,which are now deleted recent questions.I flagged both the questions.I thought flagging contained many important aspects of both questions.Are not the flagging worthy of moderators' attention.Are the flags declined but I am curious about moderators' remarks,comments.When my timed suspension will be  lifted in AI site? also I have flagged one question in World building site which too was not responded to.can my confusions be cleared.In world building site the suspension will be lifted on 27042019 .</p>
",AImeta,posted two questions ai site deleted recent questionsi flagged questionsi thought flagging contained many important aspects questionsare flagging worthy moderators attentionare flags declined curious moderators remarks commentswhen timed suspension lifted ai site also flagged one question world building site responded tocan confusions clearedin world building site suspension lifted 27042019
1,"<blockquote>
  <p>I thought flagging contained many important aspects of both questions.</p>
</blockquote>

<p><a href=""https://ai.stackexchange.com/help/flagging"">Flagging</a> should only be used to indicate that moderator action is needed. Flags are not visible to most users, so they are not suitable for expanding or clarifying a question. If you would like to change a post, you can edit it using the ""edit"" link.</p>

<blockquote>
  <p>When my timed suspension will be lifted in AI site?</p>
</blockquote>

<p>As far as I know you haven't been <a href=""https://meta.stackexchange.com/q/125268/295684"">suspended</a> on AI. If you receive an error message when trying to post, it is likely that you've encountered a <a href=""https://ai.stackexchange.com/help/question-bans"">question ban</a>. These are placed automatically by the system after many of your questions were poorly received. Questions that fall short of our <a href=""https://ai.stackexchange.com/help/how-to-ask"">quality standards</a> (e.g. by addressing numerous unrelated topics, having unclear/illegible writing, or being <a href=""https://ai.stackexchange.com/help/dont-ask"">unsuited for Q&amp;A format</a>) are subject to closure and eventually removal. Question bans may be lifted after existing posts are improved; there are also occasional chances to ask another question anyway.</p>

<blockquote>
  <p>In world building site the suspension will be lifted on 27042019</p>
</blockquote>

<p>Your Worldbuilding profile indicates your account is suspended ""because of low-quality contributions."" This indicates similar consistent issues as a question ban. Please review Worldbuilding's asking guidance for what they expect from questions.</p>
",AImeta,thought flagging contained many important aspects questions used indicate moderator action needed flags visible users suitable expanding clarifying question would like change post edit using edit link timed suspension lifted ai site far know ai receive error message trying post likely encountered placed automatically system many questions poorly received questions fall short eg addressing numerous unrelated topics unclear illegible writing subject closure eventually removal question bans may lifted existing posts improved also occasional chances ask another question anyway world building site suspension lifted 27042019 worldbuilding profile indicates account suspended low quality contributions indicates similar consistent issues question ban please review worldbuilding asking guidance expect questions
1,"<p>Personally I don't mind the softball questions that could have been answered with a Google search because I feel SE:AI can add context to a Wikipedia entry, and I think we should be the #2 result for that stuff, behind Wikipedia but certainly ahead of Quora.  (Drives traffic to our site and potentially expands our user base.)</p>

<p>Regarding the other stuff, I think we need more voting in general, both up and down!</p>
",AImeta,personally mind softball questions could answered google search feel se ai add context wikipedia entry think 2 result stuff behind wikipedia certainly ahead quora drives traffic site potentially expands user base regarding stuff think need voting general
1,"<p>I have noticed that this website is full of spam. Wouldn't it be beneficial, in order to improve the quality of the contents of this website, to peer-review questions and answers before posting them?</p>

<p>A few possible advantages:</p>

<ol>
<li>No more spam</li>
<li>Less number of duplicate questions and answers</li>
<li>No more off-topic questions and answers</li>
<li>It might motivate users to be more active</li>
</ol>

<p>A few disadvantages</p>

<ol>
<li><p>It might slow down the process of helping. </p>

<ul>
<li>However, an answer can't be given if there isn't someone that can peer-review the post (anyway)</li>
</ul></li>
</ol>

<p>The peer-reviews shouldn't be very sophisticated. They should only be used to determine if a post is</p>

<ol>
<li>spam</li>
<li>off-topic</li>
<li>not a duplicate</li>
</ol>

<p>What are your ideas? Of course, we can already mark questions as duplicate or even delete posts. However, with this preventive approach, we would avoid cluttering the website, to start with.</p>
",AImeta,noticed website full spam would beneficial order improve quality contents website peer review questions answers posting possible advantages spam less number duplicate questions answers topic questions answers might motivate users active disadvantages might slow process helping however answer given someone peer review post anyway peer reviews sophisticated used determine post spam topic duplicate ideas course already mark questions duplicate even delete posts however preventive approach would avoid cluttering website start
1,"<p>Let us sort the ideas a bit. A “peer review before posting” is equal to a time synchronous quality control. That means, a question is posted on time code 00:00 and the decision if it's spam or not is made in a limited timeframe which is around 1 days. This results into a incoming queue which has to be processed with a guarantied maximum response time.</p>

<p>The problem is, that in such a case the poster of the incoming traffic will determine what the moderators on the Q&amp;A website have to do. Let me give an example. A stranger is posting a question about neural networks on Monday, at 07:00 AM. Then the stranger is forcing the moderators to decide about this posting until Tuesday at 07:00 AM. Otherwise the queue becomes jammed.</p>

<p>The alternative to an synchronous incoming control is an asynchronous peer review. Which means, that all incoming messages are passing the filter, and the moderators will decide by their own wishes which of the postings should be answered and which not. If no queue is there, the line can't be blocked.</p>
",AImeta,let us sort ideas bit peer review posting equal time synchronous quality control means question posted time code 0000 decision spam made limited timeframe around 1 days results incoming queue processed guarantied maximum response time problem case poster incoming traffic determine moderators q website let give example stranger posting question neural networks monday 0700 stranger forcing moderators decide posting tuesday 0700 otherwise queue becomes jammed alternative synchronous incoming control asynchronous peer review means incoming messages passing filter moderators decide wishes postings answered queue line blocked
1,"<p>Opening this Meta to solicit opinions.  (I'll put my own in a separate answer.)</p>

<ul>
<li>Is referencing a Quora question materially different than referencing one's blog?</li>
<li>Should this be addressed by voting, where the answer is judged on the strenght of the content, as opposed to the source? </li>
</ul>
",AImeta,opening meta solicit opinions put separate answer referencing quora question materially different referencing one blog addressed voting answer judged strenght content opposed source
1,"<p>My feeling is this should be addressed by voting since Quora is no more commercial than Stack (limited ads,) thus such links don't constitute spam.</p>

<p>I do see Stack &amp; Quora in competition, although I hope Stack will ultimately prevail in terms of search rankings.  (US Alexa ranking for Stack is 115 worldwide and 65 in the US, vs. 78/47, so we're not quite there yet.)</p>

<p>But, in some sense, both sites have the same mission, if Stack seems to to a better job because of our voting system.  </p>
",AImeta,feeling addressed voting since quora commercial stack limited ads thus links constitute spam see stack quora competition although hope stack ultimately prevail terms search rankings us alexa ranking stack 115 worldwide 65 us vs 7847 quite yet sense sites mission stack seems better job voting system
1,"<p>Just found something immensely interesting on ai.SE.</p>

<p><a href=""https://ai.stackexchange.com/questions/9582/can-someone-suggest-me-a-platform-to-develop-a-mental-health-mobile-app-for-andr"">First Question</a></p>

<p><a href=""https://ai.stackexchange.com/questions/9542/can-someone-suggest-me-a-platform-to-develop-a-mental-health-mobile-app-for-andr"">Second Question:)</a></p>

<p><strong>Both the questions are identical.</strong> They are not just duplicate questions rephrasing eachother, <strong>they are literally the same.</strong> </p>

<p>I don't know how neither of them was not marked as duplicate by fellow users. <em>Moreover, the questions have received separate answers and upvotes too</em>. Does this raise any concerns to/from the community?</p>
",AImeta,found something immensely interesting aise questions identical duplicate questions rephrasing eachother literally know neither marked duplicate fellow users moreover questions received separate answers upvotes raise concerns community
1,"<p>Looking at it, it looks like the OP didn't realise how user accounts work, or how the site works, so created a new account and a new post in order to be able to interact with the post.</p>

<p>I have flagged for the posts and the user accounts to be merged.</p>

<p>It's not a major issue - on a small site with few active members things like this happen, just vote to close as dupe or flag if necessary.</p>
",AImeta,looking looks like op realise user accounts work site works created new account new post order able interact post flagged posts user accounts merged major issue small site active members things like happen vote close dupe flag necessary
1,"<p>I think it's fine, right? As long as it's not just a link, but there is some explanation surrounding it. Referencing things that have been written elsewhere seems to be very much preferable to... copying without attribution?</p>

<p>Sometimes in my answers I'll reference papers which I'm an author on myself. I don't think that's really different in any tangible way?</p>
",AImeta,think fine right long link explanation surrounding referencing things written elsewhere seems much preferable copying without attribution sometimes answers reference papers author think really different tangible way
1,"<p>I raised the flag, since it was the second time OP posted link to quora answer written by the OP. IMO referring to one's blog is ok, but referring frequently is not ok. Also it is not much hard to copy paste from the blog and at the end attribute it to the blog (both the answers did not involve any technical or Math details), so it does not make sense not to do it.</p>

<p>Also since the user was new I did not want to comment wrongly on what's accepted and what's not in this stack, so I just thought moderators will do a better job.</p>
",AImeta,raised flag since second time op posted link quora answer written op imo referring one blog ok referring frequently ok also much hard copy paste blog end attribute blog answers involve technical math details make sense also since user new want comment wrongly accepted stack thought moderators better job
1,"<p>A new tag <code>ant-colony</code> has been introduced. I see 2 problems here:</p>

<ul>
<li>The name should have been <code>ant-colony-optimization</code></li>
<li>The tag <code>swarm-intelligence</code> should already cover ant colony optmization techniques, so it does not make much sense for a new tag.</li>
</ul>

<p>What are your thoughts?</p>
",AImeta,new tag introduced see 2 problems name tag already cover ant colony optmization techniques make much sense new tag thoughts
1,"<p>I introduced this tag because ACO is a well developed sub-field of swarm intelligence, so it deserves (IHMO) its own tag, like e.g. reinforcement learning deserves its own tag (compared to machine learning) on a website dedicated to AI.</p>

<p>I used <a href=""https://ai.stackexchange.com/questions/tagged/ant-colony"" class=""post-tag"" title=""show questions tagged &#39;ant-colony&#39;"" rel=""tag"">ant-colony</a> because it is shorter and there's no ambiguity in the field of AI. Furthermore, a lot of people do not refer to these algorithms as ""ACO"", but e.g. as ""ant colony system"" or just ""ant colony algorithms"". I would argue that <a href=""https://ai.stackexchange.com/questions/tagged/ant-colony"" class=""post-tag"" title=""show questions tagged &#39;ant-colony&#39;"" rel=""tag"">ant-colony</a> is a more general tag and expression.</p>

<p>Furthermore, several questions on ACO have already been asked on the website.</p>
",AImeta,introduced tag aco well developed sub field swarm intelligence deserves ihmo tag like eg reinforcement learning deserves tag compared machine learning website dedicated ai used shorter ambiguity field ai furthermore lot people refer algorithms aco eg ant colony system ant colony algorithms would argue general tag expression furthermore several questions aco already asked website
1,"<p>Wondering if we should maybe just have a general tag for ""ant-intelligence"" that could cover all aspects, including swarm intelligence, engineering (tunnel building) and path finding..</p>
",AImeta,wondering maybe general tag ant intelligence could cover aspects including swarm intelligence engineering tunnel building path finding
1,"<p>In this <a href=""https://ai.stackexchange.com/questions/12630/infinite-horizon-in-reinforcement-learning"">question</a> (check edit history) you can clearly see the author hosting a IEEE journal paper on a document hosting site (the IEEE links are also provided). Normally, the document should not be  able to be accessed by all (only people with IEEE membership). I am all for free knowledge and very much against monetization of research papers. But are we breaking any laws here by allowing this question or is it upto the OP only?</p>
",AImeta,check edit history clearly see author hosting ieee journal paper document hosting site ieee links also provided normally document able accessed people ieee membership free knowledge much monetization research papers breaking laws allowing question upto op
1,"<p>To be safe, I would remove the link / replace it with the official (non-PDF) link. </p>

<p>I don't know what IEEE's policy was back in 2008 (which is when this particular paper was published), but I am familiar with their policy in more recent years (since I've got some recent IEEE papers myself). Basically, all copyright is transferred to IEEE, but in return IEEE gives a few rights/privileges back to the authors. </p>

<p>This boils down to that the authors of the paper are also allowed to put certain versions of their paper (not the final published version as it appears in journal/proceedings) on their own personal homepage, or on something like arXiv (I'm not sure if arXiv was always allowed, but it is allowed recently). They do not permit publishing just anywhere though, and also certainly don't permit people who are not the original authors to distribute it wherever they like.</p>

<p>If the authors of this paper had published the pdf on their own homepages for example, we could've easily linked to that... but that does not appear to be the case here as far as I can tell. So, somewhere along the line it looks like copyright is being violated. I don't think the violation is necessarily on this site (since we just have a link to a different place, and the distribution over there on that site is the violation)... but probably better to remove it anyway.</p>
",AImeta,safe would remove link replace official non pdf link know ieee policy back 2008 particular paper published familiar policy recent years since got recent ieee papers basically copyright transferred ieee return ieee gives rights privileges back authors boils authors paper also allowed put certain versions paper final published version appears journal proceedings personal homepage something like arxiv sure arxiv always allowed allowed recently permit publishing anywhere though also certainly permit people original authors distribute wherever like authors paper published pdf homepages example could easily linked appear case far tell somewhere along line looks like copyright violated think violation necessarily site since link different place distribution site violation probably better remove anyway
1,"<p>Quora has login popup which often prevent reading answer. In my opinion it's definitely not OK to reference  Quora.</p>
",AImeta,quora login popup often prevent reading answer opinion definitely ok reference quora
1,"<p><a href=""https://ai.stackexchange.com/a/12722/1671"">https://ai.stackexchange.com/a/12722/1671</a></p>

<p>Essentially it's a cut and paste of an article posted on an presumable for-profit AI education site/venture: <a href=""https://www.analyticsvidhya.com/blog/2019/01/learning-path-data-scientist-machine-learning-2019/"" rel=""nofollow noreferrer"">https://www.analyticsvidhya.com/blog/2019/01/learning-path-data-scientist-machine-learning-2019/</a></p>

<p>I had deleted a former version of this answer for lack of attribution.</p>

<p>Technically, it's a form of promotion, but that doesn't necessarily invalidate the info.</p>

<ul>
<li><strong>Post your opinions.  I'm looking for guidance and some consensus on how the trusted, active members of the community want me to deal with this kind of post.</strong></li>
</ul>

<p>(Context: I tend to always give OP's the benefit of the doubt, and err on the side of permissibility.  Sometimes that's a strength, sometimes a weakness.  But it's you folks who are driving this community, so you preferences on the matter must outweigh my own inclinations.)  </p>
",AImeta,essentially cut paste article posted presumable profit ai education site venture deleted former version answer lack attribution technically form promotion necessarily invalidate info post opinions looking guidance consensus trusted active members community want deal kind post context tend always give op benefit doubt err side permissibility sometimes strength sometimes weakness folks driving community preferences matter must outweigh inclinations
1,"<p>I believe that, in an academic setting, this would be considered plagiarism, even though you cite or attribute it. If we accept this type of answers, we might encourage users do it again (which would not bring anything new to the web) or to adopt this strategy to easily increase their reputation.</p>

<p>So, I am against this type of answers (especially, if the author of the answer is not the author of the cited article).</p>
",AImeta,believe academic setting would considered plagiarism even though cite attribute accept type answers might encourage users would bring anything new web adopt strategy easily increase reputation type answers especially author answer author cited article
1,"<p>The following questions are extremely similar</p>
<ol>
<li><s>https://ai.stackexchange.com/q/8641/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/1432/2444"">What kind of education is required for researchers in AI?</a> and then deleted, as the answers weren't particularly useful.</li>
</ul>
<ol start=""2"">
<li><s>https://ai.stackexchange.com/q/8780/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/1913/2444"">What are the steps to follow to learn artificial intelligence?</a></li>
</ul>
<ol start=""3"">
<li><p><a href=""https://ai.stackexchange.com/q/1913/2444"">What are the steps to follow to learn artificial intelligence?</a> (get started)</p>
</li>
<li><p><s>https://ai.stackexchange.com/q/3374/2444</s></p>
</li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/1913/2444"">What are the steps to follow to learn artificial intelligence?</a></li>
</ul>
<ol start=""5"">
<li><s>https://ai.stackexchange.com/q/10513/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/3374/2444"">How does one start learning artificial intelligence?</a> and deleted given that the users have not contributed to the site for like 1 year and they have basically never participated if not in that post. Furthermore, the given answer wasn't particularly useful.</li>
</ul>
<ol start=""6"">
<li><s>https://ai.stackexchange.com/q/3548/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/3374/2444"">How does one start learning artificial intelligence?</a></li>
</ul>
<ol start=""7"">
<li><s>https://ai.stackexchange.com/q/4933/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of and merged with <a href=""https://ai.stackexchange.com/q/3548/2444"">How should I get started with artificial intelligence?</a>, which is an older question, which basically asks exactly the same thing.</li>
</ul>
<ol start=""8"">
<li><s>https://ai.stackexchange.com/q/9032/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/3548/2444"">How should I get started with artificial intelligence?</a></li>
</ul>
<ol start=""9"">
<li><s>https://ai.stackexchange.com/q/3740/2444</s></li>
</ol>
<ul>
<li>Closed as too broad</li>
</ul>
<ol start=""10"">
<li><s>https://ai.stackexchange.com/q/7986/2444</s></li>
</ol>
<ul>
<li>Closed as too broad and then deleted because the answers were all more or less poor or only opinions</li>
</ul>
<ol start=""11"">
<li><s>https://ai.stackexchange.com/q/6909/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of and merged with <a href=""https://ai.stackexchange.com/q/3548/2444"">How should I get started with artificial intelligence?</a></li>
</ul>
<ol start=""12"">
<li><a href=""https://ai.stackexchange.com/q/4464/2444"">Sources on the AI theory, philosophy, tools and applications</a> (get started, sources)</li>
<li><s>https://ai.stackexchange.com/q/6679/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/1913/2444"">What are the steps to follow to learn artificial intelligence?</a></li>
</ul>
<ol start=""14"">
<li><s>https://ai.stackexchange.com/q/4796/2444</s></li>
</ol>
<ul>
<li>Closed as too broad and deleted because the answers weren't particularly useful and the users that provided the answers have not visited the site for a long time.</li>
</ul>
<ol start=""15"">
<li><s>https://ai.stackexchange.com/q/8203/2444</s></li>
</ol>
<ul>
<li>Closed as primarily opinion-based</li>
</ul>
<ol start=""16"">
<li><s>https://ai.stackexchange.com/q/13197/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/8203/2444"">What are examples of reference books to start with AI?</a></li>
</ul>
<ol start=""17"">
<li><s>https://ai.stackexchange.com/q/6903/2444</s></li>
</ol>
<ul>
<li>Closed as primarily opinion-based</li>
</ul>
<ol start=""18"">
<li><s>https://ai.stackexchange.com/q/8432/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/7352/2444"">What are the mathematical prerequisites for an AI researcher?</a></li>
</ul>
<ol start=""19"">
<li><s>https://ai.stackexchange.com/q/13024/2444</s></li>
</ol>
<ul>
<li>Closed as primarily opinion-based</li>
</ul>
<ol start=""20"">
<li><p><a href=""https://ai.stackexchange.com/q/1432/2444"">What kind of education is required for researchers in AI?</a> (research)</p>
</li>
<li><p><s>https://ai.stackexchange.com/q/12899/2444</s></p>
</li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/1432/2444"">What kind of education is required for researchers in AI?</a> and then deleted because there was no answer.</li>
</ul>
<ol start=""22"">
<li><s>https://ai.stackexchange.com/q/13556/2444</s></li>
</ol>
<ul>
<li>Closed as a duplicate of <a href=""https://ai.stackexchange.com/q/7352/2444"">What are the mathematical prerequisites for an AI researcher?</a> and then deleted.</li>
</ul>
<ol start=""23"">
<li><p><a href=""https://ai.stackexchange.com/q/7352/2444"">What are the mathematical prerequisites for an AI researcher?</a> (math for research)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/q/6267/2444"">What are the mathematical prerequisites to be able to study general artificial intelligence?</a> (math for AGI)</p>
</li>
<li><p><s>https://ai.stackexchange.com/q/8131/2444</s></p>
</li>
</ol>
<ul>
<li>Closed as too broad</li>
</ul>
<p>And the list goes on. I believe that <strong>some</strong> of these are <em>not</em> duplicates. However, <strong>most</strong> of them <em>are</em> duplicates (because they lead to the same answer). Why are these questions not marked as duplicates? This is the only SE website (that I know of) that allows so similar questions to remain open. I think it is unproductive to keep having all these very similar questions, so most of them should be marked as duplicates (of the first question asked).</p>
<p>We also have a similar ML series</p>
<ol>
<li><a href=""https://ai.stackexchange.com/q/3291/2444"">How can I start learning mathematics for machine learning?</a></li>
<li><a href=""https://ai.stackexchange.com/q/4509/2444"">What do I need to study for machine learning?</a></li>
<li><s>https://ai.stackexchange.com/q/10725/2444</s></li>
<li><s>https://ai.stackexchange.com/q/5589/2444</s></li>
<li><a href=""https://ai.stackexchange.com/q/4780/2444"">How to start looking for machine learning opportunities in projects</a></li>
<li><a href=""https://ai.stackexchange.com/q/8987/2444"">What are the prerequisites for starting out in deep learning?</a></li>
<li><s>https://ai.stackexchange.com/q/7961/2444</s></li>
<li>https://ai.stackexchange.com/q/14136/2444</li>
<li><a href=""https://ai.stackexchange.com/q/15946/2444"">Which courses in computer science and logic are relevant to Machine Learning?</a></li>
</ol>
<p>Some of these questions have even been closed as off-topic or too broad.</p>
<p>See also</p>
<ol>
<li><a href=""https://ai.stackexchange.com/q/10070/2444"">How can I systematically learn about the theory of neural networks?</a></li>
</ol>
",AImeta,following questions extremely similar httpsaistackexchangecomq86412444 closed duplicate deleted answers particularly useful httpsaistackexchangecomq87802444 closed duplicate get started httpsaistackexchangecomq33742444 closed duplicate httpsaistackexchangecomq105132444 closed duplicate deleted given users contributed site like 1 year basically never participated post furthermore given answer particularly useful httpsaistackexchangecomq35482444 closed duplicate httpsaistackexchangecomq49332444 closed duplicate merged older question basically asks exactly thing httpsaistackexchangecomq90322444 closed duplicate httpsaistackexchangecomq37402444 closed broad httpsaistackexchangecomq79862444 closed broad deleted answers less poor opinions httpsaistackexchangecomq69092444 closed duplicate merged get started sources httpsaistackexchangecomq66792444 closed duplicate httpsaistackexchangecomq47962444 closed broad deleted answers particularly useful users provided answers visited site long time httpsaistackexchangecomq82032444 closed primarily opinion based httpsaistackexchangecomq131972444 closed duplicate httpsaistackexchangecomq69032444 closed primarily opinion based httpsaistackexchangecomq84322444 closed duplicate httpsaistackexchangecomq130242444 closed primarily opinion based research httpsaistackexchangecomq128992444 closed duplicate deleted answer httpsaistackexchangecomq135562444 closed duplicate deleted math research math agi httpsaistackexchangecomq81312444 closed broad list goes believe duplicates however duplicates lead answer questions marked duplicates se website know allows similar questions remain open think unproductive keep similar questions marked duplicates first question asked also similar ml series httpsaistackexchangecomq107252444 httpsaistackexchangecomq55892444 httpsaistackexchangecomq79612444 httpsaistackexchangecomq141362444 questions even closed topic broad see also
1,"<p>I voted this <a href=""https://ai.stackexchange.com/questions/12790/what-are-the-best-ai-courses-leading-to-ai-certifications"">question</a>n as off topic. Now, ignoring the fact whether it is off topic or not one of the answer by @AlenParker provides link to some courses, all of which are offered in a profit based manner (profit for the offering company). And out of those links at-least 2 are probably trustworthy (MIT and probably ARTIBA).</p>

<p>My problem is should we allow such answers to exist which promote some links which are clearly profit based and also cannot be trusted? This is especially highlighted with the example of a very popular company named Udemy which hosts courses for profit (but no verification) is made whether the instructor is qualified or not? Atleast 2 famous YouTubers (who provide free programming courses) have spoken out against the quality and copyright violation of these courses. So, should we allow such links to be posted? Organisations like EdX, Coursera and Udacity are fine since they are transparent, non-profit (generally according to them money goes in improving the course) and in general takes a nominal fee to provide courses from famous instructors and colleges which kind of verifies the course content.</p>

<p>So what are your thoughts on these? Keep in mind more important than than the spam viewpoint of these answers is that if someone genuinely tries these super pricey courses and does not get money's worth, the person is likely to squarely put blame on this site.</p>
",AImeta,voted n topic ignoring fact whether topic one answer alenparker provides link courses offered profit based manner profit offering company links least 2 probably trustworthy mit probably artiba problem allow answers exist promote links clearly profit based also trusted especially highlighted example popular company named udemy hosts courses profit verification made whether instructor qualified atleast 2 famous youtubers provide free programming courses spoken quality copyright violation courses allow links posted organisations like edx coursera udacity fine since transparent non profit generally according money goes improving course general takes nominal fee provide courses famous instructors colleges kind verifies course content thoughts keep mind important spam viewpoint answers someone genuinely tries super pricey courses get money worth person likely squarely put blame site
1,"<p>I also think that this type of questions should be closed as off-topic and, anyway, they will lead to primarily opinion-based answers. However, we have already a lot of these questions on the website.</p>

<p>I think that the quality of the answers should be assessed using the voting system. If someone does not agree with the suggestions, then he/she should downvote the answer (and possibly leave a comment in order to encourage the answerer to improve his/her answer). Furthemore, it is the reponsibility of the asker to accept or not an answer. In general, the web is full of misleading and incorrect information, so it is the responsibility of the web surfer to select or not any information.</p>
",AImeta,also think type questions closed topic anyway lead primarily opinion based answers however already lot questions website think quality answers assessed using voting system someone agree suggestions downvote answer possibly leave comment order encourage answerer improve answer furthemore reponsibility asker accept answer general web full misleading incorrect information responsibility web surfer select information
1,"<p>The following post <a href=""https://ai.stackexchange.com/q/7079/2444"">What topologies are largely unexplored in machine learning?</a> asks more than <span class=""math-container"">$6$</span> questions, which are quite unrelated to each other. Shouldn't this type of posts be closed as too broad? </p>

<p>According to <a href=""https://meta.stackexchange.com/q/39223/287113"">One post with multiple questions or multiple posts?</a>, the suggestion is to ask one question per post (especially, if the questions are quite unrelated), which I completely agree with. </p>

<p>See also <a href=""https://meta.stackexchange.com/q/256001/287113"">Flagging post that has multiple questions?</a> and <a href=""https://meta.stackoverflow.com/q/267058/3924118"">https://meta.stackoverflow.com/q/267058/3924118</a>. They all state that posts with multiple questions should be closed as too broad. </p>

<p>I've already flagged the question above as too broad, but my vote was rejected (so my only way of contributing to this community is to downvote such a question, which, IMHO, would anyway deserve a downvote, because of the lack of focus and simplicity). </p>

<p>Is it possible to know why moderators haven't closed this question as too broad?</p>

<p>A few other questions that should all be closed as too broad:</p>

<ul>
<li><s><a href=""https://ai.stackexchange.com/q/7547/2444"">Is topological sophistication necessary to the furtherance of AI?</a></s></li>
<li><s><a href=""https://ai.stackexchange.com/q/7517/2444"">Is human-like intelligence the smart objective?</a></s> (already closed)</li>
<li><s><a href=""https://ai.stackexchange.com/q/7205/2444"">Why Python not C?</a></s></li>
<li><s><a href=""https://ai.stackexchange.com/q/8106/2444"">What are the algebraic properties of intelligence?</a></s></li>
<li><s><a href=""https://ai.stackexchange.com/q/11233/2444"">How can a collaboration game be defined mathematically?</a></s> (already closed)</li>
<li><s><a href=""https://ai.stackexchange.com/q/7337/2444"">Is the singularity concept mathematically flawed?</a></s> (already closed)</li>
<li><a href=""https://ai.stackexchange.com/q/7310/2444"">What forces direct research in AI and is the resulting direction a good choice?</a></li>
<li><s><a href=""https://ai.stackexchange.com/q/9450/2444"">Would AI not obsessed with winning be better citizens of the world?</a></s></li>
<li><s><a href=""https://ai.stackexchange.com/q/10098/2444"">Design for a lovable and loving AI?</a></s></li>
<li><s><a href=""https://ai.stackexchange.com/q/7523/2444"">https://ai.stackexchange.com/q/7523/2444</a></s> (already closed)</li>
<li><s><a href=""https://ai.stackexchange.com/q/10055/2444"">What AI ethics classes are available and should they be taught universally?</a></s></li>
<li><s><a href=""https://ai.stackexchange.com/q/8049/2444"">In what way can we measure control between humans and machines?</a></s></li>
<li><s><a href=""https://ai.stackexchange.com/q/10287/2444"">Is AI research culture predisposed to adversarialism while even the mathematics is more friendly?</a></s> (already closed)</li>
<li><s><a href=""https://ai.stackexchange.com/q/10106/2444"">https://ai.stackexchange.com/q/10106/2444</a></s> (already closed)</li>
<li><s><a href=""https://ai.stackexchange.com/q/8915/2444"">Way to control movement and coverage in an embedded AI cleaning system?</a></s> (already closed)</li>
<li><s><a href=""https://ai.stackexchange.com/q/6809/2444"">https://ai.stackexchange.com/q/6809/2444</a></s> (already closed)</li>
<li><s><a href=""https://ai.stackexchange.com/q/14136/2444"">Learning AI and Big Data suggestion</a></s> (already closed)</li>
<li><s><a href=""https://ai.stackexchange.com/q/7804/2444"">How do I change the values of a neural net</a></s> (already closed)</li>
<li><a href=""https://ai.stackexchange.com/q/16606/2444"">How to understand the 4 steps of Monte Carlo Tree Search</a></li>
<li><s><a href=""https://ai.stackexchange.com/q/7642/2444"">The future of chatbots</a></s></li>
<li><a href=""https://ai.stackexchange.com/q/16916/2444"">Designing a reinforcement learning AI for a game of connect 4</a></li>
<li><s><a href=""https://ai.stackexchange.com/q/7280/2444"">What is the relationship between these two taxonomies for machine learning with neural networks?</a></s> (I've edited the post only to leave one question)</li>
</ul>

<p>All of these questions (which I have read) should be closed as too broad (given that they ask more than one unrelated question).</p>

<p>If this community wants to attract more people, it also needs good questions and answers, that are compliant with ""standards of quality"" of SE websites.</p>
",AImeta,following post asks 6 questions quite unrelated type posts closed broad according suggestion ask one question per post especially questions quite unrelated completely agree see also state posts multiple questions closed broad already flagged question broad vote rejected way contributing community downvote question imho would anyway deserve downvote lack focus simplicity possible know moderators closed question broad questions closed broad already closed already closed already closed already closed already closed already closed already closed already closed already closed already closed edited post leave one question questions read closed broad given ask one unrelated question community wants attract people also needs good questions answers compliant standards quality se websites
1,"<p>In this long post, I will describe a few issues associated with tags that I believe should be solved. Feel free to add your opinions regarding the issues or specific tags (or feel free to edit this question to add more issues or tags)</p>
<h3>Tags that should NOT exist</h3>
<p>I've observed that, on this website, there are a lot of tags whose meaning is not widely accepted yet or it is not understandable. <s>For example, <a href=""https://ai.stackexchange.com/questions/tagged/unassisted-learning"" class=""post-tag"" title=""show questions tagged &#39;unassisted-learning&#39;"" rel=""tag"">unassisted-learning</a>. I've never heard of this expression before (and I am involved in the field of AI). Even though an expression occurs in a web article, it doesn't mean that it deserves a tag on this website</s>.</p>
<p>I believe that only topics that have a &quot;considerable amount&quot; of associated research literature should have an associated tag, for example, questions related to ant colony optimisation (<a href=""https://ai.stackexchange.com/questions/tagged/ant-colony"" class=""post-tag"" title=""show questions tagged &#39;ant-colony&#39;"" rel=""tag"">ant-colony</a>) or related to <a href=""https://ai.stackexchange.com/questions/tagged/on-policy"" class=""post-tag"" title=""show questions tagged &#39;on-policy&#39;"" rel=""tag"">on-policy</a> or <a href=""https://ai.stackexchange.com/questions/tagged/off-policy"" class=""post-tag"" title=""show questions tagged &#39;off-policy&#39;"" rel=""tag"">off-policy</a> RL algorithms.</p>
<p>There are other tags that I believe should <strong>not</strong> exist on this website:</p>
<ul>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/bayes"" class=""post-tag"" title=""show questions tagged &#39;bayes&#39;"" rel=""tag"">bayes</a> should not exist because there are more meaningful tags (with respect to AI), such as <a href=""https://ai.stackexchange.com/questions/tagged/bayes-theorem"" class=""post-tag"" title=""show questions tagged &#39;bayes-theorem&#39;"" rel=""tag"">bayes-theorem</a> (which already exists); maybe we could also have the tag <a href=""https://ai.stackexchange.com/questions/tagged/probabilistic-graphical-model"" class=""post-tag"" title=""show questions tagged &#39;probabilistic-graphical-model&#39;"" rel=""tag"">probabilistic-graphical-model</a> (which includes e.g. Bayesian networks, whose tag <a href=""https://ai.stackexchange.com/questions/tagged/bayesian-network"" class=""post-tag"" title=""show questions tagged &#39;bayesian-network&#39;"" rel=""tag"">bayesian-network</a> already exists) for some questions that are currently a little bit ambiguously tagged with <a href=""https://ai.stackexchange.com/questions/tagged/bayes"" class=""post-tag"" title=""show questions tagged &#39;bayes&#39;"" rel=""tag"">bayes</a>); some of the questions that are currently tagged with <a href=""https://ai.stackexchange.com/questions/tagged/bayes"" class=""post-tag"" title=""show questions tagged &#39;bayes&#39;"" rel=""tag"">bayes</a> can instead be tagged with <a href=""https://ai.stackexchange.com/questions/tagged/naive-bayes"" class=""post-tag"" title=""show questions tagged &#39;naive-bayes&#39;"" rel=""tag"">naive-bayes</a> (which already exists).</p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/language-processing"" class=""post-tag"" title=""show questions tagged &#39;language-processing&#39;"" rel=""tag"">language-processing</a> should be deleted because there is already <a href=""https://ai.stackexchange.com/questions/tagged/nlp"" class=""post-tag"" title=""show questions tagged &#39;nlp&#39;"" rel=""tag"">nlp</a> or <a href=""https://ai.stackexchange.com/questions/tagged/natural-language-processing"" class=""post-tag"" title=""show questions tagged &#39;natural-language-processing&#39;"" rel=""tag"">natural-language-processing</a></s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/learning-algorithms"" class=""post-tag"" title=""show questions tagged &#39;learning-algorithms&#39;"" rel=""tag"">learning-algorithms</a> (there is already the tag <a href=""https://ai.stackexchange.com/questions/tagged/machine-learning"" class=""post-tag"" title=""show questions tagged &#39;machine-learning&#39;"" rel=""tag"">machine-learning</a>, which includes all machine learning algorithms; futhermore, AFAIK, learning algorithms is not a standard expression, whereas machine learning is.).</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/ai-community"" class=""post-tag"" title=""show questions tagged &#39;ai-community&#39;"" rel=""tag"">ai-community</a> (why exactly do we need this tag? what the relation between this tag and <a href=""https://ai.stackexchange.com/questions/tagged/social"" class=""post-tag"" title=""show questions tagged &#39;social&#39;"" rel=""tag"">social</a>? Do we need both of these tags, anyway? what's the relation between <a href=""https://ai.stackexchange.com/questions/tagged/ai-community"" class=""post-tag"" title=""show questions tagged &#39;ai-community&#39;"" rel=""tag"">ai-community</a> and <a href=""https://ai.stackexchange.com/questions/tagged/theory"" class=""post-tag"" title=""show questions tagged &#39;theory&#39;"" rel=""tag"">theory</a>?)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/software-evaluation"" class=""post-tag"" title=""show questions tagged &#39;software-evaluation&#39;"" rel=""tag"">software-evaluation</a> (this has nothing to do directly with AI; this tag should really not exist on this website, IMHO)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/software-architecture"" class=""post-tag"" title=""show questions tagged &#39;software-architecture&#39;"" rel=""tag"">software-architecture</a> (similarly to <a href=""https://ai.stackexchange.com/questions/tagged/software-evaluation"" class=""post-tag"" title=""show questions tagged &#39;software-evaluation&#39;"" rel=""tag"">software-evaluation</a>)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/topology"" class=""post-tag"" title=""show questions tagged &#39;topology&#39;"" rel=""tag"">topology</a> (How is this tag different from <a href=""https://ai.stackexchange.com/questions/tagged/architecture"" class=""post-tag"" title=""show questions tagged &#39;architecture&#39;"" rel=""tag"">architecture</a>? Maybe this should at least be clarified)</p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/self-driving"" class=""post-tag"" title=""show questions tagged &#39;self-driving&#39;"" rel=""tag"">self-driving</a> (&quot;self-driving&quot; this an adjective; the tag <a href=""https://ai.stackexchange.com/questions/tagged/autonomous-vehicles"" class=""post-tag"" title=""show questions tagged &#39;autonomous-vehicles&#39;"" rel=""tag"">autonomous-vehicles</a> is a synonym for <a href=""https://ai.stackexchange.com/questions/tagged/self-driving"" class=""post-tag"" title=""show questions tagged &#39;self-driving&#39;"" rel=""tag"">self-driving</a>, but I would completely delete <a href=""https://ai.stackexchange.com/questions/tagged/self-driving"" class=""post-tag"" title=""show questions tagged &#39;self-driving&#39;"" rel=""tag"">self-driving</a>)</s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/cars"" class=""post-tag"" title=""show questions tagged &#39;cars&#39;"" rel=""tag"">cars</a> (similarly to <a href=""https://ai.stackexchange.com/questions/tagged/self-driving"" class=""post-tag"" title=""show questions tagged &#39;self-driving&#39;"" rel=""tag"">self-driving</a>, this tag should be deleted)</s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/structured-data"" class=""post-tag"" title=""show questions tagged &#39;structured-data&#39;"" rel=""tag"">structured-data</a> (I have no idea why this tag should exist)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/reasoning"" class=""post-tag"" title=""show questions tagged &#39;reasoning&#39;"" rel=""tag"">reasoning</a> (Maybe the tag <a href=""https://ai.stackexchange.com/questions/tagged/logic"" class=""post-tag"" title=""show questions tagged &#39;logic&#39;"" rel=""tag"">logic</a> already covers this topic?)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/world-knowledge"" class=""post-tag"" title=""show questions tagged &#39;world-knowledge&#39;"" rel=""tag"">world-knowledge</a> should be deleted because there is already <a href=""https://ai.stackexchange.com/questions/tagged/knowledge-representation"" class=""post-tag"" title=""show questions tagged &#39;knowledge-representation&#39;"" rel=""tag"">knowledge-representation</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/challenges"" class=""post-tag"" title=""show questions tagged &#39;challenges&#39;"" rel=""tag"">challenges</a> (there are challenges everywhere; this tag is very vague)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/embedded-design"" class=""post-tag"" title=""show questions tagged &#39;embedded-design&#39;"" rel=""tag"">embedded-design</a> (maybe this tag should not exist)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/imperfect-information"" class=""post-tag"" title=""show questions tagged &#39;imperfect-information&#39;"" rel=""tag"">imperfect-information</a> (I know that there are games with imperfect information, but maybe this tag should not exist)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/real-world"" class=""post-tag"" title=""show questions tagged &#39;real-world&#39;"" rel=""tag"">real-world</a> should not exist, given that there is already the tag <a href=""https://ai.stackexchange.com/questions/tagged/applications"" class=""post-tag"" title=""show questions tagged &#39;applications&#39;"" rel=""tag"">applications</a>, which should cover all types of applications, so this tag should be deleted</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/gaming"" class=""post-tag"" title=""show questions tagged &#39;gaming&#39;"" rel=""tag"">gaming</a> and <a href=""https://ai.stackexchange.com/questions/tagged/game-ai"" class=""post-tag"" title=""show questions tagged &#39;game-ai&#39;"" rel=""tag"">game-ai</a> (I would delete both of them and just have a new tag <a href=""https://ai.stackexchange.com/questions/tagged/games"" class=""post-tag"" title=""show questions tagged &#39;games&#39;"" rel=""tag"">games</a>, which will include everything that is related to games in the context of AI; also, do we really need these tags, if we already have <a href=""https://ai.stackexchange.com/questions/tagged/game-theory"" class=""post-tag"" title=""show questions tagged &#39;game-theory&#39;"" rel=""tag"">game-theory</a> (which, IMHO, should exist on this website)? anyway, the description of the <a href=""https://ai.stackexchange.com/questions/tagged/gaming"" class=""post-tag"" title=""show questions tagged &#39;gaming&#39;"" rel=""tag"">gaming</a> should be updated, given that now we have a tag called <a href=""https://ai.stackexchange.com/questions/tagged/combinatorial-games"" class=""post-tag"" title=""show questions tagged &#39;combinatorial-games&#39;"" rel=""tag"">combinatorial-games</a>)</p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/detecting-patterns"" class=""post-tag"" title=""show questions tagged &#39;detecting-patterns&#39;"" rel=""tag"">detecting-patterns</a> should not exist because there is already the more common expression <a href=""https://ai.stackexchange.com/questions/tagged/pattern-recognition"" class=""post-tag"" title=""show questions tagged &#39;pattern-recognition&#39;"" rel=""tag"">pattern-recognition</a>; it should not even be considered a synonym</s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/probabilistic"" class=""post-tag"" title=""show questions tagged &#39;probabilistic&#39;"" rel=""tag"">probabilistic</a> should not exist because it an adjective and it not widely used; the non-existing tags <a href=""https://ai.stackexchange.com/questions/tagged/probabilistic-model"" class=""post-tag"" title=""show questions tagged &#39;probabilistic-model&#39;"" rel=""tag"">probabilistic-model</a> or <a href=""https://ai.stackexchange.com/questions/tagged/statistical-model"" class=""post-tag"" title=""show questions tagged &#39;statistical-model&#39;"" rel=""tag"">statistical-model</a> would have been better; anyway, the tags <a href=""https://ai.stackexchange.com/questions/tagged/math"" class=""post-tag"" title=""show questions tagged &#39;math&#39;"" rel=""tag"">math</a> or <a href=""https://ai.stackexchange.com/questions/tagged/statistical-ai"" class=""post-tag"" title=""show questions tagged &#39;statistical-ai&#39;"" rel=""tag"">statistical-ai</a> should somehow already cover associated questions, so I suggest to delete <a href=""https://ai.stackexchange.com/questions/tagged/probabilistic"" class=""post-tag"" title=""show questions tagged &#39;probabilistic&#39;"" rel=""tag"">probabilistic</a></s> (temporarily solved by renaming it to <a href=""https://ai.stackexchange.com/questions/tagged/probability"" class=""post-tag"" title=""show questions tagged &#39;probability&#39;"" rel=""tag"">probability</a>).</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/brain"" class=""post-tag"" title=""show questions tagged &#39;brain&#39;"" rel=""tag"">brain</a> maybe should not exist because there is already <a href=""https://ai.stackexchange.com/questions/tagged/biology"" class=""post-tag"" title=""show questions tagged &#39;biology&#39;"" rel=""tag"">biology</a>, which should include all questions related to biological inspired AI, but maybe we can also keep it (given that the brain is an important inspiration)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/categorical-data"" class=""post-tag"" title=""show questions tagged &#39;categorical-data&#39;"" rel=""tag"">categorical-data</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/time"" class=""post-tag"" title=""show questions tagged &#39;time&#39;"" rel=""tag"">time</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/new-ai"" class=""post-tag"" title=""show questions tagged &#39;new-ai&#39;"" rel=""tag"">new-ai</a></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/structure"" class=""post-tag"" title=""show questions tagged &#39;structure&#39;"" rel=""tag"">structure</a></s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/emergence"" class=""post-tag"" title=""show questions tagged &#39;emergence&#39;"" rel=""tag"">emergence</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/mapping-space"" class=""post-tag"" title=""show questions tagged &#39;mapping-space&#39;"" rel=""tag"">mapping-space</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/cloud-services"" class=""post-tag"" title=""show questions tagged &#39;cloud-services&#39;"" rel=""tag"">cloud-services</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/hyper-computation"" class=""post-tag"" title=""show questions tagged &#39;hyper-computation&#39;"" rel=""tag"">hyper-computation</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/dimensionality"" class=""post-tag"" title=""show questions tagged &#39;dimensionality&#39;"" rel=""tag"">dimensionality</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/google-cloud"" class=""post-tag"" title=""show questions tagged &#39;google-cloud&#39;"" rel=""tag"">google-cloud</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/quantification"" class=""post-tag"" title=""show questions tagged &#39;quantification&#39;"" rel=""tag"">quantification</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/survival"" class=""post-tag"" title=""show questions tagged &#39;survival&#39;"" rel=""tag"">survival</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/mindstorms"" class=""post-tag"" title=""show questions tagged &#39;mindstorms&#39;"" rel=""tag"">mindstorms</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/ai-box"" class=""post-tag"" title=""show questions tagged &#39;ai-box&#39;"" rel=""tag"">ai-box</a></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/predicting-ai-milestones"" class=""post-tag"" title=""show questions tagged &#39;predicting-ai-milestones&#39;"" rel=""tag"">predicting-ai-milestones</a> (there are already the tags <a href=""https://ai.stackexchange.com/questions/tagged/prediction"" class=""post-tag"" title=""show questions tagged &#39;prediction&#39;"" rel=""tag"">prediction</a>; maybe we should have the tag <a href=""https://ai.stackexchange.com/questions/tagged/ai-milestones"" class=""post-tag"" title=""show questions tagged &#39;ai-milestones&#39;"" rel=""tag"">ai-milestones</a>, but I think that the tag <a href=""https://ai.stackexchange.com/questions/tagged/history"" class=""post-tag"" title=""show questions tagged &#39;history&#39;"" rel=""tag"">history</a> already covers this)</s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/teaching-concepts"" class=""post-tag"" title=""show questions tagged &#39;teaching-concepts&#39;"" rel=""tag"">teaching-concepts</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/node-js"" class=""post-tag"" title=""show questions tagged &#39;node-js&#39;"" rel=""tag"">node-js</a></s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/art-aesthetics"" class=""post-tag"" title=""show questions tagged &#39;art-aesthetics&#39;"" rel=""tag"">art-aesthetics</a></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/ai-methods"" class=""post-tag"" title=""show questions tagged &#39;ai-methods&#39;"" rel=""tag"">ai-methods</a> (<a href=""https://ai.stackexchange.com/questions/tagged/theory"" class=""post-tag"" title=""show questions tagged &#39;theory&#39;"" rel=""tag"">theory</a> should cover this)</s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/binary"" class=""post-tag"" title=""show questions tagged &#39;binary&#39;"" rel=""tag"">binary</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/sparse-input"" class=""post-tag"" title=""show questions tagged &#39;sparse-input&#39;"" rel=""tag"">sparse-input</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/consumer-product"" class=""post-tag"" title=""show questions tagged &#39;consumer-product&#39;"" rel=""tag"">consumer-product</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/fourier-approximation"" class=""post-tag"" title=""show questions tagged &#39;fourier-approximation&#39;"" rel=""tag"">fourier-approximation</a></s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/materials-science"" class=""post-tag"" title=""show questions tagged &#39;materials-science&#39;"" rel=""tag"">materials-science</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/quotes"" class=""post-tag"" title=""show questions tagged &#39;quotes&#39;"" rel=""tag"">quotes</a> (maybe this could exist as a sub-category of <a href=""https://ai.stackexchange.com/questions/tagged/history"" class=""post-tag"" title=""show questions tagged &#39;history&#39;"" rel=""tag"">history</a>)</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/invention"" class=""post-tag"" title=""show questions tagged &#39;invention&#39;"" rel=""tag"">invention</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/accessibility"" class=""post-tag"" title=""show questions tagged &#39;accessibility&#39;"" rel=""tag"">accessibility</a></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/lfsr"" class=""post-tag"" title=""show questions tagged &#39;lfsr&#39;"" rel=""tag"">lfsr</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/fallibility"" class=""post-tag"" title=""show questions tagged &#39;fallibility&#39;"" rel=""tag"">fallibility</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/iiot"" class=""post-tag"" title=""show questions tagged &#39;iiot&#39;"" rel=""tag"">iiot</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/measured-disturbance"" class=""post-tag"" title=""show questions tagged &#39;measured-disturbance&#39;"" rel=""tag"">measured-disturbance</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/strong-narrow-ai"" class=""post-tag"" title=""show questions tagged &#39;strong-narrow-ai&#39;"" rel=""tag"">strong-narrow-ai</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/spanish-language"" class=""post-tag"" title=""show questions tagged &#39;spanish-language&#39;"" rel=""tag"">spanish-language</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/rul"" class=""post-tag"" title=""show questions tagged &#39;rul&#39;"" rel=""tag"">rul</a></s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/wetware"" class=""post-tag"" title=""show questions tagged &#39;wetware&#39;"" rel=""tag"">wetware</a></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/untagged"" class=""post-tag"" title=""show questions tagged &#39;untagged&#39;"" rel=""tag"">untagged</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/confidence"" class=""post-tag"" title=""show questions tagged &#39;confidence&#39;"" rel=""tag"">confidence</a></s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/marketability"" class=""post-tag"" title=""show questions tagged &#39;marketability&#39;"" rel=""tag"">marketability</a></s></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/analog-computing"" class=""post-tag"" title=""show questions tagged &#39;analog-computing&#39;"" rel=""tag"">analog-computing</a></p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/theorics"" class=""post-tag"" title=""show questions tagged &#39;theorics&#39;"" rel=""tag"">theorics</a> currently points to <a href=""https://ai.stackexchange.com/questions/tagged/theory"" class=""post-tag"" title=""show questions tagged &#39;theory&#39;"" rel=""tag"">theory</a>, but can't we simply delete it?</p>
</li>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/deepqa"" class=""post-tag"" title=""show questions tagged &#39;deepqa&#39;"" rel=""tag"">deepqa</a>, similarly, currently points to <a href=""https://ai.stackexchange.com/questions/tagged/watson"" class=""post-tag"" title=""show questions tagged &#39;watson&#39;"" rel=""tag"">watson</a>, but can't we simply delete it?</p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/ultraintelligent-machine"" class=""post-tag"" title=""show questions tagged &#39;ultraintelligent-machine&#39;"" rel=""tag"">ultraintelligent-machine</a> (there is already <a href=""https://ai.stackexchange.com/questions/tagged/superintelligence"" class=""post-tag"" title=""show questions tagged &#39;superintelligence&#39;"" rel=""tag"">superintelligence</a>, and <a href=""https://ai.stackexchange.com/questions/tagged/ultraintelligent-machine"" class=""post-tag"" title=""show questions tagged &#39;ultraintelligent-machine&#39;"" rel=""tag"">ultraintelligent-machine</a> is, AFAIK, not very common; a more common expression would be universal-intelligence, but I would just have <a href=""https://ai.stackexchange.com/questions/tagged/superintelligence"" class=""post-tag"" title=""show questions tagged &#39;superintelligence&#39;"" rel=""tag"">superintelligence</a>)</s></p>
</li>
</ul>
<p>In general, as a rule of thumb, if a topic or expression does not have an associated Wikipedia article, it likely means that a corresponding tag should <em>not</em> exist on this website. I have not given a motivation for each of the tags, because otherwise I would not do anything more today. It is possible that in some cases I am not seeing the reason of the existence of the corresponding tags. However, I believe that most of them should not exist.</p>
<h3>Duplicates</h3>
<p>There are tags that are duplicates</p>
<ul>
<li><p><a href=""https://ai.stackexchange.com/questions/tagged/theory"" class=""post-tag"" title=""show questions tagged &#39;theory&#39;"" rel=""tag"">theory</a> and <a href=""https://ai.stackexchange.com/questions/tagged/concepts"" class=""post-tag"" title=""show questions tagged &#39;concepts&#39;"" rel=""tag"">concepts</a> (I would leave just first one, given that the first tag is more &quot;standard&quot;, even though we can have synonymous tags)</p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/comparison"" class=""post-tag"" title=""show questions tagged &#39;comparison&#39;"" rel=""tag"">comparison</a> and <a href=""https://ai.stackexchange.com/questions/tagged/relation"" class=""post-tag"" title=""show questions tagged &#39;relation&#39;"" rel=""tag"">relation</a> (I would say that they can co-exist on this website)</s></p>
</li>
<li><p><s><a href=""https://ai.stackexchange.com/questions/tagged/strong-ai"" class=""post-tag"" title=""show questions tagged &#39;strong-ai&#39;"" rel=""tag"">strong-ai</a> and <a href=""https://ai.stackexchange.com/questions/tagged/agi"" class=""post-tag"" title=""show questions tagged &#39;agi&#39;"" rel=""tag"">agi</a> are essentially synonymous and they can both co-exist (given that both expressions are common)</s></p>
</li>
</ul>
<p>It is possible there are a lot more duplicate tags.</p>
<h3>Tags that need improvement</h3>
<p>There are tags whose definition is not clear or inconsistent with the existing posts on this website. For example, the tag <a href=""https://ai.stackexchange.com/questions/tagged/chat-bots"" class=""post-tag"" title=""show questions tagged &#39;chat-bots&#39;"" rel=""tag"">chat-bots</a>, whose current definition states</p>
<blockquote>
<p>For questions about chat-bots. NOT for questions about how to program a chat-bot, as those kinds of questions are off-topic.</p>
</blockquote>
<p>However, one of the highest upvoted question on this website with this tag is <a href=""https://ai.stackexchange.com/q/3343/2444"">What are the latest methods to train a chat bot?</a>.</p>
<p>Other tags that possibly needs improvement are <a href=""https://ai.stackexchange.com/questions/tagged/biology"" class=""post-tag"" title=""show questions tagged &#39;biology&#39;"" rel=""tag"">biology</a> and <a href=""https://ai.stackexchange.com/questions/tagged/brain"" class=""post-tag"" title=""show questions tagged &#39;brain&#39;"" rel=""tag"">brain</a>. In their current description, they have no relation to AI (so they should not even exist). These tags could be used for questions that are both related to biology (and the brain) and AI at the same time (e.g. human-inspired AI, whose tag, btw, already exists on this website).</p>
<p>I suspect that there are a lot more tags that need an improvement, in terms of description and scope.</p>
",AImeta,long post describe issues associated tags believe solved feel free add opinions regarding issues specific tags feel free edit question add issues tags tags exist observed website lot tags whose meaning widely accepted yet understandable example never heard expression involved field ai even though expression occurs web article mean deserves tag website believe topics associated research literature associated tag example questions related ant colony optimisation related rl algorithms tags believe exist website exist meaningful tags respect ai already exists maybe could also tag includes eg bayesian networks whose tag already exists questions currently little bit ambiguously tagged questions currently tagged instead tagged already exists deleted already already tag includes machine learning algorithms futhermore afaik learning algorithms standard expression whereas machine learning exactly need tag relation tag need tags anyway relation nothing directly ai tag really exist website imho similarly tag different maybe least clarified tag synonym would completely delete similarly tag deleted idea tag exist maybe tag already covers topic deleted already challenges everywhere tag vague maybe tag exist know games imperfect information maybe tag exist exist given already tag cover types applications tag deleted would delete new tag include everything related games context ai also really need tags already imho exist website anyway description updated given tag called exist already common expression even considered synonym exist adjective widely used non existing tags would better anyway tags somehow already cover associated questions suggest delete temporarily solved renaming maybe exist already include questions related biological inspired ai maybe also keep given brain important inspiration already tags maybe tag think tag already covers cover maybe could exist sub category currently points simply delete similarly currently points simply delete already afaik common common expression would universal intelligence would general rule thumb topic expression associated wikipedia article likely means corresponding tag exist website given motivation tags otherwise would anything today possible cases seeing reason existence corresponding tags however believe exist duplicates tags duplicates would leave first one given first tag even though synonymous tags would say co exist website essentially synonymous co exist given expressions common possible lot duplicate tags tags need improvement tags whose definition clear inconsistent existing posts website example tag whose current definition states questions chat bots questions program chat bot kinds questions topic however one highest upvoted question website tag tags possibly needs improvement current description relation ai even exist tags could used questions related biology brain ai time eg human inspired ai whose tag btw already exists website suspect lot tags need improvement terms description scope
1,"<p>Natural language <em>by itself</em> (that is, without considering computation-related aspects) has little to do with AI. In AI, we want to do NLP, which can be based on natural language, but the tag <a href=""https://ai.stackexchange.com/questions/tagged/natural-language-processing"" class=""post-tag"" title=""show questions tagged &#39;natural-language-processing&#39;"" rel=""tag"">natural-language-processing</a> or <a href=""https://ai.stackexchange.com/questions/tagged/nlp"" class=""post-tag"" title=""show questions tagged &#39;nlp&#39;"" rel=""tag"">nlp</a> should also include these related discussions or questions. So, the tag <a href=""https://ai.stackexchange.com/questions/tagged/natural-language"" class=""post-tag"" title=""show questions tagged &#39;natural-language&#39;"" rel=""tag"">natural-language</a> should not really exist.</p>
",AImeta,natural language without considering computation related aspects little ai ai want nlp based natural language tag also include related discussions questions tag really exist
1,"<p>I think that ""deep learning"" is already a standard expression, so this tag should be the main tag. The tag <a href=""https://ai.stackexchange.com/questions/tagged/deep-network"" class=""post-tag"" title=""show questions tagged &#39;deep-network&#39;"" rel=""tag"">deep-network</a> could also exist on this website, given that the expression ""deep neural network"" is also common, but I would not say that it is a synonym for <a href=""https://ai.stackexchange.com/questions/tagged/deep-learning"" class=""post-tag"" title=""show questions tagged &#39;deep-learning&#39;"" rel=""tag"">deep-learning</a>. A deep network is a network that is deep (that is, it possesses ""many"" layers). However, deep learning is not just concerned with the architecture of the NNs, but it also concerned with the <em>learning</em> part.</p>
",AImeta,think deep learning already standard expression tag main tag tag could also exist website given expression deep neural network also common would say synonym deep network network deep possesses many layers however deep learning concerned architecture nns also concerned learning part
1,"<p>Was trying to reformat the formula in <a href=""https://ai.stackexchange.com/questions/5177/please-explain-this-log-probability-function-what-does-each-part-mean"">this question</a>, but can't get the theta to appear under the max.</p>

<p><a href=""https://i.stack.imgur.com/XYQ4A.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XYQ4A.png"" alt=""enter image description here""></a></p>

<p>I've been going through the formatting guide, but haven't yet identified how to do it without a fraction.  (In limit functions, the placement seems to be automatic.)  Wondering if there's a way to do this simply.</p>
",AImeta,trying reformat formula get theta appear max going formatting guide yet identified without fraction limit functions placement seems automatic wondering way simply
1,"<p>Have a look at the source of this answer</p>

<p><span class=""math-container"">$$\underset{\boldsymbol{\theta}}{\operatorname{argmax}}$$</span></p>
",AImeta,look source answer undersetboldsymbolthetaoperatornameargmax
1,"<p>Currently, when you flag a question as off-topic, you cannot specify which other SE website it should belong to. I think we should at least have the option to specify that it can belong to Data Science SE, Stack Overflow and Stats SE, given that these three websites are quite related to our AI SE website.</p>
",AImeta,currently flag question topic specify se website belong think least option specify belong data science se stack overflow stats se given three websites quite related ai se website
1,"<p>I believe that the tag <a href=""https://ai.stackexchange.com/questions/tagged/sentience"" class=""post-tag"" title=""show questions tagged &#39;sentience&#39;"" rel=""tag"">sentience</a> is not necessary given that we already have <a href=""https://ai.stackexchange.com/questions/tagged/artificial-consciousness"" class=""post-tag"" title=""show questions tagged &#39;artificial-consciousness&#39;"" rel=""tag"">artificial-consciousness</a> and <a href=""https://ai.stackexchange.com/questions/tagged/emotional-intelligence"" class=""post-tag"" title=""show questions tagged &#39;emotional-intelligence&#39;"" rel=""tag"">emotional-intelligence</a>. A sentient AI is an an AI that perceives or feels (according to the dictionary definition of ""sentient""), so all questions about sentient AI fall either under <a href=""https://ai.stackexchange.com/questions/tagged/emotional-intelligence"" class=""post-tag"" title=""show questions tagged &#39;emotional-intelligence&#39;"" rel=""tag"">emotional-intelligence</a> (or <a href=""https://ai.stackexchange.com/questions/tagged/artificial-consciousness"" class=""post-tag"" title=""show questions tagged &#39;artificial-consciousness&#39;"" rel=""tag"">artificial-consciousness</a>), so I suggest it should be merged with <a href=""https://ai.stackexchange.com/questions/tagged/emotional-intelligence"" class=""post-tag"" title=""show questions tagged &#39;emotional-intelligence&#39;"" rel=""tag"">emotional-intelligence</a>. </p>
",AImeta,believe tag necessary given already sentient ai ai perceives feels according dictionary definition sentient questions sentient ai fall either suggest merged
1,"<p>The only difference between <a href=""https://ai.stackexchange.com/questions/tagged/artificial-consciousness"" class=""post-tag"" title=""show questions tagged &#39;artificial-consciousness&#39;"" rel=""tag"">artificial-consciousness</a> and <a href=""https://ai.stackexchange.com/questions/tagged/self-awareness"" class=""post-tag"" title=""show questions tagged &#39;self-awareness&#39;"" rel=""tag"">self-awareness</a> is that the former is ""restricted to engineered artifacts"", so I think these tags should be merged and only the tag <a href=""https://ai.stackexchange.com/questions/tagged/artificial-consciousness"" class=""post-tag"" title=""show questions tagged &#39;artificial-consciousness&#39;"" rel=""tag"">artificial-consciousness</a> should exist, given that ""restricted to engineered artifacts"" does not deserve its own tag on a website related to the theoretical and philosophical aspects of AI.</p>
",AImeta,difference former restricted engineered artifacts think tags merged tag exist given restricted engineered artifacts deserve tag website related theoretical philosophical aspects ai
1,"<p>I have noticed that there are a lot of questions on this website that will lead to primarily opinion-based or speculative answers. However, on this website, we also allow philosophical questions. Should the questions that lead to speculative answers be tagged with <a href=""https://ai.stackexchange.com/questions/tagged/philosophy"" class=""post-tag"" title=""show questions tagged &#39;philosophy&#39;"" rel=""tag"">philosophy</a>, should them be closed as primarily opinion-based, or should we introduce a new tag like <a href=""https://ai.stackexchange.com/questions/tagged/futurism"" class=""post-tag"" title=""show questions tagged &#39;futurism&#39;"" rel=""tag"">futurism</a>?</p>

<p>I think that most of them can be tagged with <a href=""https://ai.stackexchange.com/questions/tagged/philosophy"" class=""post-tag"" title=""show questions tagged &#39;philosophy&#39;"" rel=""tag"">philosophy</a>. A question that should be closed as primarily opinion-based is e.g. <a href=""https://ai.stackexchange.com/q/2692/2444"">Is it a good idea to pay for an deep learning course?</a>. An example of a question that will lead to speculative answers is <a href=""https://ai.stackexchange.com/q/12940/2444"">Will artificial intelligence cause mass unemployment?</a>.</p>

<p>Furthermore, I don't believe that there is the need for the tag <a href=""https://ai.stackexchange.com/questions/tagged/futurism"" class=""post-tag"" title=""show questions tagged &#39;futurism&#39;"" rel=""tag"">futurism</a>, given that this website should be dedicated to a scientific discipline and not junk science. However, given the existing large amount of this type of questions on the website, maybe we could have a tag for this type of questions.</p>
",AImeta,noticed lot questions website lead primarily opinion based speculative answers however website also allow philosophical questions questions lead speculative answers tagged closed primarily opinion based introduce new tag like think tagged question closed primarily opinion based eg example question lead speculative answers furthermore believe need tag given website dedicated scientific discipline junk science however given existing large amount type questions website maybe could tag type questions
1,"<p>Currently, the description of the tag <a href=""https://ai.stackexchange.com/questions/tagged/ai-design"" class=""post-tag"" title=""show questions tagged &#39;ai-design&#39;"" rel=""tag"">ai-design</a> is</p>

<blockquote>
  <p>For questions related to successful or novel designing standards and procedures of Artificially Intelligent agents.</p>
</blockquote>

<p>However, there are questions on this website that look like ""How should I design the architecture of a neural network to achieve X?"". I believe that this type of questions should fall under the tag <a href=""https://ai.stackexchange.com/questions/tagged/ai-design"" class=""post-tag"" title=""show questions tagged &#39;ai-design&#39;"" rel=""tag"">ai-design</a> or is there an another tag for this type of questions? If not, I suggest to change the description of the tag <a href=""https://ai.stackexchange.com/questions/tagged/ai-design"" class=""post-tag"" title=""show questions tagged &#39;ai-design&#39;"" rel=""tag"">ai-design</a> to make it more broadly applicable.</p>
",AImeta,currently description tag questions related successful novel designing standards procedures artificially intelligent agents however questions website look like design architecture neural network achieve x believe type questions fall tag another tag type questions suggest change description tag make broadly applicable
1,"<ul>
<li>Sentience can refer to biological agents, so has a broader scope.  </li>
</ul>

<p>We sometimes discuss intelligence in general, as a concept underlying AI, and do too with sentience.</p>

<ul>
<li>Emotional intelligence seems to be an informal term related to a specific kind of decision making</li>
</ul>

<p>I don't see much relation to sentience in general, except that we regard only sentient beings as having emotions in the conventional sense.</p>
",AImeta,sentience refer biological agents broader scope sometimes discuss intelligence general concept underlying ai sentience emotional intelligence seems informal term related specific kind decision making see much relation sentience general except regard sentient beings emotions conventional sense
1,"<p>Self-awareness has a lot of usage in general, and I don't think it's entirely synonymous.  Consciousness, in the most basic definition, is merely awareness of an environment.  </p>

<p>Additionally, non-artificial intelligences (humans) have self-awareness.  So it's useful to be able to distinguish.</p>
",AImeta,self awareness lot usage general think entirely synonymous consciousness basic definition merely awareness environment additionally non artificial intelligences humans self awareness useful able distinguish
1,"<p>I created a soft-question tag, but people don't seem to like using it. But just because a question is ""soft"" doesn't mean it's invalid--many of the hard science sites have the tag, which was what inspired me to add it here.</p>

<p>I don't know if this is fully sufficient, but at least part of the solution.</p>
",AImeta,created soft question tag people seem like using question soft mean invalid many hard science sites tag inspired add know fully sufficient least part solution
1,"<p>I have read this blog post <a href=""https://stackoverflow.blog/2010/10/21/when-will-my-site-graduate/"">When Will My Site Graduate?</a>. The author states</p>

<blockquote>
  <p>At 90 days into beta, we're supposed to evaluate each Area 51 beta site and either “pass” or “fail” them as full Stack Exchange sites</p>
</blockquote>

<p>How long have we been in public beta (even after being sponsored by IBM)? Don't we have enough sustainable users yet?</p>

<p>When will we <em>exactly</em> graduate?</p>
",AImeta,read blog post author states 90 days beta supposed evaluate area 51 beta site either pass fail full stack exchange sites long public beta even sponsored ibm enough sustainable users yet exactly graduate
1,"<p>According to <a href=""https://area51.stackexchange.com/proposals/93481/artificial-intelligence"">our Area 51 page</a>, we entered public beta on August 22, 2016, nearly three years ago.</p>
<p>90 days may indeed have been the cutoff in the early days of Area 51-launched Stack Exchange sites, prior even to that post. The post opens with it because users of one small site were concerned about getting shut down at that mark. It reassures those users that graduation could take longer:</p>
<blockquote>
<h3>How long can a site stay in beta?</h3>
<p>The simple answer is, <em>it takes as long as it takes</em>. We’ll wait. If a site needs more activity, go out and evangelize it. As long as your site shows steady progress and continues to make the Internet a better place to get expert answers to your questions, it will march on.</p>
</blockquote>
<p>More recently (in 2015) there was <a href=""https://meta.stackexchange.com/q/257614/295684"">a Meta Stack Exchange announcement</a> with more specifics:</p>
<blockquote>
<p>The TL;DR:</p>
<ol>
<li><strong>When a site starts to consistently receive 10 questions/day, we’ll consider it for graduation.</strong></li>
<li><strong>If a public beta site does not produce consistently helpful content, and lacks the caretakers needed for flags and spam to get handled and our Be Nice policy to be upheld, it will be closed.</strong></li>
</ol>
</blockquote>
<p>We are not at risk of closure, so we'll definitely stick around in some form (<a href=""https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sites#comment840165_257614"">perpetual beta is possible</a>). According to the Area 51 stats, we get about 7.5 questions per day, so we're making progress toward graduation eligibility. Graduation includes privilege threshold adjustments, which we <em>could</em> survive now, but without any 10K users it's probably ideal to hold off for a while.</p>
<p>The sketched graph in <a href=""https://meta.stackexchange.com/a/227016/295684"">this MSE answer</a> visually shows &quot;a typical growth pattern for a Stack Exchange site.&quot; Eyeballing our current site analytics, we seem to be at the halfway mark between the sketch's start of public beta and graduation.</p>
",AImeta,according entered public beta august 22 2016 nearly three years ago 90 days may indeed cutoff early days area 51launched stack exchange sites prior even post post opens users one small site concerned getting shut mark reassures users graduation could take longer long site stay beta simple answer takes long takes wait site needs activity go evangelize long site shows steady progress continues make internet better place get expert answers questions march recently 2015 specifics tldr site starts consistently receive 10 questions day consider graduation public beta site produce consistently helpful content lacks caretakers needed flags spam get handled nice policy upheld closed risk closure definitely stick around form according area 51 stats get 75 questions per day making progress toward graduation eligibility graduation includes privilege threshold adjustments could survive without 10k users probably ideal hold sketched graph visually shows eyeballing current site analytics seem halfway mark sketch start public beta graduation
1,"<p>I propose the following new description to make this tag more broadly applicable</p>

<blockquote>
  <p>For questions related to designing standards and procedures of intelligent agents, algorithms or models.</p>
</blockquote>
",AImeta,propose following new description make tag broadly applicable questions related designing standards procedures intelligent agents algorithms models
1,"<p>In this website as far as I know we are allowed to down vote any answer or question by losing 1 rep.
The problem with this system is that people with bad ethics can answer a question and down vote the other answers despite them being good or not. What I want to ask here is why is it even allowed to down vote answers in a question answered by you? It should be only allowed to vote in other answers, if you do not have any answer in that same post.</p>
",AImeta,website far know allowed vote answer question losing 1 repthe problem system people bad ethics answer question vote answers despite good want ask even allowed vote answers question answered allowed vote answers answer post
1,"<p>Similar situations and issues to the one you describe sometimes happen. It occurred to me that I downvoted a post and I left a comment. Moments later some of my posts were randomly downvoted (see e.g. <a href=""https://ai.meta.stackexchange.com/q/1468/2444"">Taking revenge on me because I publicly downvoted and commented</a>). Nonetheless, I believe that downvotes (and upvotes) should have a <strong>mandatory</strong> associated comment that motivates the downvote, in a similar fashion to the peer-review process that research papers need to go through. This feature or similar ones have been requested by several members of the SE community.  See e.g. these discussions <a href=""https://meta.superuser.com/q/7223"">https://meta.superuser.com/q/7223</a> or <a href=""https://meta.stackexchange.com/q/135/287113"">Encouraging people to explain downvotes</a>.</p>
",AImeta,similar situations issues one describe sometimes happen occurred downvoted post left comment moments later posts randomly downvoted see eg nonetheless believe downvotes upvotes mandatory associated comment motivates downvote similar fashion peer review process research papers need go feature similar ones requested several members se community see eg discussions
1,"<p>Since these questions will keep getting asked by new people who won't know to check for duplicates, I would create new canonical questions and close these old questions as duplicates of the canonical questions. I would tag the questions with a tag like ""introduction-to-ai"" or ""faq"" so that they are easy to find and so it's easy to redirect new people to these questions.</p>

<p>I would create the following canonical questions:</p>

<ul>
<li><p>Resource requests</p>

<ul>
<li>What are good introductory AI/Machine Learning books</li>
<li>What are good online AI/Machine Learning courses</li>
</ul></li>
<li><p>Introduction to AI/Machine Learning</p>

<ul>
<li>How can I, a beginner, start learning about AI/Machine Learning</li>
<li>What mathematical/computer science prerequisites are necessary to start learning about AI/Machine Learning?</li>
</ul></li>
<li>Careers

<ul>
<li>What career options are available for those who study AI/Machine Learning</li>
<li>How can I, a beginner, pursue a career in AI/Machine Learning</li>
</ul></li>
</ul>

<p>I think these six questions cover all of the questions you've listed, but by all means create new questions as the need arises. </p>

<p>The advantage of doing this is that less questions means that more effort can be devoted to each question, and that the questions will be easily found by people.</p>
",AImeta,since questions keep getting asked new people know check duplicates would create new canonical questions close old questions duplicates canonical questions would tag questions tag like introduction ai faq easy find easy redirect new people questions would create following canonical questions resource requests good introductory ai machine learning books good online ai machine learning courses introduction ai machine learning beginner start learning ai machine learning mathematical computer science prerequisites necessary start learning ai machine learning careers career options available study ai machine learning beginner pursue career ai machine learning think six questions cover questions listed means create new questions need arises advantage less questions means effort devoted question questions easily found people
1,"<p>One of the persistent deficiencies of our Stack is low voting participation.  This is the area we most need to improve.  </p>

<p><em>Our Q&amp;A is an informal peer review, that ultimately looks to crowdsource information vetting, ideally by knowledgeable participants.  We get a lot of good questions and answers, but the sample size is small in regard to votes.</em></p>

<p><strong>Yesterday we got a question that received 23 upvotes, and 28 answer votes, in a single day:</strong> </p>

<blockquote>
  <p><a href=""https://ai.stackexchange.com/questions/13289/are-neural-networks-prone-to-catastrophic-forgetting"">Are neural networks prone to catastrophic forgetting?</a></p>
</blockquote>

<p>I'm interested in people's thoughts--theories on how the question attracted this level of attention, the nature of question, etc.  </p>

<p>Also, <strong>how we can use this type of question to support what seems to be the ""meat and potatoes"" of the stack, which is more technically specific questions and the math.</strong>  </p>

<p><em>i.e. There are only so many unique questions you can ask about theory, philosophy, social impacts, and so forth, but the technical stuff is a boundless wellspring. The technical Q&amp;As also provide the immediate, tangible utility that built the original Stack.</em></p>
",AImeta,one persistent deficiencies stack low voting participation area need improve q informal peer review ultimately looks crowdsource information vetting ideally knowledgeable participants get lot good questions answers sample size small regard votes yesterday got question received 23 upvotes 28 answer votes single day interested people thoughts theories question attracted level attention nature question etc also use type question support seems meat potatoes stack technically specific questions math ie many unique questions ask theory philosophy social impacts forth technical stuff boundless wellspring technical q also provide immediate tangible utility built original stack
1,"<p>First of all, I think this question has attracted a lot of people because it is about neural networks, which is a ""hot topic"" nowadays, and an issue that neural networks face. Given that a lot of people use and like neural networks and were not aware of this issue, people are probably interested in knowing about this problem and how to solve it.</p>

<p>Furthermore, I think the original title of this question, <em>A flaw with nerual networks?</em>, would not have attracted so many people. I realized that the author of such post, to some extent, was asking about the catastrophic forgetting (or inference) of neural networks, so I changed the title to the current one (which is quite descriptive), which I think I has contributed to the current popularity of the question, given that it contains the known (and maybe mnemonic) technical expression ""catastrophic forgetting"". In general, I have been trying to edit questions, so that to improve their titles and make them more descriptive, which I think can potentially attract more people. The title <em>A flaw with nerual networks?</em> is not very descriptive, because neural networks might have many flaws. So, I encourage every user to edit questions to make their titles more descriptive of the actual problem.</p>

<p>The given answers are also not very technical or long, so they are accessible or understandable by anyone in the field. Hence we should also strive for simplicity, when possible!</p>

<p>There are other questions that I think should have received a lot more attention and upvotes (for example, <a href=""https://ai.stackexchange.com/q/13317/2444"">Where can I find the proof of the universal approximation theorem?</a>), but I don't know how exactly Stack Exchange tags a question as a ""hot"" (and maybe this is just my opinion).</p>
",AImeta,first think question attracted lot people neural networks hot topic nowadays issue neural networks face given lot people use like neural networks aware issue people probably interested knowing problem solve furthermore think original title question flaw nerual networks would attracted many people realized author post extent asking catastrophic forgetting inference neural networks changed title current one quite descriptive think contributed current popularity question given contains known maybe mnemonic technical expression catastrophic forgetting general trying edit questions improve titles make descriptive think potentially attract people title flaw nerual networks descriptive neural networks might many flaws encourage every user edit questions make titles descriptive actual problem given answers also technical long accessible understandable anyone field hence also strive simplicity possible questions think received lot attention upvotes example know exactly stack exchange tags question hot maybe opinion
1,"<p>I've seen many times questions get asked to find another stack (usually Data-Science or Cross-Validated) because they're focused on either implementation or coding specific questions which are clearly stated as <strong>Not</strong> to be asked on this site by the <a href=""https://ai.stackexchange.com/help/on-topic"">site's acceptable topics</a>. My question is why this decision was made, along with is it worth reconsidering?  </p>

<p>Recently it has been asked <a href=""https://ai.meta.stackexchange.com/questions/1551/when-will-we-exactly-graduate"">when this stack will get out of beta?</a> The response was that there is not enough traffic / helpful content being created. Right now, because of the AI boom of the last decade along with large companies placing bottomless resources into higher-level frameworks (tensorflow, torch, keras, sonnet, etc..) making entering this field as a developer very attractive/easy to the younger generation, they will have a lot of questions on these topics!  </p>

<p>This increased push in traffic also means more answers. If we get more people coming to ask questions, more will come to answer. And if they're already answering one, who knows, they may answer another, and so on (Dominoes).  </p>

<p>The counter-claim to this idea is probably along the lines of: <em>Implementation based questions go against the purpose of this stack which is meant to be driven by theory, ethics, and societal impacts</em>  </p>

<p>My argument to this is: For the longest time, experimentation followed this track:  </p>

<ol>
<li>Learn  </li>
<li>Research  </li>
<li>Experiment (implementation is a subset of this)</li>
<li>Wash Rinse Repeat  </li>
</ol>

<p>But with these resources flowing in, and open-sourced projects are becoming popularized, we see people becoming ML practitioners without a clue of what they're doing. Using <a href=""https://github.com/tensorflow/models/tree/master/research/object_detection"" rel=""nofollow noreferrer"">object detection api</a> people can train up a ~SoTA model on their own dataset right out of the box almost and place something like that on their resume. From there, there exist 2 types of people: The ones who are complacent with what they achieved (by just using others' code on their data) or the ones that start to think, <em>How does this work?</em>, or <em>how could I adjust this to also do that?</em></p>

<p>The latter people I feel are definitely a category of people this site wants to attract (if I've understood this site's purposes correctly). Through implementation, they are trying to understand the process. I understand the counter-claim to this is that questions should be generalized to try to assist as many people as possible, but the number of people this category would invite would make up for this difference (I have no proof/ pure speculation). Granted you want to make sure not to attract questions from the former group (people who just want to use code out of the box and go on their merry way), so you could say implementation questions have to be focused on achieving certain levels of functionality that they are struggling to achieve rather than debugging/package-specific questions. </p>

<p>I.E. I can extrapolate why the rule was made the way it was, but I think it's not taking into account this new, kind of odd line of work that has been born </p>

<ol>
<li>Experiment  </li>
<li>Learn</li>
<li>Research  </li>
<li>Wash Rinse Repeat </li>
</ol>
",AImeta,seen many times questions get asked find another stack usually data science cross validated focused either implementation coding specific questions clearly stated asked site question decision made along worth reconsidering recently asked response enough traffic helpful content created right ai boom last decade along large companies placing bottomless resources higher level frameworks tensorflow torch keras sonnet etc making entering field developer attractive easy younger generation lot questions topics increased push traffic also means answers get people coming ask questions come answer already answering one knows may answer another dominoes counter claim idea probably along lines implementation based questions go purpose stack meant driven theory ethics societal impacts argument longest time experimentation followed track learn research experiment implementation subset wash rinse repeat resources flowing open sourced projects becoming popularized see people becoming ml practitioners without clue using people train sota model dataset right box almost place something like resume exist 2 types people ones complacent achieved using others code data ones start think work could adjust also latter people feel definitely category people site wants attract understood site purposes correctly implementation trying understand process understand counter claim questions generalized try assist many people possible number people category would invite would make difference proof pure speculation granted want make sure attract questions former group people want use code box go merry way could say implementation questions focused achieving certain levels functionality struggling achieve rather debugging package specific questions ie extrapolate rule made way think taking account new kind odd line work born experiment learn research wash rinse repeat
1,"<p>If we want to accept all or most questions that are related to AI and are also on-topic on the Data Science SE, Cross Validated SE, and Stack Overflow websites, then we'd better just merge the websites. We <strong>focus</strong> on the theoretical and philosophical aspects of AI, but I would not say that all implementation-related questions are off-topic here (but <strong>we need to define precisely which ones can be on-topic</strong>, which has not yet been done, AFAIK). However, questions that involve the debugging of source code (like &quot;Why am I getting this TypeError in this machine learning program?&quot;) should be considered off-topic, because there is already Stack Overflow for these. AFAIK, this website was created because there wasn't yet a website dedicated to the philosophical (and, partially, theoretical) aspects of AI.</p>
<p>(There are a lot of questions on Stack Overflow, Data Science SE and Cross Validated SE that would be better asked here, including some of the questions I had asked there. For example, <a href=""https://datascience.stackexchange.com/q/26938/10640"">What exactly is bootstrapping in reinforcement learning?</a>. I remember I had asked it there because, at the time, I had almost no hope in this website and I thought it would not have had a future, given the number of poor questions and answers that I used to see and the small number of competent regular users. I suppose that, if I had asked that question on this website, it would not have received so much attention. There are still users on this website that degrade its quality, because they do not follow the SE standards or because they are just trolling. Furthermore, I think that moderators on this website are too slow and are hesitant to take action regarding certain questions that are not compliant with the supposed goal of the website. For example, there are a lot of broad questions on this website, which could have been avoided, if we had more active moderators that follow the rules. During this year, I've invested a lot of time on this website, so I believe that, in general, the quality of the website (answers and questions) has increased (but this is just my perception of the situation). By the way, I believe that this website still lacks more competent people in certain areas, such as geometric deep learning, POMDP, hierarchical RL, swarm intelligence, etc. People that give good answers on this website are the usual suspects. We need more diversity and perspectives.)</p>
<p><em>Which implementation-related questions should be on-topic here?</em> I believe that this is a question that should be asked on this meta (if it wasn't already asked). In any case, I believe we should still focus on the theoretical and philosophical aspects of AI. If you also like to answer questions related to implementation issues, then you'd better <strong>also</strong> use other dedicated websites, such as Stack Overflow and Data Science.</p>
<blockquote>
<p>From there, there exist 2 types of people: The ones who are complacent with what they achieved (by just using others' code on their data) or the ones that start to think, How does this work?, or how could I adjust this to also do that?</p>
<p>The latter people I feel are definitely a category of people this site wants to attract (if I've understood this site's purposes correctly). Through implementation, they are trying to understand the process. I understand the counter-claim to this is that questions should be generalized to try to assist as many people as possible, but the number of people this category would invite would make up for this difference (I have no proof/ pure speculation)</p>
</blockquote>
<p>There is Data Science SE for these people. However, maybe some implementation-related questions that also involve theoretical or philosophical aspects could also be on-topic here. For example, &quot;How is this concept usually implemented?&quot;.</p>
",AImeta,want accept questions related ai also topic data science se cross validated se stack overflow websites would better merge websites focus theoretical philosophical aspects ai would say implementation related questions topic need define precisely ones topic yet done afaik however questions involve debugging source code like considered topic already stack overflow afaik website created yet website dedicated philosophical partially theoretical aspects ai lot questions stack overflow data science se cross validated se would better asked including questions asked example remember asked time almost hope website thought would future given number poor questions answers used see small number competent regular users suppose asked question website would received much attention still users website degrade quality follow se standards trolling furthermore think moderators website slow hesitant take action regarding certain questions compliant supposed goal website example lot broad questions website could avoided active moderators follow rules year invested lot time website believe general quality website answers questions increased perception situation way believe website still lacks competent people certain areas geometric deep learning pomdp hierarchical rl swarm intelligence etc people give good answers website usual suspects need diversity perspectives implementation related questions topic believe question asked meta already asked case believe still focus theoretical philosophical aspects ai also like answer questions related implementation issues would better also use dedicated websites stack overflow data science exist 2 types people ones complacent achieved using others code data ones start think work could adjust also latter people feel definitely category people site wants attract understood site purposes correctly implementation trying understand process understand counter claim questions generalized try assist many people possible number people category would invite would make difference proof pure speculation data science se people however maybe implementation related questions also involve theoretical philosophical aspects could also topic example
1,"<p>I am referring to <a href=""https://ai.stackexchange.com/questions/13784/how-to-make-deepfake-video-without-a-fancy-pc"">this</a> question. The author asks if there exists a possibility to create deepfake-videos on a low-end PC.</p>

<p>On the one hand, I want to assume the best in people and therefore do not want to accuse them of an unethical use case. However, on the other hand, I also don't want to be naive: the majority of the videos created with deepfake are unethical.</p>

<p>Also, even if the author has good intentions and is planning to use deepfake in an ethical way, other people who stumble upon this question may not. This can, of course, happen with any question on Stack Exchange. The difference, however, is that the probability is very high that the answers to this question will be used with unethical intentions.</p>

<p>Further, there are also questions like <a href=""https://ai.stackexchange.com/questions/13782/how-do-deep-fakes-get-the-right-encoding-for-both-people"">this</a> one where the author is interested in the functionality of deepfake but is at the same time using it to create videos. Deepfake is indeed a very fascinating piece of software and explaining it could add valuable knowledge to this site. But the probability is still high that by answering it, we support unethical behavior.</p>

<p>To put it in more general terms: how should we deal with questions that have a high probability of being used unethically by the author or by other people? Deepfake is most probably just the beginning.</p>

<p><strong>Edit:</strong> I'd like to add a short description of the status quo to underline the importance of this question. Currently, answers to questions regarding deepfake are <em>encouraged</em> by the site mechanics. If one posts a valid answer, he or she gets rewarded with 10 points per upvote. That means, if we do not agree upon how we should deal with such questions, we passively support them.</p>
",AImeta,referring question author asks exists possibility create deepfake videos low end pc one hand want assume best people therefore want accuse unethical use case however hand also want naive majority videos created deepfake unethical also even author good intentions planning use deepfake ethical way people stumble upon question may course happen question stack exchange difference however probability high answers question used unethical intentions also questions like one author interested functionality deepfake time using create videos deepfake indeed fascinating piece software explaining could add valuable knowledge site probability still high answering support unethical behavior put general terms deal questions high probability used unethically author people deepfake probably beginning edit would like add short description status quo underline importance question currently answers questions regarding deepfake encouraged site mechanics one posts valid answer gets rewarded 10 points per upvote means agree upon deal questions passively support
1,"<p>Is it allowed to asking a question which is related to AI problem from a challenge or competition? In <a href=""https://puzzling.meta.stackexchange.com/questions/1674/questions-from-on-going-contests/1675#1675"">Puzzling.SE</a> it's not allowed.</p>

<p>I saw sometimes ago several questions that asked the same case, I couldn't find all questions, but few of them:</p>

<ul>
<li><a href=""https://ai.stackexchange.com/questions/13222/drawing-a-straight-line-through-points-where-the-tyre-meets-the-ground"">Drawing a straight line through points where the tyre meets the ground</a></li>
<li><a href=""https://ai.stackexchange.com/questions/13010/how-do-i-find-the-distance/13022#13022"">How do I find the distance?</a></li>
</ul>
",AImeta,allowed asking question related ai problem challenge competition allowed saw sometimes ago several questions asked case could find questions
1,"<p>According to the SE.AI archive, some examples in the past are available in which students have asked for help to solve homework problems:</p>

<ul>
<li><p><a href=""https://ai.stackexchange.com/questions/5121/neutral-network-how-to-solve-this"">neutral network - How to solve this?</a></p></li>
<li><p><a href=""https://ai.stackexchange.com/questions/7896/why-is-baseline-conditional-on-state-at-some-timestep-unbiased"">Why is baseline conditional on state at some timestep unbiased?</a></p></li>
</ul>

<p>In one case, a bounty was offered to increase the motivation to give the answer. It seems, that the SE.AI Q&amp;A website is used occasionally as a platform for solving quizzes from AI courses in the university domain. So the answer to the initial question is: yes, it's is allowed, because the referenced posts are in the archive and nobody is able to delete them.</p>
",AImeta,according seai archive examples past available students asked help solve homework problems one case bounty offered increase motivation give answer seems seai q website used occasionally platform solving quizzes ai courses university domain answer initial question yes allowed referenced posts archive nobody able delete
1,"<p>Since this question is unanswered for a week now, I would like to contribute a suggestion.</p>

<p>Questions that are <a href=""https://ai.stackexchange.com/help/on-topic"">on-topic</a> on the AI SE include the theory/concepts of AI, social issues, and so on. Questions regarding the implementation of algorithms are definitely off-topic.</p>

<p>I suggest the community should be allowed to discuss the theory and the theoretical concepts of algorithms that have a high likelihood of being used in an unethical way as long as the discourse stays purely theoretical. Questions regarding the implementation, or the application of such algorithms should be flagged as off-topic (what they actually are) and closed. These questions should be treated more strictly (when in doubt, close them) since they are not only probably off-topic but also have a higher probability of being used with unethical intentions.</p>

<p>That means, a question like <a href=""https://ai.stackexchange.com/questions/13784/how-to-make-deepfake-video-without-a-fancy-pc"">How to make deepfake video without a fancy PC?</a> should be closed and a question like <a href=""https://ai.stackexchange.com/questions/13260/what-are-the-differences-between-deepfakes-faceswap-and-face2face"">What are the differences between Deepfakes, FaceSwap and Face2Face?</a> should be left open.</p>

<p>An open issue is still where to draw the line. I think this has to be evaluated on a case by case basis. In the end, questions about the implementation of an algorithm are off-topic anyways.</p>
",AImeta,since question unanswered week would like contribute suggestion questions ai se include theory concepts ai social issues questions regarding implementation algorithms definitely topic suggest community allowed discuss theory theoretical concepts algorithms high likelihood used unethical way long discourse stays purely theoretical questions regarding implementation application algorithms flagged topic actually closed questions treated strictly doubt close since probably topic also higher probability used unethical intentions means question like closed question like left open open issue still draw line think evaluated case case basis end questions implementation algorithm topic anyways
1,"<p>I know that the website graduated but I believe in the correct question should have been: when will <a href=""https://ai.stackexchange.com"">https://ai.stackexchange.com</a> be merged with <a href=""https://datascience.stackexchange.com"">https://datascience.stackexchange.com</a> / <a href=""http://stats.stackexchange.com"">http://stats.stackexchange.com</a>? </p>

<p>It's pretty obvious from a quick glance at the <a href=""https://ai.stackexchange.com"">https://ai.stackexchange.com</a>'s questions that the vast majority of questions posted here are also on-topic on <a href=""https://datascience.stackexchange.com"">https://datascience.stackexchange.com</a> / <a href=""http://stats.stackexchange.com"">http://stats.stackexchange.com</a>. This issue was raised and discussed when <a href=""https://ai.stackexchange.com"">https://ai.stackexchange.com</a> was created, but it has never been fixed in practice.</p>
",AImeta,know website graduated believe correct question merged pretty obvious quick glance questions vast majority questions posted also topic issue raised discussed created never fixed practice
1,"<p>A closer look into the documentation of the Stack Exchange website has shown, that there is a powerful tool available called data-explorer. It's an SQL interface for query the raw data of the Q&amp;A website which includes the user reputation and all the posts. Creating an SQL query from scratch is a bit complicated because the information is distributed over different tables in a relational database system but there are many hundred! out-of-the-box SQL queries available for answering all sorts of needs.</p>

<p>For example, under the URL <a href=""https://data.stackexchange.com/ai/query/1057016/ratio-of-upvotes-to-downvotes-received"" rel=""nofollow noreferrer"">https://data.stackexchange.com/ai/query/1057016/ratio-of-upvotes-to-downvotes-received</a> a user ranking of the AI website is shown. The users can be ordered by their total reputation, but it's also possible to rank them according to the received upvotes. It's possible for a user to identify themselves in the ranking and compare the score with others. I personally got over 200 upvotes from other users. Most users of SE.AI have received fewer upvotes, but their amount of posted messages was lower. </p>

<p>In general, is there a correlation between the number of answers and upvotes?</p>
",AImeta,closer look documentation stack exchange website shown powerful tool available called data explorer sql interface query raw data q website includes user reputation posts creating sql query scratch bit complicated information distributed different tables relational database system many hundred box sql queries available answering sorts needs example url user ranking ai website shown users ordered total reputation also possible rank according received upvotes possible user identify ranking compare score others personally got 200 upvotes users users seai received fewer upvotes amount posted messages lower general correlation number answers upvotes
1,"<p>Created my account using the Join button as I usually do and I ended up with a default profile icon and a <code>user1234</code> name. Even editing my network profile and clicking ""save to all public network sites"" won't update my profile here. I had to change my name for just this site specifically and I can't find a ""import from network"" option.</p>

<p>What gives?</p>
",AImeta,created account using join button usually ended default profile icon name even editing network profile clicking save public network sites update profile change name site specifically find import network option gives
1,"<p>Earlier today I answered a question titled ""About the paper : “Label-Free Supervision of Neural Networks with Physics and Domain Knowledge”"", for which I had to check the original paper. I spent some time answering the question but then, half an hour later the user deleted his question and there goes my answer with it. I do not mind getting no votes or getting downvoted, but information being deleted so easily is quite annoying. </p>

<p>My question is, isn't there some kind of restriction on deleting answered questions so easily? If there is not, can I block the user so that I won't spend any more time trying to answer questions from him?</p>
",AImeta,earlier today answered question titled paper label free supervision neural networks physics domain knowledge check original paper spent time answering question half hour later user deleted question goes answer mind getting votes getting downvoted information deleted easily quite annoying question kind restriction deleting answered questions easily block user spend time trying answer questions
1,"<p>Yes, there are restrictions. For example, you cannot delete a question with more than one answer or with an upvoted or accepted answer. See <a href=""https://meta.stackexchange.com/q/5221/287113"">How does deleting work? What can cause a post to be deleted, and what does that actually mean? What are the criteria for deletion?</a> for more info. Apparently, your answer wasn't upvoted. </p>

<p>Regarding the ""block a user"" feature, see <a href=""https://meta.stackexchange.com/q/3353/287113"">Add the ability to ignore users</a>.</p>

<p>I understand your feelings now, given that you spent time to provide a good answer and information. However, I would advise you not to give much importance to this episode. It may happen, but this usually does not happen!</p>
",AImeta,yes restrictions example delete question one answer upvoted accepted answer see info apparently answer upvoted regarding block user feature see understand feelings given spent time provide good answer information however would advise give much importance episode may happen usually happen
1,"<p>Stack Overflow does code syntax highlighting automatically, however, ai.stackexchange doesn't.</p>

<p>I've tried to add <code>&lt;-- language: python --&gt;</code> before code lines but no syntax highlighting applied. </p>

<p>How to do code syntax highlighting on ai.stackexchange?</p>
",AImeta,stack overflow code syntax highlighting automatically however aistackexchange tried add code lines syntax highlighting applied code syntax highlighting aistackexchange
1,"<p>Customer orientation means to provide the optimal service for the user. It is equal to provide answers to a given request. The answer quality can be measured indirectly by the amount of downvotes an answers receives. If a Q&amp;A website is motivated to downvote it's own answers then the service quality is high.</p>

<p>On the first look this sounds a bit harsh, because if an answer was given, it's unfair to press the downvote button. The problem is, if all answers are treated equal this it is resulting into a missing awareness of quality. What is missing is a judgement about answers who are wrong, misleading or outdated. The only way in ensuring the maximum quality for a question is to judge strict.</p>

<p>Before a detail look in the situation at SE.AI make sense, let's try to observe what the larger Stackoverflow forum is doing. In the data explorer there is an SQL query available available, called “Most downvoted answers on the site”, <a href=""https://data.stackexchange.com/stackoverflow/query/940206/most-downvoted-answers-on-the-site"" rel=""nofollow noreferrer"">https://data.stackexchange.com/stackoverflow/query/940206/most-downvoted-answers-on-the-site</a> It lists answers who have received a lot of downvotes. The top entry has received -286 downvotes but there are many other examples available in which answers have received more than -50! downvotes. On the first look this sounds like a low quality at Stackoverflow, but the opposite is true. If many low quality answers are available, on the other side there are many answers which provides a high quality. The goal is split the answers into distinct categories: not wanted and wanted answer. And the downvote button was invented to ensure, that the distance is maximized.</p>

<p>The good news is, that the same SQL query is available for SE.AI as well. <a href=""https://data.stackexchange.com/ai/query/940206/most-downvoted-answers-on-the-site"" rel=""nofollow noreferrer"">https://data.stackexchange.com/ai/query/940206/most-downvoted-answers-on-the-site</a> Unfortunately, the resulting table looks calm. The most critical answer has received not more than -6 downvotes. And some questions have received -2. This is not a strict judgement but it's a missing measurement of the quality.</p>

<p>Do we need more downvotes to existing answers for improving the service level of SE.AI?</p>
",AImeta,customer orientation means provide optimal service user equal provide answers given request answer quality measured indirectly amount downvotes answers receives q website motivated downvote answers service quality high first look sounds bit harsh answer given unfair press downvote button problem answers treated equal resulting missing awareness quality missing judgement answers wrong misleading outdated way ensuring maximum quality question judge strict detail look situation seai make sense let try observe larger stackoverflow forum data explorer sql query available available called downvoted answers site lists answers received lot downvotes top entry received 286 downvotes many examples available answers received 50 downvotes first look sounds like low quality stackoverflow opposite true many low quality answers available side many answers provides high quality goal split answers distinct categories wanted wanted answer downvote button invented ensure distance maximized good news sql query available seai well unfortunately resulting table looks calm critical answer received 6 downvotes questions received 2 strict judgement missing measurement quality need downvotes existing answers improving service level seai
1,"<p>You're making a good point: I think we need to vote more, but also more appropriately, but, to achieve that, we need more competent and serious users! </p>

<p>For example, even though this case is a little subjective, the information given in the answer <a href=""https://ai.stackexchange.com/a/15442/2444"">https://ai.stackexchange.com/a/15442/2444</a> is based on the information you can find in a renowned book by an important person in the field. Furthermore, it is based on the knowledge of a person who has studied the topic quite seriously. Nonetheless, people have very likely inappropriately downvoted it, for some mysterious reason. </p>

<p>There are also too broad posts that have unbelievably received a lot of upvotes. For example, this one: <a href=""https://ai.stackexchange.com/q/7079/2444"">What topologies are largely unexplored in machine learning?</a>, where the user asks multiple questions, which are quite difficult to answer jointly and satisfactorily, apart from the fact that this type of posts is only useful to the original poster. So, I believe that, on this website, the voting system is not working appropriately in all cases.</p>

<p>We also need more competent regular users and moderators that are not hesitant to upvote or downvote posts and to vote to close them when necessary! </p>

<p>Regarding the comparison with Stack Overflow, you should note that Stack Overflow has a lot more users and visitors than AI.SE.</p>
",AImeta,making good point think need vote also appropriately achieve need competent serious users example even though case little subjective information given answer based information find renowned book important person field furthermore based knowledge person studied topic quite seriously nonetheless people likely inappropriately downvoted mysterious reason also broad posts unbelievably received lot upvotes example one user asks multiple questions quite difficult answer jointly satisfactorily apart fact type posts useful original poster believe website voting system working appropriately cases also need competent regular users moderators hesitant upvote downvote posts vote close necessary regarding comparison stack overflow note stack overflow lot users visitors aise
1,"<p>Wanted to put it to the community before I took any action.  John Doucette suggested it and I think it's a good idea!</p>

<p><a href=""https://ai.stackexchange.com/questions/15594/what-are-all-the-different-kinds-of-neural-networks-used-for"">What are all the different kinds of Neural Networks used for?</a></p>

<hr>

<p><em>PS
Here's the source of the chart: <a href=""https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463"" rel=""nofollow noreferrer"">https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463</a></em></p>
",AImeta,wanted put community took action john doucette suggested think good idea pshere source chart
1,"<p>I believe that only questions and answers that have been edited by multiple users and that no longer resemble the original question or answer, respectively, should be made community wiki, given that the upvotes or downvotes are no longer only associated with or attributed to the user that originally posted the answer or question. For example, this answer <a href=""https://ai.stackexchange.com/a/8688/2444"">https://ai.stackexchange.com/a/8688/2444</a> should be made a community wiki, given that its current version and quality is due to multiple users.</p>
<p>In the article <a href=""https://stackoverflow.blog/2011/08/19/the-future-of-community-wiki/"">The Future of Community Wiki</a>, it is stated in the section <strong>Community Wiki is not a &quot;Quick Fix&quot;</strong></p>
<blockquote>
<p>Many sites propose using community wiki to allow content that is on-topic and useful, but can be considered borderline or questionable in other ways. Someone notes that a certain class of question has problems, and proposes using community wiki as a quick fix.</p>
<p>If a question is valuable enough that you believe it belongs on the site, chances are you don’t need it to be community wiki! We welcome all contributions which improve the quality of a site and advertise its greatness to the rest of the world. If you allow a certain class of questions, but only under the stipulation that no one can earn reputation from them, you’ve strongly discouraged these sorts of questions. People aren’t going to put in nearly as much effort to ask them.</p>
<p><strong>Instead, strive for quality. If you're unsure a certain question class belongs on the site, don't tolerate the worst examples — demand that these questions be awesome. Questions shouldn’t be swept under the rug with community wiki; they should get the same respect and treatment as the rest of your Q&amp;A. If those questions are something you are uncomfortable showing to visitors … they probably don’t belong on your site</strong>.</p>
<p>Many things which &quot;need&quot; to be community wiki simply don't. Sometimes it’s just a matter of understanding the root of a question: <strong>&quot;Software to record video games&quot; can be turned into a great question without needing the crutch of community wiki. Or, you may need to break the original question into smaller parts</strong>; a rather well-timed Ask Different Meta post explores this very avenue.</p>
</blockquote>
<p>Hence, the question <a href=""https://ai.stackexchange.com/q/15594/2444"">What are all the different kinds of neural networks used for?</a> should probably be closed as too broad. However, given that I edited the post to include &quot;I just need a brief overview (1-2 lines) of their applications.&quot;, the scope has been slightly limited. So, at this point, more than one user has contributed to the quality and current version of the question, so maybe it should be made a community wiki (according to my belief above).</p>
<p>In the section <strong>Community Wiki is primarily for Answers</strong> of the same article</p>
<blockquote>
<p><strong>If we haven’t said this enough already, questions rarely, if ever, need community wiki</strong>. What about answers? We removed the ability for users to make a question community wiki, but left the ability for users to make an answer wiki.</p>
<p>The intent of community wiki in answers is to help share the burden of solving a question. An incomplete “seed” answer is a stepping stone to a complete solution with help from others; an incomplete question is a hindrance and an obstacle to getting a solution as no one understands the inquiry. It is in answers that the goal of community wiki, for the community, by the community, shows its truest colors.</p>
<p>Yet even in answers, true collaboration is scarce. Most of the time, a single individual can provide a complete answer. There are even times where a question looks like it’ll need a massive effort, but one gallant user steps up to the plate with an impressive and comprehensive answer.</p>
</blockquote>
<p>See also <a href=""https://meta.stackexchange.com/q/11740/287113"">What are &quot;Community Wiki&quot; posts?</a>.</p>
",AImeta,believe questions answers edited multiple users longer resemble original question answer respectively made community wiki given upvotes downvotes longer associated attributed user originally posted answer question example answer made community wiki given current version quality due multiple users article stated section community wiki many sites propose using community wiki allow content topic useful considered borderline questionable ways someone notes certain class question problems proposes using community wiki quick fix question valuable enough believe belongs site chances nt need community wiki welcome contributions improve quality site advertise greatness rest world allow certain class questions stipulation one earn reputation strongly discouraged sorts questions people nt going put nearly much effort ask instead strive quality unsure certain question class belongs site tolerate worst examples demand questions awesome questions nt swept rug community wiki get respect treatment rest q questions something uncomfortable showing visitors probably nt belong site many things rather well timed ask different meta post explores avenue hence question probably closed broad however given edited post include scope slightly limited point one user contributed quality current version question maybe made community wiki according belief section community wiki primarily answers article nt said enough already questions rarely ever need community wiki answers removed ability users make question community wiki left ability users make answer wiki intent community wiki answers help share burden solving question incomplete seed answer stepping stone complete solution help others incomplete question hindrance obstacle getting solution one understands inquiry answers goal community wiki community community shows truest colors yet even answers true collaboration scarce time single individual provide complete answer even times question looks like need massive effort one gallant user steps plate impressive comprehensive answer see also
1,"<p>This website should rarely need this feature, given that we are mainly concerned with theoretical and philosophical AI questions. Most implementation-related questions are off-topic here. You can ask them on Data Science SE or Stack Overflow. See <a href=""https://ai.stackexchange.com/help/on-topic"">Help Center > Asking > What topics can I ask about here?</a>. </p>
",AImeta,website rarely need feature given mainly concerned theoretical philosophical ai questions implementation related questions topic ask data science se stack overflow see
1,"<p>There are at least two tags that are related to requests: <a href=""https://ai.stackexchange.com/questions/tagged/reference-request"" class=""post-tag"" title=""show questions tagged &#39;reference-request&#39;"" rel=""tag"">reference-request</a> and <a href=""https://ai.stackexchange.com/questions/tagged/resource-request"" class=""post-tag"" title=""show questions tagged &#39;resource-request&#39;"" rel=""tag"">resource-request</a>. The current description of the former is</p>

<blockquote>
  <p>Use this tag when requesting examples of research or links to papers. For example, ""What paper is a good place to start in the field of X?"" or ""What are good examples of Y in research?""</p>
</blockquote>

<p>while the description of the latter is</p>

<blockquote>
  <p>Use for questions about resources helpful in AI endeavors. This can include training data. (May also be used in conjunction with ""software-evaluation"" if the request involves software as opposed to data.)</p>
</blockquote>

<p><em>Shouldn't we change the description and scope of <a href=""https://ai.stackexchange.com/questions/tagged/reference-request"" class=""post-tag"" title=""show questions tagged &#39;reference-request&#39;"" rel=""tag"">reference-request</a> to include all types of references (e.g. books, thesis, etc)?</em> I think so.</p>

<p>The description of the second tag is not very clear. <em>Any suggestions to clarify it?</em></p>

<p>It seems to me that these tags have an overlapping scope. For example, this question <a href=""https://ai.stackexchange.com/q/15634/2444"">What is the predicted timeline for driverless metros worldwide?</a> could apparently be tagged with both. <em>What do you think?</em> </p>

<p><em>Also, are these tags consistent with the on-topic page?</em></p>
",AImeta,least two tags related requests current description former use tag requesting examples research links papers example paper good place start field x good examples research description latter use questions resources helpful ai endeavors include training data may also used conjunction software evaluation request involves software opposed data change description scope include types references eg books thesis etc think description second tag clear suggestions clarify seems tags overlapping scope example question could apparently tagged think also tags consistent topic page
1,"<p>My main thought is that we've been seeing requests for data sets to use in training, and these would represent resource requests as opposed to reference requests.</p>

<p>Similarly for people looking for published code to utilize (GitHub as a resource.)</p>
",AImeta,main thought seeing requests data sets use training would represent resource requests opposed reference requests similarly people looking published code utilize github resource
1,"<p>Do we really need the tag <a href=""https://ai.stackexchange.com/questions/tagged/ai-basics"" class=""post-tag"" title=""show questions tagged &#39;ai-basics&#39;"" rel=""tag"">ai-basics</a>? </p>

<p>The description of the tag <a href=""https://ai.stackexchange.com/questions/tagged/ai-basics"" class=""post-tag"" title=""show questions tagged &#39;ai-basics&#39;"" rel=""tag"">ai-basics</a> says</p>

<blockquote>
  <p>Use for basic, fundamental questions about AI theory or practice. (i.e. design, application, implementation, mathematics of AI, philosophy of AI, etc.)</p>
</blockquote>

<p>Do we really need to distinguish between a basic question and a non-basic one? What exactly is a basic question? What is a non-basic one? </p>

<p>In my opinion, the tag <a href=""https://ai.stackexchange.com/questions/tagged/ai-basics"" class=""post-tag"" title=""show questions tagged &#39;ai-basics&#39;"" rel=""tag"">ai-basics</a> is superfluous, ambiguous and subjective, so it should not exist. There are already the tags <a href=""https://ai.stackexchange.com/questions/tagged/theory"" class=""post-tag"" title=""show questions tagged &#39;theory&#39;"" rel=""tag"">theory</a>, <a href=""https://ai.stackexchange.com/questions/tagged/philosophy"" class=""post-tag"" title=""show questions tagged &#39;philosophy&#39;"" rel=""tag"">philosophy</a>, <a href=""https://ai.stackexchange.com/questions/tagged/math"" class=""post-tag"" title=""show questions tagged &#39;math&#39;"" rel=""tag"">math</a>, <a href=""https://ai.stackexchange.com/questions/tagged/ai-design"" class=""post-tag"" title=""show questions tagged &#39;ai-design&#39;"" rel=""tag"">ai-design</a>, <a href=""https://ai.stackexchange.com/questions/tagged/applications"" class=""post-tag"" title=""show questions tagged &#39;applications&#39;"" rel=""tag"">applications</a> and <a href=""https://ai.stackexchange.com/questions/tagged/implementation"" class=""post-tag"" title=""show questions tagged &#39;implementation&#39;"" rel=""tag"">implementation</a>, which cover everything convered by <a href=""https://ai.stackexchange.com/questions/tagged/ai-basics"" class=""post-tag"" title=""show questions tagged &#39;ai-basics&#39;"" rel=""tag"">ai-basics</a>.</p>
",AImeta,really need tag description tag says use basic fundamental questions ai theory practice ie design application implementation mathematics ai philosophy ai etc really need distinguish basic question non basic one exactly basic question non basic one opinion tag superfluous ambiguous subjective exist already tags cover everything convered
1,"<p>A short look into the overview statistics have shown, that SE.AI has a poor percentage of answered questions.[1] Only 71% of the questions were answered in the past. A detailed list, which kind of of questions are remaining unanswered in the system is given by a second statistics.[2] It shows only questions which have no comments right now. That means, the OP has dropped a month ago his problem and nothing happens since then. No negative feedback, no positive comment, no nothing. The amount of postings with this criteria is around 20-30 per month.</p>

<p>A naive assumption might be, that the question quality was poor. Indeed, some questions are in the system which containing only of two sentence which is a bit short. But many questions in the list are very elaborated, are written in an academic style and enriched with additional pictures. But this doesn't improved the answer-probability.</p>

<p>Could it be, that with the questions and the user who have created them everything is fine, but SE.AI struggles in handling the incoming load in an appropriate way? </p>

<p>[1] Stackexchange all sites, <a href=""https://stackexchange.com/sites"">https://stackexchange.com/sites</a></p>

<p>[2] Stackexchange Dataexplorer, Unanswered questions without comments, <a href=""https://data.stackexchange.com/ai/query/548333/unanswered-questions-without-comments"" rel=""nofollow noreferrer"">https://data.stackexchange.com/ai/query/548333/unanswered-questions-without-comments</a></p>
",AImeta,short look overview statistics shown seai poor percentage answered questions1 71 questions answered past detailed list kind questions remaining unanswered system given second statistics2 shows questions comments right means op dropped month ago problem nothing happens since negative feedback positive comment nothing amount postings criteria around 20 30 per month naive assumption might question quality poor indeed questions system containing two sentence bit short many questions list elaborated written academic style enriched additional pictures improved answer probability could questions user created everything fine seai struggles handling incoming load appropriate way 1 stackexchange sites 2 stackexchange dataexplorer unanswered questions without comments
1,"<p>I'm not sure how big of a deal this is, since out other stats are adequate.  </p>

<p>That said, at some point, it might might make sense to start a deletion campaign of old, unanswered questions, not just to improve the metric, but to clear away the junk.</p>
",AImeta,sure big deal since stats adequate said point might might make sense start deletion campaign old unanswered questions improve metric clear away junk
1,"<p>According to <a href=""https://stackexchange.com/sites"">https://stackexchange.com/sites</a>, currently, 71% of the questions on AI SE are answered. However, similar or related websites do not have a higher percentage of answered questions. For example, on Stack Overflow, only 70% of the questions are answered. On Stats SE and Data Science SE, 65% of the questions are answered.</p>
",AImeta,according currently 71 questions ai se answered however similar related websites higher percentage answered questions example stack overflow 70 questions answered stats se data science se 65 questions answered
1,"<p>A recent question [1] was closed as offtopic and then migrated to the datascience.stackexchange.com website. One hour later, the migration request was rejected, that means the Datascience community wasn't welcome the issue. Perhaps with the idea in mind, that if they are accepting one issue, they have to welcome all the issues in future.</p>

<p>From the perspective of the OP the interesting question is, who is responsible for the sound localization problem. He was using a neural network to detect loudness difference between two ears. If he comes to the conclusion that this is maybe an Artificial Intelligence problem which can only be solved with normalized input data, the OP would perhaps open up a follow up ticket at SE.AI.</p>

<p>Is it possible for the Original Poster to open follow up tickets in which he is referencing to a previous closed ticket?</p>

<p>[1] question timeline: Training a sound localization neural network [on hold], <a href=""https://ai.stackexchange.com/posts/15956/timeline"">https://ai.stackexchange.com/posts/15956/timeline</a> </p>
",AImeta,recent question 1 closed offtopic migrated datasciencestackexchangecom website one hour later migration request rejected means datascience community welcome issue perhaps idea mind accepting one issue welcome issues future perspective op interesting question responsible sound localization problem using neural network detect loudness difference two ears comes conclusion maybe artificial intelligence problem solved normalized input data op would perhaps open follow ticket seai possible original poster open follow tickets referencing previous closed ticket 1 question timeline training sound localization neural network hold
1,"<p>This is why I avoid migration, as opposed to urging the OP to self-close and re-ask on the proper stack.  (In this case, the OP stated they would do this, but hadn't so I did the migration.)</p>

<p>I've left a comment on the question, asking if the OP could reformulate to make it more on-topic here. </p>

<p>We want to help people get the answers they need, but we need to be more aggressive about maintaining the boundaries of this Stack in terms of scope.</p>

<hr>

<p>PS- I'm not really sure about follow-up tickets, but if the OP edits and submits for re-opening, I'll see it.</p>
",AImeta,avoid migration opposed urging op self close ask proper stack case op stated would migration left comment question asking op could reformulate make topic want help people get answers need need aggressive maintaining boundaries stack terms scope ps really sure follow tickets op edits submits opening see
1,"<p>Essentially, what are your thoughts on what we need to be doing, doing better, or not doing, to grow the Stack?</p>

<p>(This topic may have been covered in the past, but I wanted to open a new thread to reflect the present status.)</p>
",AImeta,essentially thoughts need better grow stack topic may covered past wanted open new thread reflect present status
1,"<p>There are several problems. Some of them have already been raised but not addressed.</p>

<ol>
<li><p>Too broad questions (or posts with multiple questions) are not closed (immediately). See <a href=""https://ai.meta.stackexchange.com/q/1536/2444"">Why aren&#39;t too broad questions closed?</a>.</p></li>
<li><p>Too many duplicate questions, which are not marked as duplicate. See <a href=""https://ai.meta.stackexchange.com/q/1532/2444"">What should we do regarding extremely similar questions or duplicates?</a>.</p></li>
<li><p>The on-topic and off-topic pages of the site are not clear enough. See <a href=""https://ai.meta.stackexchange.com/q/1506/2444"">On-topic and off-topic pages need to be clarified</a>. </p></li>
<li><p>In general, new users should have a clear idea of the most appropriate website to ask a question (among AI SE, Data Science SE, Stats SE, and Stack Overflow), but this has not yet been clarified.</p></li>
<li><p>It is still unclear which implementation-related questions are on-topic.</p></li>
<li><p>Too many tags that should not exist because they are not directly or strictly related to our scope. See <a href=""https://ai.meta.stackexchange.com/q/1538/2444"">On the management of tags on this website</a>. In general, if a question mentions e.g. a certain concept or tool, it does not mean that an associated tag needs to be created. For example, it makes sense to have a tag associated with ant-colony optimization (given that this is a theoretical AI topic), but it makes no sense to have a tag like <a href=""https://ai.stackexchange.com/questions/tagged/accessibility"" class=""post-tag"" title=""show questions tagged &#39;accessibility&#39;"" rel=""tag"">accessibility</a> (which is extremely vague and general). In general, only tags that are associated with common concepts should exist. We shouldn't create a tag for every possible concept or tool. </p></li>
<li><p>Some users that (constantly) provide out-of-context and poor answers. These answers often look like spam, so they degrade the quality of the website.</p></li>
<li><p>Currently and generally, moderators are often not very active, responsive and strict enough. </p></li>
<li><p>There's a need for more competent people in certain areas. It seems that the usual suspects tend to answer to almost all questions. We need more diversity and competence.</p></li>
</ol>
",AImeta,several problems already raised addressed broad questions posts multiple questions closed immediately see many duplicate questions marked duplicate see topic topic pages site clear enough see general new users clear idea appropriate website ask question among ai se data science se stats se stack overflow yet clarified still unclear implementation related questions topic many tags exist directly strictly related scope see general question mentions eg certain concept tool mean associated tag needs created example makes sense tag associated ant colony optimization given theoretical ai topic makes sense tag like extremely vague general general tags associated common concepts exist create tag every possible concept tool users constantly provide context poor answers answers often look like spam degrade quality website currently generally moderators often active responsive strict enough need competent people certain areas seems usual suspects tend answer almost questions need diversity competence
1,"<p>For investigating the tag problem in detail, a look into the <a href=""https://ai.stackexchange.com/tags"">tag section</a> make sense. Right now, the list contains of 15! pages with over 500 tags in total. According to the Stackoverflow help section it's possible to delete a tag. For doing so, the tag must removed from all questions, and then the system will delete the tag at midnight with a script.</p>

<p>A possible way in dealing the tag problem is to scroll to the end of the list and search for seldom used tag. They can be unlinked from the question. In the first step, the list of all tags can be reduced to under 100 tags in total, and then it make sense to discuss which of them can be renamed and aggregated into groups.</p>

<p><em>Solving the tag problem with more tags?</em></p>

<p>A naive approach in dealing with the tag issue is to simply add more tags to the list. In the hope, that this will classify the questions better. The mentioned Stackoverflow website contains of 50000 tags. But the amount of questions in the system is greater. The ratio is 0.0028 tags per question. In contrast the ratio at SE.AI right now is 0.1 tag per question.</p>
",AImeta,investigating tag problem detail look make sense right list contains 15 pages 500 tags total according stackoverflow help section possible delete tag tag must removed questions system delete tag midnight script possible way dealing tag problem scroll end list search seldom used tag unlinked question first step list tags reduced 100 tags total make sense discuss renamed aggregated groups solving tag problem tags naive approach dealing tag issue simply add tags list hope classify questions better mentioned stackoverflow website contains 50000 tags amount questions system greater ratio 00028 tags per question contrast ratio seai right 01 tag per question
1,"<p>Deleting existing content is a restricted resource in most issue-tracking systems. Not everybody is allowed in doing so and only under certain condition a single user can do so. In SE.AI i have identified an older question not created by me which i would like to delete. The reason is, that I belief the question is too broad. Also, it was asked two years ago and according to my opinion the problem is no longer relevant for a larger audience. Should i ask first the OP, if it's ok to delete the question or is only the admin of SE.AI allowed to delete questions?</p>
",AImeta,deleting existing content restricted resource issue tracking systems everybody allowed certain condition single user seai identified older question created would like delete reason belief question broad also asked two years ago according opinion problem longer relevant larger audience ask first op ok delete question admin seai allowed delete questions
1,"<p>Questions can only be immediately deleted by their authors or by moderators. Users with the <a href=""https://ai.stackexchange.com/help/privileges/moderator-tools"">""access to moderator tools""</a> privilege can vote to delete questions that are already closed.</p>

<p>If you believe a question to be too broad or otherwise not suitable as a question on this site, you should cast a close vote if you have the <a href=""https://ai.stackexchange.com/help/privileges/close-questions"">privilege</a> or a close flag if you do not yet. We usually close questions before deleting them so that the author has a chance to fix them. Questions that are closed, haven't been touched in a while, and doesn't have content worth saving (as judged by votes on the question and its answers) will be <a href=""https://ai.stackexchange.com/help/roomba"">automatically cleaned up</a> by the system.</p>

<p>In summary, you don't need to go out of your way to try to delete the question.</p>
",AImeta,questions immediately deleted authors moderators users privilege vote delete questions already closed believe question broad otherwise suitable question site cast close vote close flag yet usually close questions deleting author chance fix questions closed touched content worth saving judged votes question answers system summary need go way try delete question
1,"<p>There's the tag <a href=""https://ai.stackexchange.com/questions/tagged/predicting-ai-milestones"" class=""post-tag"" title=""show questions tagged &#39;predicting-ai-milestones&#39;"" rel=""tag"">predicting-ai-milestones</a>, but I think it should simply be called <a href=""https://ai.stackexchange.com/questions/tagged/ai-milestones"" class=""post-tag"" title=""show questions tagged &#39;ai-milestones&#39;"" rel=""tag"">ai-milestones</a> because it is more general and also includes all questions that could be tagged with the first.</p>

<p>For example, the following question <a href=""https://ai.stackexchange.com/q/64/2444"">What were the first areas of research and what were some early successes?</a> could then be tagged with <a href=""https://ai.stackexchange.com/questions/tagged/ai-milestones"" class=""post-tag"" title=""show questions tagged &#39;ai-milestones&#39;"" rel=""tag"">ai-milestones</a>. I could have simply created the tag <a href=""https://ai.stackexchange.com/questions/tagged/ai-milestones"" class=""post-tag"" title=""show questions tagged &#39;ai-milestones&#39;"" rel=""tag"">ai-milestones</a>, but I think that <a href=""https://ai.stackexchange.com/questions/tagged/predicting-ai-milestones"" class=""post-tag"" title=""show questions tagged &#39;predicting-ai-milestones&#39;"" rel=""tag"">predicting-ai-milestones</a> should simply not exist, because it is too specific.</p>
",AImeta,tag think simply called general also includes questions could tagged first example following question could tagged could simply created tag think simply exist specific
1,"<p>There are the tags <a href=""https://ai.stackexchange.com/questions/tagged/lstm"" class=""post-tag"" title=""show questions tagged &#39;lstm&#39;"" rel=""tag"">lstm</a> and <a href=""https://ai.stackexchange.com/questions/tagged/long-short-term-memory"" class=""post-tag"" title=""show questions tagged &#39;long-short-term-memory&#39;"" rel=""tag"">long-short-term-memory</a>, but they are not marked as synonyms. Of course, the questions associated with one tag should be merged with the questions associated with the other tag.</p>
",AImeta,tags marked synonyms course questions associated one tag merged questions associated tag
1,"<p>It's telling that it's much easier to create tags than remove them, and I have to wonder if this is intentional or just a fail-safe, to avoid untagged questions.</p>

<p>I like tags in general because they allow degrees of specificity.  For instance, most of our questions involve machine learning, but in relation to what?  </p>

<p>That said, there is a lot to digest in your post and I am still going through it, so I don't have any specific response at this time, other than to note that Bayes is a good example. </p>
",AImeta,telling much easier create tags remove wonder intentional fail safe avoid untagged questions like tags general allow degrees specificity instance questions involve machine learning relation said lot digest post still going specific response time note bayes good example
1,"<p><em>I'm aware that this topic has been discussed before, and didn't have much support, but I think it's worth at least a revisit, even only if to confirm the current status.</em></p>

<ul>
<li>Is career advice be off-topic if related to academic pursuits re: professional opportunities?</li>
</ul>

<p>Here specifically questions such as ""What classes to take to get this job?""</p>

<p>If the above question is on-topic, is it worth considering allowing professional advice in general?</p>

<p>Questions might involve sub-fields that are hot at any given time, industry trends, interview process (what to expect), etc.  Types of roles that exist in organizations, and potentially even pay-scales.</p>

<ol>
<li><p>This community is made up of people studying and working in the AI field, in the private sector and academia.  Others may have recently gone through the interview process.  This constitutes a cluster with field specific knowledge, as opposed to the stacks that deal with this in general.</p></li>
<li><p>Broadening the scope could be helpful in attracting new users, who might subsequently contribute.  (My own participation on Stack in general is a product of having gotten some info I needed several years ago.)  </p></li>
<li><p>All questions and answers are dated so visitors can see how current the information is.</p></li>
</ol>

<p>We are a general AI community, so I think this subject is potentially in scope, and could expand our utility.</p>
",AImeta,aware topic discussed much support think worth least revisit even confirm current status career advice topic related academic pursuits professional opportunities specifically questions classes take get job question topic worth considering allowing professional advice general questions might involve sub fields hot given time industry trends interview process expect etc types roles exist organizations potentially even pay scales community made people studying working ai field private sector academia others may recently gone interview process constitutes cluster field specific knowledge opposed stacks deal general broadening scope could helpful attracting new users might subsequently contribute participation stack general product gotten info needed several years ago questions answers dated visitors see current information general ai community think subject potentially scope could expand utility
1,"<p>Career advice may currently be off-topic, but, more importantly, it leads to primarily opinion-based answers and related questions can be too broad. For example, to answer the question ""What classes to take to get this job?"" satisfactorily, we need to know the background of the user, his (or her) location (because certain job titles may differ from place to place), etc., and the answers to such a question can become obsolete very rapidly.</p>

<p>Personally and generally, I am not against this type of questions, but they usually lead to poor answers. I think we should <strong>NOT</strong> broaden our scope only to increase the activity of our website, at the expense of a possible degradation of the quality of the questions and answers, which, in my opinion, and qualitatively, isn't already very high. We do NOT necessarily have to be big. We just need to find our place among all other SE websites and try to focus on doing our job well.</p>

<p>To conclude, in my opinion, <strong>career advice</strong> should be <strong>OFF-TOPIC</strong>. However, questions that ask for <strong>facts</strong> (rather than opinions) can be on-topic.</p>
",AImeta,career advice may currently topic importantly leads primarily opinion based answers related questions broad example answer question classes take get job satisfactorily need know background user location certain job titles may differ place place etc answers question become obsolete rapidly personally generally type questions usually lead poor answers think broaden scope increase activity website expense possible degradation quality questions answers opinion qualitatively already high necessarily big need find place among se websites try focus job well conclude opinion career advice topic however questions ask facts rather opinions topic
1,"<p>According to the latest statistics, I'm the most downvoted user in SE.AI. Many of my answers have received -2 up to -4 downvotes. Additional the amount of comments in which the group is explaining, why I'm wrong is intensive. It seems, that for SE.AI, it's very important to delimit my answers. This process is equal to implicit rank the user higher in the hierarchy. Only a strong user is able to resist against conflicts.</p>

<p>On the first look, this is a nice situation, because if the world's best Artificial Intelligence forum think, that they should downvote my answers, i can feel welcome in the Internet. The only problem is, that from an objective point of view, the situation is a bit different. If we are comparing my answers here in the forum with the published papers available at Google Scholar, it make no sense, to criticize my answer here. If an expert user is familiar with the latest research in robotics, artificial Intelligence and neural network, he has no obligation to go into distance to my amateurish answers. Because, what i have to explain isn't so much different from what is teached in the academic papers.</p>

<p>Is it possible to stop this and judge fair?</p>

<p><em>response to answers</em></p>

<p>If a group isn't able to downvote the right alpha-user they should think about what the purpose is. I'm not here to collect negative comments but i'd like to improve SE.AI.</p>
",AImeta,according latest statistics downvoted user seai many answers received 2 4 downvotes additional amount comments group explaining wrong intensive seems seai important delimit answers process equal implicit rank user higher hierarchy strong user able resist conflicts first look nice situation world best artificial intelligence forum think downvote answers feel welcome internet problem objective point view situation bit different comparing answers forum published papers available google scholar make sense criticize answer expert user familiar latest research robotics artificial intelligence neural network obligation go distance amateurish answers explain much different teached academic papers possible stop judge fair response answers group able downvote right alpha user think purpose collect negative comments would like improve seai
1,"<p>You're claiming that your downvoted posts should not have been downvoted and they are consistent with the latest findings and research. I will give one (but hopefully very credible) example of a post of yours which rightly deserves to be downvoted because the quality of the post is very poor.</p>
<p>Let's consider your answer <a href=""https://ai.stackexchange.com/a/8433/2444"">https://ai.stackexchange.com/a/8433/2444</a> to the question <a href=""https://ai.stackexchange.com/q/8432/2444"">Which areas of applied math are relevant to AI?</a> (which is also the title of the post), but I could have picked almost any other of your posts. <strong>You are supposed to at least list the areas of applied mathematics that are relevant to the field of AI</strong>. However, in your answer, you say</p>
<blockquote>
<p>Mathematicians are always welcome in Artificial Intelligence, because this helps to get a new perspective on thinking machines. Instead of describing robots with language grounding and story telling in comic books, Mathematicians are able to formalize the problems in theorems. The dominant open question right now is how to proof with a long equation (which has to be written in TeX) that Artificial Intelligence doesn't work. This could help to start a new AI winter and discourage people from outside the ivory tower to research a topic in detail. Only mathematics can proof that the halting problem can not be solved, that the state space is to complex and that recursion never ends.</p>
<p>It is important to stay on a purely theoretical basis. A mathematician who is using Python or another kind of programming language is the worst case. The better idea is to discuss AI problems only with pen and paper, on a blackboard and with people who have a deep understanding of logic. It is important to explain Artificial Intelligence abstract. A good starting point in doing so is theoretical computer science, which is by definition about fundamental aspects of machines.</p>
</blockquote>
<p>Which areas of applied mathematics that are relevant to AI have you listed in your answer above? In your answer above, you are saying everything but answering the question, so all the points below do not answer the question or are (completely) unrelated to the question (so I will not repeat this below).</p>
<ul>
<li>mathematicians are important people in the context of AI (I agree with you),</li>
<li>how to prove long equations (but it is unclear what you mean by long equations),</li>
<li>proofs can only be written in TeX (which is, of course, untrue),</li>
<li>the inability to write proofs for long equations can start new AI winters (which is of course false)</li>
<li>only mathematicians can prove the halting problem (this is debatable, given that the halting problem was initially proved by a mathematician, which is widely considered the father of computer science, namely, Alan Turing),</li>
<li>the state space (of what?) is too complex and recursion (of some algorithm you had in mind) never ends</li>
<li>It is important to stay on a purely theoretical basis (the theory is important but theory alone does not give us food)</li>
<li>A mathematician who is using Python or another kind of programming language is the worst case (I am not sure what you mean by this, but Python is surely useful in AI)</li>
<li>The better idea is to discuss AI problems only with pen and paper, on a blackboard and with people who have a deep understanding of logic (It is surely useful to discuss AI problems, but everyone has its own way of doing)</li>
<li>It is important to explain Artificial Intelligence abstract. (You meant &quot;abstractly&quot;, because, otherwise, I don't know what is the abstract of AI. Anyway, this is very unclear)</li>
<li>A good starting point in doing so is theoretical computer science, which is by definition about fundamental aspects of machines. (Well, we can have a philosophical debate, if you want)</li>
</ul>
<p>Ok, so you have not addressed the question at all and you've provided highly misleading and <strong>wrong</strong> information. Right now, your answer has been downvoted 4 times and upvoted 0 times. I've provided an example of your answers, among many other of your posts, which simply, completely and objectively deserves to be downvoted.</p>
",AImeta,claiming downvoted posts downvoted consistent latest findings research give one hopefully credible example post rightly deserves downvoted quality post poor let consider answer question also title post could picked almost posts supposed least list areas applied mathematics relevant field ai however answer say mathematicians always welcome artificial intelligence helps get new perspective thinking machines instead describing robots language grounding story telling comic books mathematicians able formalize problems theorems dominant open question right proof long equation written tex artificial intelligence work could help start new ai winter discourage people outside ivory tower research topic detail mathematics proof halting problem solved state space complex recursion never ends important stay purely theoretical basis mathematician using python another kind programming language worst case better idea discuss ai problems pen paper blackboard people deep understanding logic important explain artificial intelligence abstract good starting point theoretical computer science definition fundamental aspects machines areas applied mathematics relevant ai listed answer answer saying everything answering question points answer question completely unrelated question repeat mathematicians important people context ai agree prove long equations unclear mean long equations proofs written tex course untrue inability write proofs long equations start new ai winters course false mathematicians prove halting problem debatable given halting problem initially proved mathematician widely considered father computer science namely alan turing state space complex recursion algorithm mind never ends important stay purely theoretical basis theory important theory alone give us food mathematician using python another kind programming language worst case sure mean python surely useful ai better idea discuss ai problems pen paper blackboard people deep understanding logic surely useful discuss ai problems everyone way important explain artificial intelligence abstract meant otherwise know abstract ai anyway unclear good starting point theoretical computer science definition fundamental aspects machines well philosophical debate want ok addressed question provided highly misleading wrong information right answer downvoted 4 times upvoted 0 times provided example answers among many posts simply completely objectively deserves downvoted
1,"<p>nbro's answer is pretty compelling, but I'll try one too.</p>

<p>I think there are a couple possible issues:</p>

<p>1.There may be a language barrier. I sometimes find the things you write difficult to parse or understand. It is possible that you know a lot about this subject, but that the way you express it in English is difficult for others to understand. In this case, you should focus on improving your mastery of English.</p>

<p>2.There is a well known effect, called the <a href=""https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect"" rel=""nofollow noreferrer"">Dunning-Kruger effect</a>. Dunning-Kruger arises when <em>knowing about</em> something is a necessary prerequisite for <em>assessing how much you know about that thing</em>. It is present in most intellectual fields. Neophytes will typically go through a phase in which they feel deep understanding of material, but in fact do not understand it well, and moreover, do not understand explanations of why their understanding is incorrect. Many of the answers you have written suggest to me that you may be experiencing this effect. In this case, the solution is to engage in more formal instruction, especially with people who understand the material a little better than you (as opposed to subject experts, unless they have pedagogical training). These people are more likely to find problems in your understanding that you can easily accept. By identifying your misunderstandings, you will then improve. Eventually, you will enter the next phase of the Dunning-Kruger model, where you feel you understand very little, even though you may already be in the top few centiles of knowledge (this is where most PhD students are, in my experience :-) )</p>

<p>3.You may be misunderstanding what sorts of answers people are hoping to receive on their questions. You can remedy this by reading the answers that are upvoted and accepted, and determining what about them makes them better received. </p>
",AImeta,nbro answer pretty compelling try one think couple possible issues 1there may language barrier sometimes find things write difficult parse understand possible know lot subject way express english difficult others understand case focus improving mastery english 2there well known effect called dunning kruger arises knowing something necessary prerequisite assessing much know thing present intellectual fields neophytes typically go phase feel deep understanding material fact understand well moreover understand explanations understanding incorrect many answers written suggest may experiencing effect case solution engage formal instruction especially people understand material little better opposed subject experts unless pedagogical training people likely find problems understanding easily accept identifying misunderstandings improve eventually enter next phase dunning kruger model feel understand little even though may already top centiles knowledge phd students experience 3you may misunderstanding sorts answers people hoping receive questions remedy reading answers upvoted accepted determining makes better received
1,"<p>I would not be opposed to making this kind of advise on topic. I think @nbro makes some good points too though. My suggestion is that we experiment with allowing this kind of question, subject to the following provisos:</p>

<ol>
<li>Questions must be of the form ""What is the ideal academic background for someone who wants to work in <em>AI Specialty X</em>.</li>
<li>Questions must not be duplicates or near duplicates.</li>
<li>Questions must be about general job titles, not positions at specific companies (that would be speculative).</li>
<li>Questions must be accompanied by examples of job postings from at least two specific companies (so that we don't get made-up titles, which we otherwise will).</li>
</ol>
",AImeta,would opposed making kind advise topic think nbro makes good points though suggestion experiment allowing kind question subject following provisos questions must form ideal academic background someone wants work ai specialty x questions must duplicates near duplicates questions must general job titles positions specific companies would speculative questions must accompanied examples job postings least two specific companies get made titles otherwise
1,"<p>The topics of our website highly overlap with the topics of CrossValidated and Data Science, but also with the topics of <a href=""https://cs.stackexchange.com"">Computer Science SE</a>, Stack Overflow and <a href=""https://philosophy.stackexchange.com"">Philosophy SE</a> (in fact, they even have <a href=""https://philosophy.stackexchange.com/questions/tagged/artificial-intelligence"">an AI tag</a> with currently 145 questions, while we barely have more philosophical questions, 169). </p>

<p>The differences between our site, CrossValidated and Data Science seem to be the focus, the users and their background, and certain topics. I think that a new and growing website, like ours, is attractive to certain people (including me) because it may represent an opportunity to show their abilities to others and maybe rule the website, while, in websites like CrossValidated, where there are already many established users, this may be more difficult. <em>But does it really make sense to have all these separate websites (especially, CrossValidated, Data Science and ours), only because of these small differences?</em></p>

<p>It may happen that users on one of these sites may not be able to (properly) answer a question on their own website, but users on other related sites may be able to answer such a question. In those cases, the asker may not receive the help that, in theory, is available, but not directly accessible.</p>

<p>In order to understand if our website deserves to live, I think we need to enumerate the topics and goals of our website that really differentiate (or not) us from the other websites. Maybe we should really focus on the topics that differentiate us from the other websites. What do you think?</p>

<h3>Topics</h3>

<p>Here's a preliminary list of such topics (I am using the tags below only to emphasize that these are on-topic here, but I am referring to the topics)</p>

<ul>
<li><a href=""https://ai.stackexchange.com/questions/tagged/swarm-intelligence"" class=""post-tag"" title=""show questions tagged &#39;swarm-intelligence&#39;"" rel=""tag"">swarm-intelligence</a>

<ul>
<li><a href=""https://ai.stackexchange.com/questions/tagged/ant-colony"" class=""post-tag"" title=""show questions tagged &#39;ant-colony&#39;"" rel=""tag"">ant-colony</a></li>
</ul></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/symbolic-ai"" class=""post-tag"" title=""show questions tagged &#39;symbolic-ai&#39;"" rel=""tag"">symbolic-ai</a> (which is a synonym for <a href=""https://ai.stackexchange.com/questions/tagged/gofai"" class=""post-tag"" title=""show questions tagged &#39;gofai&#39;"" rel=""tag"">gofai</a>)

<ul>
<li><a href=""https://ai.stackexchange.com/questions/tagged/expert-system"" class=""post-tag"" title=""show questions tagged &#39;expert-system&#39;"" rel=""tag"">expert-system</a> (maybe also on topic on <a href=""https://cs.stackexchange.com"">Computer Science SE</a>, given they have a tag for this)</li>
</ul></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/social"" class=""post-tag"" title=""show questions tagged &#39;social&#39;"" rel=""tag"">social</a></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/agi"" class=""post-tag"" title=""show questions tagged &#39;agi&#39;"" rel=""tag"">agi</a>, <a href=""https://ai.stackexchange.com/questions/tagged/strong-ai"" class=""post-tag"" title=""show questions tagged &#39;strong-ai&#39;"" rel=""tag"">strong-ai</a>, <a href=""https://ai.stackexchange.com/questions/tagged/weak-ai"" class=""post-tag"" title=""show questions tagged &#39;weak-ai&#39;"" rel=""tag"">weak-ai</a></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/history"" class=""post-tag"" title=""show questions tagged &#39;history&#39;"" rel=""tag"">history</a> (history of AI)

<ul>
<li><a href=""https://ai.stackexchange.com/questions/tagged/ai-winter"" class=""post-tag"" title=""show questions tagged &#39;ai-winter&#39;"" rel=""tag"">ai-winter</a></li>
</ul></li>
</ul>

<p>For completeness, maybe we should also list the topics that are on-topic both here and on the other sites.</p>

<ul>
<li><a href=""https://ai.stackexchange.com/questions/tagged/machine-learning"" class=""post-tag"" title=""show questions tagged &#39;machine-learning&#39;"" rel=""tag"">machine-learning</a> (on topic at CrossValidated and Data Science SE)

<ul>
<li><a href=""https://ai.stackexchange.com/questions/tagged/deep-learning"" class=""post-tag"" title=""show questions tagged &#39;deep-learning&#39;"" rel=""tag"">deep-learning</a> and <a href=""https://ai.stackexchange.com/questions/tagged/neural-networks"" class=""post-tag"" title=""show questions tagged &#39;neural-networks&#39;"" rel=""tag"">neural-networks</a></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/reinforcement-learning"" class=""post-tag"" title=""show questions tagged &#39;reinforcement-learning&#39;"" rel=""tag"">reinforcement-learning</a></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/evolutionary-algorithms"" class=""post-tag"" title=""show questions tagged &#39;evolutionary-algorithms&#39;"" rel=""tag"">evolutionary-algorithms</a></li>
</ul></li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/philosophy"" class=""post-tag"" title=""show questions tagged &#39;philosophy&#39;"" rel=""tag"">philosophy</a> (on topic at <a href=""https://philosophy.stackexchange.com"">Philosophy SE</a>)</li>
<li><a href=""https://ai.stackexchange.com/questions/tagged/search"" class=""post-tag"" title=""show questions tagged &#39;search&#39;"" rel=""tag"">search</a> (on topic at <a href=""https://cs.stackexchange.com"">Computer Science SE</a> and maybe Data Science SE)</li>
</ul>

<p>Feel free to add more topics and goals that distinguish (or not) us from especially CrossValidated and Data Science.</p>
",AImeta,topics website highly overlap topics crossvalidated data science also topics stack overflow fact even currently 145 questions barely philosophical questions 169 differences site crossvalidated data science seem focus users background certain topics think new growing website like attractive certain people including may represent opportunity show abilities others maybe rule website websites like crossvalidated already many established users may difficult really make sense separate websites especially crossvalidated data science small differences may happen users one sites may able properly answer question website users related sites may able answer question cases asker may receive help theory available directly accessible order understand website deserves live think need enumerate topics goals website really differentiate us websites maybe really focus topics differentiate us websites think topics preliminary list topics using tags emphasize topic referring topics synonym maybe also topic given tag history ai completeness maybe also list topics topic sites topic crossvalidated data science se topic topic maybe data science se feel free add topics goals distinguish us especially crossvalidated data science
1,"<p>AI has always been an interdisciplinary field. It therefore should not surprise us that AI.SE's content overlaps with that of other established stacks. I think this is essentially okay.</p>
<p>Perhaps as an analogy: The SoftwareEngineering.SE allows programming questions, but not of the same flavor as the StackOverflow main site. If you want to know <em>how to do X in language Y</em>, you visit StackOverflow. If you want to know <em>whether to do X using language Y</em>, you are better off asking on SoftwareEngineering.SE</p>
<p>If you want to know <em>how</em> to train a deep neural network in Python, you should visit DataScience.SE. If you want to know <em>whether</em> to train a deep neural network in Python (or, use any of the other various approaches in AI), you should visit AI.SE.</p>
<p>I think this means that a tag-based approach is the wrong one. We are likely to have questions that are about, say, statistical learning theory. This is part of AI. It is <em>maybe</em> part of Data Science, but I'd say it's a stretch. It is <em>maybe</em> part of statistics, but certainly not conventional statistics. It is definitely part of AI, and has been a core part for decades. Nonetheless, it encapsulates topics like support vector machines that <em>are</em> widely used in Data Science. We, therefore, oughtn't to outlaw the SVM tag. I think the same kind of argument can be used for most or all duplicate tags.</p>
<p>I'm especially concerned to see the <code>machine-learning</code> tag highlighted in the duplicates. Modern AI without machine learning is... not much.</p>
<p>I think if we focused only on the tags that are not present on other websites, we will not be able to claim to be about AI, and the site would (and perhaps should) then cease to exist. I think we'll do much better if we instead focus on claiming the <em>why</em> space.</p>
",AImeta,ai always interdisciplinary field therefore surprise us aise content overlaps established stacks think essentially okay perhaps analogy softwareengineeringse allows programming questions flavor stackoverflow main site want know x language visit stackoverflow want know whether x using language better asking softwareengineeringse want know train deep neural network python visit datasciencese want know whether train deep neural network python use various approaches ai visit aise think means tag based approach wrong one likely questions say statistical learning theory part ai maybe part data science would say stretch maybe part statistics certainly conventional statistics definitely part ai core part decades nonetheless encapsulates topics like support vector machines widely used data science therefore ought outlaw svm tag think kind argument used duplicate tags especially concerned see tag highlighted duplicates modern ai without machine learning much think focused tags present websites able claim ai site would perhaps cease exist think much better instead focus claiming space
1,"<p>As some have noticed, recently I haven't been able to spend as much time on AI.SE as I did earlier in the site's life. A lot has changed since then; our site specifically has grown and improved a lot. Originally I offered my services as an experienced user of the Stack Exchange network, but now that we are an established site it is much more desirable to have moderators with more subject matter experience.</p>

<p>I therefore believe it's time for a more active and knowledgeable contributor to take my place. A month ago, I notified the other two moderators of my intention to step down. I submitted the official notice to Stack Exchange on October 11 and will retire from moderation on November 12.</p>

<p>Some exciting news has come from this: a moderator election is being planned for AI.SE! Scheduling and details aren't nailed down yet, but it would likely begin some time in January 2020.</p>

<p>In the meantime, I am certain that the fantastic community and remaining moderators will be able to keep the site functioning smoothly. It has been a pleasure and honor to serve as moderator pro tempore, and I wish you all the best!</p>
",AImeta,noticed recently able spend much time aise earlier site life lot changed since site specifically grown improved lot originally offered services experienced user stack exchange network established site much desirable moderators subject matter experience therefore believe time active knowledgeable contributor take place month ago notified two moderators intention step submitted official notice stack exchange october 11 retire moderation november 12 exciting news come moderator election planned aise scheduling details nailed yet would likely begin time january 2020 meantime certain fantastic community remaining moderators able keep site functioning smoothly pleasure honor serve moderator pro tempore wish best
1,"<p>This community last had moderators appointed in 2017, so it's been a while...  In addition to that, you may have noticed that <a href=""https://ai.meta.stackexchange.com/q/1601/45"">one of the current mods — Ben N — is stepping down from their moderator position</a>.</p>
<p>Since moderators were last appointed in this community, we've started and &quot;graduated&quot; an experiment: and pro-tem moderators <a href=""https://meta.stackexchange.com/q/332180/208518"">are now elected</a>, just like &quot;regular&quot; moderators. As such, to find a replacement for Ben, we're looking at scheduling an election to start somewhere in January 2020. To avoid finding ourselves in a situation where an election would fail due to an insufficient number of candidates, though, I'm posting this to try to assess the community members' willingness to step up and nominate themselves, when the actual election's nomination period starts.</p>
<p>Please leave an answer if you'd be willing to run for a moderator position, should we decide to run an election. Like I mentioned, we're looking at scheduling the nomination period to start some time in January '20.</p>
<p><strong>NOTE:</strong> This is not an official election nomination thread, just a &quot;pulse check&quot; to get a notion of how many people here would be willing to step up, so you don't have to put up your whole election nomination.</p>
",AImeta,community last moderators appointed 2017 addition may noticed since moderators last appointed community started moderators find replacement ben looking scheduling election start somewhere january 2020 avoid finding situation election would fail due insufficient number candidates though posting try assess community members willingness step nominate actual election nomination period starts please leave answer would willing run moderator position decide run election like mentioned looking scheduling nomination period start time january 20 note official election nomination thread get notion many people would willing step put whole election nomination
1,"<p>I'm interested in running for a moderator position.</p>
",AImeta,interested running moderator position
1,"<p>Thank you for writing to us about this. This isn’t our final response here, but in the interest of being transparent and keeping lines of communication open,<strong><em>I myself, have been yearning for this mod - position for a long period of time.</em></strong>
Therefore, with all my interest and the inner driving force, I'm running for this! I should even be hesitated for it. </p>

<p>Thanks once again for being informed. Keep us posted of any updates.</p>
",AImeta,thank writing us nt final response interest transparent keeping lines communication open yearning mod position long period time therefore interest inner driving force running even hesitated thanks informed keep us posted updates
1,"<p>Similarly to the question <a href=""https://ai.meta.stackexchange.com/q/1578/2444"">Do we really need the tag ai-basics?</a>, do we really need the tag <a href=""https://ai.stackexchange.com/questions/tagged/concepts"" class=""post-tag"" title=""show questions tagged &#39;concepts&#39;"" rel=""tag"">concepts</a>?</p>

<p>The current description of the tag is</p>

<blockquote>
  <p>Use for broad questions on the concepts used in AI and implementations. Breakdowns of subfields, methods, and sets of methods, with an emphasis on context and utility.</p>
</blockquote>

<p>I think that the description of the tag is unclear and ambiguous, and the tag seems to be superfluous.</p>

<p>First, (too) broad questions are not suited for Stack Exchange websites. Second, we already have the tag <a href=""https://ai.stackexchange.com/questions/tagged/theory"" class=""post-tag"" title=""show questions tagged &#39;theory&#39;"" rel=""tag"">theory</a> and <a href=""https://ai.stackexchange.com/questions/tagged/implementation"" class=""post-tag"" title=""show questions tagged &#39;implementation&#39;"" rel=""tag"">implementation</a>. Regarding the part <em>Breakdowns of subfields, methods, and sets of methods, with an emphasis on context and utility.</em>, this is really very vague and unclear. Therefore, I suggest the deletion of this tag from the system.</p>
",AImeta,similarly question really need tag current description tag use broad questions concepts used ai implementations breakdowns subfields methods sets methods emphasis context utility think description tag unclear ambiguous tag seems superfluous first broad questions suited stack exchange websites second already tag regarding part breakdowns subfields methods sets methods emphasis context utility really vague unclear therefore suggest deletion tag system
1,"<p>I am happy to run, especially if there is a shortage of candidates, although I think I am not the best candidate for the job.</p>
",AImeta,happy run especially shortage candidates although think best candidate job
1,"<p>I agree we don't require the tag 'concepts'. But a quick Google search shows there is some <a href=""https://www.google.com/amp/s/www.researchgate.net/post/What_are_the_differences_between_conceptual_framework_and_theoretical_framework/amp"" rel=""nofollow noreferrer"">difference</a> between a Conceptual and Theoretical framework. So either the 'concepts' tage need to be redefined, or a new more detailed/self-explanatory tag name needs to be created.</p>

<p>Although, it is debatable whether users will adhere to such narrow difference of definition to sort questions and answers.</p>
",AImeta,agree require tag concepts quick google search shows conceptual theoretical framework either concepts tage need redefined new detailed self explanatory tag name needs created although debatable whether users adhere narrow difference definition sort questions answers
1,"<p>I would be interested in running. Though, I must say that the first two members that came to mind as the top candidates have already stated that they are interested. </p>
",AImeta,would interested running though must say first two members came mind top candidates already stated interested
1,"<p><strong>Summary</strong>: Artificial Intelligence Stack Exchange will begin the nomination stage for <a href=""https://ai.stackexchange.com/election/1"">a special election</a> on <strong>February 17, 2020</strong> to bring in two more moderators.</p>

<p>For full details of the process, see <a href=""https://meta.stackexchange.com/questions/314459/experimenting-with-pro-tempore-elections"">the announcement on Meta Stack Exchange</a>. The timeline:</p>

<ul>
<li><p>Starting on February 17, 2020, users can <a href=""https://ai.stackexchange.com/election/1"">nominate themselves</a>. Users can also ask questions on meta for potential moderators to answer. (Use the <a href=""/questions/tagged/discussion"" class=""post-tag required-tag"" title=""show questions tagged &#39;discussion&#39;"" rel=""tag"">discussion</a> and <a href=""/questions/tagged/election"" class=""post-tag"" title=""show questions tagged &#39;election&#39;"" rel=""tag"">election</a> tags.)</p></li>
<li><p>On February 24, 2020, if there are three or more candidates, we'll run an election. If not, I'll simply appoint the candidates. (There's a small chance we'll need to <a href=""https://meta.stackexchange.com/questions/274114/lets-disallow-nominations-from-people-whove-been-suspended-in-the-past-year"">remove a nomination</a>, but I doubt that will come up.)</p></li>
<li><p>If there is an election, I'll announce the results on meta on March 3, 2020. </p></li>
</ul>

<p>(Note for current moderators: there's no need to nominate yourself even though you'll likely get an email saying you should. The system assumes the first election is a graduation election, which would mean moderators would need to be re-elected. This isn't that sort of election.)</p>

<p>If you have any questions about the process, please stick them in an answer here.</p>

<hr>

<blockquote>
  <p><strong>Note:</strong> The election date was pushed back a month, due to some ongoing back-end work on the election mechanics, in order to automate some steps.</p>
</blockquote>
",AImeta,summary artificial intelligence stack exchange begin nomination stage february 17 2020 bring two moderators full details process see timeline starting february 17 2020 users users also ask questions meta potential moderators answer use tags february 24 2020 three candidates run election simply appoint candidates small chance need doubt come election announce results meta march 3 2020 note current moderators need nominate even though likely get email saying system assumes first election graduation election would mean moderators would need elected sort election questions process please stick answer note election date pushed back month due ongoing back end work election mechanics order automate steps
1,"<p>The question <a href=""https://ai.stackexchange.com/q/16525/2444"">What kind of hardware and software are required to build an AI system?</a> asks for hardware recommendations. However, there exists already a site, namely <a href=""https://hardwarerecs.stackexchange.com"">https://hardwarerecs.stackexchange.com</a>, for this specific purpose. The following question <a href=""https://ai.stackexchange.com/q/16538/2444"">What is the reason AMD Radeon is not widely used for machine learning and deep learning?</a> should also be probably closed as off-topic, for a similar reason.</p>

<p>Currently, our on-topic page does not apparently say that hardware-related questions are on-topic. We even have the tags <a href=""https://ai.stackexchange.com/questions/tagged/hardware"" class=""post-tag"" title=""show questions tagged &#39;hardware&#39;"" rel=""tag"">hardware</a> and <a href=""https://ai.stackexchange.com/questions/tagged/hardware-evaluation"" class=""post-tag"" title=""show questions tagged &#39;hardware-evaluation&#39;"" rel=""tag"">hardware-evaluation</a>, which probably should not even exist. All hardware-related questions should be implementation-related questions, so they should be off-optic here.</p>
",AImeta,question asks hardware recommendations however exists already site namely specific purpose following question also probably closed topic similar reason currently topic page apparently say hardware related questions topic even tags probably even exist hardware related questions implementation related questions optic
1,"<p>Several months ago I posted this: <a href=""https://ai.meta.stackexchange.com/q/1506/2444"">On-topic and off-topic pages need to be clarified</a>, which has <strong>NOT</strong> yet been addressed. In the past, there have been other similar posts, for example </p>

<ul>
<li><a href=""https://ai.meta.stackexchange.com/q/1252/2444"">What topics can I ask about here?</a></li>
<li><strong><a href=""https://ai.meta.stackexchange.com/q/1141/2444"">A friendly reminder that this site comes from the Science category</a></strong></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1197/2444"">How can we quickly describe our site?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1430/2444"">What should the AI.SE Site Description be?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1291/2444"">The description of the site seems incorrect</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1356/2444"">Is it time to modify our site guidelines?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1081/2444"">What kind of implementation questions should be off-topic?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1215/2444"">How to distinguish between &#39;programming&#39; and &#39;conceptual&#39; questions?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1559/2444"">Why aren&#39;t implementation based questions welcome on this stack?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1287/2444"">What is in scope under the &quot;implementation of machine learning&quot; exclusion?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1139/2444"">Can questions of programming AI/NN frameworks be on-topic?</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/1279/2444"">Technical questions are not getting closed</a></li>
<li><a href=""https://ai.meta.stackexchange.com/q/15/2444"">Do we want easy technical questions?</a></li>
</ul>

<p>Who writes the on-topic and off-topic pages? Can moderators change the on-topic and off-topic pages? If yes, why haven't they taken action? Who actually decides the content of the on-topic and off-topic pages?</p>
",AImeta,several months ago posted yet addressed past similar posts example writes topic topic pages moderators change topic topic pages yes taken action actually decides content topic topic pages
1,"<p>I think it would be useful to allow questions on hardware, since we're the general AI forum, and this is relevant.  </p>

<p>(In other words, it's better to have AI-specific hardware questions asked here, b/c other AI developers will likely have similar questions &amp; issues.)</p>

<p>In the past we have had questions about the type of hardware various algorithms that have reached AI milestones have used.  </p>

<p>It's important to understand the relationship of hardware to software in that strong Machine Learning was only possible once there was sufficient memory and processing power.</p>

<hr>

<p><a href=""https://ai.stackexchange.com/questions/tagged/hardware-evaluation"">https://ai.stackexchange.com/questions/tagged/hardware-evaluation</a></p>
",AImeta,think would useful allow questions hardware since general ai forum relevant words better ai specific hardware questions asked b c ai developers likely similar questions issues past questions type hardware various algorithms reached ai milestones used important understand relationship hardware software strong machine learning possible sufficient memory processing power
1,"<blockquote>
  <p>since we're the general AI forum</p>
</blockquote>

<p>We are not a general AI forum. This forum supposedly exists to fill a certain gap. As stated <a href=""https://ai.meta.stackexchange.com/a/1144/2444"">in this answer</a></p>

<blockquote>
  <p>It's because the OPPOSITION against creating this site argued (<strong>correctly</strong>) that we already created sites to handle this subject explicitly. The argument FOR creating this site claimed that we have a missing socio-scientific angle that needed filling.</p>
</blockquote>

<p>I believe that ALL implementation questions, such as ""Can you explain the parameters of this ML program?"", ""Why isn't my ML program working?"" or ""How do you implement this model?"", are OFF-TOPIC. They would be on-topic, if we merged this site with Data Science (aka applied machine learning). Similarly, there are already sites for <a href=""https://hardwarerecs.stackexchange.com"">hardware</a> and <a href=""https://softwarerecs.stackexchange.com"">software</a> (which already has the tag <a href=""https://softwarerecs.stackexchange.com/questions/tagged/artificial-intelligence"">ai</a>) recommendations. There is absolutely no need for duplicating services, which are available somewhere else. </p>

<p>Therefore, I strongly suggest we focus on the social, scientific and theoretical aspects of AI, otherwise, we'd better just merge this website with other websites. Do we want to have a website that 95% overlaps with another website only because people disagree on the meaning of the expressions ""artificial intelligence"" (or ""machine learning"") and ""data science""? There are so many theoretical questions that have not yet been asked. For example, there could be a lot of questions on <a href=""https://ai.stackexchange.com/questions/tagged/aixi"">AIXI</a>, which is a highly mathematical and theoretical topic (that is, a perfect topic for this site), which is not easily understandable, so I would expect a lot more questions, but we only have 2 questions. </p>

<p>Unfortunately, this website has already taken the wrong direction, IMHO. We already have a bunch of implementation, hardware, and software-related questions, which is partially due to the fact that the community and moderators do not take action with respect to the original goals of the site, which has become quite redundant.</p>

<p>However, there are also topics on other sites that would be better suited for this site, such as reinforcement learning on Stats. To conclude, apparently, there is a lot of duplication of services across sites. <strong>Maybe there should be a way of migrating even old questions from one website to the other, as a way of organizing better the communities</strong>. For example, there are a lot of theoretical ML questions on Stack Overflow, which could be migrated to this site or Stats.</p>
",AImeta,since general ai forum general ai forum forum supposedly exists fill certain gap stated opposition creating site argued correctly already created sites handle subject explicitly argument creating site claimed missing socio scientific angle needed filling believe implementation questions explain parameters ml program ml program working implement model topic would topic merged site data science aka applied machine learning similarly already sites already tag recommendations absolutely need duplicating services available somewhere else therefore strongly suggest focus social scientific theoretical aspects ai otherwise would better merge website websites want website 95 overlaps another website people disagree meaning expressions artificial intelligence machine learning data science many theoretical questions yet asked example could lot questions highly mathematical theoretical topic perfect topic site easily understandable would expect lot questions 2 questions unfortunately website already taken wrong direction imho already bunch implementation hardware software related questions partially due fact community moderators take action respect original goals site become quite redundant however also topics sites would better suited site reinforcement learning stats conclude apparently lot duplication services across sites maybe way migrating even old questions one website way organizing better communities example lot theoretical ml questions stack overflow could migrated site stats
1,"<p>We had done a consensus-based edit last year: <a href=""https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be"">What should the AI.SE Site Description be?</a>.</p>
<p>(Essentially, a bunch of active users contributed to the thread, and then the edits were made by the active mods.  Although I was hoping for more people to participate, we had to go with the input and consensus we had at the time.)</p>
<p>I do think this is something that should be revisited at regular intervals, especially since we are not fully graduated as a stack, and more flexibility in terms of modifying our scope.  (&quot;<a href=""https://www.masslive.com/patriots/2017/11/the_2017_new_england_patriots.html"" rel=""nofollow noreferrer"">Bend don't break</a>&quot; is my motto!)</p>
<p>When we revisit again, I strongly think we should take a cue from the Data Science help page b/c they provide good advice about topic overlap between stacks: <a href=""https://datascience.stackexchange.com/help/on-topic"">https://datascience.stackexchange.com/help/on-topic</a></p>
<p>I also personally think we should expand our scope to reference</p>
<ul>
<li><p>Journalism (coverage of AI in the press per public perception and fact checking)</p>
</li>
<li><p>History of AI</p>
</li>
<li><p>Mythology of AI (portrayals of AI in popular media which informs public perception)</p>
<p>and hold a referendum on other topics that contributors have chosen to answer over here, per the DS recommendation to &quot;ask on the stack with the most users.&quot;</p>
</li>
</ul>
",AImeta,done consensus based edit last year essentially bunch active users contributed thread edits made active mods although hoping people participate go input consensus time think something revisited regular intervals especially since fully graduated stack flexibility terms modifying scope motto revisit strongly think take cue data science help page b c provide good advice topic overlap stacks also personally think expand scope reference journalism coverage ai press per public perception fact checking history ai mythology ai portrayals ai popular media informs public perception hold referendum topics contributors chosen answer per ds recommendation
1,"<p>Similarly to <a href=""https://ai.meta.stackexchange.com/q/1430/2444"">What should the AI.SE Site Description be?</a> and after the discussions <a href=""https://ai.meta.stackexchange.com/q/1506/2444"">On-topic and off-topic pages need to be clarified</a> and <a href=""https://ai.meta.stackexchange.com/q/1611/2444"">Who decides and writes the on-topic and off-topic pages?</a>, I think it is time to vote for a clearer and updated version of the on-topic page, which users (but especially moderators) should <strong>strictly</strong> adhere to.</p>

<p><em>You should vote for the answer that proposes the best alternative to the current on-topic page. You can also propose a new on-topic page, if you are not happy with the current proposals.</em></p>

<p>After a reasonable consensus is reached, the moderators should update the site descriptions to match the top voted answer.</p>
",AImeta,similarly discussions think time vote clearer updated version topic page users especially moderators strictly adhere vote answer proposes best alternative current topic page also propose new topic page happy current proposals reasonable consensus reached moderators update site descriptions match top voted answer
1,"<h2>What topics can I ask about here?</h2>

<p>If you have a question about <strong>theoretical, philosophical, social, historical</strong>, and certain <strong>developmental</strong> and <strong>academic</strong> aspects of artificial intelligence, then you are <em>probably</em> in the right place to ask your question!</p>

<p>Below you can find a <em>non-exhaustive</em> list of specific topics that are considered on-topic here. Next to each topic, you have links to other stacks where the corresponding topics may also be on-topic.</p>

<h3>Specific topics</h3>

<p>You can ask a question about the <strong>theoretical</strong> aspects of the following sub-fields of artificial intelligence. </p>

<ul>
<li>Artificial general intelligence</li>
<li>Affective computing</li>
<li>Swarm intelligence</li>
<li>Evolutionary algorithms (<a href=""https://stats.stackexchange.com/help/on-topic"">1</a>, <a href=""https://stackoverflow.com/help/on-topic"">4</a>, <a href=""https://cs.stackexchange.com/help/on-topic"">6</a>)</li>
<li>Machine learning (<a href=""https://stats.stackexchange.com/help/on-topic"">1</a>, <a href=""https://datascience.stackexchange.com/help/on-topic"">2</a>, <a href=""https://stackoverflow.com/help/on-topic"">4</a>, <a href=""https://cs.stackexchange.com/help/on-topic"">6</a>)</li>
<li>Computational learning theory (<a href=""https://stats.stackexchange.com/help/on-topic"">1</a>, <a href=""https://cs.stackexchange.com/help/on-topic"">6</a>, <a href=""https://cstheory.stackexchange.com/help/on-topic"">7</a>)</li>
<li>Natural language processing and understanding (<a href=""https://cs.stackexchange.com/help/on-topic"">6</a>)</li>
<li>Computer vision (<a href=""https://stats.stackexchange.com/help/on-topic"">1</a>, <a href=""https://datascience.stackexchange.com/help/on-topic"">2</a>, <a href=""https://stackoverflow.com/help/on-topic"">4</a>, <a href=""https://cs.stackexchange.com/help/on-topic"">6</a>, <a href=""https://dsp.stackexchange.com/help/on-topic"">10</a>)</li>
<li>Knowledge representation and reasoning  (<a href=""https://cs.stackexchange.com/help/on-topic"">6</a>)</li>
<li>Robotics (<a href=""https://robotics.stackexchange.com/help/on-topic"">5</a>)</li>
<li>Planning (<a href=""https://cs.stackexchange.com/help/on-topic"">6</a>)</li>
</ul>

<p>The following <strong>philosophical</strong> (or theoretical) aspects are on-topic.</p>

<ul>
<li>Intelligence definitions and testing</li>
<li>Superintelligence</li>
<li>Emotional intelligence</li>
<li>Artificial consciousness</li>
</ul>

<p>The following <strong>social</strong> aspects are on-topic.</p>

<ul>
<li>Ethics (<a href=""https://philosophy.stackexchange.com/help/on-topic"">3</a>)</li>
<li>Explainable artificial intelligence</li>
<li>Applications</li>
</ul>

<p>The following <strong>historical</strong> aspects are on-topic.</p>

<ul>
<li>Timeline (e.g. AI winters)</li>
<li>Progress</li>
</ul>

<p>You can also ask questions about</p>

<ul>
<li>Terminology and notation</li>
<li>Proofs (<a href=""https://math.stackexchange.com/help/on-topic"">8</a>)</li>
<li>Clarifications of certain excerpts from papers, books, etc.</li>
<li>Reference requests (e.g. ""Which paper introduced vanilla RNNs?"")</li>
</ul>

<h3>Notes</h3>

<ul>
<li><p>Before posting, please, <strong>look around to see if your question has been asked before</strong>. Your question could be closed as a duplicate of another, if you don't do it.</p></li>
<li><p>You should <strong>put some effort into writing your question</strong>. If your question is unclear, it could be flagged as unclear, your question could be closed, and you will not receive help. Furthermore, we expect users to do a little bit of research before asking a question.</p></li>
<li><p><strong>Ask specific questions</strong>! If your question has potentially many answers, your question may be closed as too broad.</p></li>
<li><p><a href=""https://meta.stackexchange.com/a/39224/287113""><strong>You should try asking one question or address a single problem per post</strong></a>, unless the questions are really very related to each other. If you ask multiple questions per post, your post may be closed as too broad.</p></li>
<li><p>Ideally, we are looking for <strong>questions that can be answered objectively</strong>. More precisely, do not ask for advice (such as career path recommendation or a tool, which are, in general, <strong>off-topic</strong> here anyway) but for facts (including references) and arguments. If you have a philosophical question, you should demand a logical, rational and reasonable answer that argues the philosophical perspective (and not just an opinion).</p></li>
<li><p><strong>Implementation questions in the context of understanding the theoretical topics are on-topic</strong>. For example, if a theoretical topic is described by a certain mathematical formula and you want to understand how a certain implementation is related to the formula, then your question is on-topic. As a rule of thumb, if you can describe your problem without the source code and if you think that a solution to your problem can be given without the source code, then your question is on-topic. The source code can be provided to further clarify the issue, but you should provide a <a href=""https://stackoverflow.com/help/minimal-reproducible-example"">Minimal, Reproducible Example</a>.</p></li>
<li><p><strong>General programming questions are off-topic</strong>. For example, if you have a question like ""Why am I getting this exception?"", ""How do I merge two Pandas' data frames?"" or ""How can I use this Keras API?"", then your question is off-topic (and you should probably ask it on <a href=""https://stackoverflow.com/help/on-topic"">Stack Overflow</a>).</p></li>
<li><p>It's also OK to ask and answer your own question.</p></li>
</ul>

<h3>Overlapping Stacks</h3>

<p>If your question is not specifically on-topic for Artificial Intelligence Stack Exchange, it may be on-topic for another Stack Exchange site, such as </p>

<ol>
<li><a href=""https://stats.stackexchange.com/help/on-topic"">Cross Validated</a></li>
<li><a href=""https://datascience.stackexchange.com/help/on-topic"">Data Science</a></li>
<li><a href=""https://philosophy.stackexchange.com/help/on-topic"">Philosophy</a></li>
<li><a href=""https://stackoverflow.com/help/on-topic"">Stack Overflow</a></li>
<li><a href=""https://robotics.stackexchange.com/help/on-topic"">Robotics</a></li>
<li><a href=""https://cs.stackexchange.com/help/on-topic"">Computer Science</a></li>
<li><a href=""https://cstheory.stackexchange.com/help/on-topic"">Theoretical Computer Science</a></li>
<li><a href=""https://math.stackexchange.com/help/on-topic"">Mathematics</a></li>
<li><a href=""https://psychology.stackexchange.com/"">Psychology &amp; Neuroscience</a></li>
<li><a href=""https://dsp.stackexchange.com/help/on-topic"">Signal Processing</a></li>
</ol>

<p>Certain questions are probably on-topic on multiple of these websites. For example, machine learning questions are also on-topic at <a href=""https://stats.stackexchange.com/help/on-topic"">Cross Validated</a>, which is more statistics-oriented. There are probably other overlapping sites.</p>

<p>If no site currently exists that will accept your question, you may commit to or propose a new site at <a href=""https://area51.stackexchange.com"">Area 51</a>, the place where new Stack Exchange communities are democratically created.</p>
",AImeta,topics ask question theoretical philosophical social historical certain developmental academic aspects artificial intelligence probably right place ask question find non exhaustive list specific topics considered topic next topic links stacks corresponding topics may also topic specific topics ask question theoretical aspects following sub fields artificial intelligence artificial general intelligence affective computing swarm intelligence evolutionary algorithms machine learning computational learning theory natural language processing understanding computer vision knowledge representation reasoning robotics planning following philosophical theoretical aspects topic intelligence definitions testing superintelligence emotional intelligence artificial consciousness following social aspects topic ethics explainable artificial intelligence applications following historical aspects topic timeline eg ai winters progress also ask questions terminology notation proofs clarifications certain excerpts papers books etc reference requests eg paper introduced vanilla rnns notes posting please look around see question asked question could closed duplicate another put effort writing question question unclear could flagged unclear question could closed receive help furthermore expect users little bit research asking question ask specific questions question potentially many answers question may closed broad unless questions really related ask multiple questions per post post may closed broad ideally looking questions answered objectively precisely ask advice career path recommendation tool general topic anyway facts including references arguments philosophical question demand logical rational reasonable answer argues philosophical perspective opinion implementation questions context understanding theoretical topics topic example theoretical topic described certain mathematical formula want understand certain implementation related formula question topic rule thumb describe problem without source code think solution problem given without source code question topic source code provided clarify issue provide general programming questions topic example question like getting exception merge two pandas data frames use keras api question topic probably ask also ok ask answer question overlapping stacks question specifically topic artificial intelligence stack exchange may topic another stack exchange site certain questions probably topic multiple websites example machine learning questions also topic statistics oriented probably overlapping sites site currently exists accept question may commit propose new site place new stack exchange communities democratically created
1,"<p>I adjusted <a href=""https://ai.meta.stackexchange.com/a/1616/2444"">@nbro's answer</a> to remove the parts I thought were too restrictive. AI is a broad field, and the whitelist of ""on-topic"" areas omits a huge number of topics which are certainly within AI (consider, for contrast, <a href=""https://aaai.org/Conferences/AAAI-19/aaai19keywords/"" rel=""nofollow noreferrer"">the topics</a> that are present at AAAI this year alone, all of which are active areas of research). I think that the entry under the ""What topics can I ask about here?"" is specific enough. If we want to use a list of valid topics, we should formulate it by starting with actual active areas of research for the field, perhaps by amalgamating the keywords and topics that are present at AAAI, NIPS, UAI, IJCAI, AAMAS, CEC, and other major conferences. I suspect that's a lot more work than it's worth however.</p>

<p>I also adjusted the wording of the programming portion to better reflect the idea that programming questions are fundamentally <em>on-topic</em> here, as long as they are about AI algorithms or implementations, and not applications. I think that without this, the stack is going to lack a connection to academic AI, and will descend into a sort of futurism/singularity board. We want to encourage more programming related content, not less, but only of the kind that actually relates to AI.</p>

<h2>What topics can I ask about here?</h2>

<p>If you have a question about <strong>theoretical, philosophical, historical, social</strong> and <strong>algorithmic</strong> or <strong>academic</strong> aspects of AI, then you are <em>probably</em> in the right place to ask your question! </p>

<h3>Notes</h3>

<ul>
<li><p>Before posting, please, <strong>look around to see if your question has been asked before</strong>. Your question could be closed as a duplicate of another, if you don't do it.</p></li>
<li><p>You should <strong>put some effort into writing your question</strong>. If your question is unclear, it could be flagged as unclear, your question could be closed, and you will not receive help. Furthermore, we expect users to do a little bit of research before asking a question.</p></li>
<li><p><strong>Ask specific questions</strong>! If your question has potentially many answers, your question may be closed as too broad.</p></li>
<li><p><a href=""https://meta.stackexchange.com/a/39224/287113""><strong>You should try asking one question per post</strong></a>, unless the questions are really very related to each other. If you ask multiple questions per post, your post may be closed as too broad.</p></li>
<li><p>Ideally, we are looking for <strong>questions that can be answered objectively</strong>. More precisely, do not ask for advice (such as career path recommendation or a preferred tool, which are, in general, <strong>off-topic</strong> here anyway) but for facts (including references) and arguments. If you have a philosophical question, you should demand a logical, rational and reasonable answer that argues the philosophical perspective (and not just an opinion).</p></li>
<li><p>It's also OK to ask and answer your own question.</p></li>
<li><p>Programming questions about the implementation of AI algorithms, or the source code of implementations of those algorithms, are on-topic. <strong>Programming questions about applying AI tools to specific problems are off-topic</strong>, and probably belong on DataScience.SE, or the main StackOverflow site. If you're looking for a clarification of the implementation of a certain AI concept, then your question is on-topic. For example, if a theoretical topic is described by a certain mathematical formula and you want to understand the implementation of this formula, then your question is on-topic. However, if you have a question like ""Why am I getting this exception?"", ""How do I merge two Pandas' data frames?"", or ""How can I use Tensorflow to train a neural network to recognize cats?"" then your question is off-topic (and you should probably ask it on <a href=""https://stackoverflow.com/help/on-topic"">Stack Overflow</a>).</p></li>
</ul>

<h2>Similar websites</h2>

<p>If your question is not on-topic for Artificial Intelligence Stack Exchange, it may be on-topic for another Stack Exchange site, such as </p>

<ul>
<li><a href=""https://datascience.stackexchange.com/help/on-topic"">Data Science</a></li>
<li><a href=""https://stats.stackexchange.com/help/on-topic"">Cross Validated</a></li>
<li><a href=""https://stackoverflow.com/help/on-topic"">Stack Overflow</a></li>
<li><a href=""https://robotics.stackexchange.com/help/on-topic"">Robotics</a></li>
<li><a href=""https://cs.stackexchange.com/help/on-topic"">Computer Science</a></li>
<li><a href=""https://philosophy.stackexchange.com/help/on-topic"">Philosophy</a></li>
</ul>

<p>Certain questions are probably on-topic on multiple of these websites. For example, machine learning questions are also on-topic at <a href=""https://stats.stackexchange.com/help/on-topic"">Cross Validated</a>, which is more statistics-oriented.</p>

<p>If no site currently exists that will accept your question, you may commit to or propose a new site at <a href=""https://area51.stackexchange.com"">Area 51</a>, the place where new Stack Exchange communities are democratically created.</p>
",AImeta,adjusted remove parts thought restrictive ai broad field whitelist topic areas omits huge number topics certainly within ai consider contrast present aaai year alone active areas research think entry topics ask specific enough want use list valid topics formulate starting actual active areas research field perhaps amalgamating keywords topics present aaai nips uai ijcai aamas cec major conferences suspect lot work worth however also adjusted wording programming portion better reflect idea programming questions fundamentally topic long ai algorithms implementations applications think without stack going lack connection academic ai descend sort futurism singularity board want encourage programming related content less kind actually relates ai topics ask question theoretical philosophical historical social algorithmic academic aspects ai probably right place ask question notes posting please look around see question asked question could closed duplicate another put effort writing question question unclear could flagged unclear question could closed receive help furthermore expect users little bit research asking question ask specific questions question potentially many answers question may closed broad unless questions really related ask multiple questions per post post may closed broad ideally looking questions answered objectively precisely ask advice career path recommendation preferred tool general topic anyway facts including references arguments philosophical question demand logical rational reasonable answer argues philosophical perspective opinion also ok ask answer question programming questions implementation ai algorithms source code implementations algorithms topic programming questions applying ai tools specific problems topic probably belong datasciencese main stackoverflow site looking clarification implementation certain ai concept question topic example theoretical topic described certain mathematical formula want understand implementation formula question topic however question like getting exception merge two pandas data frames use tensorflow train neural network recognize cats question topic probably ask similar websites question topic artificial intelligence stack exchange may topic another stack exchange site certain questions probably topic multiple websites example machine learning questions also topic statistics oriented site currently exists accept question may commit propose new site place new stack exchange communities democratically created
1,"<p>Some discussions were started in the meta-section which questions are offtopic questions and should be closed next. I have to admit that I'm supporting such attempts because the SE.AI forum has in comparison to other Stackexchange websites a small close-percentage.</p>

<p>It make sense to go a step backward and describe the overall problem. In general, there is no need to delete any questions in a Q&amp;A website because the amount of space on the harddrive is unlimited and if all the postings are archived the amount of information is higher. There is no need to close or delete any questions.</p>

<p>So we have to ask, why close-advocates are motivated to do the opposite? One given reason is, that a certain question was formulated as too broad, is offtopic or is asking not for facts but for opinions. The counter argument to not close such content but left such questions in the database is, that with the search function the user can decide by it's own which kind of knowledge he needs.</p>

<p>To understand what the true reason is, for closing a question, we have to describe in the single step mode what is happen during the close workflow:</p>

<pre><code>timecode 0:00 user is posting a new question to SE.AI
timecode 0:10 the question is flagged by another user
timecode 0:20 the question gets more close votes and is officially closed
timecode 0:30 the initial user who posted the question doesn't understand why his question was marked as offtopic
</code></pre>

<p>Closing a question is equal to produce a conflict between SE.AI and the user who has dropped the initial question. From a pessimistic standpoint, any question can be closed as offtopic. That means, in theory it's possible to argue with any user who sends a request to SE.AI.</p>

<p>Why should a question be closed? Does SE.AI needs the conflict with external users? </p>
",AImeta,discussions started meta section questions offtopic questions closed next admit supporting attempts seai forum comparison stackexchange websites small close percentage make sense go step backward describe overall problem general need delete questions q website amount space harddrive unlimited postings archived amount information higher need close delete questions ask close advocates motivated opposite one given reason certain question formulated broad offtopic asking facts opinions counter argument close content left questions database search function user decide kind knowledge needs understand true reason closing question describe single step mode happen close workflow timecode 000 user posting new question seaitimecode 010 question flagged another usertimecode 020 question gets close votes officially closedtimecode 030 initial user posted question understand question marked offtopic closing question equal produce conflict seai user dropped initial question pessimistic standpoint question closed offtopic means theory possible argue user sends request seai question closed seai needs conflict external users
1,"<blockquote>
<p>It make sense to go a step backward and describe the overall problem. In general, there is no need to delete any questions in a Q&amp;A website because the amount of space on the harddrive is unlimited and if all the postings are archived the amount of information is higher. There is no need to close or delete any questions.</p>
</blockquote>
<p>I do not agree. If the question (or answer) looks like spam or will not be useful (or will even be harmful), it can (and should) be deleted.</p>
<blockquote>
<p>Closing a question is equal to produce a conflict between SE.AI and the user who has dropped the initial question.</p>
<p>Why should a question be closed?</p>
</blockquote>
<p>Closed questions can still be upvoted (or downvoted). We close questions to avoid receiving poor answers. If a question will lead to primarily opinion-based answers, then it is unlikely those opinions will be useful. If a post is too broad (it asks too many questions, asks you to give an answer that requires ages to be written, etc.), then it should be closed, because SE is not meant for these questions. We are volunteers, so we ideally want questions that can be unambiguously and quickly answered. If a question is off-topic, it should obviously be closed. We should have a goal, even though many users, including moderators, have forgotten the goal or behave as if they have forgotten it.</p>
<p>We should be nice with new users and briefly describe the rules and goals of the site, by showing them the on-topic and off-topic pages, etc. If the users (even new ones) do not want to collaborate, then there is no excuse not to close a question when it obviously requires to be closed.</p>
<p>A question should be closed when</p>
<ol>
<li><p>It is off-topic (according to the on-topic and off-topic pages and <strong>NOT</strong> according to you or your personal beliefs)</p>
</li>
<li><p>It asks more than 1 question. For example, &quot;I am new to this field. How does machine learning work, and what are the subfields of machine learning, and what are the applications of machine learning?&quot;.</p>
</li>
<li><p>It asks one question that cannot be answered within a reasonable amount of time (10-15 minutes). For example, a question like &quot;Can you explain to me this paper?&quot;.</p>
</li>
<li><p>It is unclear what the user is asking.</p>
</li>
<li><p>It will lead to opinions. For example, &quot;What do you think about the transformer architecture? Is it useful?&quot;. As a rule of thumb, if you see words like &quot;best&quot;, &quot;better&quot;, &quot;useful&quot;, &quot;useless&quot;, &quot;advice&quot;, &quot;suggestion&quot;, or sentences like &quot;What do you think...?&quot;, then there is a high chance the question will lead to opinions.</p>
</li>
</ol>
",AImeta,make sense go step backward describe overall problem general need delete questions q website amount space harddrive unlimited postings archived amount information higher need close delete questions agree question answer looks like spam useful even harmful deleted closing question equal produce conflict seai user dropped initial question question closed closed questions still upvoted downvoted close questions avoid receiving poor answers question lead primarily opinion based answers unlikely opinions useful post broad asks many questions asks give answer requires ages written etc closed se meant questions volunteers ideally want questions unambiguously quickly answered question topic obviously closed goal even though many users including moderators forgotten goal behave forgotten nice new users briefly describe rules goals site showing topic topic pages etc users even new ones want collaborate excuse close question obviously requires closed question closed topic according topic topic pages according personal beliefs asks 1 question example asks one question answered within reasonable amount time 10 15 minutes example question like unclear user asking lead opinions example high chance question lead opinions
1,"<p>I like all of the suggestions in general, and think it's now just a matter of hammering out details, and dealing with the competing concerns of brevity vs. extrapolation.</p>
<p><strong>I think we should lift some of the the guidance from Data Science re: Overlap</strong></p>
<blockquote>
<p>Even though the boundaries are not always perfectly clear and we often accept questions that are also appropriate on other sites, here are a few guiding thoughts:</p>
<p>If you think a question is equally appropriate on multiple sites, ask on the site with the most users (usually Stack Overflow or Data Science). That way you have the best chance to get good and quick answers and site contents will stay more coherent. If it is not accepted there, it can be migrated to the correct site. Don't post your questions on more than one site.</p>
<p>Other relevant sites include:</p>
<p>Open Data (Dataset requests)
Computational Science (Software packages and algorithms in applied mathematics)
etc.</p>
</blockquote>
",AImeta,like suggestions general think matter hammering details dealing competing concerns brevity vs extrapolation think lift guidance data science overlap even though boundaries always perfectly clear often accept questions also appropriate sites guiding thoughts think question equally appropriate multiple sites ask site users usually stack overflow data science way best chance get good quick answers site contents stay coherent accepted migrated correct site post questions one site relevant sites include open data dataset requestscomputational science software packages algorithms applied mathematicsetc
1,"<blockquote>
<p>Does it really make sense to have all these separate websites (especially, CrossValidated, Data Science and ours), only because of these small differences</p>
</blockquote>
<p>No, it doesn't make any sense, because whatever people are saying on meta, in practice if you look at the questions posted on AI.SE, over 90% of them are on-topic on CrossValidated and Data Science. This creates plenty of crossnetwork question duplicates, which personally kills my motivation to participate.</p>
",AImeta,really make sense separate websites especially crossvalidated data science small differences make sense whatever people saying meta practice look questions posted aise 90 topic crossvalidated data science creates plenty crossnetwork question duplicates personally kills motivation participate
1,"<p>In addition to closing poor questions, the issue of deletion of extremely poor answers has been raised, so I'm posting to solicit a conversation on guidelines for deleting answers.</p>

<p><strong>1. Off-topic answers</strong></p>

<p>This refers to answers that do not address the question.  (Exceptions would be answers that present relevant, corollary information that broadens understanding of the topic.)</p>

<p><strong>2. Disinformation</strong> </p>

<p>Unlike <a href=""https://en.wikipedia.org/wiki/Misinformation"" rel=""nofollow noreferrer"">misinformation</a>, which arises from genuine lack of understanding, <a href=""https://en.wikipedia.org/wiki/Disinformation"" rel=""nofollow noreferrer"">disinformation</a> is intentional and malicious. (The remedy for misinformation is downvoting; for disinformation the remedy is deletion.)</p>

<p><strong>3. Spam</strong></p>

<p>Using an answer to promote a product.  Also includes links to web resources not related to the subject of the question, or a relevant corollary subject.  </p>

<p><strong>4. Code of conduct violations</strong></p>

<p>Goes without saying.  Includes answers that are inflammatory, rude, contain profanity, or which target individuals who are not public figures.  </p>

<hr>

<p><strong>Bans</strong></p>

<p>Violations of the code of conduct will also likely result in bans, as the activity is clear cut. </p>

<p>For off-topic, disinformation &amp; spam, which may be less clear in some cases, repeated instances can be grounds for a ban.</p>

<hr>

<p><em>Let me know if I've missed anything, and any other thoughts on these guidelines.</em></p>
",AImeta,addition closing poor questions issue deletion extremely poor answers raised posting solicit conversation guidelines deleting answers 1 topic answers refers answers address question exceptions would answers present relevant corollary information broadens understanding topic 2 disinformation unlike arises genuine lack understanding intentional malicious remedy misinformation downvoting disinformation remedy deletion 3 spam using answer promote product also includes links web resources related subject question relevant corollary subject 4 code conduct violations goes without saying includes answers inflammatory rude contain profanity target individuals public figures bans violations code conduct also likely result bans activity clear cut topic disinformation spam may less clear cases repeated instances grounds ban let know missed anything thoughts guidelines
1,"<ul>
<li><p>We can address futurism (one of the leading drivers of misinformation about AI!) and serve an important function of myth-busting.</p></li>
<li><p>We deal with social impacts in general, which other related stacks don't address.  </p></li>
<li><p>We can take pyschology/cognitive/neuroscience questions related to AI, which may unwelcome on those stacks. </p></li>
<li><p>We can treate AI milestones in general, not just those related to statistical AI.</p></li>
</ul>

<p>re: Philosophy, although we have few questions formally containing that tag, <a href=""https://ai.stackexchange.com/questions?tab=Votes"">a search of the most voted SE:AI questions</a> reveals the subject to be popular and well-treated on this Stack.  (Compare to the <a href=""https://philosophy.stackexchange.com/questions/tagged/artificial-intelligence?tab=Newest"">relative lack of activity for AI questions on SE: Philosophy, especially in recent years</a>.)  SE:Philosophy also lack a ""neoluddism"" tag, which is the more relevant philosophy tag, in that it relates to material effects of AI implementation, including bias.</p>
",AImeta,address futurism one leading drivers misinformation ai serve important function myth busting deal social impacts general related stacks address take pyschology cognitive neuroscience questions related ai may unwelcome stacks treate ai milestones general related statistical ai philosophy although questions formally containing tag reveals subject popular well treated stack compare se philosophy also lack neoluddism tag relevant philosophy tag relates material effects ai implementation including bias
1,"<p>In general, I agree with these guidelines. However, I think that misinformation can also be a good reason for deleting an answer, because (intentionally or not) the answer can be harmful. Moreover, it is not always clear the intentions of the answerer. If a user regularly gives answers with misleading or wrong information, this is an obvious sign that his/her answers need to be deleted and this user can and probably should be banned.</p>
",AImeta,general agree guidelines however think misinformation also good reason deleting answer intentionally answer harmful moreover always clear intentions answerer user regularly gives answers misleading wrong information obvious sign answers need deleted user probably banned
1,"<p>The purpose of this post is to compile lists of exemplary question that can be used to promote SE:AI to the wider AI research and engineering community on the internet.</p>

<p>Stack provides a unique setting for exchange of specific, technical information at a large scale, and in this way is distinct among top social sites. (This is validated in the way adding math formatting allowed the stack to blossom, and has yielded a large number of exemplary answers.) </p>

<p>As an example, hare are some of my favorites:</p>

<p><a href=""https://ai.stackexchange.com/q/14159/1671"">What does the symbol $\mathbb E$ mean in these equations?</a></p>

<p><a href=""https://ai.stackexchange.com/q/6196/1671"">What is the relation between Q-learning and policy gradients methods?</a>  </p>

<p><a href=""https://ai.stackexchange.com/q/6026/1671"">Why is A* optimal if the heuristic function is admissible?</a></p>

<p>For philosophical questions, this recent query has proven fertile ground for a range of valid answers:</p>

<p><a href=""https://ai.stackexchange.com/q/15730/1671"">Can digital computers understand infinity?</a></p>
",AImeta,purpose post compile lists exemplary question used promote se ai wider ai research engineering community internet stack provides unique setting exchange specific technical information large scale way distinct among top social sites validated way adding math formatting allowed stack blossom yielded large number exemplary answers example hare favorites philosophical questions recent query proven fertile ground range valid answers
1,"<p>My sense is that answer that provide a religious perspective can be on-topic for certain issues related to social or philosophical subjects, but do need to be well supported, and ideally should be well referenced.  </p>
",AImeta,sense answer provide religious perspective topic certain issues related social philosophical subjects need well supported ideally well referenced
1,"<p>Here's a non-exhaustive list of my favorite questions and answers, which does not mean they are perfect or cannot be improved.</p>

<h3>Questions</h3>

<ul>
<li><a href=""https://ai.stackexchange.com/q/13261/2444"">Why do we need common sense in AI?</a></li>
<li><a href=""https://ai.stackexchange.com/q/11679/2444"">Why doesn&#39;t Q-learning converge when using function approximation?</a></li>
<li><a href=""https://ai.stackexchange.com/q/13289/2444"">Are neural networks prone to catastrophic forgetting?</a></li>
<li><a href=""https://ai.stackexchange.com/q/12971/2444"">What sort of mathematical problems are there in AI that people are working on?</a></li>
<li><a href=""https://ai.stackexchange.com/q/145/2444"">What is the relevance of AIXI on current artificial intelligence research?</a></li>
<li><a href=""https://ai.stackexchange.com/q/17044/2444"">Why is dropout favoured compared to reducing the number of units in hidden layers?</a></li>
<li><a href=""https://ai.stackexchange.com/q/17670/2444"">How can supervised learning be viewed as a conditional probability of the labels given the inputs?</a></li>
<li><a href=""https://ai.stackexchange.com/q/7416/2444"">Can neural networks be used to prove conjectures?</a></li>
</ul>

<h3>Answers</h3>

<ul>
<li><a href=""https://ai.stackexchange.com/a/17881/2444"">How to estimate the capacity of a neural network?</a></li>
<li><a href=""https://ai.stackexchange.com/a/11133/2444"">What is the Bellman operator in reinforcement learning?</a></li>
<li><a href=""https://ai.stackexchange.com/a/13293/2444"">Are neural networks prone to catastrophic forgetting?</a></li>
<li><a href=""https://ai.stackexchange.com/a/10818/2444"">What is the difference between First-Visit Monte-Carlo and Every-Visit Monte-Carlo Policy Evaluation?</a></li>
<li><a href=""https://ai.stackexchange.com/a/14247/2444"">Why do we need explainable AI?</a></li>
<li><a href=""https://ai.stackexchange.com/a/10377/2444"">What is the relevance of AIXI on current artificial intelligence research?</a></li>
<li><a href=""https://ai.stackexchange.com/a/10624/2444"">What is self-supervised learning in machine learning?</a></li>
<li><a href=""https://ai.stackexchange.com/a/17328/2444"">Why is a softmax used rather than dividing each activation by the sum?</a></li>
<li><a href=""https://ai.stackexchange.com/a/8909/2444"">How is iterative deepening A* better than A*?</a></li>
<li><a href=""https://ai.stackexchange.com/a/11387/2444"">What is artificial intelligence?</a></li>
</ul>

<p>Of course, I am biased towards questions and answers where I am involved, but this does not mean that there aren't many other good questions and answers on this site.</p>
",AImeta,non exhaustive list favorite questions answers mean perfect improved questions answers course biased towards questions answers involved mean many good questions answers site
1,"<p>It's New Year's Day in <a href=""https://en.wikipedia.org/wiki/Zulu_Time"" rel=""nofollow noreferrer"">Stack Exchange land</a>...</p>

<p>A distinguishing characteristic of these sites is how they are moderated:</p>

<blockquote>
  <p>We designed the Stack Exchange network engine to be mostly self-regulating, in that we amortize the overall moderation cost of the system across thousands of teeny-tiny slices of effort contributed by regular, everyday users.<br>
  -- <a href=""http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/"">A Theory of Moderation</a></p>
</blockquote>

<p>While there certainly are <a href=""https://stackoverflow.blog/2018/11/21/our-theory-of-moderation-re-visited/"">Moderators</a> here, a significant amount of the <em>moderation</em> is done by ordinary people, using the privileges 
they've earned by virtue of their contributions to the site. Each of you contributes a little bit of time and effort, and together you accomplish much.</p>

<p>As we enter a new year, let's pause and reflect, taking a moment to appreciate the work that we do here together. 
And what could be more festive than a big pile of numbers? 
So here is a breakdown of moderation actions performed on Artificial Intelligence over the past 12 months:</p>

<pre><code>                 Action                  Moderators Community¹
---------------------------------------- ---------- ----------
Users suspended²                                  3          6
Users destroyed³                                  1          0
Users deleted                                     1          0
Users contacted                                   9          0
Tasks reviewed⁴: Suggested Edit queue           300        604
Tasks reviewed⁴: Reopen Vote queue               17         49
Tasks reviewed⁴: Low Quality Posts queue         65         99
Tasks reviewed⁴: Late Answer queue               64        127
Tasks reviewed⁴: First Post queue               666      1,284
Tasks reviewed⁴: Close Votes queue              684        744
Tags merged                                      14          0
Tag synonyms proposed                             9          0
Tag synonyms created                             10          0
Revisions redacted                                1          0
Questions unprotected                             0          2
Questions reopened                               19          0
Questions protected                               1         38
Questions migrated                               47          0
Questions merged                                  2          0
Questions flagged⁵                                2        534
Questions closed                                215         65
Question flags handled⁵                         273        263
Posts unlocked                                    0         11
Posts undeleted                                  10         45
Posts locked                                      1        101
Posts deleted⁶                                  213        899
Posts bumped                                      0        910
Comments undeleted                                9          0
Comments flagged                                  1      1,362
Comments deleted⁷                             1,567      1,116
Comment flags handled                         1,223        140
Answers flagged                                   4        502
Answer flags handled                            384        122
All comments on a post moved to chat              5          0
</code></pre>

<h3>Footnotes</h3>

<p>¹ ""Community"" here refers both to <a href=""https://ai.stackexchange.com/users"">the membership of Artificial Intelligence</a> <em>without</em> <a href=""https://ai.stackexchange.com/users?tab=moderators"">diamonds next to their names</a>, and to the automated systems otherwise known as <a href=""https://ai.stackexchange.com/users/-1"">user #-1</a>.</p>

<p>² The system will suspend users under three circumstances: when a user is recreated after being previously suspended, when a user is recreated after being destroyed for spam or abuse, and when a network-wide suspension is in effect on an account.</p>

<p>³ A ""destroyed"" user is deleted along with all that they had posted: questions, answers, comments. <a href=""https://meta.stackexchange.com/questions/88994/what-is-the-difference-between-a-deleted-user-and-a-destroyed-user"">Generally used as an expedient way of getting rid of spam.</a></p>

<p>⁴ This counts every review that was submitted (not skipped) - so the 2 suggested edits reviews needed to approve an edit would count as 2, the goal being to indicate the frequency of moderation actions. This also applies to flags, etc.</p>

<p>⁵ Includes close flags (but <em>not</em> close or reopen votes).</p>

<p>⁶ This ignores numerous deletions that happen automatically in response to some other action.</p>

<p>⁷ This includes comments deleted by their own authors (which also account for some number of handled comment flags).   </p>

<h3>Further reading:</h3>

<ul>
<li><p>Wanna see how these numbers have changed over time? I posted a similar report here last year: <a href=""https://ai.meta.stackexchange.com/questions/1483/2018-a-year-in-moderation"">2018: a year in moderation</a>...</p></li>
<li><p>You can also check out <a href=""https://stackexchange.com/search?q=title%3A%222019%3A+a+year+in+moderation%22"">this report on other sites</a></p></li>
<li>Or peruse <a href=""https://meta.stackexchange.com/questions/341507/2019-a-year-in-closing"">detailed information on the number of questions closed and reopened across all sites</a></li>
</ul>

<p>Wishing you all a happy new year...</p>
",AImeta,new year day distinguishing characteristic sites moderated designed stack exchange network engine mostly self regulating amortize overall moderation cost system across thousands teeny tiny slices effort contributed regular everyday users certainly significant amount moderation done ordinary people using privileges earned virtue contributions site contributes little bit time effort together accomplish much enter new year let pause reflect taking moment appreciate work together could festive big pile numbers breakdown moderation actions performed artificial intelligence past 12 months action moderators community¹ users suspended² 3 6users destroyed³ 1 0users deleted 1 0users contacted 9 0tasks reviewed⁴ suggested edit queue 300 604tasks reviewed⁴ reopen vote queue 17 49tasks reviewed⁴ low quality posts queue 65 99tasks reviewed⁴ late answer queue 64 127tasks reviewed⁴ first post queue 666 1284tasks reviewed⁴ close votes queue 684 744tags merged 14 0tag synonyms proposed 9 0tag synonyms created 10 0revisions redacted 1 0questions unprotected 0 2questions reopened 19 0questions protected 1 38questions migrated 47 0questions merged 2 0questions flagged⁵ 2 534questions closed 215 65question flags handled⁵ 273 263posts unlocked 0 11posts undeleted 10 45posts locked 1 101posts deleted⁶ 213 899posts bumped 0 910comments undeleted 9 0comments flagged 1 1362comments deleted⁷ 1567 1116comment flags handled 1223 140answers flagged 4 502answer flags handled 384 122all comments post moved chat 5 0 footnotes ¹ community refers without automated systems otherwise known ² system suspend users three circumstances user recreated previously suspended user recreated destroyed spam abuse network wide suspension effect account ³ destroyed user deleted along posted questions answers comments ⁴ counts every review submitted skipped 2 suggested edits reviews needed approve edit would count 2 goal indicate frequency moderation actions also applies flags etc ⁵ includes close flags close reopen votes ⁶ ignores numerous deletions happen automatically response action ⁷ includes comments deleted authors also account number handled comment flags reading wanna see numbers changed time posted similar report last year also check peruse wishing happy new year
1,"<p>Given that the IBM logo disappeared from our website, I suspect that <a href=""https://ai.meta.stackexchange.com/q/1404/2444"">IBM no longer sponsors us</a>. Meanwhile, CrossValidated is now sponsored by <a href=""https://stats.meta.stackexchange.com/q/5833/82135"">AWS (machine learning)</a>. Are we still sponsored by IBM? If not, why not? Anyway, this sponsorship does not seem to have been beneficial to us. We need a more effective way of attracting experts.</p>
",AImeta,given ibm logo disappeared website suspect meanwhile crossvalidated sponsored still sponsored ibm anyway sponsorship seem beneficial us need effective way attracting experts
1,"<p>In stack overflow there is a couple community bots that aims to help moderation by automatically flagging posts with the stack exchange API, like <a href=""https://stackoverflow.blog/2019/09/17/meet-the-bots-that-help-moderate-stack-overflow/"">this</a>. Is bots like this used in artificial intelligence stack exchange currently? </p>

<p>If one decided to create a bot for accelerating moderation by flagging duplicates and off-topic questions, is that specifically allowed in the website? A bot that helps to automatically flag questions and duplicates may help a lot in removing and noticing unwanted posts and answers, and with a machine learning algorithm one can classify it to a very high degree of accuracy.</p>

<p>Related questions:</p>

<p><a href=""https://meta.stackexchange.com/q/299383/544012"">Would more-heavily involved moderation bots be beneficial to Stack Exchange?</a></p>

<p><a href=""https://meta.stackexchange.com/q/261172/544012"">Present and future of bots on Stack Exchange</a></p>
",AImeta,stack overflow couple community bots aims help moderation automatically flagging posts stack exchange api like bots like used artificial intelligence stack exchange currently one decided create bot accelerating moderation flagging duplicates topic questions specifically allowed website bot helps automatically flag questions duplicates may help lot removing noticing unwanted posts answers machine learning algorithm one classify high degree accuracy related questions
1,"<p>Yes, <a href=""https://charcoal-se.org/#whats-smokey"" rel=""nofollow noreferrer"">SmokeDetector</a> is active on Artificial Intelligence as well, and it's <a href=""https://meta.stackexchange.com/q/291301/295232"">automatically flagging posts</a> of which it's 99.75% sure it's spam. Fortunately, Artificial Intelligence <a href=""https://metasmoke.erwaysoftware.com/sites/dash?utf8=%E2%9C%93&amp;site_id=322&amp;months=12&amp;tab=all"" rel=""nofollow noreferrer"">doesn't see as much spam as the rest of the network</a>, and only 117 flags have been cast last year. Most (all?) other bots in that blog post are tuned towards Stack Overflow content and can't be ported directly to Artificial Intelligence, though some of them might be after some adjustments.</p>

<blockquote>
  <p>If one decided to create a bot for accelerating moderation by flagging duplicates and off-topic questions, is that specifically allowed in the website? A bot that helps to automatically flag questions and duplicates may help a lot in removing and noticing unwanted posts and answers</p>
</blockquote>

<p>Yes, that is allowed, as long as you don't do anything stupid. You need to be reasonably sure the flag accuracy is at least as high as the average human user (which is about 95% IIRC). If you get flag banned because of a bad algorithm, that's your own problem.</p>

<blockquote>
  <p>and with a machine learning algorithm one can classify it to a very high degree of accuracy.</p>
</blockquote>

<p>Well ... that might surprise you. SmokeDetector relies heavily on old-school regexes. We've tried a few times to classify spam based on machine learning, and we got nowhere near the 95% mark, let alone the 99.75% needed for autoflagging. (That percentage is so high because validated spam flags carry a heavy penalty.) Determining off-topic and duplicate questions looks even more challenging to me, but I hope you can surprise us.</p>
",AImeta,yes active artificial intelligence well 9975 sure spam fortunately artificial intelligence 117 flags cast last year bots blog post tuned towards stack overflow content ported directly artificial intelligence though might adjustments one decided create bot accelerating moderation flagging duplicates topic questions specifically allowed website bot helps automatically flag questions duplicates may help lot removing noticing unwanted posts answers yes allowed long anything stupid need reasonably sure flag accuracy least high average human user 95 iirc get flag banned bad algorithm problem machine learning algorithm one classify high degree accuracy well might surprise smokedetector relies heavily old school regexes tried times classify spam based machine learning got nowhere near 95 mark let alone 9975 needed autoflagging percentage high validated spam flags carry heavy penalty determining topic duplicate questions looks even challenging hope surprise us
1,"<p>Quoting <a href=""https://ai.meta.stackexchange.com/questions/1404/something-new-coming-to-the-artificial-intelligence-stack-exchange?noredirect=1#comment3202_1404"">this comment</a> by Stack Exchange's Director of New Community Development, Robert Cartaino:</p>

<blockquote>
  <p>The IBM sponsorship has concluded, but AWS has signed on to take over later this year! We are currently finalizing the materials needed and it should go live when everything is completed.</p>
</blockquote>

<p>According to the <a href=""https://web.archive.org/web/20200114103020/https://ai.stackexchange.com/"" rel=""nofollow noreferrer"">Wayback Machine</a>, the logo started to show somewhere between January 10th and 14th.</p>
",AImeta,quoting stack exchange director new community development robert cartaino ibm sponsorship concluded aws signed take later year currently finalizing materials needed go live everything completed according logo started show somewhere january 10th 14th
1,"<p>When viewing this site (main or meta) in my main browser, there is an empty 'SPONSORED BY' label just under the top bar:</p>

<p><a href=""https://i.stack.imgur.com/VzK3w.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VzK3w.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/UIsyY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UIsyY.png"" alt=""enter image description here""></a></p>

<p>When viewing in another browser, the AWS logo is showing correctly:</p>

<p><a href=""https://i.stack.imgur.com/aNhyH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aNhyH.png"" alt=""enter image description here""></a></p>
",AImeta,viewing site main meta main browser empty isponsored label top bar viewing another browser aws logo showing correctly
1,"<p><a href=""https://ai.meta.stackexchange.com/questions/1636/empty-sponsored-by-label-under-top-bar-aws-logo-not-shown#comment3208_1636"">Catija's hunch</a> was right: the logo is blocked by uBlock, since it's a link to ad.doubleclick.net.</p>

<p>I <em>would</em> have checked that, if I hadn't seen the AWS logo on <a href=""https://stats.stackexchange.com/"">Cross Validated</a> a few weeks ago. But right now it's not showing there either. I guess the ad link is important enough (in terms of revenue, or just part of the sponsorship contract) to keep it, so I'm no longer considering it a <a href=""https://ai.stackexchange.com/questions/tagged/bug"" class=""post-tag"" title=""show questions tagged &#39;bug&#39;"" rel=""tag"">bug</a>.</p>
",AImeta,right logo blocked ublock since link addoubleclicknet would checked seen aws logo weeks ago right showing either guess ad link important enough terms revenue part sponsorship contract keep longer considering
1,"<p>There seems to be a disconnect on the 'Tour' page about what is and isn't on topic here. Quoting directly from the about text (emphasis mine):</p>

<blockquote>
  <p>Artificial Intelligence Stack Exchange is a question and answer site for people interested in AI theory, <strong>mathematics</strong>, research, discovery, <strong>design</strong>, <strong>development</strong>, practice, embedded uses, cognition, policy, and impact. It's built and run by you as part of the Stack Exchange network of Q&amp;A sites. With your help, we're working together to build a library of detailed answers to every question about artificial intelligence.</p>
</blockquote>

<p>But then further down the page it has a ""Don't ask about"" section that includes:</p>

<blockquote>
  <p>Programming of artificial intelligence or machine learning</p>
</blockquote>

<p>If I hadn't read further down the page to the dont ask about section, I would think that programming and code is on topic here. Mathematics, design and development could easily be misinterpreted as: I'm designing an AI to fit this data set, but I'm getting poor results using keras how can I devlope this model to be better?</p>

<p>(This isn't a complaint, just trying to help the site)</p>
",AImeta,seems disconnect notour page topic quoting directly text emphasis mine artificial intelligence stack exchange question answer site people interested ai theory mathematics research discovery design development practice embedded uses cognition policy impact built run part stack exchange network q sites help working together build library detailed answers every question artificial intelligence page ask section includes programming artificial intelligence machine learning read page nt ask section would think programming code topic mathematics design development could easily misinterpreted designing ai fit data set getting poor results using keras devlope model better complaint trying help site
1,"<p>This issue has been discussed several times in the past. AFAIK, initially,  this site wasn't meant to accept machine learning, statistics and programming questions (because that's already covered by other sites), but machine learning questions have been asked on this site for a long time and, given that they are considered part of AI, they are certainly considered on-topic now. However, not all implementation- or programming-related questions are on-topic here. I've proposed a <a href=""https://ai.meta.stackexchange.com/a/1616/2444"">new description for the on-topic page</a>, which also attempts to explain which programming questions can be on-topic here, even though this is still a grey area, honestly. See <a href=""https://ai.meta.stackexchange.com/q/1615/2444"">What should the on-topic page look like?</a>. My proposal has now become the <a href=""https://ai.stackexchange.com/help/on-topic"">new on-topic page</a>. I suggest you carefully read and follow it.</p>
",AImeta,issue discussed several times past afaik initially site meant accept machine learning statistics programming questions already covered sites machine learning questions asked site long time given considered part ai certainly considered topic however implementation programming related questions topic proposed also attempts explain programming questions topic even though still grey area honestly see proposal become suggest carefully read follow
1,"<p>The 2020 Community Moderator Election is now underway!</p>

<p>Community moderator elections have three phases:</p>

<ol>
<li>Nomination phase</li>
<li>Primary phase</li>
<li>Election phase</li>
</ol>

<p>Most elections take between two and three weeks, but this depends on how many candidates there are.</p>

<p>Please visit the official election page at</p>

<p><a href=""https://ai.stackexchange.com/election"">https://ai.stackexchange.com/election</a></p>

<p>for more detail, and to participate!</p>

<p>If you have general questions about the election process, or questions for moderator candidates, feel free to ask them here on meta -- just make sure your questions are tagged <a href=""/questions/tagged/election"" class=""post-tag"" title=""show questions tagged &#39;election&#39;"" rel=""tag"">election</a>.</p>
",AImeta,2020 community moderator election underway community moderator elections three phases nomination phase primary phase election phase elections take two three weeks depends many candidates please visit official election page detail participate general questions election process questions moderator candidates feel free ask meta make sure questions tagged
1,"<p>Artificial Intelligence's <a href=""https://ai.stackexchange.com/election/1"">first moderator election</a> has come to a close, the votes have been tallied and the two new moderators are:</p>
<p><a href=""https://ai.stackexchange.com/users/2444/nbro""><img src=""https://ai.stackexchange.com/users/flair/2444.png"" alt=""nbro"" /></a> <a href=""https://ai.stackexchange.com/users/16909/john-doucette""><img src=""https://ai.stackexchange.com/users/flair/16909.png"" alt=""John Doucette"" /></a></p>
<p>They'll be joining <a href=""https://ai.stackexchange.com/users?tab=moderators"">the existing crew</a> shortly—please thank them for volunteering, and share your assistance and advice with them as they learn the ropes!</p>
<p>For details on how the voting played out, you can download the election results <a href=""https://ai.stackexchange.com/election/1"">here</a>, or <a href=""https://www.opavote.com/results/4701123745153024/0"" rel=""nofollow noreferrer"">view a summary report online</a>.</p>
<hr />
<p>More hands ended up being needed, so the Community Team reached out to the top runner up in this election — let's welcome them to the team too:</p>
<p><a href=""https://ai.stackexchange.com/users/1641/nbro""><img src=""https://ai.stackexchange.com/users/flair/1641.png"" alt=""Dennis Soemers"" /></a></p>
",AImeta,artificial intelligence come close votes tallied two new moderators joining shortly please thank volunteering share assistance advice learn ropes details voting played download election results hands ended needed community team reached top runner election let welcome team
1,"<p>I am really flattered by this opportunity and vote of confidence! I will try to do my best, in collaboration with the other moderators and community members! Feel free to ping me in <a href=""https://chat.stackexchange.com/rooms/43371/the-singularity"">our main chat room</a> and I will try to answer as soon as possible. Hopefully, our community will continue to grow in quantity but especially in quality!</p>
",AImeta,really flattered opportunity vote confidence try best collaboration moderators community members feel free ping try answer soon possible hopefully community continue grow quantity especially quality
1,"<p>Having a look at different <a href=""https://stackexchange.com/sites#name"">sites</a> of Stack Exchage, it feels like <strong>Computer Vision</strong> page is really missing!</p>

<p>There obviously exists almost relevant pages, such as <a href=""https://ai.stackexchange.com/"">AI</a>, <a href=""https://robotics.stackexchange.com/"">Robotics</a>, <a href=""https://dsp.stackexchange.com/"">Signal Processing</a>, <a href=""https://computergraphics.stackexchange.com/"">Computer Graphics</a> and <a href=""https://stackoverflow.com/"">stack overflow</a> in which people can ask questions.</p>

<p>Why does not Stack Exchange make one specific page for researchers or anyone with interests in the area of Computer Vision? </p>

<p>Is there any particular reason or is it more of multidisciplinary subjects according to the founder of Stack Exchange?</p>
",AImeta,look different stack exchage feels like computer vision page really missing obviously exists almost relevant pages people ask questions stack exchange make one specific page researchers anyone interests area computer vision particular reason multidisciplinary subjects according founder stack exchange
1,"<blockquote>
  <p>Why does not Stack Exchange make one specific page for researchers or anyone with interests in the area of Computer Vision?</p>
</blockquote>

<p>Apparently, there was a proposal for a computer vision SE site, but <a href=""https://stats.meta.stackexchange.com/a/2799/82135"">the proposal was deleted</a> because of low activity. In general, if there aren't enough users interested in the topic and enough activity, the site will not be created.</p>

<p>Computer vision is clearly an AI topic, so, in general, any theoretical CV question is on-topic here. See <a href=""https://ai.stackexchange.com/questions/tagged/computer-vision"">all our CV questions</a>.</p>

<p>Signal Processing SE is also an appropriate site to ask CV questions. In fact, in the past, I've asked some questions there. <a href=""https://stats.stackexchange.com/tags"">Stats SE</a> may also be an appropriate site to ask your question.</p>

<p>See also <a href=""https://stats.meta.stackexchange.com/q/2794/82135"">Stack Exchange site to ask questions about computer vision?</a>.</p>
",AImeta,stack exchange make one specific page researchers anyone interests area computer vision apparently proposal computer vision se site low activity general enough users interested topic enough activity site created computer vision clearly ai topic general theoretical cv question topic see signal processing se also appropriate site ask cv questions fact past asked questions may also appropriate site ask question see also
1,"<p>As part of comment In one of my posts or flaggings, I mentioned machine learning instead of data mining. There is no excuse for my wrong posting or flagging. Is this the reason that my posts are no longer accepted or the reason for my timed suspension in many sites including the AI site?</p>
",AImeta,part comment one posts flaggings mentioned machine learning instead data mining excuse wrong posting flagging reason posts longer accepted reason timed suspension many sites including ai site
1,"<p>No, this is not the reason. The reason is that you create posts whose content is off-topic. Please, see <a href=""https://ai.stackexchange.com/help/on-topic"">our on-topic page</a>. Please, read it very carefully (especially, the notes)! If something is unclear there, please, let me know or ask another meta-question.</p>
",AImeta,reason reason create posts whose content topic please see please read carefully especially notes something unclear please let know ask another meta question
1,"<p>More than one year ago, a question was asked here in order to define the new description for our site <a href=""https://ai.meta.stackexchange.com/q/1430/2444"">What should the AI.SE Site Description be?</a>. I think it's time to possibly revise the description of the site after having updated <a href=""https://ai.stackexchange.com/help/on-topic"">the on-topic page</a> (based on the most upvoted answer to <a href=""https://ai.meta.stackexchange.com/q/1615/2444"">this question</a>). The most upvoted answer, after a reasonable amount of time (1-2 weeks) will be used as the new description for our site. So, please, vote for the answer that contains the most next appropriate description of the site or the answer that says that the current description is good enough.</p>
",AImeta,one year ago question asked order define new description site think time possibly revise description site updated based upvoted answer upvoted answer reasonable amount time 1 2 weeks used new description site please vote answer contains next appropriate description site answer says current description good enough
1,"<p>I believe that the current description of the site does not highlight certain important aspects of the site (e.g. AI history) and it contains redundant or noisy information. </p>

<p>In the current description of the site, the topics that I believe are redundant or noisy are</p>

<ul>
<li>mathematics (theory)</li>
<li>discovery (theory/development), </li>
<li>design (theory/development), </li>
<li>practice (development), </li>
<li>embedded uses (development), </li>
<li>cognition (theory)</li>
<li>policy (social)</li>
<li>impact  (social)</li>
</ul>

<p>So, here's my initial new proposal (based on the current first paragraph of the <a href=""https://ai.stackexchange.com/help/on-topic"">new on-topic page</a>).</p>

<blockquote>
  <p>Artificial Intelligence Stack Exchange is a question and answer site for people interested in the <strong>theoretical</strong> (including mathematical), <strong>philosophical, social, historical</strong>, and <em>certain</em> developmental and academic aspects of artificial intelligence.</p>
</blockquote>

<p>Maybe we could also explicitly mention ""research""?</p>
",AImeta,believe current description site highlight certain important aspects site eg ai history contains redundant noisy information current description site topics believe redundant noisy mathematics theory discovery theory development design theory development practice development embedded uses development cognition theory policy social impact social initial new proposal based current first paragraph artificial intelligence stack exchange question answer site people interested theoretical including mathematical philosophical social historical certain developmental academic aspects artificial intelligence maybe could also explicitly mention research
1,"<p>I have been editing many posts in order to correct language mistakes, clarify the post and question, and to make the titles as much descriptive of the actual problem or question as possible. In this post, I will focus on the importance of creating posts with descriptive titles. </p>

<p>The title needs to be descriptive and suggestive of the actual problem or question because it provides the first impression and information to the readers, which may or not decide to read the post depending on the title.</p>

<p>For example, let's consider the following post: <a href=""https://ai.stackexchange.com/q/18712/2444"">Why is my derivation of the back-propagation equations inconsistent with Andrew Ng&#39;s slides from Coursera?</a>. The current title of this post is already quite descriptive, after my last edit. However, the original title of this post was ""Derivation vs Coding of derivation(numpy) in deep learning"", which is quite vague and not suggestive. 
The current title suggests that the problem is related to the back-propagation algorithm and Andrew Ng's material from Coursera and that there's an inconsistency between different derivations of equations. So, someone reading up the titles of questions, while looking for some interesting posts to answer, can already decide whether they will or not potentially be able to answer the question (or maybe get the information that they need, if they are looking for help). In this case, if you are familiar with the back-propagation algorithm and the math and maybe if you have followed Andrew Ng's course, you will probably be able to answer the question, so you may decide to click on the post. </p>

<p>To conclude, a good post usually has a descriptive (but not necessarily very long) title of the actual problem or question. If you cannot summarise well your problem in the title, then you probably need to understand better your problem before asking a question. Furthermore, if you have multiple questions, then you probably cannot create a post with a descriptive title of those multiple questions and problems, so this is a clear sign that you should create multiple posts, one for each of the questions or problems, as suggested in <a href=""https://ai.stackexchange.com/help/on-topic"">our on-topic page</a>. So, I encourage our regular users and editors to edit the posts so that they follow this simple guideline. </p>

<p>Any comments?</p>
",AImeta,editing many posts order correct language mistakes clarify post question make titles much descriptive actual problem question possible post focus importance creating posts descriptive titles title needs descriptive suggestive actual problem question provides first impression information readers may decide read post depending title example let consider following post current title post already quite descriptive last edit however original title post derivation vs coding derivationnumpy deep learning quite vague suggestive current title suggests problem related back propagation algorithm andrew ng material coursera inconsistency different derivations equations someone reading titles questions looking interesting posts answer already decide whether potentially able answer question maybe get information need looking help case familiar back propagation algorithm math maybe followed andrew ng course probably able answer question may decide click post conclude good post usually descriptive necessarily long title actual problem question summarise well problem title probably need understand better problem asking question furthermore multiple questions probably create post descriptive title multiple questions problems clear sign create multiple posts one questions problems suggested encourage regular users editors edit posts follow simple guideline comments
1,"<p>I am writing this post to announce the existence of three new chat rooms: </p>

<ul>
<li><a href=""https://chat.stackexchange.com/rooms/106639/agi"">AGI</a> (exclusively dedicated to artificial general intelligence)</li>
<li><a href=""https://chat.stackexchange.com/rooms/106641/rl"">RL</a> (exclusively dedicated to reinforcement learning)</li>
<li><a href=""https://chat.stackexchange.com/rooms/106655/colt"">COLT</a> (exclusively dedicated to computational learning theory)</li>
</ul>

<p>Although our site is relatively small compared to many other Stack Exchange sites, the idea is to promote the discussion of these fundamental (to our site) topics, as well as the diffusion of high-quality resources and information dedicated to them.</p>

<p>Both chat rooms already have several RSS feeds associated with them. Some of them do not really provide high-quality content, so I am considering their removal. Specifically, I am considering the removal of the RSS feeds associated with Reddit, which often do not provide high-quality content.</p>

<p>Feel free to suggest below more RSS feeds (that provide high-quality content) that could potentially be added to these chat rooms. I am currently considering the addition of the RSS feed associated with DeepMind's blog (which has already been added to <a href=""https://chat.stackexchange.com/rooms/43371/the-singularity"">our main chat room</a>) to both chat rooms, although the blog isn't completely dedicated to these topics.</p>
",AImeta,writing post announce existence three new chat rooms exclusively dedicated artificial general intelligence exclusively dedicated reinforcement learning exclusively dedicated computational learning theory although site relatively small compared many stack exchange sites idea promote discussion fundamental site topics well diffusion high quality resources information dedicated chat rooms already several rss feeds associated really provide high quality content considering removal specifically considering removal rss feeds associated reddit often provide high quality content feel free suggest rss feeds provide high quality content could potentially added chat rooms currently considering addition rss feed associated deepmind blog already added chat rooms although blog completely dedicated topics
1,"<p>Artificial intelligence is very related to <a href=""https://plato.stanford.edu/entries/cognitive-science/"" rel=""nofollow noreferrer"">cognitive science</a>, but which questions related to cognitive science should be on- or off-topic here? Which questions are more appropriate for our site and which ones are more appropriate for e.g. for <a href=""https://psychology.stackexchange.com/"">https://psychology.stackexchange.com/</a>?</p>

<p>I am looking for answers from people that are studying or have studied cognitive science and that can provide some insights.</p>
",AImeta,artificial intelligence related questions related cognitive science topic questions appropriate site ones appropriate eg looking answers people studying studied cognitive science provide insights
1,"<p>Similarly to <a href=""https://ai.meta.stackexchange.com/q/1654/2444"">On the importance of descriptive and informative titles for posts</a>, in this post, I will motivate the importance of regularly voting (both upvoting and downvoting).</p>

<p>Since I've been elected (by you) a moderator of this community (about 1 month ago), I've noticed that only a few people regularly vote (either up- or down-vote). For example, only 8 people have apparently cast an upvote or downvote during this month (and half of them are the usual suspects). You can see the statistics <a href=""https://ai.stackexchange.com/users?tab=voters"">here</a>. </p>

<p>Now, if you look at <a href=""https://area51.stackexchange.com/proposals/93481/artificial-intelligence"">these other statistics of our site</a>, you will see that we currently have more than 3k visits <strong>per day</strong>, 467 avid users and 30,504 total users. We also have more than 10 questions per day. </p>

<p>Our statistics are generally looking good (and I think they have been improving), but not all of them. For example, only 67% of the questions are answered. Why? This can be due to different reasons. For example, maybe our community needs to be even bigger or maybe most of the visitors are only interested in reading, rather than asking or answering questions. However, I think that one important reason why these statistics are still not perfect can be due to the fact that especially regular and avid users are not voting enough. </p>

<p>I acknowledge that not all questions are interesting (to everyone) or relevant and that certain answers are also not awesome, but I think that votes shouldn't just be cast in those cases, but also to assess the correctness of an answer or the clarity or general quality of a question. </p>

<p>Everyone has its own reasons to be on a Stack Exchange site (in particular, AI SE). One of those reasons is probably to learn more (either by asking or trying to answer a question) and the other is that you feel empowered (in my opinion) by your peers when you receive an upvote and, when you receive a downvote, hopefully, it's an indication that you need to improve (although, often, this can also mean that someone simply doesn't agree with you, etc., etc., but I don't want to dwell on these corner cases). Voting is one of our fuels that allows us to prosper and grow. If we don't regularly do that, the community can stagnate and we don't encourage especially new users to keep visiting our site. </p>

<p>Now, do <strong>not</strong> go around and start randomly upvoting or downvoting! You should first make sure that the question or answer is good enough for an upvote, according to your knowledge, which implies that you should first read the post. However, if you do <strong>not</strong> have a good knowledge of the topic, I strongly discourage you to cast a vote, because that vote can be misleading. Maybe this is also one of the reasons many people don't cast votes, but I still think that many people often don't vote only because they are lazy, they forget about the voting system or maybe they vote only when they see excellent answers that show them new insights. Again, no, votes should ALSO be used to assess the quality and correctness of the post, and not just its originality or interestingness. Of course, we expect more original and interesting questions to receive more votes. </p>

<p>Finally, although concluding a post with this may look pessimistic, I want to stress out that you should also downvote when an answer is incorrect or question is unclear, etc.</p>

<p>See also <a href=""https://ai.meta.stackexchange.com/q/62/2444"">Vote Early, Vote Often!</a> (from more than 3 years ago).</p>
",AImeta,similarly post motivate importance regularly voting upvoting downvoting since elected moderator community 1 month ago noticed people regularly vote either vote example 8 people apparently cast upvote downvote month half usual suspects see statistics look see currently 3k visits per day 467 avid users 30504 total users also 10 questions per day statistics generally looking good think improving example 67 questions answered due different reasons example maybe community needs even bigger maybe visitors interested reading rather asking answering questions however think one important reason statistics still perfect due fact especially regular avid users voting enough acknowledge questions interesting everyone relevant certain answers also awesome think votes cast cases also assess correctness answer clarity general quality question everyone reasons stack exchange site particular ai se one reasons probably learn either asking trying answer question feel empowered opinion peers receive upvote receive downvote hopefully indication need improve although often also mean someone simply agree etc etc want dwell corner cases voting one fuels allows us prosper grow regularly community stagnate encourage especially new users keep visiting site go around start randomly upvoting downvoting first make sure question answer good enough upvote according knowledge implies first read post however good knowledge topic strongly discourage cast vote vote misleading maybe also one reasons many people cast votes still think many people often vote lazy forget voting system maybe vote see excellent answers show new insights votes also used assess quality correctness post originality interestingness course expect original interesting questions receive votes finally although concluding post may look pessimistic want stress also downvote answer incorrect question unclear etc see also 3 years ago
1,"<p>After <a href=""https://ai.meta.stackexchange.com/q/1636/2444"">Empty &#39;SPONSORED BY&#39; label under top bar - AWS logo not shown</a>, the ""sponsored by"" has completely disappeared from the site. Are we still sponsored by AWS or anyone?</p>
",AImeta,sponsored completely disappeared site still sponsored aws anyone
1,"<p>Essentially, because voting activity on SE:AI is still sub-optimal, it's rare for a question to recieve 5 close votes from the community.  </p>

<p>(Here the community refers to non-moderators--mods can close at will.)</p>

<p>I personally like this because it's better when closures represent the will of the community, as opposed to the will of an individual moderator, in all but exception cases where the question or answer clearly causes harm.</p>

<p>Note: I only feel comfortable proposing this b/c members of our community tend to adhere to the ""be nice"" policy, and are generally seeking to help the OP by asking for more clarity.</p>
",AImeta,essentially voting activity se ai still sub optimal rare question recieve 5 close votes community community refers non moderators mods close personally like better closures represent community opposed individual moderator exception cases question answer clearly causes harm note feel comfortable proposing b c members community tend adhere nice policy generally seeking help op asking clarity
1,"<p>This tag is used by staff when sharing concepts in the Discovery phase relating to product or configuration changes. In most cases a direction and/or goal has been established, and there has likely been some amount of time invested into discovery work and research. The post is being presented to the Community for feedback to be taken into consideration. Where possible, the post includes specific questions to help guide Community feedback.</p>
",AImeta,tag used staff sharing concepts discovery phase relating product configuration changes cases direction andor goal established likely amount time invested discovery work research post presented community feedback taken consideration possible post includes specific questions help guide community feedback
1,Indicates that the post shares product or configuration change concepts during the Discovery phase. Open to receiving feedback from the Community preceding implementation.,AImeta,indicates post shares product configuration change concepts discovery phase open receiving feedback community preceding implementation
1,"<p>We've had a recent spam attack that resulted in an overwhelming number of links to medium articles, blogs, and other unreliable information sources.</p>
<p>(We're asking users to be extra vigilant until we can get this cleaned up--<strong>please flag any spam like content for moderator deletion.</strong>)</p>
<p>We've also added two important new guidelines in our <a href=""https://ai.stackexchange.com/help/on-topic"">on-topic page</a>:</p>
<blockquote>
<p>Answers with cut-and-paste content and no additional context or explanation will be deleted, even if you cite the source &amp; provide a link. We encourage citation from reliable sources, but answerers are expected to (at least) describe in their own words the reason for the excerpt, and why it answers or comments on the question.</p>
<p>Don't post content to primarily promote yourself, blogs, articles, or source code. StackExchange is a Q&amp;A site, where good questions ideally receive more than one well founded answer.</p>
</blockquote>
",AImeta,recent spam attack resulted overwhelming number links medium articles blogs unreliable information sources asking users extra vigilant get cleaned please flag spam like content moderator deletion also added two important new guidelines answers cut paste content additional context explanation deleted even cite source provide link encourage citation reliable sources answerers expected least describe words reason excerpt answers comments question post content primarily promote blogs articles source code stackexchange q site good questions ideally receive one well founded answer
1,"<p>ai.meta.stackexchange.com is (correctly) showing that I have no badges.</p>

<p>It suggests ""Take the Tour and earn your first badge"".</p>

<p>I do that, and it says I've been awarded a badge.</p>

<p>But when I go back to the original page, it still says I have no badges and still suggests ""Take the Tour and earn your first badge"".</p>

<p>Is something broken here?</p>

<p>UPDATE:</p>

<p>As far as I know, the ""meta"" sites don't normally even offer a tour, much less keep insisting on it.</p>

<p>But now that I've submitted this question, the original problem has of course gone away and I've been awarded a ""student"" badge.</p>

<p>However, unlike all the other sites, I haven't been automatically awarded a ""biographer"" badge.  (E.g. expatriots.meta or travel.meta)</p>

<p>I really don't care about the badges themselves, but something unusual is happening on this site.</p>
",AImeta,aimetastackexchangecom correctly showing badges suggests take tour earn first badge says awarded badge go back original page still says badges still suggests take tour earn first badge something broken update far know meta sites normally even offer tour much less keep insisting submitted question original problem course gone away awarded student badge however unlike sites automatically awarded biographer badge eg expatriotsmeta travelmeta really care badges something unusual happening site
1,"<p>The ""sponsored by"" is gone, for now, because the site sponsorship is currently paused.</p>

<p>While we don't have a set date yet for the sponsorship to return, current conversations with AWS point to relaunching in early Q3, though the date isn't locked in yet.</p>
",AImeta,sponsored gone site sponsorship currently paused set date yet sponsorship return current conversations aws point relaunching early q3 though date locked yet
1,"<p>I came across this <a href=""https://ai.stackexchange.com/questions/123/does-the-chinese-room-argument-hold-against-ai"">question</a> about Chinese Room argument. I was reading a book where the author tries a different way to disprove CR argument. My point is the question:</p>

<blockquote>
  <p>Does the Chinese room argument hold? Can we argue that artificial intelligence is merely clever algorithmics?</p>
</blockquote>

<p>can generate opinionated answers based on the field one is expert in. A mathematician might treat the problem in a different way compared to a neurobio/psychology person. Should such questions remain open?</p>
",AImeta,came across chinese room argument reading book author tries different way disprove cr argument point question chinese room argument hold argue artificial intelligence merely clever algorithmics generate opinionated answers based field one expert mathematician might treat problem different way compared neurobio psychology person questions remain open
1,"<blockquote>
  <p>Should such questions remain open?</p>
</blockquote>

<p>Yes. The CR argument is probably the most famous argument in the philosophy of artificial intelligence. It's about the meaning of intelligence, imitation and understanding. The typical bad answer to this question is one where someone just says ""yes"" or ""no"" without providing a rational explanation or considering previous debates, discussions, and philosophical positions on the topic.</p>

<p>In general, philosophical questions related to AI are on-topic on our site, as <a href=""https://ai.stackexchange.com/help/on-topic"">our on-topic page</a> explicitly says. </p>

<p>Questions that are considered opinion-based are e.g.</p>

<ul>
<li>Which book <em>do you think</em> is <em>the best</em> (for task X)?</li>
<li><em>Do you think</em> that AI will take over the world?</li>
</ul>

<p>All questions that ask explicitly for opinions (e.g. that start like ""What do you think...""?), rather than for an objective answer, are opinion-based, and you should flag them to be closed as such. </p>

<p>Sometimes, certain opinion-based questions can be rephrased. For example, the question ""What is the best tool to solve task X given constraints Y?"" could be rephrased as ""What are some available tools to solve...?"", which would be more acceptable. </p>

<p>The question above ""Do you think that AI will take over the world?"" could also be ""saved"", if rephrased differently. For example, we could ask instead </p>

<blockquote>
  <p>What are the existing arguments of real philosophers about the topic 'AI takeover'? Why do they think it will happen or not?</p>
</blockquote>

<p>These questions can lead to more useful answers, where users will need to refer to existing philosophical work rather than providing their own opinion based on their possibly wrong intuition. (Btw, I don't think this question has already been asked, so feel free to ask it!)</p>

<p>As a rule of thumb, avoid term/expressions such as</p>

<ul>
<li>Do you think...?</li>
<li>What is <em>the best</em>...? </li>
<li>Do you like...?</li>
</ul>
",AImeta,questions remain open yes cr argument probably famous argument philosophy artificial intelligence meaning intelligence imitation understanding typical bad answer question one someone says yes without providing rational explanation considering previous debates discussions philosophical positions topic general philosophical questions related ai topic site explicitly says questions considered opinion based eg book think best task x think ai take world questions ask explicitly opinions eg start like think rather objective answer opinion based flag closed sometimes certain opinion based questions rephrased example question best tool solve task x given constraints could rephrased available tools solve would acceptable question think ai take world could also saved rephrased differently example could ask instead existing arguments real philosophers topic ai takeover think happen questions lead useful answers users need refer existing philosophical work rather providing opinion based possibly wrong intuition btw think question already asked feel free ask rule thumb avoid term expressions think best like
1,"<p>My take is that it's a philosophical question, and all philosophy outside of formal logic is essentially opinion, just that those opinions have to be well founded and well argued.  (i.e. without logical falacies.)</p>

<p>This particular question yielded several solid answers that make the point that the Chinese Room Argument is highly subjective, and assumes some special quality of human cognition (which has not yet been proved, only speculated on.)</p>
",AImeta,take philosophical question philosophy outside formal logic essentially opinion opinions well founded well argued ie without logical falacies particular question yielded several solid answers make point chinese room argument highly subjective assumes special quality human cognition yet proved speculated
1,"<p>These tags seem to be effectively interchangeable for all questions I've seen them used in. Should they be merged?</p>

<p>(Note: I agree <a href=""https://ai.stackexchange.com/questions/tagged/graph-neural-networks"" class=""post-tag"" title=""show questions tagged &#39;graph-neural-networks&#39;"" rel=""tag"">graph-neural-networks</a> should remain distinct.)</p>
",AImeta,tags seem effectively interchangeable questions seen used merged note agree remain distinct
1,"<p>Can we ask questions about deep learning model recommendations/suggestions like which model to choose or for any reference links??</p>
",AImeta,ask questions deep learning model recommendations suggestions like model choose reference links
1,"<p>Yes, but do not use the words <em>recommendation</em> or <em>suggestion</em> in your questions. Avoid words that can lead to opinions and try to ask questions that can be answered objectively and that are as much specific as possible, i.e. ask for facts or evidence.</p>

<p>For example, the question ""Which model <em>should</em> I use for object detection?"" is not very specific, and can lead to opinions (because you're using ""should""). There are many models for object detection. You should at least describe which objects you want to detect (and, in general, your dataset), and why you're asking for a reference model to use: haven't you found one already by searching the web? If yes, share it with us, and explain why you think it's not ""good enough"". A better way of rephrasing that question would be </p>

<blockquote>
  <p>Which models are more likely to perform well on this specific problem X with this data Y? I have found models Z and W, but, given that I am not very familiar with them, I don't know which one is more appropriate for my scenario.</p>
</blockquote>

<p>or something like that.</p>

<p>You can also ask for references (paper, books, articles), but, again, try to be specific and explain your problem well and why are you looking for a reference.</p>
",AImeta,yes use words recommendation suggestion questions avoid words lead opinions try ask questions answered objectively much specific possible ie ask facts evidence example question model use object detection specific lead opinions using many models object detection least describe objects want detect general dataset asking reference model use found one already searching web yes share us explain think good enough better way rephrasing question would models likely perform well specific problem x data found models z w given familiar know one appropriate scenario something like also ask references paper books articles try specific explain problem well looking reference
1,"<p>Can we ask for an intuitive explanation of models, algorithms, and topics related to Artificial Intelligence and Deep Learning?</p>
",AImeta,ask intuitive explanation models algorithms topics related artificial intelligence deep learning
1,"<p>Yes, you can ask for an intuitive explanation of a model, algorithm or, in general, topic. Just make sure that you clarify in your post what exactly you are looking for.</p>

<p>For example, if you're looking for an intuitive explanation of how a u-net works, you should ask</p>

<blockquote>
  <p><strong>Intuitively</strong>, how does u-net work? What are the main ideas behind this model?</p>
</blockquote>

<p>If you just ask </p>

<blockquote>
  <p>How does u-net work?</p>
</blockquote>

<p>a person could think that you are looking for a detailed explanation (and that could even considered a too broad post). Alternatively, if you are (also) looking for a detailed explanation, you may (also) ask for a reference that explains the topic in detail.</p>

<p>Moreover, before asking a question, you should probably do a little bit of research on your own, then explain WHAT you haven't understood in the sources that you have researched/read so far (maybe you should also cite the sources that you have read).</p>
",AImeta,yes ask intuitive explanation model algorithm general topic make sure clarify post exactly looking example looking intuitive explanation u net works ask intuitively u net work main ideas behind model ask u net work person could think looking detailed explanation could even considered broad post alternatively also looking detailed explanation may also ask reference explains topic detail moreover asking question probably little bit research explain understood sources researched read far maybe also cite sources read
1,"<p>From Sutton and Barto's book Reinforcement Learning (Adaptive Computation and Machine Learning series), the following definition is given for Q-Learning :</p>
<p><a href=""https://i.stack.imgur.com/6rEPb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6rEPb.png"" alt=""enter image description here"" /></a></p>
<p>I', planning to ask a question in combining the above algorithm with policy gradient learning but I'm struggling to format it correctly with MathJax. Here is what I have so far which looks awful in comparison to above algorithm:</p>
<p><span class=""math-container"">$$
Algorithm \hspace{1mm} parameters: step size \hspace{1mm} \alpha \in (0 , 1] , \epsilon &gt; 0 \\
Initialize \hspace{1mm} Q \hspace{1mm} ( s, a ), \  \forall s \in S^+ , a \in A ( s ), arbitrarily \hspace{1mm} except \hspace{1mm} that \hspace{1mm} Q ( terminal , . ) = 0 \\
Loop \hspace{1mm} for \hspace{1mm} each \hspace{1mm} step \hspace{1mm} of \hspace{1mm} episode: \\
Choose \hspace{1mm} A \hspace{1mm} from \hspace{1mm} S \hspace{1mm} using  \hspace{1mm} some \hspace{1mm} policy  \hspace{1mm} derived  \hspace{1mm} from  \hspace{1mm} Q (eg  \hspace{1mm} \epsilon  \hspace{1mm} greedy)
$$</span></p>
<p>Can some pointers in writing out RL algorithms with MathJax be shared ?  Ideally can my mathjax code be amended such that it renders the same output as above Q-Learning algorithm (in image) ?</p>
<p>Is mathjax being used in this site or some other math notation rendering library ?</p>
",AImeta,sutton barto book reinforcement learning adaptive computation machine learning series following definition given q learning planning ask question combining algorithm policy gradient learning struggling format correctly mathjax far looks awful comparison algorithm algorithm hspace1 mm parameters step size hspace1 mm alpha 0 1 epsilon 0 initialize hspace1 mm q hspace1 mm forall arbitrarily hspace1 mm except hspace1 mm hspace1 mm q terminal 0 loop hspace1 mm hspace1 mm hspace1 mm step hspace1 mm hspace1 mm episode choose hspace1 mm hspace1 mm hspace1 mm hspace1 mm using hspace1 mm hspace1 mm policy hspace1 mm derived hspace1 mm hspace1 mm q eg hspace1 mm epsilon hspace1 mm greedy pointers writing rl algorithms mathjax shared ideally mathjax code amended renders output q learning algorithm image mathjax used site math notation rendering library
1,"<p>Don't use MathJax unless you need to. Here are some hacks to do formatting like this:</p>
<ul>
<li><p>Blockquotes (<code>&gt;</code>). Useful for marking out a block of text as different, without doing much additional formatting to them.</p>
</li>
<li><p>Inline MathJax. You can enclose MathJax in <code>$</code> to make it render in line (ie. not on a seperate, centered line. eg. <code>$\alpha$</code> gives <span class=""math-container"">$\alpha$</span></p>
</li>
<li><p>Indenting. Number of ways to achieve this. <code>$\quad$</code> (and similar) might be most familiar to you, but piles of unbreakable spaces (<code>&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;</code>) also works as a hack-y way to do this.</p>
</li>
<li><p>Linebreaks. You can do linebreaks by having multiple spaces at the end of a line, or using the html tag <code>&lt;br/&gt;</code></p>
</li>
</ul>
<p>To see it in action with your specific example:</p>
<blockquote>
<p>Algorithm parameters: step size  <span class=""math-container"">$\alpha \in (0 , 1] , \epsilon &gt; 0$</span><br />
Initialize  <span class=""math-container"">$Q  ( s, a ), \  \forall s \in S^+ , a \in A ( s ),$</span> arbitrarily except that <span class=""math-container"">$Q ( terminal , \cdot ) = 0$</span></p>
<p>Loop for each episode:<br />
<span class=""math-container"">$\quad$</span>Initialize <span class=""math-container"">$S$</span><br />
<span class=""math-container"">$\quad$</span>Loop  for  each  step  of  episode:<br />
<span class=""math-container"">$\qquad$</span>Choose  <span class=""math-container"">$A$</span> from <span class=""math-container"">$S$</span> using some policy derived from <span class=""math-container"">$Q$</span> (eg <span class=""math-container"">$\epsilon$</span>-greedy)<br />
<span class=""math-container"">$\qquad$</span>Take action <span class=""math-container"">$A$</span>, observe <span class=""math-container"">$R, S'$</span><br />
<span class=""math-container"">$\qquad Q(S,A) \leftarrow Q(S,A) + \alpha[R+\gamma \max_a(S', a) - Q(S, A)]$</span><br />
<span class=""math-container"">$\qquad S \leftarrow S'$</span><br />
<span class=""math-container"">$\quad$</span> until <span class=""math-container"">$S$</span> is terminal</p>
</blockquote>
<p>Which is produced from:</p>
<pre><code>&gt; Algorithm parameters: step size  $\alpha \in (0 , 1] , \epsilon &gt; 0$   
Initialize  $Q  ( s, a ), \  \forall s \in S^+ , a \in A ( s ),$ arbitrarily except that $Q ( terminal , \cdot ) = 0$    
&gt;
&gt; Loop for each episode:  
$\quad$Initialize $S$   
$\quad$Loop  for  each  step  of  episode:    
$\qquad$Choose  $A$ from $S$ using some policy derived from $Q$ (eg $\epsilon$-greedy)   
$\qquad$Take action $A$, observe $R, S'$   
$\qquad Q(S,A) \leftarrow Q(S,A) + \alpha[R+\gamma \max_a(S', a) - Q(S, A)]$   
$\qquad S \leftarrow S'$    
$\quad$ until $S$ is terminal
</code></pre>
",AImeta,use mathjax unless need hacks formatting like blockquotes useful marking block text different without much additional formatting inline mathjax enclose mathjax make render line ie seperate centered line eg gives alpha indenting number ways achieve similar might familiar piles unbreakable spaces also works hack way linebreaks linebreaks multiple spaces end line using html tag see action specific example algorithm parameters step size alpha 0 1 epsilon 0 initialize q forall arbitrarily except q terminal cdot 0 loop episode quad initialize quad loop step episode qquad choose using policy derived q eg epsilon greedy qquad take action observe r qquad qs leftarrow qs alphargamma max_as qs qquad leftarrow quad terminal produced 0 initialize q forall arbitrarily except q terminal cdot 0 loop episode quadinitialize quadloop step episode qquadchoose using policy derived q eg epsilongreedy qquadtake action observe r qquad qs leftarrow qs alphargamma max_as qs qquad leftarrow quad terminal
1,"<p>It's been only a few months since I was elected (by you) a moderator of <a href=""https://ai.stackexchange.com/"">Artificial Intelligence Stack Exchange</a>, but the time has come to step down for several reasons</p>
<ol>
<li><p>I was suspended on <a href=""https://stats.stackexchange.com/"">Stats SE</a> for having left the following comment under some of the questions there.</p>
<blockquote>
<p>Please, ask this question on <a href=""https://ai.stackexchange.com/"">Artificial Intelligence Stack Exchange</a>, which is a more appropriate site to ask theoretical questions related to reinforcement learning. If you ask it there, please, delete it from here.</p>
</blockquote>
<p>The excuse of the other moderators (from other SE sites) is that I was disruptive and that RL is also on-topic on Stats SE. It is true that RL is also on-topic on Stats SE. However, no matter what your position/opinion is (i.e. if you think I was disruptive or not), from my perspective, this was unnecessary (i.e. not a sufficiently good reason to suspend me) and thus disrespectful.</p>
</li>
<li><p>Most other moderators (from other SE sites, not our own site) don't seem to like me because of my direct personality (as some of you probably have already experienced), and they continually attack me and pretend that I am the black sheep of the group. Of course, this situation is at least discouraging and realistically unacceptable for me to continue to moderate a SE site.</p>
</li>
<li><p>I spent too much time and effort on this site. I tried to make our community a better place (hopefully, I was able to achieve my goal to some extent), but I understand now that I can't solve all the problems alone. If the community does not want to build a better place, I can't do it either. So, from now on, it's up to you.</p>
<p>(NOTE: of course, this third point is not really a reason to step down and it wasn't really a reason why I stepped down. I wanted to say that it's important that all community members (at least the regular ones) help to maintain the site by flagging content, editing posts, etc., without the need for moderators to intervene. That's not the main job of a moderator, although a moderator can and should also do it, whenever this is required. It's up to all of us, including myself and other moderators, to make this place a better place! If you don't know how you can contribute to the site, please, <a href=""https://ai.meta.stackexchange.com/q/1686/2444"">read this post</a>)</p>
</li>
</ol>
<p>I am sorry that I will basically leave you alone, given that the other moderators have been rarely active recently, but it's the best thing for me now.</p>
",AImeta,months since elected moderator time come step several reasons suspended left following comment questions please ask question appropriate site ask theoretical questions related reinforcement learning ask please delete excuse moderators se sites disruptive rl also topic stats se true rl also topic stats se however matter position opinion ie think disruptive perspective unnecessary ie sufficiently good reason suspend thus disrespectful moderators se sites site seem like direct personality probably already experienced continually attack pretend black sheep group course situation least discouraging realistically unacceptable continue moderate se site spent much time effort site tried make community better place hopefully able achieve goal extent understand solve problems alone community want build better place either note course third point really reason step really reason stepped wanted say important community members least regular ones help maintain site flagging content editing posts etc without need moderators intervene main job moderator although moderator also whenever required us including moderators make place better place know contribute site please sorry basically leave alone given moderators rarely active recently best thing
1,"<blockquote>
<p>I spent too much time and effort on this site. I tried to make our community a better place (hopefully, I was able to achieve my goal to some extent), but I understand now that I can't solve all the problems alone. If the community does not want to build a better place, I can't do it either. So, from now on, it's up to you.</p>
</blockquote>
<p>I've certainly noticed your efforts having had a visible, positive impact on the site. In particular your frequent editing for clarification, and retagging, have been clearly visible. As you mentioned yourself in the comments though, these kinds of things are not strictly responsbilities for only moderators, and you could in theory continue contributing to the site in these kinds of way even after stepping down. Is this something that you still see yourself doing with some level of activity (even if less than before)? Of course it's important that you only do this if you feel like it, noone should feel pressured to remain active on the site if they don't want.</p>
",AImeta,spent much time effort site tried make community better place hopefully able achieve goal extent understand solve problems alone community want build better place either certainly noticed efforts visible positive impact site particular frequent editing clarification retagging clearly visible mentioned comments though kinds things strictly responsbilities moderators could theory continue contributing site kinds way even stepping something still see level activity even less course important feel like noone feel pressured remain active site want
1,"<p>Can we ask questions about programming questions on Pytorch, TensorFlow, or any deep learning frameworks??</p>
",AImeta,ask questions programming questions pytorch tensorflow deep learning frameworks
1,"<p>No.</p>
<p>General programming issues are off-topic here. For example, if you have an exception/bug/error in your source code or you don't know how to use a certain library/API, then that's off-topic. If you have this type of question, the most appropriate site is probably Stack Overflow (or Data Science SE).</p>
<p>However, if you want to understand how a certain concept/algorithm/model is implemented, then you can ask questions about that because that's more a conceptual question. <a href=""https://ai.stackexchange.com/q/20803/2444"">Here is an example of such a question</a>. (But, please, try to ask a specific and clear question that explains what you don't really understand, so that to facilitate the answerer's life).</p>
<p><a href=""https://ai.stackexchange.com/help/on-topic"">Our on-topic page</a> actually states these things explicitly, so I suggest that you read or at least skim through our on-topic page again.</p>
",AImeta,general programming issues topic example exception bug error source code know use certain library api topic type question appropriate site probably stack overflow data science se however want understand certain concept algorithm model implemented ask questions conceptual question please try ask specific clear question explains really understand facilitate answerer life actually states things explicitly suggest read least skim topic page
1,"<p>I'm personally in favor of this, but the overall consensus is that we should focus on theory, as opposed to implementation.</p>
<p>(We haven't historically had good response to programming or implementation questions, so the argument for leaving those to overflow and other stacks is strong.)</p>
",AImeta,personally favor overall consensus focus theory opposed implementation historically good response programming implementation questions argument leaving overflow stacks strong
1,"<p>After <a href=""https://ai.meta.stackexchange.com/q/1681/2444"">I have stepped down as a moderator</a> (at least, temporarily, i.e. I don't know yet if I will come back as a moderator later), one user asked me how a user/visitor can contribute to the site and help to maintain it. So, I decided to create this meta-post that hopefully will guide you.</p>
<p>There are different ways to help the community and the site, apart from asking interesting questions (that nobody has yet asked) and providing high-quality answers (have a look at <a href=""https://cstheory.meta.stackexchange.com/q/300"">this post</a>, which gives you some information about what a good question is). I will try to be concise so that you can more easily memorize the main points.</p>
<ol>
<li><p>Get familiar with our <a href=""https://ai.stackexchange.com/help/on-topic"">on-topic page</a>. It's been updated recently (during this year) after a reasonable consensus. However, if something is unclear or you don't agree with something, please, ask a meta-question, so that we can all address that issue.</p>
</li>
<li><p>Edit posts (questions or answers) to improve them (in any possible way, e.g. to improve the titles, to correct mistakes, to improve the readability, to use more appropriate tags, etc.). I have written <a href=""https://ai.meta.stackexchange.com/q/1654/2444"">this post</a> that hopefully will convince you of the importance of descriptive titles.</p>
</li>
<li><p>Flag content that is off-topic or inconsistent with the <a href=""https://ai.stackexchange.com/help/on-topic"">on-topic page</a>. This not only includes flagging posts (questions or answers), but comments too. In general, useless comments should be flagged for deletion; in fact, comments are generally meant to be temporary; if you have an answer (that you think is good enough), write it formally, and not as a comment.</p>
</li>
<li><p>Vote (either up or down)! <a href=""https://ai.meta.stackexchange.com/q/1660/2444"">Here</a> is a post that motivates the importance of voting. Please, read it!</p>
</li>
<li><p>If you see an unclear question or answer, ask for clarification below that post. Try to be nice (especially with new users)!</p>
</li>
<li><p>It's perfectly fine to read old posts and apply the previous four suggestions.</p>
</li>
<li><p>If you have access to <a href=""https://ai.stackexchange.com/review"">the <em>rewiew queues</em></a>, have a look at them from time to time. Please, read <a href=""https://ai.stackexchange.com/help/privileges/access-review-queues"">this article</a> for more info.</p>
</li>
<li><p>Visit <a href=""https://chat.stackexchange.com/rooms/43371/the-singularity"">our main chat room</a> and connect with other people!</p>
</li>
<li><p>If you have a friend that is interested in artificial intelligence, talk to him about this site! We need more experts or experienced users, but also people that are new to AI that ask interesting questions.</p>
</li>
<li><p>Participate in meta (here) more regularly. Meta should be used to raise the issues with the main site. If you see an issue, ask a question, or share it with us.</p>
</li>
<li><p>There are posts that have not yet been updated to use latex, so you may want to do that. <a href=""https://ai.meta.stackexchange.com/a/1319/2444"">Here</a> is a list of them.</p>
</li>
</ol>
<p>(If you see other ways of helping the site, feel free to edit this post or leave a comment below).</p>
",AImeta,least temporarily ie know yet come back moderator later one user asked user visitor contribute site help maintain decided create meta post hopefully guide different ways help community site apart asking interesting questions nobody yet asked providing high quality answers look gives information good question try concise easily memorize main points get familiar updated recently year reasonable consensus however something unclear agree something please ask meta question address issue edit posts questions answers improve possible way eg improve titles correct mistakes improve readability use appropriate tags etc written hopefully convince importance descriptive titles flag content topic inconsistent includes flagging posts questions answers comments general useless comments flagged deletion fact comments generally meant temporary answer think good enough write formally comment vote either post motivates importance voting please read see unclear question answer ask clarification post try nice especially new users perfectly fine read old posts apply previous four suggestions access look time time please read info visit connect people friend interested artificial intelligence talk site need experts experienced users also people new ai ask interesting questions participate meta regularly meta used raise issues main site see issue ask question share us posts yet updated use latex may want list see ways helping site feel free edit post leave comment
1,"<p>Editing tags is also always welcome (and I think you get a little rep for it.)</p>
<p><em>Note: We do require reliable references for tag info.</em></p>
<hr />
<p>Also, Vote!  THat's our method of vetting information, so more vote is always better.  Also incentivizes quality contributors and disincentivizes low quality content.</p>
",AImeta,editing tags also always welcome think get little rep note require reliable references tag info also vote method vetting information vote always better also incentivizes quality contributors disincentivizes low quality content
1,"<p>Congratulations to our new moderator, Dennis! He has a very good overall knowledge of the AI field, he's patient, and he's been around for a long time, which shows that he cares about this community. I think he will be a good moderator (if he remains at least as active as he has been)!</p>
",AImeta,congratulations new moderator dennis good overall knowledge ai field patient around long time shows cares community think good moderator remains least active
1,"<p>Seems AWS came back up in the &quot;Sponsored by&quot; section recently, this is what it looks like right now:</p>
<p><a href=""https://i.stack.imgur.com/zv8hA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zv8hA.png"" alt=""enter image description here"" /></a></p>
",AImeta,seems aws came back section recently looks like right
